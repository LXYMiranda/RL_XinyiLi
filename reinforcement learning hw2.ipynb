{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.3\n"
     ]
    }
   ],
   "source": [
    "# set the environment of the game\n",
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     #os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the environment of the game\n",
    "env = gym.make('CartPole-v0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the training hyperparameters\n",
    "\n",
    "state_size = 4 # our input is an observation with four elements\n",
    "action_size = env.action_space.n  # number of actions (push to left or push to right)\n",
    "possible_actions = np.identity(2, dtype = int).tolist()\n",
    "\n",
    "\n",
    "# training hyperparameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "number_epoch = 500 # number of epochs for training\n",
    "batch_size = 1000 # defines number of samples work though\n",
    "\n",
    "training = True \n",
    "hidden_size_1 = 53\n",
    "hidden_size_2 = 34\n",
    "\n",
    "max_steps = 200 # Max steps per episode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the discounted some of reward from current step onward\n",
    "def discount_rewards(r, gamma = 0.95, normalization = False):\n",
    "    discounted_r = np.zeros_like(r) #make a vector of zeros with the size of input\n",
    "    running_add = 0\n",
    "    for t in reversed(range(0, len(r))):\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "        \n",
    "    if normalization: # do normalization for reward to have more smooth gradient\n",
    "        mean = np.mean(discounted_r)\n",
    "        std = np.std(discounted_r)\n",
    "        discounted_r = (discounted_r - mean)/(std)\n",
    "        \n",
    "    return discounted_r \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the policy network \n",
    "\n",
    "class PGNetwork():\n",
    "    def __init__(self, state_size, action_size, learning_rate, hidden_size_1, hidden_size_2, name = 'PGNetwork'):\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "     \n",
    "        \n",
    "        # generate a network such that with a given state, the policy gives an action\n",
    "        with tf.variable_scope(name):\n",
    "            with tf.name_scope('inputs'):\n",
    "            # we create placeholder\n",
    "                self.inputs = tf.placeholder(tf.float32, shape = [None, state_size], name = 'inputs')\n",
    "                self.actions = tf.placeholder(tf.int32, shape = [None, action_size], name = 'actions')\n",
    "                self.discounted_episode_rewards = tf.placeholder(tf.float32, shape = [None, ], name = 'discounted_episode_rewards')\n",
    "            \n",
    "            # CNN is often used for image process, because here we are not dealing with image, we use general fully connected layers\n",
    "            with tf.name_scope('layer1'):\n",
    "                # filters gives the number of filters in the hidden nn\n",
    "                self.layer1 = tf.contrib.layers.fully_connected(inputs = self.inputs,\n",
    "                                             num_outputs = self.hidden_size_1,\n",
    "                                             activation_fn = tf.nn.elu,\n",
    "                                             weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                                       \n",
    "\n",
    "            with tf.name_scope('layer2'):\n",
    "                # filters gives the number of filters in the hidden nn\n",
    "                self.layer2 = tf.contrib.layers.fully_connected(inputs = self.layer1,\n",
    "                                             num_outputs = self.hidden_size_2,   \n",
    "                                             activation_fn = tf.nn.elu,\n",
    "                                             weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    " \n",
    "            with tf.name_scope('logits'):\n",
    "                # get the action distribution from the fully connected NN\n",
    "                self.logits = tf.layers.dense(inputs = self.layer2,\n",
    "                                             kernel_initializer = tf.contrib.layers.xavier_initializer(),      \n",
    "                                             units = self.action_size, \n",
    "                                             activation = None)\n",
    "                \n",
    "            with tf.name_scope('softmax'):\n",
    "                self.action_distribution = tf.nn.softmax(self.logits)\n",
    "                \n",
    "            # define the loss function\n",
    "            with tf.name_scope('loss'):\n",
    "                self.cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = self.logits, labels = self.actions)\n",
    "                #self.log_action_probability = tf.nn.softmax_cross_entropy_with_logits(logits = self.outputlayer, labels = self.actions)\n",
    "                self.weighted_likelihoods = tf.multiply(self.cross_entropy, self.discounted_episode_rewards)\n",
    "                self.loss = tf.reduce_mean(self.weighted_likelihoods)\n",
    "                \n",
    "            with tf.name_scope('train'):\n",
    "                self.optimizer = tf.train.AdamOptimizer(self.learning_rate,  beta1=0.9, beta2=0.99)\n",
    "                self.train_opt = self.optimizer.minimize(self.loss)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value estimator network\n",
    "class VENetwork():\n",
    "    def __init__(self, state_size, learning_rate,  name = 'VENetwork'):\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.output_size = 1\n",
    "        self.learning_rate = learning_rate\n",
    "        self.hidden_size_1 = 16\n",
    "        #self.hidden_size_2 = hidden_size_2\n",
    "     \n",
    "        \n",
    "        # generate a network such that with a given state, the policy gives an action\n",
    "        with tf.variable_scope(name):\n",
    "            with tf.name_scope('inputs'):\n",
    "            # we create placeholder\n",
    "                self.inputs = tf.placeholder(tf.float32, shape = [None, state_size], name = 'inputs')\n",
    "                self.discounted_episode_rewards = tf.placeholder(tf.float32, shape = [None, ], name = 'discounted_episode_rewards')\n",
    "            \n",
    "            # CNN is often used for image process, because here we are not dealing with image, we use general fully connected layers\n",
    "            with tf.name_scope('layer1'):\n",
    "                # filters gives the number of filters in the convolution nn\n",
    "                self.layer1 = tf.contrib.layers.fully_connected(inputs = self.inputs,\n",
    "                                             num_outputs = self.hidden_size_1,\n",
    "                                             activation_fn = tf.nn.elu,\n",
    "                                             weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                                       \n",
    "            \n",
    "            #with tf.name_scope('layer2'):\n",
    "                # filters gives the number of filters in the convolution nn\n",
    "            #    self.layer2 = tf.contrib.layers.fully_connected(inputs = self.layer1,\n",
    "            #                                 num_outputs = self.hidden_size_2,   \n",
    "            #                                 activation_fn = tf.nn.elu,\n",
    "            #                                 weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                \n",
    "             \n",
    "            with tf.name_scope('output'):\n",
    "                # get the action distribution from the fully connected NN\n",
    "                self.output_layer = tf.layers.dense(inputs = self.layer1,\n",
    "                                             kernel_initializer = tf.contrib.layers.xavier_initializer(),      \n",
    "                                             units = self.output_size, \n",
    "                                             activation = None)\n",
    "                \n",
    "                self.state_value_estimation = tf.squeeze(self.output_layer)\n",
    "                \n",
    "            # define the loss function\n",
    "            with tf.name_scope('loss'):\n",
    "\n",
    "                self.loss = tf.reduce_mean(tf.squared_difference(self.state_value_estimation, self.discounted_episode_rewards))\n",
    "                \n",
    "            with tf.name_scope('train'):\n",
    "                self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "                self.train_opt = self.optimizer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the environment \n",
    "# initialize network and session\n",
    "tf.reset_default_graph()\n",
    "PGN = PGNetwork(state_size, action_size, learning_rate, hidden_size_1, hidden_size_2)\n",
    "VEN = VENetwork(state_size, learning_rate)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the policy until it reached maximum batch number and outputs information of each step (batch number)\n",
    "# for each episode\n",
    "def make_batch(batch_size):\n",
    "    states, actions, rewards_of_episode, rewards_of_batch,rewards_of_episode0, discounted_rewards = [],[],[],[],[],[]\n",
    "    # keep track of how many episodes in our batch (useful when we need to calculate the average reward)\n",
    "    episode_num = 1\n",
    "    # get a new state\n",
    "    state = env.reset()\n",
    "   \n",
    "    while True:\n",
    "        \n",
    "        action_probability_distribution = sess.run(PGN.action_distribution, feed_dict = {PGN.inputs: state.reshape(1, state_size)})\n",
    "        state_value_estimation = sess.run(VEN.state_value_estimation, feed_dict = {VEN.inputs: state.reshape(1, state_size)})\n",
    "        action = np.random.choice(range(action_probability_distribution.shape[1]), p = action_probability_distribution.ravel())\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        action_ = [0,0]\n",
    "        action_[action] = 1\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action_)\n",
    "        rewards_of_episode.append(reward)\n",
    "        rewards_of_episode0.append(reward-state_value_estimation)\n",
    "\n",
    "        if done:\n",
    "            rewards_of_batch.append(rewards_of_episode)\n",
    "    \n",
    "            discounted_rewards.append(discount_rewards(rewards_of_episode0, gamma = 0.95, normalization = True))\n",
    "            \n",
    "            if len(np.concatenate(rewards_of_batch)) > batch_size:\n",
    "                break\n",
    "                \n",
    "            rewards_of_episode = []\n",
    "            rewards_of_episode0 = []\n",
    "            episode_num +=1\n",
    "            \n",
    "            state = env.reset()\n",
    "        else:\n",
    "            state = next_state\n",
    "\n",
    "    return np.stack(np.array(states)), np.stack(np.array(actions)), np.concatenate(rewards_of_batch), np.concatenate(discounted_rewards), episode_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1028,) ()\n",
      "epoch 1\n",
      "====================================\n",
      "Epoch:  1 / 500\n",
      "------------\n",
      "Number of training episodes: 41\n",
      "Total reward:1028.0\n",
      "Mean Reward of that batch 25.073170731707318\n",
      "Average Reward of all training: 25.073170731707318\n",
      "Max reward for a batch so far: 1028.0\n",
      "check 1028.0\n",
      "Training loss:0.0067292326129972935\n",
      "Cross Entropy:[0.6949106  0.71694565 0.69459105 ... 0.7402917  0.67389506 0.642808  ]\n",
      "VE Training loss:1.0363086462020874\n",
      "check (1002,) ()\n",
      "epoch 2\n",
      "====================================\n",
      "Epoch:  2 / 500\n",
      "------------\n",
      "Number of training episodes: 43\n",
      "Total reward:1002.0\n",
      "Mean Reward of that batch 23.302325581395348\n",
      "Average Reward of all training: 24.187748156551333\n",
      "Max reward for a batch so far: 1028.0\n",
      "check 1002.0\n",
      "Training loss:-0.0003793962823692709\n",
      "Cross Entropy:[0.6999422  0.6911365  0.67745197 ... 0.64025176 0.77001095 0.6368575 ]\n",
      "VE Training loss:1.072463870048523\n",
      "check (1011,) ()\n",
      "epoch 3\n",
      "====================================\n",
      "Epoch:  3 / 500\n",
      "------------\n",
      "Number of training episodes: 48\n",
      "Total reward:1011.0\n",
      "Mean Reward of that batch 21.0625\n",
      "Average Reward of all training: 23.145998771034225\n",
      "Max reward for a batch so far: 1028.0\n",
      "check 1011.0\n",
      "Training loss:-0.002989135915413499\n",
      "Cross Entropy:[0.6755411  0.69518006 0.7095911  ... 0.6640363  0.7304095  0.6644502 ]\n",
      "VE Training loss:1.0195958614349365\n",
      "check (1005,) ()\n",
      "epoch 4\n",
      "====================================\n",
      "Epoch:  4 / 500\n",
      "------------\n",
      "Number of training episodes: 43\n",
      "Total reward:1005.0\n",
      "Mean Reward of that batch 23.372093023255815\n",
      "Average Reward of all training: 23.202522334089622\n",
      "Max reward for a batch so far: 1028.0\n",
      "check 1005.0\n",
      "Training loss:-0.0058892229571938515\n",
      "Cross Entropy:[0.72507614 0.6400087  0.6604171  ... 0.65505373 0.7047475  0.7483453 ]\n",
      "VE Training loss:1.0464246273040771\n",
      "check (1039,) ()\n",
      "epoch 5\n",
      "====================================\n",
      "Epoch:  5 / 500\n",
      "------------\n",
      "Number of training episodes: 36\n",
      "Total reward:1039.0\n",
      "Mean Reward of that batch 28.86111111111111\n",
      "Average Reward of all training: 24.33424008949392\n",
      "Max reward for a batch so far: 1039.0\n",
      "check 1039.0\n",
      "Training loss:-0.005285268649458885\n",
      "Cross Entropy:[0.73637974 0.78045857 0.8154522  ... 0.9852551  0.42223802 0.4485439 ]\n",
      "VE Training loss:0.9953294992446899\n",
      "check (1015,) ()\n",
      "epoch 6\n",
      "====================================\n",
      "Epoch:  6 / 500\n",
      "------------\n",
      "Number of training episodes: 40\n",
      "Total reward:1015.0\n",
      "Mean Reward of that batch 25.375\n",
      "Average Reward of all training: 24.507700074578267\n",
      "Max reward for a batch so far: 1039.0\n",
      "check 1015.0\n",
      "Training loss:-0.011245783418416977\n",
      "Cross Entropy:[0.64345306 0.6803995  0.74810314 ... 0.68804383 0.76845336 0.55319184]\n",
      "VE Training loss:0.9774361252784729\n",
      "check (1046,) ()\n",
      "epoch 7\n",
      "====================================\n",
      "Epoch:  7 / 500\n",
      "------------\n",
      "Number of training episodes: 37\n",
      "Total reward:1046.0\n",
      "Mean Reward of that batch 28.27027027027027\n",
      "Average Reward of all training: 25.045210102534266\n",
      "Max reward for a batch so far: 1046.0\n",
      "check 1046.0\n",
      "Training loss:-0.017646515741944313\n",
      "Cross Entropy:[0.63495535 0.7130682  0.79498655 ... 0.47297737 0.5250648  0.8178832 ]\n",
      "VE Training loss:1.0369199514389038\n",
      "check (1093,) ()\n",
      "epoch 8\n",
      "====================================\n",
      "Epoch:  8 / 500\n",
      "------------\n",
      "Number of training episodes: 32\n",
      "Total reward:1093.0\n",
      "Mean Reward of that batch 34.15625\n",
      "Average Reward of all training: 26.184090089717486\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1093.0\n",
      "Training loss:-0.01163424551486969\n",
      "Cross Entropy:[0.7605613  0.8571414  0.49160132 ... 0.71450925 0.82114285 0.49730316]\n",
      "VE Training loss:0.942741334438324\n",
      "check (1004,) ()\n",
      "epoch 9\n",
      "====================================\n",
      "Epoch:  9 / 500\n",
      "------------\n",
      "Number of training episodes: 34\n",
      "Total reward:1004.0\n",
      "Mean Reward of that batch 29.529411764705884\n",
      "Average Reward of all training: 26.55579249804953\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1004.0\n",
      "Training loss:-0.0048752957955002785\n",
      "Cross Entropy:[0.62057424 0.649165   0.76392436 ... 0.9083874  0.43765807 0.4894842 ]\n",
      "VE Training loss:1.0024834871292114\n",
      "check (1003,) ()\n",
      "epoch 10\n",
      "====================================\n",
      "Epoch:  10 / 500\n",
      "------------\n",
      "Number of training episodes: 26\n",
      "Total reward:1003.0\n",
      "Mean Reward of that batch 38.57692307692308\n",
      "Average Reward of all training: 27.757905555936883\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1003.0\n",
      "Training loss:0.001625072443857789\n",
      "Cross Entropy:[0.7891849  0.5003152  0.8000969  ... 0.4532333  0.90665233 0.43047163]\n",
      "VE Training loss:1.1139267683029175\n",
      "Model saved\n",
      "check (1039,) ()\n",
      "epoch 11\n",
      "====================================\n",
      "Epoch:  11 / 500\n",
      "------------\n",
      "Number of training episodes: 30\n",
      "Total reward:1039.0\n",
      "Mean Reward of that batch 34.63333333333333\n",
      "Average Reward of all training: 28.382944444791107\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1039.0\n",
      "Training loss:-0.015378113836050034\n",
      "Cross Entropy:[0.626634   0.76788735 0.91931653 ... 0.7933533  0.9585531  1.1220198 ]\n",
      "VE Training loss:1.0113592147827148\n",
      "check (1019,) ()\n",
      "epoch 12\n",
      "====================================\n",
      "Epoch:  12 / 500\n",
      "------------\n",
      "Number of training episodes: 28\n",
      "Total reward:1019.0\n",
      "Mean Reward of that batch 36.392857142857146\n",
      "Average Reward of all training: 29.050437169629944\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1019.0\n",
      "Training loss:-0.011958065442740917\n",
      "Cross Entropy:[0.78013563 0.48065934 0.5999863  ... 0.80988806 0.9932429  0.36827376]\n",
      "VE Training loss:1.0074574947357178\n",
      "check (1029,) ()\n",
      "epoch 13\n",
      "====================================\n",
      "Epoch:  13 / 500\n",
      "------------\n",
      "Number of training episodes: 30\n",
      "Total reward:1029.0\n",
      "Mean Reward of that batch 34.3\n",
      "Average Reward of all training: 29.454249695043025\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1029.0\n",
      "Training loss:-0.021698057651519775\n",
      "Cross Entropy:[0.79466164 0.46255347 0.8071854  ... 0.31965655 0.3905525  0.4773    ]\n",
      "VE Training loss:1.0306757688522339\n",
      "check (1001,) ()\n",
      "epoch 14\n",
      "====================================\n",
      "Epoch:  14 / 500\n",
      "------------\n",
      "Number of training episodes: 25\n",
      "Total reward:1001.0\n",
      "Mean Reward of that batch 40.04\n",
      "Average Reward of all training: 30.21037471682567\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1001.0\n",
      "Training loss:-0.0023142751306295395\n",
      "Cross Entropy:[0.7884009  1.0023727  0.3513115  ... 0.26976308 1.2494899  0.24560478]\n",
      "VE Training loss:1.0299731492996216\n",
      "check (1005,) ()\n",
      "epoch 15\n",
      "====================================\n",
      "Epoch:  15 / 500\n",
      "------------\n",
      "Number of training episodes: 29\n",
      "Total reward:1005.0\n",
      "Mean Reward of that batch 34.6551724137931\n",
      "Average Reward of all training: 30.506694563290164\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1005.0\n",
      "Training loss:-0.004126252606511116\n",
      "Cross Entropy:[0.83832604 0.41665468 0.8581269  ... 0.6132088  0.7684789  0.49472255]\n",
      "VE Training loss:1.0844825506210327\n",
      "check (1002,) ()\n",
      "epoch 16\n",
      "====================================\n",
      "Epoch:  16 / 500\n",
      "------------\n",
      "Number of training episodes: 28\n",
      "Total reward:1002.0\n",
      "Mean Reward of that batch 35.785714285714285\n",
      "Average Reward of all training: 30.83663329594167\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1002.0\n",
      "Training loss:-0.018133345991373062\n",
      "Cross Entropy:[0.5664643  0.7748143  1.0121028  ... 0.12533909 0.15372089 1.7591764 ]\n",
      "VE Training loss:0.9909431338310242\n",
      "check (1009,) ()\n",
      "epoch 17\n",
      "====================================\n",
      "Epoch:  17 / 500\n",
      "------------\n",
      "Number of training episodes: 20\n",
      "Total reward:1009.0\n",
      "Mean Reward of that batch 50.45\n",
      "Average Reward of all training: 31.99036074912157\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1009.0\n",
      "Training loss:-0.007275128737092018\n",
      "Cross Entropy:[0.60116947 0.5698052  0.7809537  ... 0.2005155  1.4734174  0.1764905 ]\n",
      "VE Training loss:1.123762845993042\n",
      "check (1036,) ()\n",
      "epoch 18\n",
      "====================================\n",
      "Epoch:  18 / 500\n",
      "------------\n",
      "Number of training episodes: 25\n",
      "Total reward:1036.0\n",
      "Mean Reward of that batch 41.44\n",
      "Average Reward of all training: 32.51534070750371\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1036.0\n",
      "Training loss:-0.0070114354602992535\n",
      "Cross Entropy:[0.5740796  0.59305537 0.84141266 ... 1.2150799  0.23313585 0.31185985]\n",
      "VE Training loss:1.041433572769165\n",
      "check (1009,) ()\n",
      "epoch 19\n",
      "====================================\n",
      "Epoch:  19 / 500\n",
      "------------\n",
      "Number of training episodes: 21\n",
      "Total reward:1009.0\n",
      "Mean Reward of that batch 48.04761904761905\n",
      "Average Reward of all training: 33.33282904119399\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1009.0\n",
      "Training loss:0.0009943920886144042\n",
      "Cross Entropy:[0.8437635  0.3835955  0.55490565 ... 0.14007586 0.18856809 0.25433618]\n",
      "VE Training loss:1.0693962574005127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1043,) ()\n",
      "epoch 20\n",
      "====================================\n",
      "Epoch:  20 / 500\n",
      "------------\n",
      "Number of training episodes: 21\n",
      "Total reward:1043.0\n",
      "Mean Reward of that batch 49.666666666666664\n",
      "Average Reward of all training: 34.14952092246762\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1043.0\n",
      "Training loss:-0.0027646103408187628\n",
      "Cross Entropy:[0.58640707 0.5555722  0.59223884 ... 0.76034594 1.1122868  1.5080118 ]\n",
      "VE Training loss:1.0403532981872559\n",
      "Model saved\n",
      "check (1055,) ()\n",
      "epoch 21\n",
      "====================================\n",
      "Epoch:  21 / 500\n",
      "------------\n",
      "Number of training episodes: 23\n",
      "Total reward:1055.0\n",
      "Mean Reward of that batch 45.869565217391305\n",
      "Average Reward of all training: 34.707618269844936\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1055.0\n",
      "Training loss:-0.0026362822391092777\n",
      "Cross Entropy:[0.5280139  0.61956453 0.5116076  ... 0.46530277 0.74461997 0.39985812]\n",
      "VE Training loss:1.1169158220291138\n",
      "check (1024,) ()\n",
      "epoch 22\n",
      "====================================\n",
      "Epoch:  22 / 500\n",
      "------------\n",
      "Number of training episodes: 23\n",
      "Total reward:1024.0\n",
      "Mean Reward of that batch 44.52173913043478\n",
      "Average Reward of all training: 35.15371467259902\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1024.0\n",
      "Training loss:-0.005382616072893143\n",
      "Cross Entropy:[0.858706   0.3656541  0.8444245  ... 0.34576055 0.48536652 0.7162959 ]\n",
      "VE Training loss:1.0447230339050293\n",
      "check (1028,) ()\n",
      "epoch 23\n",
      "====================================\n",
      "Epoch:  23 / 500\n",
      "------------\n",
      "Number of training episodes: 21\n",
      "Total reward:1028.0\n",
      "Mean Reward of that batch 48.95238095238095\n",
      "Average Reward of all training: 35.75365668476345\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1028.0\n",
      "Training loss:0.0004270934732630849\n",
      "Cross Entropy:[0.8921088  0.34720752 0.542279   ... 0.93317646 1.3454082  0.17877778]\n",
      "VE Training loss:1.1261522769927979\n",
      "check (1017,) ()\n",
      "epoch 24\n",
      "====================================\n",
      "Epoch:  24 / 500\n",
      "------------\n",
      "Number of training episodes: 14\n",
      "Total reward:1017.0\n",
      "Mean Reward of that batch 72.64285714285714\n",
      "Average Reward of all training: 37.290706703850695\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1017.0\n",
      "Training loss:-0.00017318800382781774\n",
      "Cross Entropy:[0.8541484  1.1961268  0.23678462 ... 0.43969744 0.6163489  0.5702228 ]\n",
      "VE Training loss:1.1315052509307861\n",
      "check (1063,) ()\n",
      "epoch 25\n",
      "====================================\n",
      "Epoch:  25 / 500\n",
      "------------\n",
      "Number of training episodes: 18\n",
      "Total reward:1063.0\n",
      "Mean Reward of that batch 59.05555555555556\n",
      "Average Reward of all training: 38.161300657918886\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1063.0\n",
      "Training loss:-0.016415784135460854\n",
      "Cross Entropy:[0.5925285  0.5180029  0.60580444 ... 0.3312382  0.9848919  0.27680475]\n",
      "VE Training loss:1.0968098640441895\n",
      "check (1079,) ()\n",
      "epoch 26\n",
      "====================================\n",
      "Epoch:  26 / 500\n",
      "------------\n",
      "Number of training episodes: 18\n",
      "Total reward:1079.0\n",
      "Mean Reward of that batch 59.94444444444444\n",
      "Average Reward of all training: 38.999113880477566\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1079.0\n",
      "Training loss:-0.00903092510998249\n",
      "Cross Entropy:[0.85206586 0.3445826  0.5401264  ... 0.96139157 0.29162905 0.41521642]\n",
      "VE Training loss:1.1050881147384644\n",
      "check (1043,) ()\n",
      "epoch 27\n",
      "====================================\n",
      "Epoch:  27 / 500\n",
      "------------\n",
      "Number of training episodes: 16\n",
      "Total reward:1043.0\n",
      "Mean Reward of that batch 65.1875\n",
      "Average Reward of all training: 39.96905410712654\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1043.0\n",
      "Training loss:-0.01302526704967022\n",
      "Cross Entropy:[0.5634817  0.54225254 0.84517395 ... 2.107562   0.07385062 0.10545358]\n",
      "VE Training loss:1.1541110277175903\n",
      "check (1026,) ()\n",
      "epoch 28\n",
      "====================================\n",
      "Epoch:  28 / 500\n",
      "------------\n",
      "Number of training episodes: 13\n",
      "Total reward:1026.0\n",
      "Mean Reward of that batch 78.92307692307692\n",
      "Average Reward of all training: 41.3602692076962\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1026.0\n",
      "Training loss:-0.025078851729631424\n",
      "Cross Entropy:[0.57413286 0.5220189  0.8110182  ... 0.95271087 1.4349141  0.15188584]\n",
      "VE Training loss:1.0651531219482422\n",
      "check (1081,) ()\n",
      "epoch 29\n",
      "====================================\n",
      "Epoch:  29 / 500\n",
      "------------\n",
      "Number of training episodes: 12\n",
      "Total reward:1081.0\n",
      "Mean Reward of that batch 90.08333333333333\n",
      "Average Reward of all training: 43.040374867200924\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1081.0\n",
      "Training loss:-0.004928320646286011\n",
      "Cross Entropy:[0.58517635 0.5249709  0.84811926 ... 0.16926819 1.5073682  0.13587885]\n",
      "VE Training loss:1.1278448104858398\n",
      "check (1043,) ()\n",
      "epoch 30\n",
      "====================================\n",
      "Epoch:  30 / 500\n",
      "------------\n",
      "Number of training episodes: 14\n",
      "Total reward:1043.0\n",
      "Mean Reward of that batch 74.5\n",
      "Average Reward of all training: 44.08902903829423\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1043.0\n",
      "Training loss:-0.02058829925954342\n",
      "Cross Entropy:[0.863085   0.3242949  0.5174743  ... 1.1288083  0.21610533 1.2908026 ]\n",
      "VE Training loss:1.1885178089141846\n",
      "Model saved\n",
      "check (1032,) ()\n",
      "epoch 31\n",
      "====================================\n",
      "Epoch:  31 / 500\n",
      "------------\n",
      "Number of training episodes: 13\n",
      "Total reward:1032.0\n",
      "Mean Reward of that batch 79.38461538461539\n",
      "Average Reward of all training: 45.22759633978846\n",
      "Max reward for a batch so far: 1093.0\n",
      "check 1032.0\n",
      "Training loss:0.004786591045558453\n",
      "Cross Entropy:[0.5794894  0.9239001  0.3049216  ... 0.58280635 0.5942008  0.948328  ]\n",
      "VE Training loss:1.0450764894485474\n",
      "check (1109,) ()\n",
      "epoch 32\n",
      "====================================\n",
      "Epoch:  32 / 500\n",
      "------------\n",
      "Number of training episodes: 15\n",
      "Total reward:1109.0\n",
      "Mean Reward of that batch 73.93333333333334\n",
      "Average Reward of all training: 46.12465062083673\n",
      "Max reward for a batch so far: 1109.0\n",
      "check 1109.0\n",
      "Training loss:-0.01847977377474308\n",
      "Cross Entropy:[0.67982525 1.0701724  0.24598256 ... 0.6915768  0.51245713 0.7827578 ]\n",
      "VE Training loss:1.0081802606582642\n",
      "check (1030,) ()\n",
      "epoch 33\n",
      "====================================\n",
      "Epoch:  33 / 500\n",
      "------------\n",
      "Number of training episodes: 11\n",
      "Total reward:1030.0\n",
      "Mean Reward of that batch 93.63636363636364\n",
      "Average Reward of all training: 47.56439950009513\n",
      "Max reward for a batch so far: 1109.0\n",
      "check 1030.0\n",
      "Training loss:0.0009411219507455826\n",
      "Cross Entropy:[0.74998707 0.37280187 0.7859436  ... 0.42153692 0.792676   0.33903694]\n",
      "VE Training loss:1.1831694841384888\n",
      "check (1038,) ()\n",
      "epoch 34\n",
      "====================================\n",
      "Epoch:  34 / 500\n",
      "------------\n",
      "Number of training episodes: 11\n",
      "Total reward:1038.0\n",
      "Mean Reward of that batch 94.36363636363636\n",
      "Average Reward of all training: 48.94084764314045\n",
      "Max reward for a batch so far: 1109.0\n",
      "check 1038.0\n",
      "Training loss:-0.017715459689497948\n",
      "Cross Entropy:[0.6221157  0.47414023 0.6042811  ... 0.34892663 0.53166854 0.80234236]\n",
      "VE Training loss:1.225992202758789\n",
      "check (1071,) ()\n",
      "epoch 35\n",
      "====================================\n",
      "Epoch:  35 / 500\n",
      "------------\n",
      "Number of training episodes: 8\n",
      "Total reward:1071.0\n",
      "Mean Reward of that batch 133.875\n",
      "Average Reward of all training: 51.3675377104793\n",
      "Max reward for a batch so far: 1109.0\n",
      "check 1071.0\n",
      "Training loss:-0.016924027353525162\n",
      "Cross Entropy:[0.72274685 0.4019806  0.6805556  ... 0.5255463  0.64607805 0.46514505]\n",
      "VE Training loss:1.0671285390853882\n",
      "check (1118,) ()\n",
      "epoch 36\n",
      "====================================\n",
      "Epoch:  36 / 500\n",
      "------------\n",
      "Number of training episodes: 10\n",
      "Total reward:1118.0\n",
      "Mean Reward of that batch 111.8\n",
      "Average Reward of all training: 53.04621721852154\n",
      "Max reward for a batch so far: 1118.0\n",
      "check 1118.0\n",
      "Training loss:-0.024547109380364418\n",
      "Cross Entropy:[0.6877388  0.42401937 0.6673801  ... 2.0092528  0.08651288 2.1604507 ]\n",
      "VE Training loss:1.0479490756988525\n",
      "check (1006,) ()\n",
      "epoch 37\n",
      "====================================\n",
      "Epoch:  37 / 500\n",
      "------------\n",
      "Number of training episodes: 10\n",
      "Total reward:1006.0\n",
      "Mean Reward of that batch 100.6\n",
      "Average Reward of all training: 54.33145459099393\n",
      "Max reward for a batch so far: 1118.0\n",
      "check 1006.0\n",
      "Training loss:-0.02163056470453739\n",
      "Cross Entropy:[0.7650257  0.3591706  0.80052507 ... 0.19057626 1.4354845  0.15535502]\n",
      "VE Training loss:0.9433929324150085\n",
      "check (1073,) ()\n",
      "epoch 38\n",
      "====================================\n",
      "Epoch:  38 / 500\n",
      "------------\n",
      "Number of training episodes: 10\n",
      "Total reward:1073.0\n",
      "Mean Reward of that batch 107.3\n",
      "Average Reward of all training: 55.72536368070461\n",
      "Max reward for a batch so far: 1118.0\n",
      "check 1073.0\n",
      "Training loss:-0.005532439798116684\n",
      "Cross Entropy:[0.62489706 0.44223747 0.6696638  ... 0.7268891  1.0529742  0.26676875]\n",
      "VE Training loss:1.1276075839996338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1169,) ()\n",
      "epoch 39\n",
      "====================================\n",
      "Epoch:  39 / 500\n",
      "------------\n",
      "Number of training episodes: 11\n",
      "Total reward:1169.0\n",
      "Mean Reward of that batch 106.27272727272727\n",
      "Average Reward of all training: 57.021449926653915\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1169.0\n",
      "Training loss:-0.02011018991470337\n",
      "Cross Entropy:[0.69413507 1.1257586  0.2180802  ... 0.11261839 1.9308714  0.0835974 ]\n",
      "VE Training loss:1.083898901939392\n",
      "check (1046,) ()\n",
      "epoch 40\n",
      "====================================\n",
      "Epoch:  40 / 500\n",
      "------------\n",
      "Number of training episodes: 9\n",
      "Total reward:1046.0\n",
      "Mean Reward of that batch 116.22222222222223\n",
      "Average Reward of all training: 58.501469234043135\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1046.0\n",
      "Training loss:-0.030573656782507896\n",
      "Cross Entropy:[0.7390274 1.1778281 0.2090649 ... 0.4119439 0.6231837 0.9098507]\n",
      "VE Training loss:1.0924530029296875\n",
      "Model saved\n",
      "check (1146,) ()\n",
      "epoch 41\n",
      "====================================\n",
      "Epoch:  41 / 500\n",
      "------------\n",
      "Number of training episodes: 9\n",
      "Total reward:1146.0\n",
      "Mean Reward of that batch 127.33333333333333\n",
      "Average Reward of all training: 60.180295187684365\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1146.0\n",
      "Training loss:-0.0054768468253314495\n",
      "Cross Entropy:[0.5871659  0.9445877  1.3669884  ... 0.10950552 0.17457797 0.27459547]\n",
      "VE Training loss:1.1552326679229736\n",
      "check (1036,) ()\n",
      "epoch 42\n",
      "====================================\n",
      "Epoch:  42 / 500\n",
      "------------\n",
      "Number of training episodes: 8\n",
      "Total reward:1036.0\n",
      "Mean Reward of that batch 129.5\n",
      "Average Reward of all training: 61.83076434988235\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1036.0\n",
      "Training loss:-0.022683987393975258\n",
      "Cross Entropy:[0.66423273 1.0636315  0.24620569 ... 0.05560311 0.07814761 0.1100081 ]\n",
      "VE Training loss:0.9866487979888916\n",
      "check (1011,) ()\n",
      "epoch 43\n",
      "====================================\n",
      "Epoch:  43 / 500\n",
      "------------\n",
      "Number of training episodes: 8\n",
      "Total reward:1011.0\n",
      "Mean Reward of that batch 126.375\n",
      "Average Reward of all training: 63.3317930859316\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1011.0\n",
      "Training loss:-0.0027964843902736902\n",
      "Cross Entropy:[0.6639511  0.4001267  0.6976816  ... 0.7974106  0.34858155 0.9589267 ]\n",
      "VE Training loss:0.9600288271903992\n",
      "check (1033,) ()\n",
      "epoch 44\n",
      "====================================\n",
      "Epoch:  44 / 500\n",
      "------------\n",
      "Number of training episodes: 9\n",
      "Total reward:1033.0\n",
      "Mean Reward of that batch 114.77777777777777\n",
      "Average Reward of all training: 64.50102001074629\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1033.0\n",
      "Training loss:-0.006502772681415081\n",
      "Cross Entropy:[0.80252624 1.2650746  0.18251906 ... 1.2684847  1.8431938  0.08989125]\n",
      "VE Training loss:1.13882577419281\n",
      "check (1113,) ()\n",
      "epoch 45\n",
      "====================================\n",
      "Epoch:  45 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1113.0\n",
      "Mean Reward of that batch 159.0\n",
      "Average Reward of all training: 66.60099734384082\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1113.0\n",
      "Training loss:-0.0043539865873754025\n",
      "Cross Entropy:[0.63527834 0.4229416  0.6133924  ... 0.15856098 0.28374213 0.9365941 ]\n",
      "VE Training loss:1.2110662460327148\n",
      "check (1083,) ()\n",
      "epoch 46\n",
      "====================================\n",
      "Epoch:  46 / 500\n",
      "------------\n",
      "Number of training episodes: 9\n",
      "Total reward:1083.0\n",
      "Mean Reward of that batch 120.33333333333333\n",
      "Average Reward of all training: 67.76909160448196\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1083.0\n",
      "Training loss:-0.005437598098069429\n",
      "Cross Entropy:[0.59794366 0.4310555  0.7887637  ... 0.24167426 1.1495488  0.17010884]\n",
      "VE Training loss:1.1573494672775269\n",
      "check (1110,) ()\n",
      "epoch 47\n",
      "====================================\n",
      "Epoch:  47 / 500\n",
      "------------\n",
      "Number of training episodes: 8\n",
      "Total reward:1110.0\n",
      "Mean Reward of that batch 138.75\n",
      "Average Reward of all training: 69.27932369800362\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1110.0\n",
      "Training loss:-0.010532478801906109\n",
      "Cross Entropy:[0.66224253 1.1585258  0.19337535 ... 0.321889   0.910225   0.22473244]\n",
      "VE Training loss:1.0204704999923706\n",
      "check (1065,) ()\n",
      "epoch 48\n",
      "====================================\n",
      "Epoch:  48 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1065.0\n",
      "Mean Reward of that batch 177.5\n",
      "Average Reward of all training: 71.53392112096186\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1065.0\n",
      "Training loss:-0.005666552111506462\n",
      "Cross Entropy:[0.745142   0.32019424 0.5991502  ... 0.33364877 0.81054527 0.28305596]\n",
      "VE Training loss:1.1294586658477783\n",
      "check (1160,) ()\n",
      "epoch 49\n",
      "====================================\n",
      "Epoch:  49 / 500\n",
      "------------\n",
      "Number of training episodes: 8\n",
      "Total reward:1160.0\n",
      "Mean Reward of that batch 145.0\n",
      "Average Reward of all training: 73.03322885318714\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1160.0\n",
      "Training loss:-0.009497536346316338\n",
      "Cross Entropy:[0.7285914  0.32757765 0.76478297 ... 0.3408701  0.59118575 0.48575664]\n",
      "VE Training loss:1.0239089727401733\n",
      "check (1027,) ()\n",
      "epoch 50\n",
      "====================================\n",
      "Epoch:  50 / 500\n",
      "------------\n",
      "Number of training episodes: 9\n",
      "Total reward:1027.0\n",
      "Mean Reward of that batch 114.11111111111111\n",
      "Average Reward of all training: 73.85478649834562\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1027.0\n",
      "Training loss:-0.007301230449229479\n",
      "Cross Entropy:[0.55539846 1.0184906  0.22731604 ... 0.5928342  0.43813708 0.7164634 ]\n",
      "VE Training loss:1.0867979526519775\n",
      "Model saved\n",
      "check (1020,) ()\n",
      "epoch 51\n",
      "====================================\n",
      "Epoch:  51 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1020.0\n",
      "Mean Reward of that batch 170.0\n",
      "Average Reward of all training: 75.73998676308395\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1020.0\n",
      "Training loss:-0.014405467547476292\n",
      "Cross Entropy:[0.63138735 0.3705108  0.73053914 ... 0.51426375 0.50676227 0.85211754]\n",
      "VE Training loss:1.0827652215957642\n",
      "check (1077,) ()\n",
      "epoch 52\n",
      "====================================\n",
      "Epoch:  52 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1077.0\n",
      "Mean Reward of that batch 153.85714285714286\n",
      "Average Reward of all training: 77.24223976489276\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1077.0\n",
      "Training loss:-0.013290904462337494\n",
      "Cross Entropy:[0.57102454 0.4212555  0.54942894 ... 0.22125521 1.0189166  0.1909364 ]\n",
      "VE Training loss:0.9812272191047668\n",
      "check (1118,) ()\n",
      "epoch 53\n",
      "====================================\n",
      "Epoch:  53 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1118.0\n",
      "Mean Reward of that batch 159.71428571428572\n",
      "Average Reward of all training: 78.79831610356055\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1118.0\n",
      "Training loss:-0.009359902702271938\n",
      "Cross Entropy:[0.70703644 1.2668221  1.9345534  ... 0.13940029 0.22262576 0.34826988]\n",
      "VE Training loss:1.0220715999603271\n",
      "check (1114,) ()\n",
      "epoch 54\n",
      "====================================\n",
      "Epoch:  54 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1114.0\n",
      "Mean Reward of that batch 185.66666666666666\n",
      "Average Reward of all training: 80.77735963250697\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1114.0\n",
      "Training loss:0.00349722383543849\n",
      "Cross Entropy:[0.60405064 0.36131656 0.6457151  ... 0.33623725 0.7523904  0.335291  ]\n",
      "VE Training loss:0.977652907371521\n",
      "check (1043,) ()\n",
      "epoch 55\n",
      "====================================\n",
      "Epoch:  55 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1043.0\n",
      "Mean Reward of that batch 149.0\n",
      "Average Reward of all training: 82.01777127555229\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1043.0\n",
      "Training loss:0.0009668886195868254\n",
      "Cross Entropy:[0.710613   0.314007   0.6967418  ... 0.17812997 0.3540274  0.65412253]\n",
      "VE Training loss:1.06256103515625\n",
      "check (1081,) ()\n",
      "epoch 56\n",
      "====================================\n",
      "Epoch:  56 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1081.0\n",
      "Mean Reward of that batch 154.42857142857142\n",
      "Average Reward of all training: 83.31082127828479\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1081.0\n",
      "Training loss:-0.002749557374045253\n",
      "Cross Entropy:[0.6760332  1.2769861  0.14477777 ... 2.2328322  0.04802041 0.07701373]\n",
      "VE Training loss:0.9899427890777588\n",
      "check (1071,) ()\n",
      "epoch 57\n",
      "====================================\n",
      "Epoch:  57 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1071.0\n",
      "Mean Reward of that batch 153.0\n",
      "Average Reward of all training: 84.5334384488412\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1071.0\n",
      "Training loss:0.003952528350055218\n",
      "Cross Entropy:[0.7599937  0.27580792 0.77971697 ... 0.4994836  0.830498   0.33091468]\n",
      "VE Training loss:0.9968122839927673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1014,) ()\n",
      "epoch 58\n",
      "====================================\n",
      "Epoch:  58 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1014.0\n",
      "Mean Reward of that batch 169.0\n",
      "Average Reward of all training: 85.9897584755853\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1014.0\n",
      "Training loss:-0.013449572958052158\n",
      "Cross Entropy:[0.74079406 1.4036249  0.11906946 ... 0.74270093 0.28399792 0.5489378 ]\n",
      "VE Training loss:1.0092222690582275\n",
      "check (1128,) ()\n",
      "epoch 59\n",
      "====================================\n",
      "Epoch:  59 / 500\n",
      "------------\n",
      "Number of training episodes: 8\n",
      "Total reward:1128.0\n",
      "Mean Reward of that batch 141.0\n",
      "Average Reward of all training: 86.9221354505754\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1128.0\n",
      "Training loss:-0.023851288482546806\n",
      "Cross Entropy:[0.76364595 0.25603956 0.5633168  ... 0.10807535 0.19080973 1.2718754 ]\n",
      "VE Training loss:1.007515549659729\n",
      "check (1143,) ()\n",
      "epoch 60\n",
      "====================================\n",
      "Epoch:  60 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1143.0\n",
      "Mean Reward of that batch 163.28571428571428\n",
      "Average Reward of all training: 88.19486176449438\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1143.0\n",
      "Training loss:0.004159221425652504\n",
      "Cross Entropy:[0.74536407 1.4279135  0.11509345 ... 0.56283927 0.8950048  0.3144602 ]\n",
      "VE Training loss:1.041462779045105\n",
      "Model saved\n",
      "check (1025,) ()\n",
      "epoch 61\n",
      "====================================\n",
      "Epoch:  61 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1025.0\n",
      "Mean Reward of that batch 146.42857142857142\n",
      "Average Reward of all training: 89.149512742594\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1025.0\n",
      "Training loss:-0.01366033311933279\n",
      "Cross Entropy:[0.6299744  1.2526866  0.14168432 ... 0.01251263 0.02292114 0.04294133]\n",
      "VE Training loss:1.0631299018859863\n",
      "check (1143,) ()\n",
      "epoch 62\n",
      "====================================\n",
      "Epoch:  62 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1143.0\n",
      "Mean Reward of that batch 190.5\n",
      "Average Reward of all training: 90.78419802093926\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1143.0\n",
      "Training loss:-0.004243862349539995\n",
      "Cross Entropy:[0.70471776 0.2822255  0.66183496 ... 0.19717331 1.0928247  0.1636039 ]\n",
      "VE Training loss:1.1406244039535522\n",
      "check (1112,) ()\n",
      "epoch 63\n",
      "====================================\n",
      "Epoch:  63 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1112.0\n",
      "Mean Reward of that batch 185.33333333333334\n",
      "Average Reward of all training: 92.28497794653282\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1112.0\n",
      "Training loss:-0.0075647057965397835\n",
      "Cross Entropy:[0.6356802  1.3416425  0.11743774 ... 0.9789705  0.19711156 1.1050658 ]\n",
      "VE Training loss:1.0047144889831543\n",
      "check (1038,) ()\n",
      "epoch 64\n",
      "====================================\n",
      "Epoch:  64 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1038.0\n",
      "Mean Reward of that batch 173.0\n",
      "Average Reward of all training: 93.54615016611822\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1038.0\n",
      "Training loss:0.004330210387706757\n",
      "Cross Entropy:[0.58201486 0.35051277 0.84316844 ... 0.9516307  0.18567528 0.36293036]\n",
      "VE Training loss:0.9688904285430908\n",
      "check (1023,) ()\n",
      "epoch 65\n",
      "====================================\n",
      "Epoch:  65 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1023.0\n",
      "Mean Reward of that batch 170.5\n",
      "Average Reward of all training: 94.73005554817794\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1023.0\n",
      "Training loss:-0.011463888920843601\n",
      "Cross Entropy:[0.6655743  1.4108796  0.10344524 ... 0.18530156 0.35179338 0.6227449 ]\n",
      "VE Training loss:0.9816026091575623\n",
      "check (1025,) ()\n",
      "epoch 66\n",
      "====================================\n",
      "Epoch:  66 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1025.0\n",
      "Mean Reward of that batch 170.83333333333334\n",
      "Average Reward of all training: 95.88313551461968\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1025.0\n",
      "Training loss:0.0038402725476771593\n",
      "Cross Entropy:[0.74658734 1.5388279  0.08967079 ... 0.12790701 1.4804379  0.07943603]\n",
      "VE Training loss:0.9673258662223816\n",
      "check (1059,) ()\n",
      "epoch 67\n",
      "====================================\n",
      "Epoch:  67 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1059.0\n",
      "Mean Reward of that batch 176.5\n",
      "Average Reward of all training: 97.08637229798357\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1059.0\n",
      "Training loss:0.005331504158675671\n",
      "Cross Entropy:[0.60865355 0.3347747  0.84229046 ... 0.940099   0.2193656  1.0954742 ]\n",
      "VE Training loss:1.0127651691436768\n",
      "check (1168,) ()\n",
      "epoch 68\n",
      "====================================\n",
      "Epoch:  68 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1168.0\n",
      "Mean Reward of that batch 166.85714285714286\n",
      "Average Reward of all training: 98.11241304150063\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1168.0\n",
      "Training loss:-0.0164339542388916\n",
      "Cross Entropy:[0.57206434 0.3464837  0.8600602  ... 2.0827868  0.06046506 0.11892891]\n",
      "VE Training loss:0.9196459650993347\n",
      "check (1060,) ()\n",
      "epoch 69\n",
      "====================================\n",
      "Epoch:  69 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1060.0\n",
      "Mean Reward of that batch 176.66666666666666\n",
      "Average Reward of all training: 99.25088048534361\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1060.0\n",
      "Training loss:-0.0002784944954328239\n",
      "Cross Entropy:[0.5985903  1.2692277  0.12834296 ... 0.47229314 0.9486267  0.21714146]\n",
      "VE Training loss:0.9979167580604553\n",
      "check (1130,) ()\n",
      "epoch 70\n",
      "====================================\n",
      "Epoch:  70 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1130.0\n",
      "Mean Reward of that batch 188.33333333333334\n",
      "Average Reward of all training: 100.52348695460061\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1130.0\n",
      "Training loss:0.002797280438244343\n",
      "Cross Entropy:[0.75239277 0.23418637 0.57924783 ... 1.1571344  0.14731441 0.27084985]\n",
      "VE Training loss:1.0215564966201782\n",
      "Model saved\n",
      "check (1163,) ()\n",
      "epoch 71\n",
      "====================================\n",
      "Epoch:  71 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1163.0\n",
      "Mean Reward of that batch 166.14285714285714\n",
      "Average Reward of all training: 101.44770343612534\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1163.0\n",
      "Training loss:-0.009974503889679909\n",
      "Cross Entropy:[0.65252984 0.28706706 0.65878284 ... 0.30281192 0.7243252  0.27799657]\n",
      "VE Training loss:0.931410014629364\n",
      "check (1163,) ()\n",
      "epoch 72\n",
      "====================================\n",
      "Epoch:  72 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1163.0\n",
      "Mean Reward of that batch 166.14285714285714\n",
      "Average Reward of all training: 102.34624723760773\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1163.0\n",
      "Training loss:-0.011374264024198055\n",
      "Cross Entropy:[0.58692193 0.3264798  0.5777562  ... 0.61378944 0.31894702 0.8027915 ]\n",
      "VE Training loss:0.9966132044792175\n",
      "check (1057,) ()\n",
      "epoch 73\n",
      "====================================\n",
      "Epoch:  73 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1057.0\n",
      "Mean Reward of that batch 176.16666666666666\n",
      "Average Reward of all training: 103.3574858599236\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1057.0\n",
      "Training loss:-0.01855241321027279\n",
      "Cross Entropy:[0.76281786 1.5114805  0.09565617 ... 0.36963284 0.5533317  0.3539351 ]\n",
      "VE Training loss:1.0159690380096436\n",
      "check (1031,) ()\n",
      "epoch 74\n",
      "====================================\n",
      "Epoch:  74 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1031.0\n",
      "Mean Reward of that batch 171.83333333333334\n",
      "Average Reward of all training: 104.28283515010482\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1031.0\n",
      "Training loss:-0.001116590341553092\n",
      "Cross Entropy:[0.71859616 0.2553813  0.7168604  ... 0.34093744 0.8110118  0.22900896]\n",
      "VE Training loss:0.9924230575561523\n",
      "check (1117,) ()\n",
      "epoch 75\n",
      "====================================\n",
      "Epoch:  75 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1117.0\n",
      "Mean Reward of that batch 186.16666666666666\n",
      "Average Reward of all training: 105.37461957032565\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1117.0\n",
      "Training loss:-0.006108785048127174\n",
      "Cross Entropy:[0.75999016 0.24718885 0.72297657 ... 1.0094476  0.17593518 0.49587983]\n",
      "VE Training loss:1.0265250205993652\n",
      "check (1049,) ()\n",
      "epoch 76\n",
      "====================================\n",
      "Epoch:  76 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1049.0\n",
      "Mean Reward of that batch 174.83333333333334\n",
      "Average Reward of all training: 106.28855001457573\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1049.0\n",
      "Training loss:0.018138587474822998\n",
      "Cross Entropy:[0.6700395  1.419821   0.10309744 ... 0.40368947 0.6846514  0.26891991]\n",
      "VE Training loss:0.9518433213233948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1072,) ()\n",
      "epoch 77\n",
      "====================================\n",
      "Epoch:  77 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1072.0\n",
      "Mean Reward of that batch 178.66666666666666\n",
      "Average Reward of all training: 107.228525555512\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1072.0\n",
      "Training loss:-0.0005435610073618591\n",
      "Cross Entropy:[0.7378892 1.5360596 0.087049  ... 0.5872363 0.298734  0.6922266]\n",
      "VE Training loss:0.9872849583625793\n",
      "check (1155,) ()\n",
      "epoch 78\n",
      "====================================\n",
      "Epoch:  78 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1155.0\n",
      "Mean Reward of that batch 192.5\n",
      "Average Reward of all training: 108.32174958685158\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1155.0\n",
      "Training loss:-0.00393707025796175\n",
      "Cross Entropy:[0.75123614 1.4909959  0.09979896 ... 0.05738474 0.1218955  0.2663347 ]\n",
      "VE Training loss:1.0344771146774292\n",
      "check (1142,) ()\n",
      "epoch 79\n",
      "====================================\n",
      "Epoch:  79 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1142.0\n",
      "Mean Reward of that batch 190.33333333333334\n",
      "Average Reward of all training: 109.35987090009819\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1142.0\n",
      "Training loss:-0.0026106140576303005\n",
      "Cross Entropy:[0.58821744 1.273507   2.1463096  ... 0.06010142 0.14236806 0.33083856]\n",
      "VE Training loss:0.9811200499534607\n",
      "check (1160,) ()\n",
      "epoch 80\n",
      "====================================\n",
      "Epoch:  80 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1160.0\n",
      "Mean Reward of that batch 193.33333333333334\n",
      "Average Reward of all training: 110.40953918051363\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1160.0\n",
      "Training loss:-0.016766449436545372\n",
      "Cross Entropy:[0.78333735 0.22864862 0.78487766 ... 0.08232148 1.6045872  0.09408365]\n",
      "VE Training loss:0.981803297996521\n",
      "Model saved\n",
      "check (1104,) ()\n",
      "epoch 81\n",
      "====================================\n",
      "Epoch:  81 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1104.0\n",
      "Mean Reward of that batch 184.0\n",
      "Average Reward of all training: 111.31806338816162\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1104.0\n",
      "Training loss:-0.014151230454444885\n",
      "Cross Entropy:[0.6980743  0.27705643 0.62994885 ... 0.62508225 0.34262878 0.5962568 ]\n",
      "VE Training loss:0.9491322636604309\n",
      "check (1045,) ()\n",
      "epoch 82\n",
      "====================================\n",
      "Epoch:  82 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1045.0\n",
      "Mean Reward of that batch 174.16666666666666\n",
      "Average Reward of all training: 112.0845097696068\n",
      "Max reward for a batch so far: 1169.0\n",
      "check 1045.0\n",
      "Training loss:-0.002409266075119376\n",
      "Cross Entropy:[0.7506597  1.5116905  0.09364422 ... 0.5702968  1.1866454  0.13862516]\n",
      "VE Training loss:1.0333545207977295\n",
      "check (1200,) ()\n",
      "epoch 83\n",
      "====================================\n",
      "Epoch:  83 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 113.14373254346695\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.007261594291776419\n",
      "Cross Entropy:[0.69744664 0.2553824  0.7117693  ... 0.32769758 0.9225038  0.15764764]\n",
      "VE Training loss:1.004406452178955\n",
      "check (1106,) ()\n",
      "epoch 84\n",
      "====================================\n",
      "Epoch:  84 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1106.0\n",
      "Mean Reward of that batch 184.33333333333334\n",
      "Average Reward of all training: 113.99122779096537\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1106.0\n",
      "Training loss:0.004738017451018095\n",
      "Cross Entropy:[0.6028706  1.3644673  0.10433801 ... 0.35112038 0.63375896 0.43721256]\n",
      "VE Training loss:0.995442807674408\n",
      "check (1167,) ()\n",
      "epoch 85\n",
      "====================================\n",
      "Epoch:  85 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1167.0\n",
      "Mean Reward of that batch 194.5\n",
      "Average Reward of all training: 114.93838981695401\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1167.0\n",
      "Training loss:0.007112334482371807\n",
      "Cross Entropy:[0.86293566 0.18905891 0.49989164 ... 0.2600101  0.94195247 0.1638804 ]\n",
      "VE Training loss:1.000612497329712\n",
      "check (1056,) ()\n",
      "epoch 86\n",
      "====================================\n",
      "Epoch:  86 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1056.0\n",
      "Mean Reward of that batch 176.0\n",
      "Average Reward of all training: 115.64840854001268\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1056.0\n",
      "Training loss:0.007985766045749187\n",
      "Cross Entropy:[0.66122055 0.28463942 0.79208124 ... 0.44329464 0.9282285  0.22333275]\n",
      "VE Training loss:0.9811314940452576\n",
      "check (1089,) ()\n",
      "epoch 87\n",
      "====================================\n",
      "Epoch:  87 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1089.0\n",
      "Mean Reward of that batch 181.5\n",
      "Average Reward of all training: 116.40532338438035\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1089.0\n",
      "Training loss:-0.006196309346705675\n",
      "Cross Entropy:[0.57755    1.3639913  2.3542542  ... 0.50858617 0.97188133 1.5923116 ]\n",
      "VE Training loss:0.9314019083976746\n",
      "check (1145,) ()\n",
      "epoch 88\n",
      "====================================\n",
      "Epoch:  88 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1145.0\n",
      "Mean Reward of that batch 190.83333333333334\n",
      "Average Reward of all training: 117.25109622470936\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1145.0\n",
      "Training loss:-0.005273373331874609\n",
      "Cross Entropy:[0.6393515  0.28005987 0.64809096 ... 0.0376127  0.08026335 0.17071635]\n",
      "VE Training loss:0.9366192817687988\n",
      "check (1033,) ()\n",
      "epoch 89\n",
      "====================================\n",
      "Epoch:  89 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1033.0\n",
      "Mean Reward of that batch 172.16666666666666\n",
      "Average Reward of all training: 117.86812510607966\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1033.0\n",
      "Training loss:-0.0007918165065348148\n",
      "Cross Entropy:[0.53750765 1.2489691  0.12133203 ... 0.393354   0.6174331  0.3037719 ]\n",
      "VE Training loss:0.902131199836731\n",
      "check (1105,) ()\n",
      "epoch 90\n",
      "====================================\n",
      "Epoch:  90 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1105.0\n",
      "Mean Reward of that batch 184.16666666666666\n",
      "Average Reward of all training: 118.60477556786395\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1105.0\n",
      "Training loss:-0.0030455368105322123\n",
      "Cross Entropy:[0.8697643  0.18668446 0.5102881  ... 0.0849985  1.5785732  0.07525969]\n",
      "VE Training loss:0.9515712261199951\n",
      "Model saved\n",
      "check (1095,) ()\n",
      "epoch 91\n",
      "====================================\n",
      "Epoch:  91 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1095.0\n",
      "Mean Reward of that batch 182.5\n",
      "Average Reward of all training: 119.30692089129401\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1095.0\n",
      "Training loss:0.011301625519990921\n",
      "Cross Entropy:[0.6023385  0.28977606 0.6247206  ... 0.1082201  0.25846058 0.5706562 ]\n",
      "VE Training loss:0.979354202747345\n",
      "check (1153,) ()\n",
      "epoch 92\n",
      "====================================\n",
      "Epoch:  92 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1153.0\n",
      "Mean Reward of that batch 192.16666666666666\n",
      "Average Reward of all training: 120.09887464972198\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1153.0\n",
      "Training loss:-0.0033479840494692326\n",
      "Cross Entropy:[0.70663166 0.24033633 0.66290176 ... 0.7271981  0.26891336 0.6137907 ]\n",
      "VE Training loss:0.9352675080299377\n",
      "check (1026,) ()\n",
      "epoch 93\n",
      "====================================\n",
      "Epoch:  93 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1026.0\n",
      "Mean Reward of that batch 171.0\n",
      "Average Reward of all training: 120.64619857821958\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1026.0\n",
      "Training loss:-0.014465101063251495\n",
      "Cross Entropy:[0.71819854 0.2273489  0.60320616 ... 0.60662097 0.33276996 0.626349  ]\n",
      "VE Training loss:0.9904389977455139\n",
      "check (1087,) ()\n",
      "epoch 94\n",
      "====================================\n",
      "Epoch:  94 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1087.0\n",
      "Mean Reward of that batch 181.16666666666666\n",
      "Average Reward of all training: 121.29003334511795\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1087.0\n",
      "Training loss:0.008333071134984493\n",
      "Cross Entropy:[0.60661376 0.30060887 0.83364916 ... 0.28586987 0.6010827  0.31263757]\n",
      "VE Training loss:0.9835023283958435\n",
      "check (1145,) ()\n",
      "epoch 95\n",
      "====================================\n",
      "Epoch:  95 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1145.0\n",
      "Mean Reward of that batch 163.57142857142858\n",
      "Average Reward of all training: 121.73510066328966\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1145.0\n",
      "Training loss:-0.006902989465743303\n",
      "Cross Entropy:[0.9824399  0.15192997 0.41220105 ... 0.83366704 0.20544337 0.5033058 ]\n",
      "VE Training loss:0.9142172932624817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 96\n",
      "====================================\n",
      "Epoch:  96 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 122.55036003138041\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004714453127235174\n",
      "Cross Entropy:[0.8007611  0.19712652 0.89312476 ... 0.9375659  0.16374955 1.138126  ]\n",
      "VE Training loss:0.9822216033935547\n",
      "check (1008,) ()\n",
      "epoch 97\n",
      "====================================\n",
      "Epoch:  97 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1008.0\n",
      "Mean Reward of that batch 168.0\n",
      "Average Reward of all training: 123.01891302074762\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1008.0\n",
      "Training loss:-0.010838034562766552\n",
      "Cross Entropy:[0.6284267  0.285923   0.7959713  ... 0.7400355  0.24963526 0.6480371 ]\n",
      "VE Training loss:0.9047507047653198\n",
      "check (1150,) ()\n",
      "epoch 98\n",
      "====================================\n",
      "Epoch:  98 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1150.0\n",
      "Mean Reward of that batch 191.66666666666666\n",
      "Average Reward of all training: 123.71940030284883\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1150.0\n",
      "Training loss:0.0014941307017579675\n",
      "Cross Entropy:[0.44543177 0.4129103  0.41654408 ... 2.2599633  0.03758755 0.09450001]\n",
      "VE Training loss:0.9455475211143494\n",
      "check (1028,) ()\n",
      "epoch 99\n",
      "====================================\n",
      "Epoch:  99 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1028.0\n",
      "Mean Reward of that batch 171.33333333333334\n",
      "Average Reward of all training: 124.20034912133858\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1028.0\n",
      "Training loss:-0.022320669144392014\n",
      "Cross Entropy:[0.62546194 0.2687714  0.7179291  ... 0.45112485 0.45413148 0.98001003]\n",
      "VE Training loss:0.9709537029266357\n",
      "check (1066,) ()\n",
      "epoch 100\n",
      "====================================\n",
      "Epoch:  100 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1066.0\n",
      "Mean Reward of that batch 177.66666666666666\n",
      "Average Reward of all training: 124.73501229679185\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1066.0\n",
      "Training loss:-0.015589209273457527\n",
      "Cross Entropy:[0.69054633 0.25840738 0.7448603  ... 0.2733478  0.8625709  0.16492444]\n",
      "VE Training loss:0.9716513156890869\n",
      "Model saved\n",
      "check (1189,) ()\n",
      "epoch 101\n",
      "====================================\n",
      "Epoch:  101 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1189.0\n",
      "Mean Reward of that batch 198.16666666666666\n",
      "Average Reward of all training: 125.46205837966188\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1189.0\n",
      "Training loss:0.001893474254757166\n",
      "Cross Entropy:[0.5882102  0.30559063 0.55526793 ... 0.4430819  0.42569593 0.48655045]\n",
      "VE Training loss:0.9590240120887756\n",
      "check (1108,) ()\n",
      "epoch 102\n",
      "====================================\n",
      "Epoch:  102 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1108.0\n",
      "Mean Reward of that batch 184.66666666666666\n",
      "Average Reward of all training: 126.04249571580898\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1108.0\n",
      "Training loss:-0.004992175381630659\n",
      "Cross Entropy:[0.77764386 0.19968715 0.53947043 ... 1.2973517  0.09922916 0.2097796 ]\n",
      "VE Training loss:0.9918813109397888\n",
      "check (1193,) ()\n",
      "epoch 103\n",
      "====================================\n",
      "Epoch:  103 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1193.0\n",
      "Mean Reward of that batch 198.83333333333334\n",
      "Average Reward of all training: 126.74920287714419\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1193.0\n",
      "Training loss:-0.020268909633159637\n",
      "Cross Entropy:[0.6654161  0.26500425 0.77032256 ... 0.26262626 0.7375349  1.6708256 ]\n",
      "VE Training loss:0.9849216938018799\n",
      "check (1200,) ()\n",
      "epoch 104\n",
      "====================================\n",
      "Epoch:  104 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 127.45353746486397\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0031570387072861195\n",
      "Cross Entropy:[0.7883613  1.6369433  0.07476732 ... 1.3105526  0.09845552 0.26670247]\n",
      "VE Training loss:0.9619885087013245\n",
      "check (1167,) ()\n",
      "epoch 105\n",
      "====================================\n",
      "Epoch:  105 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1167.0\n",
      "Mean Reward of that batch 194.5\n",
      "Average Reward of all training: 128.09207520329383\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1167.0\n",
      "Training loss:-0.002372231800109148\n",
      "Cross Entropy:[0.5754328  1.3568703  0.10076861 ... 0.3584113  0.98789716 0.15409282]\n",
      "VE Training loss:0.9976106882095337\n",
      "check (1136,) ()\n",
      "epoch 106\n",
      "====================================\n",
      "Epoch:  106 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1136.0\n",
      "Mean Reward of that batch 189.33333333333334\n",
      "Average Reward of all training: 128.66982292150175\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1136.0\n",
      "Training loss:-0.00011322028149152175\n",
      "Cross Entropy:[0.8135918  1.7307609  0.06330153 ... 0.17861278 0.54113865 0.3174751 ]\n",
      "VE Training loss:0.991560161113739\n",
      "check (1178,) ()\n",
      "epoch 107\n",
      "====================================\n",
      "Epoch:  107 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1178.0\n",
      "Mean Reward of that batch 196.33333333333334\n",
      "Average Reward of all training: 129.30219217768712\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1178.0\n",
      "Training loss:-0.0006464648758992553\n",
      "Cross Entropy:[0.63828206 0.26837444 0.7654477  ... 1.1384815  0.18118986 0.49192894]\n",
      "VE Training loss:1.002020239830017\n",
      "check (1181,) ()\n",
      "epoch 108\n",
      "====================================\n",
      "Epoch:  108 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1181.0\n",
      "Mean Reward of that batch 196.83333333333334\n",
      "Average Reward of all training: 129.92748052172087\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1181.0\n",
      "Training loss:0.00665969168767333\n",
      "Cross Entropy:[0.7213673  0.22523916 0.6427802  ... 0.25165805 0.86513686 0.16935897]\n",
      "VE Training loss:1.0384224653244019\n",
      "check (1200,) ()\n",
      "epoch 109\n",
      "====================================\n",
      "Epoch:  109 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 130.57034767289775\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0021846136078238487\n",
      "Cross Entropy:[0.6045899  0.28991416 0.83768106 ... 0.6912581  1.4342512  0.09413639]\n",
      "VE Training loss:0.9904378056526184\n",
      "check (1054,) ()\n",
      "epoch 110\n",
      "====================================\n",
      "Epoch:  110 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1054.0\n",
      "Mean Reward of that batch 175.66666666666666\n",
      "Average Reward of all training: 130.98031420920472\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1054.0\n",
      "Training loss:-0.005932950880378485\n",
      "Cross Entropy:[0.63575697 0.25645372 0.7260781  ... 0.2826203  0.59472555 1.136615  ]\n",
      "VE Training loss:1.0414735078811646\n",
      "Model saved\n",
      "check (1194,) ()\n",
      "epoch 111\n",
      "====================================\n",
      "Epoch:  111 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1194.0\n",
      "Mean Reward of that batch 199.0\n",
      "Average Reward of all training: 131.59310417128395\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1194.0\n",
      "Training loss:0.003802793798968196\n",
      "Cross Entropy:[0.58009714 0.30787435 0.5216454  ... 0.38109896 0.48413607 1.1041392 ]\n",
      "VE Training loss:1.0115281343460083\n",
      "check (1120,) ()\n",
      "epoch 112\n",
      "====================================\n",
      "Epoch:  112 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1120.0\n",
      "Mean Reward of that batch 186.66666666666666\n",
      "Average Reward of all training: 132.0848324078499\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1120.0\n",
      "Training loss:-0.013431092724204063\n",
      "Cross Entropy:[0.7242468  0.22638279 0.71858394 ... 0.32043308 0.65537983 0.37201855]\n",
      "VE Training loss:1.0197356939315796\n",
      "check (1168,) ()\n",
      "epoch 113\n",
      "====================================\n",
      "Epoch:  113 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1168.0\n",
      "Mean Reward of that batch 194.66666666666666\n",
      "Average Reward of all training: 132.6386539499633\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1168.0\n",
      "Training loss:-0.0012130035320296884\n",
      "Cross Entropy:[0.62243986 0.25357392 0.7051213  ... 0.12117723 1.4497632  2.724695  ]\n",
      "VE Training loss:0.9998432397842407\n",
      "check (1045,) ()\n",
      "epoch 114\n",
      "====================================\n",
      "Epoch:  114 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1045.0\n",
      "Mean Reward of that batch 174.16666666666666\n",
      "Average Reward of all training: 133.00293476326772\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1045.0\n",
      "Training loss:-0.01350382249802351\n",
      "Cross Entropy:[0.57694733 0.30369166 0.5299914  ... 0.16208924 1.1888163  0.08993755]\n",
      "VE Training loss:1.0084251165390015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1109,) ()\n",
      "epoch 115\n",
      "====================================\n",
      "Epoch:  115 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1109.0\n",
      "Mean Reward of that batch 184.83333333333334\n",
      "Average Reward of all training: 133.45363388126827\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1109.0\n",
      "Training loss:1.7762937204679474e-05\n",
      "Cross Entropy:[0.7106867  0.22408581 0.6464306  ... 0.15821901 1.2752908  0.09046236]\n",
      "VE Training loss:0.9598700404167175\n",
      "check (1160,) ()\n",
      "epoch 116\n",
      "====================================\n",
      "Epoch:  116 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1160.0\n",
      "Mean Reward of that batch 193.33333333333334\n",
      "Average Reward of all training: 133.96983818688955\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1160.0\n",
      "Training loss:-0.001948269084095955\n",
      "Cross Entropy:[0.6735107  0.24549735 0.65495044 ... 0.11383701 1.479311   2.7974143 ]\n",
      "VE Training loss:0.9562765955924988\n",
      "check (1131,) ()\n",
      "epoch 117\n",
      "====================================\n",
      "Epoch:  117 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1131.0\n",
      "Mean Reward of that batch 188.5\n",
      "Average Reward of all training: 134.43590794597594\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1131.0\n",
      "Training loss:0.0010308283381164074\n",
      "Cross Entropy:[0.643933   1.5328108  0.07598088 ... 0.4843189  0.43595606 0.9344994 ]\n",
      "VE Training loss:0.9520359635353088\n",
      "check (1141,) ()\n",
      "epoch 118\n",
      "====================================\n",
      "Epoch:  118 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1141.0\n",
      "Mean Reward of that batch 190.16666666666666\n",
      "Average Reward of all training: 134.90820251140553\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1141.0\n",
      "Training loss:-0.010074838064610958\n",
      "Cross Entropy:[0.77314764 0.19153199 0.5532862  ... 0.86305124 1.8513479  0.0469575 ]\n",
      "VE Training loss:0.9730433225631714\n",
      "check (1200,) ()\n",
      "epoch 119\n",
      "====================================\n",
      "Epoch:  119 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 135.45519240626766\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.002239604713395238\n",
      "Cross Entropy:[0.8078245  0.17995936 0.8911743  ... 2.627287   0.02650235 0.08669216]\n",
      "VE Training loss:0.9658286571502686\n",
      "check (1200,) ()\n",
      "epoch 120\n",
      "====================================\n",
      "Epoch:  120 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 135.99306580288211\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.008313467726111412\n",
      "Cross Entropy:[0.70965594 0.2086108  0.6008607  ... 1.5364497  0.08306382 0.25010538]\n",
      "VE Training loss:0.9702020287513733\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 121\n",
      "====================================\n",
      "Epoch:  121 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 136.52204873013102\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0027124807238578796\n",
      "Cross Entropy:[0.759038   0.19419117 0.56069857 ... 1.5710692  0.07051052 1.6262734 ]\n",
      "VE Training loss:0.996324896812439\n",
      "check (1200,) ()\n",
      "epoch 122\n",
      "====================================\n",
      "Epoch:  122 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 137.04235980611355\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011119291186332703\n",
      "Cross Entropy:[0.5590382  0.29951182 0.8766593  ... 1.5189601  0.07959522 0.24855967]\n",
      "VE Training loss:1.011699914932251\n",
      "check (1187,) ()\n",
      "epoch 123\n",
      "====================================\n",
      "Epoch:  123 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1187.0\n",
      "Mean Reward of that batch 197.83333333333334\n",
      "Average Reward of all training: 137.53659536324543\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1187.0\n",
      "Training loss:0.0014443754917010665\n",
      "Cross Entropy:[0.66429824 0.23111153 0.72647536 ... 1.0425625  0.16588953 1.211399  ]\n",
      "VE Training loss:0.9557037949562073\n",
      "check (1186,) ()\n",
      "epoch 124\n",
      "====================================\n",
      "Epoch:  124 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1186.0\n",
      "Mean Reward of that batch 197.66666666666666\n",
      "Average Reward of all training: 138.02151529311172\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1186.0\n",
      "Training loss:0.0032971238251775503\n",
      "Cross Entropy:[0.6230657  0.25686184 0.6530892  ... 0.17841165 0.42571282 0.5266738 ]\n",
      "VE Training loss:0.9848337173461914\n",
      "check (1103,) ()\n",
      "epoch 125\n",
      "====================================\n",
      "Epoch:  125 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1103.0\n",
      "Mean Reward of that batch 183.83333333333334\n",
      "Average Reward of all training: 138.3880098374335\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1103.0\n",
      "Training loss:0.005114771891385317\n",
      "Cross Entropy:[0.69786125 0.24169494 0.6606733  ... 0.49191266 0.35798115 0.45427272]\n",
      "VE Training loss:0.9928173422813416\n",
      "check (1200,) ()\n",
      "epoch 126\n",
      "====================================\n",
      "Epoch:  126 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 138.87699388634275\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.01433645561337471\n",
      "Cross Entropy:[0.56327987 0.30475608 0.54043895 ... 0.923923   0.16794805 0.47020277]\n",
      "VE Training loss:0.9940309524536133\n",
      "check (1196,) ()\n",
      "epoch 127\n",
      "====================================\n",
      "Epoch:  127 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1196.0\n",
      "Mean Reward of that batch 199.33333333333334\n",
      "Average Reward of all training: 139.35302805521667\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1196.0\n",
      "Training loss:-0.0014840624062344432\n",
      "Cross Entropy:[0.56647414 0.28211653 0.7594379  ... 0.38938543 0.5740075  1.3156204 ]\n",
      "VE Training loss:0.9630568623542786\n",
      "check (1200,) ()\n",
      "epoch 128\n",
      "====================================\n",
      "Epoch:  128 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 139.8268325235353\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.005011184141039848\n",
      "Cross Entropy:[0.5657041  0.31328142 0.8935225  ... 0.12964436 0.40347296 0.43429238]\n",
      "VE Training loss:0.9900243282318115\n",
      "check (1152,) ()\n",
      "epoch 129\n",
      "====================================\n",
      "Epoch:  129 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1152.0\n",
      "Mean Reward of that batch 192.0\n",
      "Average Reward of all training: 140.23127568226758\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1152.0\n",
      "Training loss:0.0034062406048178673\n",
      "Cross Entropy:[0.6547034  0.23612428 0.639875   ... 0.77488714 0.22502823 0.8194337 ]\n",
      "VE Training loss:0.9537816643714905\n",
      "check (1193,) ()\n",
      "epoch 130\n",
      "====================================\n",
      "Epoch:  130 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1193.0\n",
      "Mean Reward of that batch 198.83333333333334\n",
      "Average Reward of all training: 140.68206074112194\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1193.0\n",
      "Training loss:-0.0005252818809822202\n",
      "Cross Entropy:[0.5592053  0.31568205 0.521518   ... 0.51298255 0.970875   0.2228471 ]\n",
      "VE Training loss:0.9720194935798645\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 131\n",
      "====================================\n",
      "Epoch:  131 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 141.13486943775462\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0019729998894035816\n",
      "Cross Entropy:[0.8415902  0.17818394 0.50335217 ... 0.09849614 0.25462428 0.76209295]\n",
      "VE Training loss:0.9792031645774841\n",
      "check (1187,) ()\n",
      "epoch 132\n",
      "====================================\n",
      "Epoch:  132 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1187.0\n",
      "Mean Reward of that batch 197.83333333333334\n",
      "Average Reward of all training: 141.56440325514535\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1187.0\n",
      "Training loss:-0.007049435283988714\n",
      "Cross Entropy:[0.5878881  0.27275208 0.73716646 ... 1.4334478  0.10004783 1.4132909 ]\n",
      "VE Training loss:0.9533101916313171\n",
      "check (1200,) ()\n",
      "epoch 133\n",
      "====================================\n",
      "Epoch:  133 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 142.0037686442044\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0017344971420243382\n",
      "Cross Entropy:[0.60032165 0.28938475 0.5714404  ... 0.42244315 0.5501992  0.39812514]\n",
      "VE Training loss:0.9748570919036865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1132,) ()\n",
      "epoch 134\n",
      "====================================\n",
      "Epoch:  134 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1132.0\n",
      "Mean Reward of that batch 188.66666666666666\n",
      "Average Reward of all training: 142.3519992264616\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1132.0\n",
      "Training loss:-0.025910843163728714\n",
      "Cross Entropy:[0.82326186 0.19652134 0.5859445  ... 0.05998826 0.15297028 1.1246465 ]\n",
      "VE Training loss:0.9691994786262512\n",
      "check (1174,) ()\n",
      "epoch 135\n",
      "====================================\n",
      "Epoch:  135 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1174.0\n",
      "Mean Reward of that batch 195.66666666666666\n",
      "Average Reward of all training: 142.7469226889816\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1174.0\n",
      "Training loss:0.009621607139706612\n",
      "Cross Entropy:[0.6775753  0.24802558 0.7352384  ... 0.12078979 1.1937082  0.12394488]\n",
      "VE Training loss:0.9659517407417297\n",
      "check (1200,) ()\n",
      "epoch 136\n",
      "====================================\n",
      "Epoch:  136 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 143.16790119862145\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0033062989823520184\n",
      "Cross Entropy:[0.5608385  0.31191638 0.5270637  ... 1.469422   2.5134695  0.02755162]\n",
      "VE Training loss:0.9507846832275391\n",
      "check (1167,) ()\n",
      "epoch 137\n",
      "====================================\n",
      "Epoch:  137 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1167.0\n",
      "Mean Reward of that batch 194.5\n",
      "Average Reward of all training: 143.54258805118627\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1167.0\n",
      "Training loss:-0.0007446696981787682\n",
      "Cross Entropy:[0.877908   1.8081067  0.05832013 ... 0.44945133 0.46683723 0.4089105 ]\n",
      "VE Training loss:0.9548038840293884\n",
      "check (1200,) ()\n",
      "epoch 138\n",
      "====================================\n",
      "Epoch:  138 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 143.95169973197477\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.017128972336649895\n",
      "Cross Entropy:[0.5537737  1.3466835  0.09849732 ... 0.41310355 0.3706409  0.49895316]\n",
      "VE Training loss:0.9624750018119812\n",
      "check (1073,) ()\n",
      "epoch 139\n",
      "====================================\n",
      "Epoch:  139 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1073.0\n",
      "Mean Reward of that batch 178.83333333333334\n",
      "Average Reward of all training: 144.20264673630112\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1073.0\n",
      "Training loss:-0.008907097391784191\n",
      "Cross Entropy:[0.61052483 0.27934772 0.58723694 ... 0.26208827 0.6735258  1.3203416 ]\n",
      "VE Training loss:0.942783772945404\n",
      "check (1182,) ()\n",
      "epoch 140\n",
      "====================================\n",
      "Epoch:  140 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1182.0\n",
      "Mean Reward of that batch 197.0\n",
      "Average Reward of all training: 144.57977068818468\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1182.0\n",
      "Training loss:-0.008107680827379227\n",
      "Cross Entropy:[0.8507386  0.17598785 0.50754887 ... 1.1944528  0.12129285 1.2873563 ]\n",
      "VE Training loss:0.9510896801948547\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 141\n",
      "====================================\n",
      "Epoch:  141 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 144.97282195989968\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0022300623822957277\n",
      "Cross Entropy:[0.872542   0.16564906 0.4701563  ... 0.91140074 0.17459038 1.021748  ]\n",
      "VE Training loss:0.9547638893127441\n",
      "check (1148,) ()\n",
      "epoch 142\n",
      "====================================\n",
      "Epoch:  142 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1148.0\n",
      "Mean Reward of that batch 191.33333333333334\n",
      "Average Reward of all training: 145.29930443436047\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1148.0\n",
      "Training loss:-0.0010673858923837543\n",
      "Cross Entropy:[0.73040736 0.21347275 0.7699299  ... 0.6825355  1.5932133  0.06367867]\n",
      "VE Training loss:0.9492420554161072\n",
      "check (1137,) ()\n",
      "epoch 143\n",
      "====================================\n",
      "Epoch:  143 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1137.0\n",
      "Mean Reward of that batch 189.5\n",
      "Average Reward of all training: 145.60840020754677\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1137.0\n",
      "Training loss:-0.011738775297999382\n",
      "Cross Entropy:[0.73308074 0.2289679  0.69901437 ... 0.17834273 0.98726654 0.14368305]\n",
      "VE Training loss:0.9578738212585449\n",
      "check (1120,) ()\n",
      "epoch 144\n",
      "====================================\n",
      "Epoch:  144 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1120.0\n",
      "Mean Reward of that batch 186.66666666666666\n",
      "Average Reward of all training: 145.8935270579573\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1120.0\n",
      "Training loss:0.005401664413511753\n",
      "Cross Entropy:[0.67249566 1.5585829  0.07349093 ... 0.62880254 0.34495187 0.50325906]\n",
      "VE Training loss:0.9395725727081299\n",
      "check (1186,) ()\n",
      "epoch 145\n",
      "====================================\n",
      "Epoch:  145 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1186.0\n",
      "Mean Reward of that batch 197.66666666666666\n",
      "Average Reward of all training: 146.25058319318978\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1186.0\n",
      "Training loss:-0.0025702673010528088\n",
      "Cross Entropy:[0.9314889  0.16229267 0.93452793 ... 1.6922909  0.05749144 0.11467251]\n",
      "VE Training loss:0.9832068085670471\n",
      "check (1185,) ()\n",
      "epoch 146\n",
      "====================================\n",
      "Epoch:  146 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1185.0\n",
      "Mean Reward of that batch 197.5\n",
      "Average Reward of all training: 146.60160659597616\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1185.0\n",
      "Training loss:-0.0206932220607996\n",
      "Cross Entropy:[0.74091566 0.21361718 0.6283783  ... 0.17283066 1.053705   0.13570182]\n",
      "VE Training loss:0.9389623999595642\n",
      "check (1185,) ()\n",
      "epoch 147\n",
      "====================================\n",
      "Epoch:  147 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1185.0\n",
      "Mean Reward of that batch 197.5\n",
      "Average Reward of all training: 146.9478541701532\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1185.0\n",
      "Training loss:0.004261799156665802\n",
      "Cross Entropy:[0.63882023 0.27157724 0.82510984 ... 0.09516302 1.3479931  0.09281833]\n",
      "VE Training loss:0.9980568885803223\n",
      "check (1171,) ()\n",
      "epoch 148\n",
      "====================================\n",
      "Epoch:  148 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1171.0\n",
      "Mean Reward of that batch 195.16666666666666\n",
      "Average Reward of all training: 147.27365695729176\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1171.0\n",
      "Training loss:-0.0061821043491363525\n",
      "Cross Entropy:[0.92165244 0.15460503 0.45536768 ... 1.4379387  0.09714315 0.29718867]\n",
      "VE Training loss:0.9555952548980713\n",
      "check (1200,) ()\n",
      "epoch 149\n",
      "====================================\n",
      "Epoch:  149 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 147.6275250314039\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.003469482995569706\n",
      "Cross Entropy:[0.8978504  0.17549068 0.8428447  ... 0.68643916 0.25481996 0.7108804 ]\n",
      "VE Training loss:0.9882055521011353\n",
      "check (1200,) ()\n",
      "epoch 150\n",
      "====================================\n",
      "Epoch:  150 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 147.9766748645279\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0017649508081376553\n",
      "Cross Entropy:[0.76017433 1.6938369  0.06274111 ... 0.55659974 0.27810317 0.68152064]\n",
      "VE Training loss:0.9462288618087769\n",
      "Model saved\n",
      "check (1165,) ()\n",
      "epoch 151\n",
      "====================================\n",
      "Epoch:  151 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1165.0\n",
      "Mean Reward of that batch 194.16666666666666\n",
      "Average Reward of all training: 148.28256884997253\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1165.0\n",
      "Training loss:0.006486833561211824\n",
      "Cross Entropy:[0.6136707  0.2777099  0.84718883 ... 1.2172608  0.1276462  0.44374222]\n",
      "VE Training loss:0.9827175736427307\n",
      "check (1180,) ()\n",
      "epoch 152\n",
      "====================================\n",
      "Epoch:  152 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1180.0\n",
      "Mean Reward of that batch 196.66666666666666\n",
      "Average Reward of all training: 148.6008852829771\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1180.0\n",
      "Training loss:0.004970957525074482\n",
      "Cross Entropy:[0.9831171  0.14275704 0.43213308 ... 0.16690949 0.4719192  0.3994239 ]\n",
      "VE Training loss:0.9455204606056213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1174,) ()\n",
      "epoch 153\n",
      "====================================\n",
      "Epoch:  153 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1174.0\n",
      "Mean Reward of that batch 195.66666666666666\n",
      "Average Reward of all training: 148.908504769145\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1174.0\n",
      "Training loss:-0.02022477053105831\n",
      "Cross Entropy:[0.77927756 0.19377455 0.8176161  ... 0.53197896 0.29168996 0.6494969 ]\n",
      "VE Training loss:0.9571539163589478\n",
      "check (1179,) ()\n",
      "epoch 154\n",
      "====================================\n",
      "Epoch:  154 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1179.0\n",
      "Mean Reward of that batch 196.5\n",
      "Average Reward of all training: 149.21754045246226\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1179.0\n",
      "Training loss:-0.006249654106795788\n",
      "Cross Entropy:[0.5663532  0.2997517  0.5212433  ... 0.40311927 0.99748117 1.9214089 ]\n",
      "VE Training loss:0.9487678408622742\n",
      "check (1154,) ()\n",
      "epoch 155\n",
      "====================================\n",
      "Epoch:  155 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1154.0\n",
      "Mean Reward of that batch 192.33333333333334\n",
      "Average Reward of all training: 149.49570685814527\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1154.0\n",
      "Training loss:0.00582392793148756\n",
      "Cross Entropy:[0.6104044  0.27788046 0.5437474  ... 0.14795701 0.44414583 0.3867022 ]\n",
      "VE Training loss:0.991614818572998\n",
      "check (1180,) ()\n",
      "epoch 156\n",
      "====================================\n",
      "Epoch:  156 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1180.0\n",
      "Mean Reward of that batch 196.66666666666666\n",
      "Average Reward of all training: 149.79808480563582\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1180.0\n",
      "Training loss:0.016444174572825432\n",
      "Cross Entropy:[0.6038873  0.25863576 0.7514828  ... 0.12463339 0.4145425  0.39139712]\n",
      "VE Training loss:0.9249834418296814\n",
      "check (1181,) ()\n",
      "epoch 157\n",
      "====================================\n",
      "Epoch:  157 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1181.0\n",
      "Mean Reward of that batch 196.83333333333334\n",
      "Average Reward of all training: 150.0976723758759\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1181.0\n",
      "Training loss:0.006194036453962326\n",
      "Cross Entropy:[0.785896   1.7923725  0.05275238 ... 0.759712   1.9302502  0.03567917]\n",
      "VE Training loss:0.9791291952133179\n",
      "check (1142,) ()\n",
      "epoch 158\n",
      "====================================\n",
      "Epoch:  158 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1142.0\n",
      "Mean Reward of that batch 190.33333333333334\n",
      "Average Reward of all training: 150.35232845788514\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1142.0\n",
      "Training loss:0.0005295848823152483\n",
      "Cross Entropy:[1.0451149  0.12516376 0.3773491  ... 0.16571803 1.2948375  0.09898505]\n",
      "VE Training loss:0.971088171005249\n",
      "check (1200,) ()\n",
      "epoch 159\n",
      "====================================\n",
      "Epoch:  159 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 150.6645779644393\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.00476854620501399\n",
      "Cross Entropy:[0.6406948  0.2592504  0.7984139  ... 0.20676896 0.8670012  0.19418833]\n",
      "VE Training loss:0.9988753199577332\n",
      "check (1154,) ()\n",
      "epoch 160\n",
      "====================================\n",
      "Epoch:  160 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1154.0\n",
      "Mean Reward of that batch 192.33333333333334\n",
      "Average Reward of all training: 150.9250076854949\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1154.0\n",
      "Training loss:0.00459983479231596\n",
      "Cross Entropy:[0.8406495  0.16569926 0.49445218 ... 0.09335858 0.2719291  0.7447198 ]\n",
      "VE Training loss:0.955204963684082\n",
      "Model saved\n",
      "check (1181,) ()\n",
      "epoch 161\n",
      "====================================\n",
      "Epoch:  161 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1181.0\n",
      "Mean Reward of that batch 196.83333333333334\n",
      "Average Reward of all training: 151.21015256529515\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1181.0\n",
      "Training loss:0.0011844602413475513\n",
      "Cross Entropy:[0.80931526 0.196265   0.64280754 ... 1.411953   0.08986814 0.2768634 ]\n",
      "VE Training loss:0.92597895860672\n",
      "check (1167,) ()\n",
      "epoch 162\n",
      "====================================\n",
      "Epoch:  162 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1167.0\n",
      "Mean Reward of that batch 194.5\n",
      "Average Reward of all training: 151.4773738457563\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1167.0\n",
      "Training loss:0.00972905382514\n",
      "Cross Entropy:[0.9913652  0.132765   0.40731505 ... 0.49496508 0.4131821  0.3890171 ]\n",
      "VE Training loss:0.9432946443557739\n",
      "check (1184,) ()\n",
      "epoch 163\n",
      "====================================\n",
      "Epoch:  163 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1184.0\n",
      "Mean Reward of that batch 197.33333333333334\n",
      "Average Reward of all training: 151.75869875058805\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1184.0\n",
      "Training loss:-0.006128976587206125\n",
      "Cross Entropy:[0.82038236 0.18601057 0.6018005  ... 0.0940638  0.27649936 0.76945746]\n",
      "VE Training loss:0.9418383240699768\n",
      "check (1139,) ()\n",
      "epoch 164\n",
      "====================================\n",
      "Epoch:  164 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1139.0\n",
      "Mean Reward of that batch 189.83333333333334\n",
      "Average Reward of all training: 151.99086115658042\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1139.0\n",
      "Training loss:-0.0012464305618777871\n",
      "Cross Entropy:[0.8557162  0.16802847 0.5260831  ... 0.3755684  0.5142738  0.35285234]\n",
      "VE Training loss:0.9485718607902527\n",
      "check (1146,) ()\n",
      "epoch 165\n",
      "====================================\n",
      "Epoch:  165 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1146.0\n",
      "Mean Reward of that batch 191.0\n",
      "Average Reward of all training: 152.22728017987387\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1146.0\n",
      "Training loss:0.009682479314506054\n",
      "Cross Entropy:[0.851019   0.17552948 0.5815383  ... 0.31573996 0.5105951  0.3908559 ]\n",
      "VE Training loss:0.944756031036377\n",
      "check (1200,) ()\n",
      "epoch 166\n",
      "====================================\n",
      "Epoch:  166 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 152.51506764866983\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011986525729298592\n",
      "Cross Entropy:[0.4785658  0.32850668 0.9615692  ... 1.7647374  0.06026732 0.18849769]\n",
      "VE Training loss:0.945388674736023\n",
      "check (1095,) ()\n",
      "epoch 167\n",
      "====================================\n",
      "Epoch:  167 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1095.0\n",
      "Mean Reward of that batch 182.5\n",
      "Average Reward of all training: 152.69461814179155\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1095.0\n",
      "Training loss:1.5938118735903117e-07\n",
      "Cross Entropy:[0.72431904 0.19779405 0.7899102  ... 0.9865118  0.18114331 0.814107  ]\n",
      "VE Training loss:0.9698185324668884\n",
      "check (1136,) ()\n",
      "epoch 168\n",
      "====================================\n",
      "Epoch:  168 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1136.0\n",
      "Mean Reward of that batch 189.33333333333334\n",
      "Average Reward of all training: 152.91270573221738\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1136.0\n",
      "Training loss:0.006008793134242296\n",
      "Cross Entropy:[0.60601157 0.26079768 0.5854716  ... 0.18275125 0.5057938  0.36279362]\n",
      "VE Training loss:0.9841830730438232\n",
      "check (1163,) ()\n",
      "epoch 169\n",
      "====================================\n",
      "Epoch:  169 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1163.0\n",
      "Mean Reward of that batch 193.83333333333334\n",
      "Average Reward of all training: 153.15483962334824\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1163.0\n",
      "Training loss:0.005554540548473597\n",
      "Cross Entropy:[0.73737866 0.19178618 0.58403546 ... 0.563582   0.27198693 0.7907102 ]\n",
      "VE Training loss:0.9520485997200012\n",
      "check (1077,) ()\n",
      "epoch 170\n",
      "====================================\n",
      "Epoch:  170 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1077.0\n",
      "Mean Reward of that batch 179.5\n",
      "Average Reward of all training: 153.3098111549756\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1077.0\n",
      "Training loss:0.012514257803559303\n",
      "Cross Entropy:[0.68317264 0.21819013 0.6748696  ... 0.16120501 0.41398224 0.5049531 ]\n",
      "VE Training loss:0.9549795389175415\n",
      "Model saved\n",
      "check (1180,) ()\n",
      "epoch 171\n",
      "====================================\n",
      "Epoch:  171 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1180.0\n",
      "Mean Reward of that batch 196.66666666666666\n",
      "Average Reward of all training: 153.56336001761707\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1180.0\n",
      "Training loss:-0.011150502599775791\n",
      "Cross Entropy:[0.7990837  0.18143259 0.81647384 ... 0.40668032 1.0446858  0.1374123 ]\n",
      "VE Training loss:0.9457611441612244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1076,) ()\n",
      "epoch 172\n",
      "====================================\n",
      "Epoch:  172 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1076.0\n",
      "Mean Reward of that batch 179.33333333333334\n",
      "Average Reward of all training: 153.71318544387123\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1076.0\n",
      "Training loss:-0.003270538290962577\n",
      "Cross Entropy:[0.5203339  0.29378664 0.86797976 ... 0.14518872 1.0525761  0.14655045]\n",
      "VE Training loss:0.9186097979545593\n",
      "check (1062,) ()\n",
      "epoch 173\n",
      "====================================\n",
      "Epoch:  173 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1062.0\n",
      "Mean Reward of that batch 177.0\n",
      "Average Reward of all training: 153.84779130835753\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1062.0\n",
      "Training loss:0.012011063285171986\n",
      "Cross Entropy:[0.7459697  0.20223421 0.6503798  ... 0.41314057 0.89540243 0.2167224 ]\n",
      "VE Training loss:0.940028727054596\n",
      "check (1121,) ()\n",
      "epoch 174\n",
      "====================================\n",
      "Epoch:  174 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1121.0\n",
      "Mean Reward of that batch 186.83333333333334\n",
      "Average Reward of all training: 154.0373633889608\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1121.0\n",
      "Training loss:-0.0037003320176154375\n",
      "Cross Entropy:[0.5184302  0.29600406 0.8716945  ... 0.6227835  0.27625352 0.6928582 ]\n",
      "VE Training loss:0.9322399497032166\n",
      "check (1098,) ()\n",
      "epoch 175\n",
      "====================================\n",
      "Epoch:  175 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1098.0\n",
      "Mean Reward of that batch 183.0\n",
      "Average Reward of all training: 154.20286416959533\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1098.0\n",
      "Training loss:-0.006824959069490433\n",
      "Cross Entropy:[0.7175355  1.6972251  0.05824726 ... 0.21176255 0.62474555 0.26711205]\n",
      "VE Training loss:0.9438345432281494\n",
      "check (1126,) ()\n",
      "epoch 176\n",
      "====================================\n",
      "Epoch:  176 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1126.0\n",
      "Mean Reward of that batch 187.66666666666666\n",
      "Average Reward of all training: 154.39299941105597\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1126.0\n",
      "Training loss:-0.004570750053972006\n",
      "Cross Entropy:[0.6226576  0.25650916 0.5823429  ... 0.43065485 0.47580028 0.27914748]\n",
      "VE Training loss:0.9412763714790344\n",
      "check (1158,) ()\n",
      "epoch 177\n",
      "====================================\n",
      "Epoch:  177 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1158.0\n",
      "Mean Reward of that batch 193.0\n",
      "Average Reward of all training: 154.61111805845113\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1158.0\n",
      "Training loss:-0.005097608547657728\n",
      "Cross Entropy:[0.5771324  0.27995887 0.5402467  ... 0.04397144 0.12803003 0.377622  ]\n",
      "VE Training loss:0.9454651474952698\n",
      "check (1063,) ()\n",
      "epoch 178\n",
      "====================================\n",
      "Epoch:  178 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1063.0\n",
      "Mean Reward of that batch 177.16666666666666\n",
      "Average Reward of all training: 154.73783462366583\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1063.0\n",
      "Training loss:-0.013658912852406502\n",
      "Cross Entropy:[0.8212112  0.17222865 0.8777709  ... 0.6539139  1.4071256  0.09414973]\n",
      "VE Training loss:0.9478708505630493\n",
      "check (1015,) ()\n",
      "epoch 179\n",
      "====================================\n",
      "Epoch:  179 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1015.0\n",
      "Mean Reward of that batch 169.16666666666666\n",
      "Average Reward of all training: 154.81844262390607\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1015.0\n",
      "Training loss:0.001540960161946714\n",
      "Cross Entropy:[0.5649587 0.2620469 0.610502  ... 0.161692  1.0526451 2.098102 ]\n",
      "VE Training loss:0.910698413848877\n",
      "check (1133,) ()\n",
      "epoch 180\n",
      "====================================\n",
      "Epoch:  180 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1133.0\n",
      "Mean Reward of that batch 188.83333333333334\n",
      "Average Reward of all training: 155.00741423895843\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1133.0\n",
      "Training loss:-0.011455690488219261\n",
      "Cross Entropy:[0.6733969  0.21027268 0.62993544 ... 0.05739195 0.14016725 0.33188674]\n",
      "VE Training loss:0.8861184120178223\n",
      "Model saved\n",
      "check (1120,) ()\n",
      "epoch 181\n",
      "====================================\n",
      "Epoch:  181 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1120.0\n",
      "Mean Reward of that batch 186.66666666666666\n",
      "Average Reward of all training: 155.1823272357966\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1120.0\n",
      "Training loss:0.0013766748597845435\n",
      "Cross Entropy:[0.7313811  0.1895419  0.822999   ... 0.5068484  0.29863787 0.59705216]\n",
      "VE Training loss:0.9479616284370422\n",
      "check (1137,) ()\n",
      "epoch 182\n",
      "====================================\n",
      "Epoch:  182 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1137.0\n",
      "Mean Reward of that batch 189.5\n",
      "Average Reward of all training: 155.37088587735818\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1137.0\n",
      "Training loss:0.0026668214704841375\n",
      "Cross Entropy:[0.6850111  0.22076693 0.687779   ... 1.0543569  0.12467991 0.35794905]\n",
      "VE Training loss:0.9410431385040283\n",
      "check (1119,) ()\n",
      "epoch 183\n",
      "====================================\n",
      "Epoch:  183 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1119.0\n",
      "Mean Reward of that batch 186.5\n",
      "Average Reward of all training: 155.54099032611578\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1119.0\n",
      "Training loss:0.0038278321735560894\n",
      "Cross Entropy:[0.5944931  0.26492396 0.5685115  ... 0.71774226 0.2557723  0.55480975]\n",
      "VE Training loss:0.9356322884559631\n",
      "check (1183,) ()\n",
      "epoch 184\n",
      "====================================\n",
      "Epoch:  184 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1183.0\n",
      "Mean Reward of that batch 197.16666666666666\n",
      "Average Reward of all training: 155.7672168279666\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1183.0\n",
      "Training loss:-0.0014937828527763486\n",
      "Cross Entropy:[0.68800586 1.5840975  0.07235675 ... 0.09589849 0.2480826  0.5860516 ]\n",
      "VE Training loss:0.964886486530304\n",
      "check (1153,) ()\n",
      "epoch 185\n",
      "====================================\n",
      "Epoch:  185 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1153.0\n",
      "Mean Reward of that batch 192.16666666666666\n",
      "Average Reward of all training: 155.96397061087848\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1153.0\n",
      "Training loss:0.0014959948603063822\n",
      "Cross Entropy:[0.6855359  0.21565643 0.7079641  ... 0.1705874  0.5378108  0.31209046]\n",
      "VE Training loss:0.9980007410049438\n",
      "check (1169,) ()\n",
      "epoch 186\n",
      "====================================\n",
      "Epoch:  186 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1169.0\n",
      "Mean Reward of that batch 194.83333333333334\n",
      "Average Reward of all training: 156.17294567927877\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1169.0\n",
      "Training loss:-0.02508806250989437\n",
      "Cross Entropy:[0.7063607  0.2252657  0.7550547  ... 0.50017464 1.199048   2.1693118 ]\n",
      "VE Training loss:0.9546878933906555\n",
      "check (1072,) ()\n",
      "epoch 187\n",
      "====================================\n",
      "Epoch:  187 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1072.0\n",
      "Mean Reward of that batch 178.66666666666666\n",
      "Average Reward of all training: 156.2932329572862\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1072.0\n",
      "Training loss:-0.0044230506755411625\n",
      "Cross Entropy:[0.69652396 0.2000331  0.78289986 ... 0.2866254  0.84817827 1.8813398 ]\n",
      "VE Training loss:0.9402586817741394\n",
      "check (1200,) ()\n",
      "epoch 188\n",
      "====================================\n",
      "Epoch:  188 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 156.52571576070488\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.012385734356939793\n",
      "Cross Entropy:[0.7524383  0.19754088 0.6485825  ... 0.35293266 0.4663672  0.37928468]\n",
      "VE Training loss:0.9603920578956604\n",
      "check (1107,) ()\n",
      "epoch 189\n",
      "====================================\n",
      "Epoch:  189 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1107.0\n",
      "Mean Reward of that batch 184.5\n",
      "Average Reward of all training: 156.6737278466271\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1107.0\n",
      "Training loss:-0.024025917053222656\n",
      "Cross Entropy:[0.6001334  1.5599822  0.06460205 ... 0.7446507  0.20806645 0.77638686]\n",
      "VE Training loss:0.9344662427902222\n",
      "check (1063,) ()\n",
      "epoch 190\n",
      "====================================\n",
      "Epoch:  190 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1063.0\n",
      "Mean Reward of that batch 177.16666666666666\n",
      "Average Reward of all training: 156.78158541936415\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1063.0\n",
      "Training loss:-0.004724789876490831\n",
      "Cross Entropy:[0.7341957  0.19123615 0.79298735 ... 0.36241138 0.57523924 0.23286729]\n",
      "VE Training loss:1.004843831062317\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1144,) ()\n",
      "epoch 191\n",
      "====================================\n",
      "Epoch:  191 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1144.0\n",
      "Mean Reward of that batch 190.66666666666666\n",
      "Average Reward of all training: 156.95899422170604\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1144.0\n",
      "Training loss:-0.0028214554768055677\n",
      "Cross Entropy:[0.61974615 0.24710989 0.59379023 ... 1.0579131  0.12846322 1.2210128 ]\n",
      "VE Training loss:0.9285492897033691\n",
      "check (1181,) ()\n",
      "epoch 192\n",
      "====================================\n",
      "Epoch:  192 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1181.0\n",
      "Mean Reward of that batch 196.83333333333334\n",
      "Average Reward of all training: 157.16667307124575\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1181.0\n",
      "Training loss:0.0007132324972189963\n",
      "Cross Entropy:[0.5885524  0.25078857 0.6090099  ... 0.2614068  0.63253623 0.2718841 ]\n",
      "VE Training loss:0.981525719165802\n",
      "check (1168,) ()\n",
      "epoch 193\n",
      "====================================\n",
      "Epoch:  193 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1168.0\n",
      "Mean Reward of that batch 194.66666666666666\n",
      "Average Reward of all training: 157.36097355619611\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1168.0\n",
      "Training loss:0.0010169744491577148\n",
      "Cross Entropy:[0.64821273 0.23665883 0.7810315  ... 0.01056565 0.02319536 0.05246047]\n",
      "VE Training loss:0.9618682861328125\n",
      "check (1178,) ()\n",
      "epoch 194\n",
      "====================================\n",
      "Epoch:  194 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1178.0\n",
      "Mean Reward of that batch 196.33333333333334\n",
      "Average Reward of all training: 157.5618620086556\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1178.0\n",
      "Training loss:-0.002773631364107132\n",
      "Cross Entropy:[0.5972605  1.519497   0.07159954 ... 0.09746092 1.6472473  0.05951561]\n",
      "VE Training loss:0.9778414368629456\n",
      "check (1095,) ()\n",
      "epoch 195\n",
      "====================================\n",
      "Epoch:  195 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1095.0\n",
      "Mean Reward of that batch 182.5\n",
      "Average Reward of all training: 157.68974989579067\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1095.0\n",
      "Training loss:0.006665833294391632\n",
      "Cross Entropy:[0.5748482  0.24879237 0.75122106 ... 0.24138232 0.6845291  1.5759015 ]\n",
      "VE Training loss:0.9755637645721436\n",
      "check (1165,) ()\n",
      "epoch 196\n",
      "====================================\n",
      "Epoch:  196 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1165.0\n",
      "Mean Reward of that batch 194.16666666666666\n",
      "Average Reward of all training: 157.87585661400945\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1165.0\n",
      "Training loss:0.002391222631558776\n",
      "Cross Entropy:[0.8603753  0.15638557 0.9304546  ... 0.5342437  0.31082156 0.54510814]\n",
      "VE Training loss:0.9677411913871765\n",
      "check (1200,) ()\n",
      "epoch 197\n",
      "====================================\n",
      "Epoch:  197 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 158.0896847530246\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0005429188604466617\n",
      "Cross Entropy:[0.7994434  0.16764435 0.5132125  ... 0.51832205 1.0656165  1.8419857 ]\n",
      "VE Training loss:0.9884445071220398\n",
      "check (1200,) ()\n",
      "epoch 198\n",
      "====================================\n",
      "Epoch:  198 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 158.30135301184774\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006189870648086071\n",
      "Cross Entropy:[0.6655221  0.23840225 0.6081026  ... 0.9491034  0.15034899 0.9868534 ]\n",
      "VE Training loss:0.9861453175544739\n",
      "check (1200,) ()\n",
      "epoch 199\n",
      "====================================\n",
      "Epoch:  199 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 158.51089395148668\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004416137468069792\n",
      "Cross Entropy:[0.6877392  0.22027193 0.68182534 ... 0.1351593  0.35955307 0.5767154 ]\n",
      "VE Training loss:0.9807917475700378\n",
      "check (1200,) ()\n",
      "epoch 200\n",
      "====================================\n",
      "Epoch:  200 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 158.71833948172926\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.010090087540447712\n",
      "Cross Entropy:[0.53102446 1.3372927  0.09473263 ... 0.4831258  1.0695626  0.16213304]\n",
      "VE Training loss:0.9929684400558472\n",
      "Model saved\n",
      "check (1156,) ()\n",
      "epoch 201\n",
      "====================================\n",
      "Epoch:  201 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1156.0\n",
      "Mean Reward of that batch 192.66666666666666\n",
      "Average Reward of all training: 158.88723663190308\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1156.0\n",
      "Training loss:-0.0024348022416234016\n",
      "Cross Entropy:[0.6262835  0.23529881 0.6912017  ... 2.0920262  0.0500416  0.11436751]\n",
      "VE Training loss:0.964293360710144\n",
      "check (1200,) ()\n",
      "epoch 202\n",
      "====================================\n",
      "Epoch:  202 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 159.0907651634283\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.005304017104208469\n",
      "Cross Entropy:[0.84306747 1.8457679  0.05234972 ... 0.59144634 0.31804624 0.7880324 ]\n",
      "VE Training loss:1.0167245864868164\n",
      "check (1200,) ()\n",
      "epoch 203\n",
      "====================================\n",
      "Epoch:  203 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 159.2922884877464\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0013176961801946163\n",
      "Cross Entropy:[0.5891738  0.28282994 0.5333656  ... 0.33579615 0.4205212  0.5157058 ]\n",
      "VE Training loss:0.9973219037055969\n",
      "check (1124,) ()\n",
      "epoch 204\n",
      "====================================\n",
      "Epoch:  204 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1124.0\n",
      "Mean Reward of that batch 187.33333333333334\n",
      "Average Reward of all training: 159.42974458993064\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1124.0\n",
      "Training loss:0.0003578858159016818\n",
      "Cross Entropy:[0.6451065  0.2431336  0.75221    ... 0.95253164 0.13022734 0.37468848]\n",
      "VE Training loss:0.9814150333404541\n",
      "check (1200,) ()\n",
      "epoch 205\n",
      "====================================\n",
      "Epoch:  205 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 159.62764827485782\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005802782252430916\n",
      "Cross Entropy:[0.80693763 0.18623304 0.59177023 ... 0.06930911 0.22987515 0.70424277]\n",
      "VE Training loss:0.999325156211853\n",
      "check (1200,) ()\n",
      "epoch 206\n",
      "====================================\n",
      "Epoch:  206 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 159.8236305647857\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0027711004950106144\n",
      "Cross Entropy:[0.61934525 0.24986678 0.7468341  ... 1.4571782  0.08113847 0.26609138]\n",
      "VE Training loss:0.9971995949745178\n",
      "check (1160,) ()\n",
      "epoch 207\n",
      "====================================\n",
      "Epoch:  207 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1160.0\n",
      "Mean Reward of that batch 193.33333333333334\n",
      "Average Reward of all training: 159.98551318685597\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1160.0\n",
      "Training loss:-0.0035302401520311832\n",
      "Cross Entropy:[0.9431333  0.14174536 0.4162526  ... 0.30898657 0.82784784 0.20394026]\n",
      "VE Training loss:0.9972538352012634\n",
      "check (1189,) ()\n",
      "epoch 208\n",
      "====================================\n",
      "Epoch:  208 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1189.0\n",
      "Mean Reward of that batch 198.16666666666666\n",
      "Average Reward of all training: 160.16907642473967\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1189.0\n",
      "Training loss:0.0030818278901278973\n",
      "Cross Entropy:[0.6132959  0.2640725  0.59841764 ... 1.823301   0.06476184 0.20599107]\n",
      "VE Training loss:1.0110089778900146\n",
      "check (1181,) ()\n",
      "epoch 209\n",
      "====================================\n",
      "Epoch:  209 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1181.0\n",
      "Mean Reward of that batch 196.83333333333334\n",
      "Average Reward of all training: 160.34450349128795\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1181.0\n",
      "Training loss:0.010822426527738571\n",
      "Cross Entropy:[0.77739656 0.1987135  0.61679643 ... 1.0785261  0.09884112 0.22785209]\n",
      "VE Training loss:1.016862392425537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1184,) ()\n",
      "epoch 210\n",
      "====================================\n",
      "Epoch:  210 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1184.0\n",
      "Mean Reward of that batch 197.33333333333334\n",
      "Average Reward of all training: 160.52064077625008\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1184.0\n",
      "Training loss:-0.004868335090577602\n",
      "Cross Entropy:[0.75998676 1.6496638  0.06916384 ... 1.1146573  0.09892675 1.6232429 ]\n",
      "VE Training loss:0.9711143970489502\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 211\n",
      "====================================\n",
      "Epoch:  211 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 160.70774674413516\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.00675421254709363\n",
      "Cross Entropy:[0.8561737  0.1691455  0.919852   ... 0.41483006 0.38186666 0.43766946]\n",
      "VE Training loss:1.0215065479278564\n",
      "check (1200,) ()\n",
      "epoch 212\n",
      "====================================\n",
      "Epoch:  212 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 160.89308756137982\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.006804824806749821\n",
      "Cross Entropy:[0.5021051  0.31845668 0.8856565  ... 0.50830406 0.32892638 0.52751315]\n",
      "VE Training loss:1.0002299547195435\n",
      "check (1097,) ()\n",
      "epoch 213\n",
      "====================================\n",
      "Epoch:  213 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1097.0\n",
      "Mean Reward of that batch 182.83333333333334\n",
      "Average Reward of all training: 160.9960934100744\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1097.0\n",
      "Training loss:0.002985082333907485\n",
      "Cross Entropy:[0.7559368  0.1987349  0.8216802  ... 0.2907545  0.811512   0.20024563]\n",
      "VE Training loss:0.9956973791122437\n",
      "check (1171,) ()\n",
      "epoch 214\n",
      "====================================\n",
      "Epoch:  214 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1171.0\n",
      "Mean Reward of that batch 195.16666666666666\n",
      "Average Reward of all training: 161.15576898603982\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1171.0\n",
      "Training loss:0.007437844295054674\n",
      "Cross Entropy:[1.0046294  0.13387758 0.38729504 ... 0.51071966 0.30741712 0.6586492 ]\n",
      "VE Training loss:1.0032944679260254\n",
      "check (1200,) ()\n",
      "epoch 215\n",
      "====================================\n",
      "Epoch:  215 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 161.3364398279652\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0064313714392483234\n",
      "Cross Entropy:[0.92416596 0.17109798 0.85795665 ... 1.4551585  0.0856802  0.2696595 ]\n",
      "VE Training loss:1.0115253925323486\n",
      "check (1115,) ()\n",
      "epoch 216\n",
      "====================================\n",
      "Epoch:  216 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1115.0\n",
      "Mean Reward of that batch 185.83333333333334\n",
      "Average Reward of all training: 161.44985137197156\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1115.0\n",
      "Training loss:0.002458424074575305\n",
      "Cross Entropy:[0.7651614  0.19339019 0.8734044  ... 0.09790137 0.26636404 0.7329754 ]\n",
      "VE Training loss:0.9702674150466919\n",
      "check (1200,) ()\n",
      "epoch 217\n",
      "====================================\n",
      "Epoch:  217 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 161.62750182647858\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.018830830231308937\n",
      "Cross Entropy:[0.92270106 0.15671849 0.9984955  ... 0.09448764 0.27359265 0.73847103]\n",
      "VE Training loss:0.9918124675750732\n",
      "check (1200,) ()\n",
      "epoch 218\n",
      "====================================\n",
      "Epoch:  218 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 161.80352246030208\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.007177668623626232\n",
      "Cross Entropy:[0.6451286  0.2581178  0.61956394 ... 0.04949139 0.14672288 0.42512807]\n",
      "VE Training loss:0.9840447902679443\n",
      "check (1074,) ()\n",
      "epoch 219\n",
      "====================================\n",
      "Epoch:  219 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1074.0\n",
      "Mean Reward of that batch 179.0\n",
      "Average Reward of all training: 161.88204518879385\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1074.0\n",
      "Training loss:0.00888805277645588\n",
      "Cross Entropy:[0.7336143  0.20252047 0.56682837 ... 0.26412743 0.8599012  0.13833848]\n",
      "VE Training loss:0.9384963512420654\n",
      "check (1200,) ()\n",
      "epoch 220\n",
      "====================================\n",
      "Epoch:  220 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 162.05530861975387\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.000382417842047289\n",
      "Cross Entropy:[0.9156593  0.15426467 0.45193747 ... 0.8112196  1.8136113  0.05055728]\n",
      "VE Training loss:0.9793060421943665\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 221\n",
      "====================================\n",
      "Epoch:  221 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 162.2270040558636\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.011684004217386246\n",
      "Cross Entropy:[0.69148266 0.24557577 0.77159595 ... 0.09325194 0.27314967 0.62698716]\n",
      "VE Training loss:0.9557350873947144\n",
      "check (1127,) ()\n",
      "epoch 222\n",
      "====================================\n",
      "Epoch:  222 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1127.0\n",
      "Mean Reward of that batch 187.83333333333334\n",
      "Average Reward of all training: 162.34234788143777\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1127.0\n",
      "Training loss:0.0005233302363194525\n",
      "Cross Entropy:[0.5069888  0.3087456  0.55436647 ... 0.3725466  0.41741025 1.0039644 ]\n",
      "VE Training loss:0.9792080521583557\n",
      "check (1178,) ()\n",
      "epoch 223\n",
      "====================================\n",
      "Epoch:  223 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1178.0\n",
      "Mean Reward of that batch 196.33333333333334\n",
      "Average Reward of all training: 162.49477382516824\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1178.0\n",
      "Training loss:-0.0013178904773667455\n",
      "Cross Entropy:[0.47377858 1.2123071  0.11488667 ... 0.13490622 0.39939454 0.44299394]\n",
      "VE Training loss:0.966928243637085\n",
      "check (1179,) ()\n",
      "epoch 224\n",
      "====================================\n",
      "Epoch:  224 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1179.0\n",
      "Mean Reward of that batch 196.5\n",
      "Average Reward of all training: 162.6465828705916\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1179.0\n",
      "Training loss:-0.0007735754479654133\n",
      "Cross Entropy:[0.58561987 0.2502397  0.6826683  ... 0.72835076 0.22679736 0.7414457 ]\n",
      "VE Training loss:0.9266115427017212\n",
      "check (1116,) ()\n",
      "epoch 225\n",
      "====================================\n",
      "Epoch:  225 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1116.0\n",
      "Mean Reward of that batch 186.0\n",
      "Average Reward of all training: 162.75037583561118\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1116.0\n",
      "Training loss:0.020947061479091644\n",
      "Cross Entropy:[0.6657946  0.25080135 0.58711237 ... 0.2077991  0.7149711  0.2278535 ]\n",
      "VE Training loss:0.938814640045166\n",
      "check (1173,) ()\n",
      "epoch 226\n",
      "====================================\n",
      "Epoch:  226 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1173.0\n",
      "Mean Reward of that batch 195.5\n",
      "Average Reward of all training: 162.89528567704653\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1173.0\n",
      "Training loss:-0.010306784883141518\n",
      "Cross Entropy:[0.47430003 1.2295952  0.11016624 ... 0.01216822 0.02526661 0.05405448]\n",
      "VE Training loss:0.95549076795578\n",
      "check (1200,) ()\n",
      "epoch 227\n",
      "====================================\n",
      "Epoch:  227 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 163.0587425683371\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.003298493567854166\n",
      "Cross Entropy:[0.9490812  0.15349464 0.9296988  ... 0.49520645 0.29635468 0.75180936]\n",
      "VE Training loss:0.9646478295326233\n",
      "check (1127,) ()\n",
      "epoch 228\n",
      "====================================\n",
      "Epoch:  228 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1127.0\n",
      "Mean Reward of that batch 187.83333333333334\n",
      "Average Reward of all training: 163.16740305414848\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1127.0\n",
      "Training loss:0.0008457127842120826\n",
      "Cross Entropy:[0.3950473  0.4307941  1.2076058  ... 0.14757405 0.44324696 0.40379375]\n",
      "VE Training loss:0.9446429014205933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1180,) ()\n",
      "epoch 229\n",
      "====================================\n",
      "Epoch:  229 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1180.0\n",
      "Mean Reward of that batch 196.66666666666666\n",
      "Average Reward of all training: 163.3136880480896\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1180.0\n",
      "Training loss:0.012485774233937263\n",
      "Cross Entropy:[0.6910589  0.21544002 0.7490305  ... 0.3742536  0.41583183 0.56020075]\n",
      "VE Training loss:0.9530219435691833\n",
      "check (1164,) ()\n",
      "epoch 230\n",
      "====================================\n",
      "Epoch:  230 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1164.0\n",
      "Mean Reward of that batch 194.0\n",
      "Average Reward of all training: 163.44710679570662\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1164.0\n",
      "Training loss:-0.008193887770175934\n",
      "Cross Entropy:[0.89338183 0.15326467 0.45949057 ... 0.18489926 0.62229747 0.2353302 ]\n",
      "VE Training loss:0.9432901740074158\n",
      "Model saved\n",
      "check (1175,) ()\n",
      "epoch 231\n",
      "====================================\n",
      "Epoch:  231 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1175.0\n",
      "Mean Reward of that batch 195.83333333333334\n",
      "Average Reward of all training: 163.58730691058813\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1175.0\n",
      "Training loss:-0.0022914723958820105\n",
      "Cross Entropy:[0.6287858  0.24060617 0.702082   ... 0.66333926 0.2595655  0.689753  ]\n",
      "VE Training loss:0.950764000415802\n",
      "check (1200,) ()\n",
      "epoch 232\n",
      "====================================\n",
      "Epoch:  232 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 163.74425817390454\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.010907202959060669\n",
      "Cross Entropy:[0.7558697  0.192055   0.82924736 ... 0.6504463  1.5587137  0.0641991 ]\n",
      "VE Training loss:0.9478546380996704\n",
      "check (1200,) ()\n",
      "epoch 233\n",
      "====================================\n",
      "Epoch:  233 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 163.89986221607663\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.006904483772814274\n",
      "Cross Entropy:[0.80793345 0.18117893 0.5685294  ... 0.46820307 0.33436927 0.5645781 ]\n",
      "VE Training loss:0.9498321413993835\n",
      "check (1200,) ()\n",
      "epoch 234\n",
      "====================================\n",
      "Epoch:  234 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.05413630917033\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.001985270995646715\n",
      "Cross Entropy:[0.67474645 1.6140648  0.06622103 ... 1.0133574  0.14169519 0.45051172]\n",
      "VE Training loss:0.9331489205360413\n",
      "check (1110,) ()\n",
      "epoch 235\n",
      "====================================\n",
      "Epoch:  235 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1110.0\n",
      "Mean Reward of that batch 185.0\n",
      "Average Reward of all training: 164.14326764402492\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1110.0\n",
      "Training loss:0.006887617986649275\n",
      "Cross Entropy:[0.6468591  0.22001386 0.7548804  ... 0.30716646 0.5187645  0.3314432 ]\n",
      "VE Training loss:0.9435641169548035\n",
      "check (1151,) ()\n",
      "epoch 236\n",
      "====================================\n",
      "Epoch:  236 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1151.0\n",
      "Mean Reward of that batch 191.83333333333334\n",
      "Average Reward of all training: 164.260598430844\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1151.0\n",
      "Training loss:0.00920812040567398\n",
      "Cross Entropy:[0.94304    0.1557241  0.52867407 ... 0.2542048  0.5103268  1.1542643 ]\n",
      "VE Training loss:0.9356162548065186\n",
      "check (1200,) ()\n",
      "epoch 237\n",
      "====================================\n",
      "Epoch:  237 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.41139759358305\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.008441462181508541\n",
      "Cross Entropy:[0.741786   0.19961305 0.62336046 ... 1.0138025  0.12870882 1.0883464 ]\n",
      "VE Training loss:0.9755326509475708\n",
      "check (1163,) ()\n",
      "epoch 238\n",
      "====================================\n",
      "Epoch:  238 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1163.0\n",
      "Mean Reward of that batch 193.83333333333334\n",
      "Average Reward of all training: 164.5350191723215\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1163.0\n",
      "Training loss:-0.01756184548139572\n",
      "Cross Entropy:[0.59074396 0.24648336 0.7277564  ... 1.0643741  2.120231   0.03758192]\n",
      "VE Training loss:0.9532908201217651\n",
      "check (1200,) ()\n",
      "epoch 239\n",
      "====================================\n",
      "Epoch:  239 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.6834082134415\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0014974975492805243\n",
      "Cross Entropy:[0.5821647  0.24560198 0.712742   ... 0.27773264 0.7809988  0.20267838]\n",
      "VE Training loss:0.9356278777122498\n",
      "check (1200,) ()\n",
      "epoch 240\n",
      "====================================\n",
      "Epoch:  240 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.83056067921882\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.009964149445295334\n",
      "Cross Entropy:[0.46979478 1.3014843  0.09135614 ... 0.71646357 0.23337074 0.6372232 ]\n",
      "VE Training loss:0.9836854934692383\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 241\n",
      "====================================\n",
      "Epoch:  241 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 164.97649196270754\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.001201509265229106\n",
      "Cross Entropy:[0.6025435  0.27075064 0.888546   ... 0.74083126 0.19582112 0.58729553]\n",
      "VE Training loss:0.9378211498260498\n",
      "check (1071,) ()\n",
      "epoch 242\n",
      "====================================\n",
      "Epoch:  242 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1071.0\n",
      "Mean Reward of that batch 178.5\n",
      "Average Reward of all training: 165.03237422732445\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1071.0\n",
      "Training loss:-0.013866438530385494\n",
      "Cross Entropy:[0.7260382  1.7314383  0.05565216 ... 0.54309064 1.4263577  2.5917459 ]\n",
      "VE Training loss:0.991308867931366\n",
      "check (1200,) ()\n",
      "epoch 243\n",
      "====================================\n",
      "Epoch:  243 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.17627392186222\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.002786720637232065\n",
      "Cross Entropy:[0.6340364  0.24317792 0.60260737 ... 0.16641544 0.47210824 0.37893197]\n",
      "VE Training loss:0.9722062945365906\n",
      "check (1200,) ()\n",
      "epoch 244\n",
      "====================================\n",
      "Epoch:  244 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.31899411070705\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0028826880734413862\n",
      "Cross Entropy:[0.8372876  0.17365289 0.8035011  ... 1.4959129  0.07374931 1.4629626 ]\n",
      "VE Training loss:0.9741281270980835\n",
      "check (1200,) ()\n",
      "epoch 245\n",
      "====================================\n",
      "Epoch:  245 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.4605492367858\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.003351453924551606\n",
      "Cross Entropy:[0.7334741  1.6748735  2.8022888  ... 0.7601971  0.17967443 0.84233606]\n",
      "VE Training loss:0.9941600561141968\n",
      "check (1200,) ()\n",
      "epoch 246\n",
      "====================================\n",
      "Epoch:  246 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.60095350818096\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.002922812243923545\n",
      "Cross Entropy:[0.7108087  0.19164073 0.7849743  ... 1.5226299  0.06810781 0.2342324 ]\n",
      "VE Training loss:0.9749245047569275\n",
      "check (1198,) ()\n",
      "epoch 247\n",
      "====================================\n",
      "Epoch:  247 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1198.0\n",
      "Mean Reward of that batch 199.66666666666666\n",
      "Average Reward of all training: 165.7388713752194\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1198.0\n",
      "Training loss:-0.018735427409410477\n",
      "Cross Entropy:[0.8024976  0.17612222 0.590757   ... 0.07879952 0.25995606 0.59334236]\n",
      "VE Training loss:0.999729573726654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 248\n",
      "====================================\n",
      "Epoch:  248 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 165.8770210874161\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.019271310418844223\n",
      "Cross Entropy:[0.70500195 0.20107557 0.7260556  ... 1.6246624  0.05459621 0.16785735]\n",
      "VE Training loss:0.9972675442695618\n",
      "check (1200,) ()\n",
      "epoch 249\n",
      "====================================\n",
      "Epoch:  249 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.0140611633702\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.005751046352088451\n",
      "Cross Entropy:[0.46848983 0.3357164  1.0608981  ... 0.46601075 0.34209624 1.0095166 ]\n",
      "VE Training loss:1.012027621269226\n",
      "check (1200,) ()\n",
      "epoch 250\n",
      "====================================\n",
      "Epoch:  250 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.15000491871672\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0005015619681216776\n",
      "Cross Entropy:[0.60136014 1.5632954  0.06408965 ... 0.2689887  0.52313626 0.33578354]\n",
      "VE Training loss:0.9995720386505127\n",
      "Model saved\n",
      "check (1169,) ()\n",
      "epoch 251\n",
      "====================================\n",
      "Epoch:  251 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1169.0\n",
      "Mean Reward of that batch 194.83333333333334\n",
      "Average Reward of all training: 166.2642811275399\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1169.0\n",
      "Training loss:-0.012081735767424107\n",
      "Cross Entropy:[0.6792685  1.7045357  0.05376058 ... 1.0792952  0.1163116  1.0740061 ]\n",
      "VE Training loss:1.0025230646133423\n",
      "check (1197,) ()\n",
      "epoch 252\n",
      "====================================\n",
      "Epoch:  252 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1197.0\n",
      "Mean Reward of that batch 199.5\n",
      "Average Reward of all training: 166.39616890084332\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1197.0\n",
      "Training loss:-0.006942068692296743\n",
      "Cross Entropy:[0.85698736 0.15506749 0.5357962  ... 0.8231589  0.16744836 0.8748454 ]\n",
      "VE Training loss:1.0288703441619873\n",
      "check (1200,) ()\n",
      "epoch 253\n",
      "====================================\n",
      "Epoch:  253 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.52899036763841\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004454352892935276\n",
      "Cross Entropy:[0.7315059  0.18855989 0.74507284 ... 1.2754811  0.09981558 0.3680367 ]\n",
      "VE Training loss:1.000254511833191\n",
      "check (1200,) ()\n",
      "epoch 254\n",
      "====================================\n",
      "Epoch:  254 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.66076599611227\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0053686280734837055\n",
      "Cross Entropy:[0.74827236 0.19274302 0.69126666 ... 0.27413374 0.7101023  0.17499365]\n",
      "VE Training loss:1.0269966125488281\n",
      "check (1125,) ()\n",
      "epoch 255\n",
      "====================================\n",
      "Epoch:  255 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1125.0\n",
      "Mean Reward of that batch 187.5\n",
      "Average Reward of all training: 166.74248848240202\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1125.0\n",
      "Training loss:0.008338847197592258\n",
      "Cross Entropy:[0.6638362  0.21261449 0.6404712  ... 0.27254698 0.5338174  0.27336103]\n",
      "VE Training loss:0.9843549132347107\n",
      "check (1200,) ()\n",
      "epoch 256\n",
      "====================================\n",
      "Epoch:  256 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 166.87240063676765\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.009597858414053917\n",
      "Cross Entropy:[0.75108457 0.18401016 0.71587574 ... 0.46607223 0.3264256  0.4266155 ]\n",
      "VE Training loss:0.9979495406150818\n",
      "check (1180,) ()\n",
      "epoch 257\n",
      "====================================\n",
      "Epoch:  257 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1180.0\n",
      "Mean Reward of that batch 196.66666666666666\n",
      "Average Reward of all training: 166.98833163299292\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1180.0\n",
      "Training loss:-0.014496726915240288\n",
      "Cross Entropy:[0.81675476 1.9466374  0.04034142 ... 0.37824243 0.35756788 0.4628417 ]\n",
      "VE Training loss:1.0072828531265259\n",
      "check (1200,) ()\n",
      "epoch 258\n",
      "====================================\n",
      "Epoch:  258 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.11628383596582\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0012603199575096369\n",
      "Cross Entropy:[0.8864274  0.13347188 0.4564938  ... 0.23428257 0.54141444 0.31494692]\n",
      "VE Training loss:1.0312718152999878\n",
      "check (1200,) ()\n",
      "epoch 259\n",
      "====================================\n",
      "Epoch:  259 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.2432479910393\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.016111109405755997\n",
      "Cross Entropy:[0.59466136 0.22318132 0.7564517  ... 0.06558867 0.20184256 0.78407395]\n",
      "VE Training loss:0.9846486449241638\n",
      "check (1200,) ()\n",
      "epoch 260\n",
      "====================================\n",
      "Epoch:  260 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.3692354987661\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.003385957097634673\n",
      "Cross Entropy:[0.4873281  0.30275556 1.0590429  ... 0.7285619  0.20803702 0.6122308 ]\n",
      "VE Training loss:1.0397719144821167\n",
      "Model saved\n",
      "check (1149,) ()\n",
      "epoch 261\n",
      "====================================\n",
      "Epoch:  261 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1149.0\n",
      "Mean Reward of that batch 191.5\n",
      "Average Reward of all training: 167.46169053516928\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1149.0\n",
      "Training loss:0.01452761422842741\n",
      "Cross Entropy:[0.5962414  0.22113787 0.7744699  ... 0.7753485  0.23195925 0.57576084]\n",
      "VE Training loss:1.0310382843017578\n",
      "check (1151,) ()\n",
      "epoch 262\n",
      "====================================\n",
      "Epoch:  262 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1151.0\n",
      "Mean Reward of that batch 191.83333333333334\n",
      "Average Reward of all training: 167.55471207256687\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1151.0\n",
      "Training loss:-0.00243670167401433\n",
      "Cross Entropy:[0.6800529  0.18539208 0.7483496  ... 0.05839919 0.17982522 0.50689155]\n",
      "VE Training loss:1.013279676437378\n",
      "check (1200,) ()\n",
      "epoch 263\n",
      "====================================\n",
      "Epoch:  263 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.6780781863594\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.01294122263789177\n",
      "Cross Entropy:[0.6698704  0.181466   0.782337   ... 0.7380796  0.14881648 0.43896845]\n",
      "VE Training loss:1.0098048448562622\n",
      "check (1200,) ()\n",
      "epoch 264\n",
      "====================================\n",
      "Epoch:  264 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 167.80050970838076\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.008883425034582615\n",
      "Cross Entropy:[0.5041475  0.29257417 0.43418986 ... 0.22999516 0.83987385 0.13351287]\n",
      "VE Training loss:1.0028914213180542\n",
      "check (1190,) ()\n",
      "epoch 265\n",
      "====================================\n",
      "Epoch:  265 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1190.0\n",
      "Mean Reward of that batch 198.33333333333334\n",
      "Average Reward of all training: 167.91572791073907\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1190.0\n",
      "Training loss:-0.01840272545814514\n",
      "Cross Entropy:[0.7301729  0.17491868 0.6341872  ... 2.2352877  0.02054389 0.0535519 ]\n",
      "VE Training loss:0.9898749589920044\n",
      "check (1200,) ()\n",
      "epoch 266\n",
      "====================================\n",
      "Epoch:  266 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.03634547498442\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.004190314561128616\n",
      "Cross Entropy:[0.74061143 0.18122974 0.69763047 ... 1.3752176  0.07084941 0.24651094]\n",
      "VE Training loss:0.9876644611358643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 267\n",
      "====================================\n",
      "Epoch:  267 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.15605953687586\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.00366887915879488\n",
      "Cross Entropy:[0.6950828  0.2007609  0.62130463 ... 0.07284842 0.28240633 0.52356076]\n",
      "VE Training loss:0.9842110276222229\n",
      "check (1200,) ()\n",
      "epoch 268\n",
      "====================================\n",
      "Epoch:  268 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.27488021024573\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0022394387051463127\n",
      "Cross Entropy:[0.7708742  0.15891778 0.83327043 ... 0.2583155  0.50551367 0.31176725]\n",
      "VE Training loss:1.0349596738815308\n",
      "check (1200,) ()\n",
      "epoch 269\n",
      "====================================\n",
      "Epoch:  269 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.39281745853478\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.001775971264578402\n",
      "Cross Entropy:[0.56518435 1.5429798  0.06305835 ... 0.07757107 0.23763084 0.69654447]\n",
      "VE Training loss:1.025596022605896\n",
      "check (1107,) ()\n",
      "epoch 270\n",
      "====================================\n",
      "Epoch:  270 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1107.0\n",
      "Mean Reward of that batch 184.5\n",
      "Average Reward of all training: 168.45247369016982\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1107.0\n",
      "Training loss:-0.010830666869878769\n",
      "Cross Entropy:[0.5546142  0.26262975 0.48337445 ... 0.17666984 0.7055223  0.178808  ]\n",
      "VE Training loss:1.009291648864746\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 271\n",
      "====================================\n",
      "Epoch:  271 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.56888522636848\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0011625726474449039\n",
      "Cross Entropy:[0.92244434 0.12479281 0.45179012 ... 0.13735701 0.4392295  0.36915272]\n",
      "VE Training loss:1.0151110887527466\n",
      "check (1197,) ()\n",
      "epoch 272\n",
      "====================================\n",
      "Epoch:  272 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1197.0\n",
      "Mean Reward of that batch 199.5\n",
      "Average Reward of all training: 168.68260256009506\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1197.0\n",
      "Training loss:0.007781748194247484\n",
      "Cross Entropy:[0.6318622  0.19982529 0.7010209  ... 0.07187337 0.21580218 0.60082424]\n",
      "VE Training loss:1.021193265914917\n",
      "check (1143,) ()\n",
      "epoch 273\n",
      "====================================\n",
      "Epoch:  273 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1143.0\n",
      "Mean Reward of that batch 190.5\n",
      "Average Reward of all training: 168.76251976683463\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1143.0\n",
      "Training loss:-0.015543436631560326\n",
      "Cross Entropy:[0.7099122  0.1728795  0.6013856  ... 0.31825283 0.86859477 0.17180549]\n",
      "VE Training loss:1.0243724584579468\n",
      "check (1115,) ()\n",
      "epoch 274\n",
      "====================================\n",
      "Epoch:  274 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1115.0\n",
      "Mean Reward of that batch 185.83333333333334\n",
      "Average Reward of all training: 168.82482200612841\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1115.0\n",
      "Training loss:-0.000884003471583128\n",
      "Cross Entropy:[0.7662147  0.1498742  0.8923877  ... 0.16781723 1.1418161  0.08698431]\n",
      "VE Training loss:1.0137913227081299\n",
      "check (1200,) ()\n",
      "epoch 275\n",
      "====================================\n",
      "Epoch:  275 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 168.93818628974248\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0035326986107975245\n",
      "Cross Entropy:[0.7104312  0.17287128 0.7730578  ... 0.8718935  0.13435481 0.4603505 ]\n",
      "VE Training loss:1.009884238243103\n",
      "check (1184,) ()\n",
      "epoch 276\n",
      "====================================\n",
      "Epoch:  276 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1184.0\n",
      "Mean Reward of that batch 197.33333333333334\n",
      "Average Reward of all training: 169.04106725729173\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1184.0\n",
      "Training loss:0.007076622452586889\n",
      "Cross Entropy:[0.586485   0.23929234 0.5313598  ... 2.3256166  0.01915399 0.04755946]\n",
      "VE Training loss:0.9923155307769775\n",
      "check (1200,) ()\n",
      "epoch 277\n",
      "====================================\n",
      "Epoch:  277 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.1528323574459\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.008593975566327572\n",
      "Cross Entropy:[0.6776915  0.17849901 0.76007843 ... 0.5321593  0.2492258  0.5566759 ]\n",
      "VE Training loss:1.0160995721817017\n",
      "check (1200,) ()\n",
      "epoch 278\n",
      "====================================\n",
      "Epoch:  278 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.26379339213136\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0019181915558874607\n",
      "Cross Entropy:[0.5354127  0.25097528 0.53505635 ... 0.29350457 0.9082585  0.13915865]\n",
      "VE Training loss:0.9822908639907837\n",
      "check (1200,) ()\n",
      "epoch 279\n",
      "====================================\n",
      "Epoch:  279 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.37395900721333\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0003852748777717352\n",
      "Cross Entropy:[0.7045117  1.8495792  0.04083008 ... 0.48809028 1.4638213  0.0583334 ]\n",
      "VE Training loss:0.9938045144081116\n",
      "check (1200,) ()\n",
      "epoch 280\n",
      "====================================\n",
      "Epoch:  280 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.48333772504472\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.00045364259858615696\n",
      "Cross Entropy:[0.68998265 0.19325538 0.67740834 ... 0.3190982  1.028841   2.243621  ]\n",
      "VE Training loss:0.9896093606948853\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 281\n",
      "====================================\n",
      "Epoch:  281 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.59193794666376\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0064739990048110485\n",
      "Cross Entropy:[0.73666644 0.18614556 0.68995285 ... 0.14822213 0.9875746  0.12415433]\n",
      "VE Training loss:0.9876881837844849\n",
      "check (1200,) ()\n",
      "epoch 282\n",
      "====================================\n",
      "Epoch:  282 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.6997679539451\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.00420547416433692\n",
      "Cross Entropy:[0.7541642  0.18427889 0.69962645 ... 0.23912689 0.64159495 0.27647197]\n",
      "VE Training loss:0.9850453734397888\n",
      "check (1200,) ()\n",
      "epoch 283\n",
      "====================================\n",
      "Epoch:  283 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.806835911705\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0026479267980903387\n",
      "Cross Entropy:[0.6580927  0.20877141 0.6505621  ... 0.3882881  0.36940745 0.41783485]\n",
      "VE Training loss:1.0048837661743164\n",
      "check (1200,) ()\n",
      "epoch 284\n",
      "====================================\n",
      "Epoch:  284 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 169.91314986976238\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0021490741055458784\n",
      "Cross Entropy:[0.72831845 1.7935972  0.04763835 ... 0.2634237  0.6105726  1.6737405 ]\n",
      "VE Training loss:0.9787531495094299\n",
      "check (1200,) ()\n",
      "epoch 285\n",
      "====================================\n",
      "Epoch:  285 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.0187177649562\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.010610876604914665\n",
      "Cross Entropy:[0.873611   0.14772885 0.88325346 ... 0.80686194 1.7673212  0.05694611]\n",
      "VE Training loss:1.000814437866211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 286\n",
      "====================================\n",
      "Epoch:  286 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.1235474231207\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.003728570183739066\n",
      "Cross Entropy:[0.65642726 0.20016816 0.67206156 ... 0.23446363 0.8311931  1.9739044 ]\n",
      "VE Training loss:0.9813210964202881\n",
      "check (1096,) ()\n",
      "epoch 287\n",
      "====================================\n",
      "Epoch:  287 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1096.0\n",
      "Mean Reward of that batch 182.66666666666666\n",
      "Average Reward of all training: 170.16725167135604\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1096.0\n",
      "Training loss:0.016981318593025208\n",
      "Cross Entropy:[0.6016152  0.22819307 0.61461985 ... 0.79723704 0.18074073 0.8055097 ]\n",
      "VE Training loss:0.9863051772117615\n",
      "check (1200,) ()\n",
      "epoch 288\n",
      "====================================\n",
      "Epoch:  288 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.2708376030527\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004794748965650797\n",
      "Cross Entropy:[0.55046606 0.2673377  0.5104986  ... 0.17768854 0.706953   1.8729167 ]\n",
      "VE Training loss:1.0059057474136353\n",
      "check (1200,) ()\n",
      "epoch 289\n",
      "====================================\n",
      "Epoch:  289 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.3737066770906\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.012100091204047203\n",
      "Cross Entropy:[0.6850497  0.19462283 0.66392004 ... 0.27348727 0.8293249  0.17478296]\n",
      "VE Training loss:0.9815753102302551\n",
      "check (1200,) ()\n",
      "epoch 290\n",
      "====================================\n",
      "Epoch:  290 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.47586630923857\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0034935411531478167\n",
      "Cross Entropy:[0.5939228  0.23628326 0.781125   ... 0.46186453 0.36430874 0.3637931 ]\n",
      "VE Training loss:0.9872757196426392\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 291\n",
      "====================================\n",
      "Epoch:  291 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.57732381333054\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0011916160583496094\n",
      "Cross Entropy:[0.8192356  0.17478387 0.7430005  ... 0.2743533  0.75259566 1.6655667 ]\n",
      "VE Training loss:0.9840079545974731\n",
      "check (1200,) ()\n",
      "epoch 292\n",
      "====================================\n",
      "Epoch:  292 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.6780864030109\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.007087430916726589\n",
      "Cross Entropy:[0.8629873  0.14714229 0.4851822  ... 0.92117107 2.0940979  0.03342732]\n",
      "VE Training loss:0.9813894629478455\n",
      "check (1200,) ()\n",
      "epoch 293\n",
      "====================================\n",
      "Epoch:  293 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.7781611934443\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.00978910457342863\n",
      "Cross Entropy:[0.9815682  0.12095374 0.3857663  ... 0.22615986 0.70392275 0.18870322]\n",
      "VE Training loss:0.9855916500091553\n",
      "check (1200,) ()\n",
      "epoch 294\n",
      "====================================\n",
      "Epoch:  294 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.8775552029904\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.005746414884924889\n",
      "Cross Entropy:[0.7558409  0.18171394 0.8103458  ... 1.1121278  0.13319373 0.46118075]\n",
      "VE Training loss:0.972744882106781\n",
      "check (1200,) ()\n",
      "epoch 295\n",
      "====================================\n",
      "Epoch:  295 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 170.9762753548447\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011041533201932907\n",
      "Cross Entropy:[0.7065017  0.19700055 0.61692935 ... 0.17783743 0.7631752  0.21198167]\n",
      "VE Training loss:0.9928067922592163\n",
      "check (1200,) ()\n",
      "epoch 296\n",
      "====================================\n",
      "Epoch:  296 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.0743284786459\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0015742334071546793\n",
      "Cross Entropy:[0.68267655 0.21910614 0.7144873  ... 1.8980054  0.04091728 0.11861397]\n",
      "VE Training loss:0.9819287061691284\n",
      "check (1200,) ()\n",
      "epoch 297\n",
      "====================================\n",
      "Epoch:  297 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.17172131205112\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.00111220998223871\n",
      "Cross Entropy:[0.7466592  0.19064148 0.7900015  ... 0.13756762 0.4076227  0.46528876]\n",
      "VE Training loss:0.9760650396347046\n",
      "check (1200,) ()\n",
      "epoch 298\n",
      "====================================\n",
      "Epoch:  298 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.26846050227914\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.010664896108210087\n",
      "Cross Entropy:[0.8822277  0.15408207 0.48135912 ... 0.54233015 0.33785793 1.0480253 ]\n",
      "VE Training loss:0.9789326190948486\n",
      "check (1200,) ()\n",
      "epoch 299\n",
      "====================================\n",
      "Epoch:  299 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.3645526076227\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.005122826900333166\n",
      "Cross Entropy:[0.5623059  0.28941616 0.88518727 ... 0.28442937 0.58282065 0.27920744]\n",
      "VE Training loss:0.9824725389480591\n",
      "check (1137,) ()\n",
      "epoch 300\n",
      "====================================\n",
      "Epoch:  300 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1137.0\n",
      "Mean Reward of that batch 189.5\n",
      "Average Reward of all training: 171.4250040989306\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1137.0\n",
      "Training loss:-0.01589260622859001\n",
      "Cross Entropy:[0.6162797  0.27167663 0.56440973 ... 0.41806984 0.42801324 0.39710107]\n",
      "VE Training loss:0.987138032913208\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 301\n",
      "====================================\n",
      "Epoch:  301 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.51993764013017\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0008002169779501855\n",
      "Cross Entropy:[0.6681471  0.23269197 0.7037981  ... 0.23756993 0.63925946 0.26612735]\n",
      "VE Training loss:0.9674825072288513\n",
      "check (1200,) ()\n",
      "epoch 302\n",
      "====================================\n",
      "Epoch:  302 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.6142424823814\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006419776938855648\n",
      "Cross Entropy:[0.6764167  0.23450483 0.6680293  ... 1.4456586  0.08112868 0.26771247]\n",
      "VE Training loss:0.9497179985046387\n",
      "check (1200,) ()\n",
      "epoch 303\n",
      "====================================\n",
      "Epoch:  303 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.70792485042634\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0039029160980135202\n",
      "Cross Entropy:[0.61578906 1.4290104  0.09003714 ... 0.71872437 0.24226218 0.7479062 ]\n",
      "VE Training loss:0.9531549215316772\n",
      "check (1200,) ()\n",
      "epoch 304\n",
      "====================================\n",
      "Epoch:  304 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.80099088710259\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0019923010841012\n",
      "Cross Entropy:[0.5945129  0.27638248 0.7944076  ... 0.15690681 0.4901501  0.3286634 ]\n",
      "VE Training loss:0.9637401103973389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 305\n",
      "====================================\n",
      "Epoch:  305 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.89344665468585\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0026046722196042538\n",
      "Cross Entropy:[0.69062    0.22401169 0.7670766  ... 0.11596071 0.3954147  0.38719264]\n",
      "VE Training loss:0.9749867916107178\n",
      "check (1200,) ()\n",
      "epoch 306\n",
      "====================================\n",
      "Epoch:  306 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 171.98529813620647\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005780340638011694\n",
      "Cross Entropy:[0.5235062  0.3406339  0.4818951  ... 1.4476554  0.07237981 0.14388272]\n",
      "VE Training loss:1.0001882314682007\n",
      "check (1200,) ()\n",
      "epoch 307\n",
      "====================================\n",
      "Epoch:  307 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.07655123674002\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004630756564438343\n",
      "Cross Entropy:[0.8646244  1.7911744  0.05881044 ... 1.7427089  0.05451719 0.14245357]\n",
      "VE Training loss:1.0023266077041626\n",
      "check (1200,) ()\n",
      "epoch 308\n",
      "====================================\n",
      "Epoch:  308 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.16721178467267\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0004397833254188299\n",
      "Cross Entropy:[0.5865527  0.28251258 0.63618237 ... 0.10434585 0.23924786 0.86947745]\n",
      "VE Training loss:0.9548911452293396\n",
      "check (1200,) ()\n",
      "epoch 309\n",
      "====================================\n",
      "Epoch:  309 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.25728553294235\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006490676663815975\n",
      "Cross Entropy:[0.76205355 0.23278236 0.6984702  ... 0.25984445 0.6092878  0.35489446]\n",
      "VE Training loss:0.9931541681289673\n",
      "check (1153,) ()\n",
      "epoch 310\n",
      "====================================\n",
      "Epoch:  310 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1153.0\n",
      "Mean Reward of that batch 192.16666666666666\n",
      "Average Reward of all training: 172.32150934305113\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1153.0\n",
      "Training loss:0.004015185404568911\n",
      "Cross Entropy:[0.8467619  1.7542422  2.8106234  ... 0.3181759  0.76825666 0.24517061]\n",
      "VE Training loss:0.986430287361145\n",
      "Model saved\n",
      "check (1151,) ()\n",
      "epoch 311\n",
      "====================================\n",
      "Epoch:  311 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1151.0\n",
      "Mean Reward of that batch 191.83333333333334\n",
      "Average Reward of all training: 172.3842483269427\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1151.0\n",
      "Training loss:-0.01971847005188465\n",
      "Cross Entropy:[0.8086165  0.19227691 0.49146312 ... 1.1539346  0.13867974 0.40812406]\n",
      "VE Training loss:0.9689500331878662\n",
      "check (1200,) ()\n",
      "epoch 312\n",
      "====================================\n",
      "Epoch:  312 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.47276035153584\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0005640538292936981\n",
      "Cross Entropy:[0.8431957  0.18336205 0.46761775 ... 0.35676885 0.52504736 1.1808327 ]\n",
      "VE Training loss:0.9918542504310608\n",
      "check (1200,) ()\n",
      "epoch 313\n",
      "====================================\n",
      "Epoch:  313 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.56070680408683\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.012652414850890636\n",
      "Cross Entropy:[0.6519185  0.26251826 0.67396635 ... 0.09309001 0.2544641  0.65327746]\n",
      "VE Training loss:0.9750857353210449\n",
      "check (1146,) ()\n",
      "epoch 314\n",
      "====================================\n",
      "Epoch:  314 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1146.0\n",
      "Mean Reward of that batch 191.0\n",
      "Average Reward of all training: 172.61943066776809\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1146.0\n",
      "Training loss:-0.03505207225680351\n",
      "Cross Entropy:[1.0131849  0.14838575 0.3822257  ... 0.11615124 0.34649426 0.53715533]\n",
      "VE Training loss:0.9528024792671204\n",
      "check (1200,) ()\n",
      "epoch 315\n",
      "====================================\n",
      "Epoch:  315 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.70635311009264\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0042501226998865604\n",
      "Cross Entropy:[0.5339578  0.36862418 0.9541192  ... 0.56194264 0.4167955  0.44267377]\n",
      "VE Training loss:0.9626319408416748\n",
      "check (1082,) ()\n",
      "epoch 316\n",
      "====================================\n",
      "Epoch:  316 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1082.0\n",
      "Mean Reward of that batch 180.33333333333334\n",
      "Average Reward of all training: 172.73048912345735\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1082.0\n",
      "Training loss:-0.005925741046667099\n",
      "Cross Entropy:[0.63594854 0.28713846 0.6508838  ... 0.57070774 0.3637185  0.9793089 ]\n",
      "VE Training loss:0.9785873889923096\n",
      "check (1200,) ()\n",
      "epoch 317\n",
      "====================================\n",
      "Epoch:  317 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.8165128170742\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.012643832713365555\n",
      "Cross Entropy:[0.76895833 0.2336284  0.6200229  ... 0.5689734  0.36252245 0.48184738]\n",
      "VE Training loss:0.9487982988357544\n",
      "check (1200,) ()\n",
      "epoch 318\n",
      "====================================\n",
      "Epoch:  318 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 172.90199548117144\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0050988150760531425\n",
      "Cross Entropy:[0.7853896  0.22320755 0.8270142  ... 0.12106717 0.33461356 0.571589  ]\n",
      "VE Training loss:0.9599675536155701\n",
      "check (1139,) ()\n",
      "epoch 319\n",
      "====================================\n",
      "Epoch:  319 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1139.0\n",
      "Mean Reward of that batch 189.83333333333334\n",
      "Average Reward of all training: 172.95507177537883\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1139.0\n",
      "Training loss:-0.013327171094715595\n",
      "Cross Entropy:[0.666682   0.26382795 0.65949243 ... 2.4662943  0.02597283 0.04424531]\n",
      "VE Training loss:0.9903581738471985\n",
      "check (1160,) ()\n",
      "epoch 320\n",
      "====================================\n",
      "Epoch:  320 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1160.0\n",
      "Mean Reward of that batch 193.33333333333334\n",
      "Average Reward of all training: 173.01875384274746\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1160.0\n",
      "Training loss:-0.0044333310797810555\n",
      "Cross Entropy:[0.967547   0.16426495 1.0762686  ... 0.68133485 0.3580429  0.49162596]\n",
      "VE Training loss:0.9756096005439758\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 321\n",
      "====================================\n",
      "Epoch:  321 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.10280756909404\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.01056328509002924\n",
      "Cross Entropy:[0.7363254  0.2511438  0.673334   ... 0.6486305  0.29024568 0.75097674]\n",
      "VE Training loss:0.9836446046829224\n",
      "check (1089,) ()\n",
      "epoch 322\n",
      "====================================\n",
      "Epoch:  322 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1089.0\n",
      "Mean Reward of that batch 181.5\n",
      "Average Reward of all training: 173.12888580645708\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1089.0\n",
      "Training loss:-0.00251125474460423\n",
      "Cross Entropy:[0.6347951  0.29856446 0.7701005  ... 0.49405178 0.37573117 0.8738462 ]\n",
      "VE Training loss:0.9635979533195496\n",
      "check (1200,) ()\n",
      "epoch 323\n",
      "====================================\n",
      "Epoch:  323 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.21207811046187\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004336514510214329\n",
      "Cross Entropy:[0.8342862  0.2004635  0.5084653  ... 0.4807537  0.35515884 0.67479974]\n",
      "VE Training loss:0.9540364742279053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1125,) ()\n",
      "epoch 324\n",
      "====================================\n",
      "Epoch:  324 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1125.0\n",
      "Mean Reward of that batch 187.5\n",
      "Average Reward of all training: 173.2561766348123\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1125.0\n",
      "Training loss:0.012615768238902092\n",
      "Cross Entropy:[0.77538145 0.22079103 0.560025   ... 0.32002345 0.65218335 0.2535715 ]\n",
      "VE Training loss:0.9510459899902344\n",
      "check (1200,) ()\n",
      "epoch 325\n",
      "====================================\n",
      "Epoch:  325 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.3384653220898\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.008348347619175911\n",
      "Cross Entropy:[0.8052609  0.22890534 0.61498713 ... 1.4309262  0.10751367 0.3254831 ]\n",
      "VE Training loss:0.9893689751625061\n",
      "check (1200,) ()\n",
      "epoch 326\n",
      "====================================\n",
      "Epoch:  326 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.42024917079505\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0013067699037492275\n",
      "Cross Entropy:[0.8415443  0.20075534 0.50643945 ... 0.20194641 0.44081762 0.91528213]\n",
      "VE Training loss:0.9749711155891418\n",
      "check (1131,) ()\n",
      "epoch 327\n",
      "====================================\n",
      "Epoch:  327 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1131.0\n",
      "Mean Reward of that batch 188.5\n",
      "Average Reward of all training: 173.46636461675592\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1131.0\n",
      "Training loss:-0.013065208680927753\n",
      "Cross Entropy:[0.5111163  0.37358677 0.53198004 ... 0.23776206 0.58005244 1.2098992 ]\n",
      "VE Training loss:0.950434148311615\n",
      "check (1146,) ()\n",
      "epoch 328\n",
      "====================================\n",
      "Epoch:  328 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1146.0\n",
      "Mean Reward of that batch 191.0\n",
      "Average Reward of all training: 173.51982082219263\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1146.0\n",
      "Training loss:-0.008680622093379498\n",
      "Cross Entropy:[0.49621478 0.38664752 0.51862884 ... 0.01885608 0.03231657 0.05812186]\n",
      "VE Training loss:0.9838324785232544\n",
      "check (1144,) ()\n",
      "epoch 329\n",
      "====================================\n",
      "Epoch:  329 / 500\n",
      "------------\n",
      "Number of training episodes: 7\n",
      "Total reward:1144.0\n",
      "Mean Reward of that batch 163.42857142857142\n",
      "Average Reward of all training: 173.48914833163448\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1144.0\n",
      "Training loss:-0.016277886927127838\n",
      "Cross Entropy:[0.76285076 0.23311828 0.8429569  ... 0.3629584  0.5763094  0.33988786]\n",
      "VE Training loss:0.9438400864601135\n",
      "check (1200,) ()\n",
      "epoch 330\n",
      "====================================\n",
      "Epoch:  330 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.56948424578104\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.007922436110675335\n",
      "Cross Entropy:[0.5629986  1.2396882  0.12820014 ... 0.08794364 0.21030901 0.49721977]\n",
      "VE Training loss:0.9470111131668091\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 331\n",
      "====================================\n",
      "Epoch:  331 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.6493347465491\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.004267103038728237\n",
      "Cross Entropy:[0.76857233 0.25974903 0.6829221  ... 1.0648624  0.19266967 0.5401225 ]\n",
      "VE Training loss:0.9234991669654846\n",
      "check (1200,) ()\n",
      "epoch 332\n",
      "====================================\n",
      "Epoch:  332 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.72870422020407\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0061841742135584354\n",
      "Cross Entropy:[0.91792035 0.18752435 0.98070014 ... 0.1342556  0.35312754 0.84904087]\n",
      "VE Training loss:0.9481961131095886\n",
      "check (1162,) ()\n",
      "epoch 333\n",
      "====================================\n",
      "Epoch:  333 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1162.0\n",
      "Mean Reward of that batch 193.66666666666666\n",
      "Average Reward of all training: 173.78857798130457\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1162.0\n",
      "Training loss:0.004882467910647392\n",
      "Cross Entropy:[0.601058   0.32888967 0.59125847 ... 0.31691793 0.62923294 1.1302906 ]\n",
      "VE Training loss:0.9462167024612427\n",
      "check (1200,) ()\n",
      "epoch 334\n",
      "====================================\n",
      "Epoch:  334 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.86705529273777\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.001333517604507506\n",
      "Cross Entropy:[0.88066125 0.20893984 0.557034   ... 0.10146625 0.25975105 0.7721176 ]\n",
      "VE Training loss:0.9225006103515625\n",
      "check (1200,) ()\n",
      "epoch 335\n",
      "====================================\n",
      "Epoch:  335 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 173.94506408290871\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004154341295361519\n",
      "Cross Entropy:[0.53245836 0.36915267 0.89292794 ... 0.46195564 0.52635795 0.31152272]\n",
      "VE Training loss:0.9425150752067566\n",
      "check (1153,) ()\n",
      "epoch 336\n",
      "====================================\n",
      "Epoch:  336 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1153.0\n",
      "Mean Reward of that batch 192.16666666666666\n",
      "Average Reward of all training: 173.99929504297944\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1153.0\n",
      "Training loss:-0.010484753176569939\n",
      "Cross Entropy:[1.1948565  0.12780073 1.2714782  ... 0.6518197  1.3822051  0.0971729 ]\n",
      "VE Training loss:0.9385912418365479\n",
      "check (1200,) ()\n",
      "epoch 337\n",
      "====================================\n",
      "Epoch:  337 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.0764484701516\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006255807355046272\n",
      "Cross Entropy:[0.91752434 0.18835275 0.9484992  ... 0.21303345 0.8687409  0.21779174]\n",
      "VE Training loss:0.9377173781394958\n",
      "check (1200,) ()\n",
      "epoch 338\n",
      "====================================\n",
      "Epoch:  338 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.1531453681689\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.002699833596125245\n",
      "Cross Entropy:[0.55141085 0.35257855 0.8422052  ... 0.3976881  0.47022855 0.46571207]\n",
      "VE Training loss:0.9614099264144897\n",
      "check (1194,) ()\n",
      "epoch 339\n",
      "====================================\n",
      "Epoch:  339 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1194.0\n",
      "Mean Reward of that batch 199.0\n",
      "Average Reward of all training: 174.226439924605\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1194.0\n",
      "Training loss:-0.0041320533491671085\n",
      "Cross Entropy:[0.40618804 0.9150423  0.21182206 ... 0.57976633 0.34328282 0.5795914 ]\n",
      "VE Training loss:0.9545812606811523\n",
      "check (1200,) ()\n",
      "epoch 340\n",
      "====================================\n",
      "Epoch:  340 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.30224451306202\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.006607750430703163\n",
      "Cross Entropy:[0.76831186 0.23132996 0.572888   ... 0.15407574 0.3953741  0.51504856]\n",
      "VE Training loss:0.9062749147415161\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 341\n",
      "====================================\n",
      "Epoch:  341 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.37760449982724\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006939942017197609\n",
      "Cross Entropy:[0.51932645 1.1953944  2.1002162  ... 0.15070556 0.39330846 0.5162501 ]\n",
      "VE Training loss:0.965319812297821\n",
      "check (1200,) ()\n",
      "epoch 342\n",
      "====================================\n",
      "Epoch:  342 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.45252378491548\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.005435558967292309\n",
      "Cross Entropy:[0.78758395 0.21386199 0.9226459  ... 1.0843143  0.1812736  0.49637735]\n",
      "VE Training loss:0.9637628197669983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 343\n",
      "====================================\n",
      "Epoch:  343 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.52700622286034\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004519718699157238\n",
      "Cross Entropy:[0.68989533 1.5087637  2.5040486  ... 0.6732346  1.2966617  0.12594414]\n",
      "VE Training loss:0.9203617572784424\n",
      "check (1200,) ()\n",
      "epoch 344\n",
      "====================================\n",
      "Epoch:  344 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.60105562337526\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004547474440187216\n",
      "Cross Entropy:[0.5218447 1.1454923 1.9799428 ... 0.3078931 0.7481061 0.2525732]\n",
      "VE Training loss:0.9420560598373413\n",
      "check (1200,) ()\n",
      "epoch 345\n",
      "====================================\n",
      "Epoch:  345 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.67467575200317\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.007981308735907078\n",
      "Cross Entropy:[0.73669004 1.4910598  0.09302788 ... 0.6010917  0.33529153 0.6191123 ]\n",
      "VE Training loss:0.9256885647773743\n",
      "check (1200,) ()\n",
      "epoch 346\n",
      "====================================\n",
      "Epoch:  346 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.7478703307546\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004414808005094528\n",
      "Cross Entropy:[0.42219472 0.4506767  0.4342518  ... 0.3723719  0.7373375  0.31797504]\n",
      "VE Training loss:0.927732527256012\n",
      "check (1176,) ()\n",
      "epoch 347\n",
      "====================================\n",
      "Epoch:  347 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1176.0\n",
      "Mean Reward of that batch 196.0\n",
      "Average Reward of all training: 174.80911566121353\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1176.0\n",
      "Training loss:0.004159265663474798\n",
      "Cross Entropy:[1.0985528  0.14679052 0.3936035  ... 0.2282446  0.80085516 1.4175934 ]\n",
      "VE Training loss:0.970890998840332\n",
      "check (1200,) ()\n",
      "epoch 348\n",
      "====================================\n",
      "Epoch:  348 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.8815032598882\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0050757694989442825\n",
      "Cross Entropy:[0.4474435  1.0126731  0.17878029 ... 0.1519057  0.34298837 0.70754397]\n",
      "VE Training loss:0.963914692401886\n",
      "check (1200,) ()\n",
      "epoch 349\n",
      "====================================\n",
      "Epoch:  349 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 174.95347602991717\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0014017232460901141\n",
      "Cross Entropy:[0.28185812 0.7001885  1.4005069  ... 0.04809574 0.12832807 1.2705669 ]\n",
      "VE Training loss:0.9768442511558533\n",
      "check (1199,) ()\n",
      "epoch 350\n",
      "====================================\n",
      "Epoch:  350 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1199.0\n",
      "Mean Reward of that batch 199.83333333333334\n",
      "Average Reward of all training: 175.02456133649835\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1199.0\n",
      "Training loss:-0.005292964167892933\n",
      "Cross Entropy:[0.86685836 0.21493699 0.80932146 ... 0.1659476  1.0738168  2.0473309 ]\n",
      "VE Training loss:1.0014857053756714\n",
      "Model saved\n",
      "check (1172,) ()\n",
      "epoch 351\n",
      "====================================\n",
      "Epoch:  351 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1172.0\n",
      "Mean Reward of that batch 195.33333333333334\n",
      "Average Reward of all training: 175.08242108577707\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1172.0\n",
      "Training loss:0.000971543078776449\n",
      "Cross Entropy:[0.76638424 0.22022066 0.8961146  ... 0.13348126 0.31928533 0.70288086]\n",
      "VE Training loss:0.942030131816864\n",
      "check (1171,) ()\n",
      "epoch 352\n",
      "====================================\n",
      "Epoch:  352 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1171.0\n",
      "Mean Reward of that batch 195.16666666666666\n",
      "Average Reward of all training: 175.13947860163188\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1171.0\n",
      "Training loss:0.007435276638716459\n",
      "Cross Entropy:[0.6218723  0.28453657 0.7091712  ... 0.88331103 0.18494444 0.46294838]\n",
      "VE Training loss:0.9814696907997131\n",
      "check (1200,) ()\n",
      "epoch 353\n",
      "====================================\n",
      "Epoch:  353 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.20990500785953\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.016325684264302254\n",
      "Cross Entropy:[0.34888098 0.84350854 0.22356804 ... 0.56116295 0.38455227 0.4578393 ]\n",
      "VE Training loss:0.9432465434074402\n",
      "check (1194,) ()\n",
      "epoch 354\n",
      "====================================\n",
      "Epoch:  354 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1194.0\n",
      "Mean Reward of that batch 199.0\n",
      "Average Reward of all training: 175.27710866602942\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1194.0\n",
      "Training loss:-0.0009811343625187874\n",
      "Cross Entropy:[0.51011324 0.36539862 0.5521134  ... 0.40408388 0.75561184 0.32713926]\n",
      "VE Training loss:0.9766753911972046\n",
      "check (1200,) ()\n",
      "epoch 355\n",
      "====================================\n",
      "Epoch:  355 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.34675061344907\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.013202973641455173\n",
      "Cross Entropy:[0.49261656 0.38166377 0.8816246  ... 0.4733584  1.070943   0.14932874]\n",
      "VE Training loss:0.9445600509643555\n",
      "check (1200,) ()\n",
      "epoch 356\n",
      "====================================\n",
      "Epoch:  356 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.41600131397308\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0006293408223427832\n",
      "Cross Entropy:[0.5654303  0.36202127 0.8950107  ... 0.09355303 0.23442101 0.827744  ]\n",
      "VE Training loss:0.9669396877288818\n",
      "check (1200,) ()\n",
      "epoch 357\n",
      "====================================\n",
      "Epoch:  357 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.48486405539052\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.00845699105411768\n",
      "Cross Entropy:[0.89272326 1.7021314  0.07335901 ... 0.21558869 0.5400826  0.37117827]\n",
      "VE Training loss:0.9589760303497314\n",
      "check (1200,) ()\n",
      "epoch 358\n",
      "====================================\n",
      "Epoch:  358 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.55334208875536\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0012259181821718812\n",
      "Cross Entropy:[1.0551777  1.9149076  0.05767207 ... 0.10475678 0.21238537 1.0353259 ]\n",
      "VE Training loss:0.9487703442573547\n",
      "check (1200,) ()\n",
      "epoch 359\n",
      "====================================\n",
      "Epoch:  359 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.62143862889812\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0112741868942976\n",
      "Cross Entropy:[0.4761137  1.0792599  0.15988006 ... 1.0972615  0.13538244 1.336032  ]\n",
      "VE Training loss:0.9466426372528076\n",
      "check (1200,) ()\n",
      "epoch 360\n",
      "====================================\n",
      "Epoch:  360 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.68915685492894\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004775173030793667\n",
      "Cross Entropy:[0.5867537  1.2527001  0.12982707 ... 1.1816514  0.13861178 0.35317144]\n",
      "VE Training loss:0.9184172749519348\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 361\n",
      "====================================\n",
      "Epoch:  361 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.75649991073246\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.01164211705327034\n",
      "Cross Entropy:[0.8642293  0.22731413 0.5460268  ... 0.25746363 0.5446166  0.41767925]\n",
      "VE Training loss:0.9939243793487549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 362\n",
      "====================================\n",
      "Epoch:  362 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.8234709054542\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.001080106943845749\n",
      "Cross Entropy:[0.5590471  0.35754752 0.64915955 ... 1.5876428  0.08489294 0.14147447]\n",
      "VE Training loss:0.9496296048164368\n",
      "check (1200,) ()\n",
      "epoch 363\n",
      "====================================\n",
      "Epoch:  363 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.8900729139791\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.007535476703196764\n",
      "Cross Entropy:[0.68845856 0.3078575  0.68847287 ... 2.1005445  0.04597885 0.0690725 ]\n",
      "VE Training loss:0.9432631134986877\n",
      "check (1200,) ()\n",
      "epoch 364\n",
      "====================================\n",
      "Epoch:  364 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 175.95630897740224\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005718231201171875\n",
      "Cross Entropy:[0.850091   0.227154   0.48326313 ... 0.25605312 0.83012664 0.2579743 ]\n",
      "VE Training loss:0.965110182762146\n",
      "check (1200,) ()\n",
      "epoch 365\n",
      "====================================\n",
      "Epoch:  365 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.02218210349156\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006645099725574255\n",
      "Cross Entropy:[0.42289504 0.8972208  0.23284103 ... 0.18936338 0.36060435 0.7051755 ]\n",
      "VE Training loss:0.9668782353401184\n",
      "check (1200,) ()\n",
      "epoch 366\n",
      "====================================\n",
      "Epoch:  366 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.08769526714323\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006257606204599142\n",
      "Cross Entropy:[0.7445932  0.30235857 0.6589579  ... 0.2976249  0.86979234 0.2008118 ]\n",
      "VE Training loss:1.0287925004959106\n",
      "check (1200,) ()\n",
      "epoch 367\n",
      "====================================\n",
      "Epoch:  367 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.15285141082947\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0002793931926134974\n",
      "Cross Entropy:[0.59719026 0.38311216 0.7873727  ... 0.17552638 1.2725877  0.12234496]\n",
      "VE Training loss:0.9755902886390686\n",
      "check (1071,) ()\n",
      "epoch 368\n",
      "====================================\n",
      "Epoch:  368 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1071.0\n",
      "Mean Reward of that batch 178.5\n",
      "Average Reward of all training: 176.1592295319957\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1071.0\n",
      "Training loss:0.0013558381469920278\n",
      "Cross Entropy:[0.59026253 0.41074452 0.8597224  ... 0.27058622 0.5334617  0.9590045 ]\n",
      "VE Training loss:0.957286536693573\n",
      "check (1167,) ()\n",
      "epoch 369\n",
      "====================================\n",
      "Epoch:  369 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1167.0\n",
      "Mean Reward of that batch 194.5\n",
      "Average Reward of all training: 176.20893351700386\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1167.0\n",
      "Training loss:0.0070890942588448524\n",
      "Cross Entropy:[0.47092664 0.9201131  0.24374217 ... 0.10183196 1.9650882  0.04995247]\n",
      "VE Training loss:0.9503691792488098\n",
      "check (1069,) ()\n",
      "epoch 370\n",
      "====================================\n",
      "Epoch:  370 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1069.0\n",
      "Mean Reward of that batch 178.16666666666666\n",
      "Average Reward of all training: 176.21422468767864\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1069.0\n",
      "Training loss:0.002695197705179453\n",
      "Cross Entropy:[0.42677283 0.8405607  0.27640933 ... 0.51626694 0.5074721  0.43783957]\n",
      "VE Training loss:0.9715636968612671\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 371\n",
      "====================================\n",
      "Epoch:  371 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.27833728959862\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.005344822071492672\n",
      "Cross Entropy:[0.6974971  0.31259334 0.6147462  ... 1.2111441  0.16855909 0.38286132]\n",
      "VE Training loss:0.976335883140564\n",
      "check (1199,) ()\n",
      "epoch 372\n",
      "====================================\n",
      "Epoch:  372 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1199.0\n",
      "Mean Reward of that batch 199.83333333333334\n",
      "Average Reward of all training: 176.34165717143662\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1199.0\n",
      "Training loss:-0.020382089540362358\n",
      "Cross Entropy:[0.9178568  0.24363257 0.8986292  ... 1.7411861  0.08399086 0.16180679]\n",
      "VE Training loss:0.9387180805206299\n",
      "check (1131,) ()\n",
      "epoch 373\n",
      "====================================\n",
      "Epoch:  373 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1131.0\n",
      "Mean Reward of that batch 188.5\n",
      "Average Reward of all training: 176.3742532648108\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1131.0\n",
      "Training loss:-0.0023681563325226307\n",
      "Cross Entropy:[0.40421486 0.6161917  0.3631258  ... 0.829106   0.24277234 0.4471429 ]\n",
      "VE Training loss:0.9568831920623779\n",
      "check (1200,) ()\n",
      "epoch 374\n",
      "====================================\n",
      "Epoch:  374 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.4374237106268\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.01045827567577362\n",
      "Cross Entropy:[0.5810807  1.0851984  0.19602594 ... 0.06559782 0.11990144 1.6129493 ]\n",
      "VE Training loss:0.9512467384338379\n",
      "check (1111,) ()\n",
      "epoch 375\n",
      "====================================\n",
      "Epoch:  375 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1111.0\n",
      "Mean Reward of that batch 185.16666666666666\n",
      "Average Reward of all training: 176.4607016918429\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1111.0\n",
      "Training loss:-0.010226535610854626\n",
      "Cross Entropy:[0.60415465 0.35818154 0.6821859  ... 0.11100461 0.19783865 1.1742091 ]\n",
      "VE Training loss:0.965330958366394\n",
      "check (1200,) ()\n",
      "epoch 376\n",
      "====================================\n",
      "Epoch:  376 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.5233062086199\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.015524027869105339\n",
      "Cross Entropy:[0.78655267 1.431715   0.11930542 ... 0.23487674 0.522601   0.4423424 ]\n",
      "VE Training loss:0.9713418483734131\n",
      "check (1200,) ()\n",
      "epoch 377\n",
      "====================================\n",
      "Epoch:  377 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.58557860594453\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004872471559792757\n",
      "Cross Entropy:[0.55806214 0.4070433  0.58866787 ... 0.7621312  0.23969962 0.40749484]\n",
      "VE Training loss:0.9555995464324951\n",
      "check (1200,) ()\n",
      "epoch 378\n",
      "====================================\n",
      "Epoch:  378 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.64752151968543\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004063854925334454\n",
      "Cross Entropy:[0.48319066 0.50710636 0.44560984 ... 0.595392   0.39147297 0.77669525]\n",
      "VE Training loss:0.9585015773773193\n",
      "check (1145,) ()\n",
      "epoch 379\n",
      "====================================\n",
      "Epoch:  379 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1145.0\n",
      "Mean Reward of that batch 190.83333333333334\n",
      "Average Reward of all training: 176.68495110230717\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1145.0\n",
      "Training loss:0.005006303545087576\n",
      "Cross Entropy:[0.48382604 0.9311098  0.24339326 ... 0.50325155 0.958364   0.22087505]\n",
      "VE Training loss:0.9689565896987915\n",
      "check (1200,) ()\n",
      "epoch 380\n",
      "====================================\n",
      "Epoch:  380 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.7463064941432\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006781075615435839\n",
      "Cross Entropy:[0.80208945 1.4374287  0.1163307  ... 0.4905784  0.5735466  1.122299  ]\n",
      "VE Training loss:1.0410608053207397\n",
      "Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 381\n",
      "====================================\n",
      "Epoch:  381 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.80733981043156\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.011698850430548191\n",
      "Cross Entropy:[0.59472847 1.1016847  0.19257784 ... 0.19203444 0.3978257  0.6180343 ]\n",
      "VE Training loss:0.9443707466125488\n",
      "check (1128,) ()\n",
      "epoch 382\n",
      "====================================\n",
      "Epoch:  382 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1128.0\n",
      "Mean Reward of that batch 188.0\n",
      "Average Reward of all training: 176.83663996799586\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1128.0\n",
      "Training loss:0.009476106613874435\n",
      "Cross Entropy:[0.4070606  0.5967596  1.1024557  ... 0.28862214 0.9518056  0.24187551]\n",
      "VE Training loss:0.9454041719436646\n",
      "check (1099,) ()\n",
      "epoch 383\n",
      "====================================\n",
      "Epoch:  383 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1099.0\n",
      "Mean Reward of that batch 183.16666666666666\n",
      "Average Reward of all training: 176.8531674528488\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1099.0\n",
      "Training loss:-0.0009840878192335367\n",
      "Cross Entropy:[0.6433707  0.35300133 0.73185956 ... 0.46963692 0.52046645 0.48088962]\n",
      "VE Training loss:0.9541409015655518\n",
      "check (1200,) ()\n",
      "epoch 384\n",
      "====================================\n",
      "Epoch:  384 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.91344566260702\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0014431615127250552\n",
      "Cross Entropy:[0.601162   1.0739963  1.6672654  ... 0.77277124 1.2532264  0.15992476]\n",
      "VE Training loss:0.9581979513168335\n",
      "check (1200,) ()\n",
      "epoch 385\n",
      "====================================\n",
      "Epoch:  385 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 176.97341073880804\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0007484658272005618\n",
      "Cross Entropy:[0.83183175 0.25948164 0.9559267  ... 1.3962239  0.12129201 0.24780695]\n",
      "VE Training loss:0.9750065207481384\n",
      "check (1163,) ()\n",
      "epoch 386\n",
      "====================================\n",
      "Epoch:  386 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1163.0\n",
      "Mean Reward of that batch 193.83333333333334\n",
      "Average Reward of all training: 177.0170892947524\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1163.0\n",
      "Training loss:-0.00099264457821846\n",
      "Cross Entropy:[0.44947004 0.822165   0.3073092  ... 0.21742493 1.0698763  1.7587957 ]\n",
      "VE Training loss:0.9667197465896606\n",
      "check (1200,) ()\n",
      "epoch 387\n",
      "====================================\n",
      "Epoch:  387 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.0764766609158\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005643331911414862\n",
      "Cross Entropy:[0.5854121  0.39648917 0.7130674  ... 0.7106576  0.34791917 0.6942561 ]\n",
      "VE Training loss:1.0185132026672363\n",
      "check (1026,) ()\n",
      "epoch 388\n",
      "====================================\n",
      "Epoch:  388 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1026.0\n",
      "Mean Reward of that batch 171.0\n",
      "Average Reward of all training: 177.06081563859385\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1026.0\n",
      "Training loss:-0.001594402128830552\n",
      "Cross Entropy:[0.5303003  0.9884542  0.22893453 ... 0.04791599 0.06408898 0.08579487]\n",
      "VE Training loss:0.9683895111083984\n",
      "check (1164,) ()\n",
      "epoch 389\n",
      "====================================\n",
      "Epoch:  389 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1164.0\n",
      "Mean Reward of that batch 194.0\n",
      "Average Reward of all training: 177.10436109967716\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1164.0\n",
      "Training loss:0.002387689659371972\n",
      "Cross Entropy:[0.74549496 1.2888011  0.15675487 ... 0.26771092 0.9814356  0.22402455]\n",
      "VE Training loss:1.0336792469024658\n",
      "check (1200,) ()\n",
      "epoch 390\n",
      "====================================\n",
      "Epoch:  390 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.16306786608826\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.008917968720197678\n",
      "Cross Entropy:[0.6687864  1.2193495  1.9225429  ... 0.77906156 0.28073794 0.5075968 ]\n",
      "VE Training loss:1.0250800848007202\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 391\n",
      "====================================\n",
      "Epoch:  391 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.22147434213406\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0011291229166090488\n",
      "Cross Entropy:[0.87141114 0.26425558 0.49620244 ... 0.3953414  0.6500811  1.1514887 ]\n",
      "VE Training loss:1.000206470489502\n",
      "check (1149,) ()\n",
      "epoch 392\n",
      "====================================\n",
      "Epoch:  392 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1149.0\n",
      "Mean Reward of that batch 191.5\n",
      "Average Reward of all training: 177.25789915248578\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1149.0\n",
      "Training loss:-0.002785965334624052\n",
      "Cross Entropy:[0.64147794 0.4150752  0.80248487 ... 0.45502746 0.599304   0.4106237 ]\n",
      "VE Training loss:0.9728230237960815\n",
      "check (1046,) ()\n",
      "epoch 393\n",
      "====================================\n",
      "Epoch:  393 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1046.0\n",
      "Mean Reward of that batch 174.33333333333334\n",
      "Average Reward of all training: 177.25045750918005\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1046.0\n",
      "Training loss:0.008036485873162746\n",
      "Cross Entropy:[0.44560146 0.59643    1.0709409  ... 0.8928778  0.26100174 0.9170487 ]\n",
      "VE Training loss:0.9638420343399048\n",
      "check (1100,) ()\n",
      "epoch 394\n",
      "====================================\n",
      "Epoch:  394 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1100.0\n",
      "Mean Reward of that batch 183.33333333333334\n",
      "Average Reward of all training: 177.26589628030735\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1100.0\n",
      "Training loss:0.0030133125837892294\n",
      "Cross Entropy:[0.74664015 1.2296213  1.7991692  ... 0.72665673 0.3285751  0.5310893 ]\n",
      "VE Training loss:0.9528427124023438\n",
      "check (1161,) ()\n",
      "epoch 395\n",
      "====================================\n",
      "Epoch:  395 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1161.0\n",
      "Mean Reward of that batch 193.5\n",
      "Average Reward of all training: 177.30699527706605\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1161.0\n",
      "Training loss:-0.004527446813881397\n",
      "Cross Entropy:[0.6307689  0.42051965 0.6282771  ... 0.28654984 0.43879867 0.67029524]\n",
      "VE Training loss:0.979529857635498\n",
      "check (1020,) ()\n",
      "epoch 396\n",
      "====================================\n",
      "Epoch:  396 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1020.0\n",
      "Mean Reward of that batch 170.0\n",
      "Average Reward of all training: 177.28854326879065\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1020.0\n",
      "Training loss:-0.005113224033266306\n",
      "Cross Entropy:[0.49815446 0.5635114  0.45704335 ... 2.3019195  0.04461465 0.05647923]\n",
      "VE Training loss:0.9798167943954468\n",
      "check (1081,) ()\n",
      "epoch 397\n",
      "====================================\n",
      "Epoch:  397 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1081.0\n",
      "Mean Reward of that batch 180.16666666666666\n",
      "Average Reward of all training: 177.2957929498936\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1081.0\n",
      "Training loss:-0.012076184153556824\n",
      "Cross Entropy:[0.96880484 1.5582547  0.11616673 ... 1.762557   2.5480723  0.03526854]\n",
      "VE Training loss:0.9876484274864197\n",
      "check (1098,) ()\n",
      "epoch 398\n",
      "====================================\n",
      "Epoch:  398 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1098.0\n",
      "Mean Reward of that batch 183.0\n",
      "Average Reward of all training: 177.31012512841147\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1098.0\n",
      "Training loss:-0.004120307508856058\n",
      "Cross Entropy:[0.7237608  1.2090786  0.18358104 ... 0.2964483  0.51564634 0.5405698 ]\n",
      "VE Training loss:0.9613850712776184\n",
      "check (1085,) ()\n",
      "epoch 399\n",
      "====================================\n",
      "Epoch:  399 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1085.0\n",
      "Mean Reward of that batch 180.83333333333334\n",
      "Average Reward of all training: 177.31895522416315\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1085.0\n",
      "Training loss:0.004510160535573959\n",
      "Cross Entropy:[0.81919867 0.29135364 0.5230629  ... 0.16910432 0.29866078 0.8955145 ]\n",
      "VE Training loss:1.0136361122131348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 400\n",
      "====================================\n",
      "Epoch:  400 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.37565783610273\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0006319443346001208\n",
      "Cross Entropy:[0.6516976  0.3935681  0.67606634 ... 0.32965788 0.59045005 0.46019083]\n",
      "VE Training loss:0.9561377763748169\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 401\n",
      "====================================\n",
      "Epoch:  401 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.43207764199772\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.007370618171989918\n",
      "Cross Entropy:[0.7526746  1.2633947  0.16261615 ... 0.40139747 0.77589333 0.29973596]\n",
      "VE Training loss:1.0148626565933228\n",
      "check (1200,) ()\n",
      "epoch 402\n",
      "====================================\n",
      "Epoch:  402 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.48821675234103\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.003313415916636586\n",
      "Cross Entropy:[0.53975886 0.95000994 0.2510354  ... 0.6432708  0.4685736  0.50957656]\n",
      "VE Training loss:1.034851312637329\n",
      "check (1184,) ()\n",
      "epoch 403\n",
      "====================================\n",
      "Epoch:  403 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1184.0\n",
      "Mean Reward of that batch 197.33333333333334\n",
      "Average Reward of all training: 177.53746021780253\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1184.0\n",
      "Training loss:-0.01407981850206852\n",
      "Cross Entropy:[0.5593064  0.48343575 0.522766   ... 1.4494219  0.16005418 0.3230746 ]\n",
      "VE Training loss:0.9982182383537292\n",
      "check (1200,) ()\n",
      "epoch 404\n",
      "====================================\n",
      "Epoch:  404 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.59306056379808\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.014916757121682167\n",
      "Cross Entropy:[0.93246704 1.5404743  0.1151419  ... 0.18657576 1.3450239  1.9851414 ]\n",
      "VE Training loss:1.0472522974014282\n",
      "check (1077,) ()\n",
      "epoch 405\n",
      "====================================\n",
      "Epoch:  405 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1077.0\n",
      "Mean Reward of that batch 179.5\n",
      "Average Reward of all training: 177.59776905623315\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1077.0\n",
      "Training loss:0.0026313140988349915\n",
      "Cross Entropy:[0.77356064 1.3359804  0.14081684 ... 0.13095912 0.20599002 0.34020993]\n",
      "VE Training loss:1.0171122550964355\n",
      "check (1023,) ()\n",
      "epoch 406\n",
      "====================================\n",
      "Epoch:  406 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1023.0\n",
      "Mean Reward of that batch 170.5\n",
      "Average Reward of all training: 177.58028686643945\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1023.0\n",
      "Training loss:0.006034892052412033\n",
      "Cross Entropy:[0.5257208  0.9509588  0.24397588 ... 0.12956624 0.16742568 1.6045392 ]\n",
      "VE Training loss:1.0355485677719116\n",
      "check (1075,) ()\n",
      "epoch 407\n",
      "====================================\n",
      "Epoch:  407 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1075.0\n",
      "Mean Reward of that batch 179.16666666666666\n",
      "Average Reward of all training: 177.58418460550638\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1075.0\n",
      "Training loss:-0.0021315428894013166\n",
      "Cross Entropy:[0.8163306  1.342037   0.1535978  ... 0.18869573 1.2904059  0.13551529]\n",
      "VE Training loss:0.9932205080986023\n",
      "check (1200,) ()\n",
      "epoch 408\n",
      "====================================\n",
      "Epoch:  408 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.63912532951247\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.007104970049113035\n",
      "Cross Entropy:[0.5038764  0.92556775 0.25032684 ... 0.3415908  0.61721873 0.42624134]\n",
      "VE Training loss:1.0189913511276245\n",
      "check (1020,) ()\n",
      "epoch 409\n",
      "====================================\n",
      "Epoch:  409 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1020.0\n",
      "Mean Reward of that batch 170.0\n",
      "Average Reward of all training: 177.62044776146965\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1020.0\n",
      "Training loss:-0.005544494371861219\n",
      "Cross Entropy:[0.6173356  1.0682213  0.2115916  ... 1.0760658  0.1609029  0.22500083]\n",
      "VE Training loss:1.0226876735687256\n",
      "check (1061,) ()\n",
      "epoch 410\n",
      "====================================\n",
      "Epoch:  410 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1061.0\n",
      "Mean Reward of that batch 176.83333333333334\n",
      "Average Reward of all training: 177.6185279701815\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1061.0\n",
      "Training loss:-2.134486749127973e-05\n",
      "Cross Entropy:[0.70515716 0.33490193 0.62951756 ... 1.2783468  0.14579372 0.25185573]\n",
      "VE Training loss:0.9661123156547546\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 411\n",
      "====================================\n",
      "Epoch:  411 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.6729841065071\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.012463671155273914\n",
      "Cross Entropy:[0.76673025 1.2839391  0.16304725 ... 0.5143123  0.9353525  0.24245808]\n",
      "VE Training loss:0.9818941354751587\n",
      "check (1200,) ()\n",
      "epoch 412\n",
      "====================================\n",
      "Epoch:  412 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.72717589265636\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.003691592952236533\n",
      "Cross Entropy:[0.626261   1.149806   0.1740347  ... 0.34814566 0.6377996  0.4063595 ]\n",
      "VE Training loss:0.9965880513191223\n",
      "check (1200,) ()\n",
      "epoch 413\n",
      "====================================\n",
      "Epoch:  413 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.78110524884846\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.005418469198048115\n",
      "Cross Entropy:[0.6775782  0.35853586 0.73837274 ... 1.1588867  0.17449486 0.35975108]\n",
      "VE Training loss:1.0113967657089233\n",
      "check (1200,) ()\n",
      "epoch 414\n",
      "====================================\n",
      "Epoch:  414 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.8347740767498\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0011794384336099029\n",
      "Cross Entropy:[0.62512946 0.37975213 0.5990466  ... 0.1468357  1.5337116  0.10236704]\n",
      "VE Training loss:0.9793758988380432\n",
      "check (1200,) ()\n",
      "epoch 415\n",
      "====================================\n",
      "Epoch:  415 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.8881842596974\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.01010997872799635\n",
      "Cross Entropy:[0.7972436  0.26684058 0.84419584 ... 0.64726514 0.3627699  0.62646294]\n",
      "VE Training loss:0.9683937430381775\n",
      "check (1200,) ()\n",
      "epoch 416\n",
      "====================================\n",
      "Epoch:  416 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.94133766291927\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0015578801976516843\n",
      "Cross Entropy:[0.47020203 0.49668092 0.45546705 ... 0.15042622 1.3707271  0.12418223]\n",
      "VE Training loss:0.9874103665351868\n",
      "check (1200,) ()\n",
      "epoch 417\n",
      "====================================\n",
      "Epoch:  417 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 177.9942361337516\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.01250335294753313\n",
      "Cross Entropy:[0.7686962  1.4217263  0.1179051  ... 0.19361426 1.12464    1.9755461 ]\n",
      "VE Training loss:0.9541975855827332\n",
      "check (1200,) ()\n",
      "epoch 418\n",
      "====================================\n",
      "Epoch:  418 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.04688150185268\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.008571223355829716\n",
      "Cross Entropy:[0.55980337 0.41574404 0.9187089  ... 0.40998152 0.5384059  0.40623182]\n",
      "VE Training loss:0.973319411277771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 419\n",
      "====================================\n",
      "Epoch:  419 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.0992755794139\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011900408193469048\n",
      "Cross Entropy:[0.6350927  1.2053525  0.15847105 ... 0.6172737  1.2123246  0.13729301]\n",
      "VE Training loss:0.9679028391838074\n",
      "check (1200,) ()\n",
      "epoch 420\n",
      "====================================\n",
      "Epoch:  420 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.15142016136767\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0013401213800534606\n",
      "Cross Entropy:[0.83728087 1.6018106  0.08347283 ... 0.18710592 0.3669547  0.6878756 ]\n",
      "VE Training loss:0.9665055274963379\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 421\n",
      "====================================\n",
      "Epoch:  421 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.20331702559244\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0025092600844800472\n",
      "Cross Entropy:[0.6405908  0.35296223 0.5888157  ... 0.14206012 0.31055078 0.7451238 ]\n",
      "VE Training loss:0.9659799933433533\n",
      "check (1092,) ()\n",
      "epoch 422\n",
      "====================================\n",
      "Epoch:  422 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1092.0\n",
      "Mean Reward of that batch 182.0\n",
      "Average Reward of all training: 178.21231390467872\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1092.0\n",
      "Training loss:-0.00922979786992073\n",
      "Cross Entropy:[0.886419   0.20519221 0.45080537 ... 0.03209437 0.0444044  0.06277828]\n",
      "VE Training loss:0.9731371402740479\n",
      "check (1200,) ()\n",
      "epoch 423\n",
      "====================================\n",
      "Epoch:  423 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.26382143681897\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0012732545146718621\n",
      "Cross Entropy:[0.5991864  0.37317958 0.55030537 ... 0.06969332 0.13563634 0.2661154 ]\n",
      "VE Training loss:0.9321499466896057\n",
      "check (1200,) ()\n",
      "epoch 424\n",
      "====================================\n",
      "Epoch:  424 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.31508600890194\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.010943016968667507\n",
      "Cross Entropy:[1.1239066  2.0080135  0.05101481 ... 0.17808199 0.36192596 0.66109   ]\n",
      "VE Training loss:0.9714314937591553\n",
      "check (1200,) ()\n",
      "epoch 425\n",
      "====================================\n",
      "Epoch:  425 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.3661093359398\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0010241619311273098\n",
      "Cross Entropy:[0.6130603  0.33446214 0.76250947 ... 0.06017966 0.12408525 1.4401724 ]\n",
      "VE Training loss:0.9620299339294434\n",
      "check (1200,) ()\n",
      "epoch 426\n",
      "====================================\n",
      "Epoch:  426 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.41689311684135\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004738735966384411\n",
      "Cross Entropy:[0.68249065 0.28221208 0.717029   ... 1.0026677  0.1873499  0.4809624 ]\n",
      "VE Training loss:0.9313998222351074\n",
      "check (1200,) ()\n",
      "epoch 427\n",
      "====================================\n",
      "Epoch:  427 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.46743903460052\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.003815480973571539\n",
      "Cross Entropy:[0.6819484  0.30193663 0.62902135 ... 0.34735012 0.5668048  0.37259516]\n",
      "VE Training loss:0.9626896381378174\n",
      "check (1200,) ()\n",
      "epoch 428\n",
      "====================================\n",
      "Epoch:  428 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.5177487564823\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.007933005690574646\n",
      "Cross Entropy:[0.6006689  1.2138658  0.14075439 ... 0.5585242  0.33026347 0.64659256]\n",
      "VE Training loss:0.9366220831871033\n",
      "check (1200,) ()\n",
      "epoch 429\n",
      "====================================\n",
      "Epoch:  429 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.5678239342061\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.012094794772565365\n",
      "Cross Entropy:[0.47162068 0.44664264 0.4198456  ... 0.78481007 0.23001051 0.8546584 ]\n",
      "VE Training loss:0.9533325433731079\n",
      "check (1200,) ()\n",
      "epoch 430\n",
      "====================================\n",
      "Epoch:  430 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.61766620412655\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.002230450278148055\n",
      "Cross Entropy:[1.0425647  1.9348574  0.05362693 ... 1.3684013  0.12531753 0.33255458]\n",
      "VE Training loss:0.9480822682380676\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 431\n",
      "====================================\n",
      "Epoch:  431 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.66727718741166\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.001530530396848917\n",
      "Cross Entropy:[1.051237   0.14690898 0.34950513 ... 0.82660747 0.22639573 0.5418048 ]\n",
      "VE Training loss:0.963501513004303\n",
      "check (1200,) ()\n",
      "epoch 432\n",
      "====================================\n",
      "Epoch:  432 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.71665849021858\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0007435782463289797\n",
      "Cross Entropy:[0.41540214 0.96358097 0.18856    ... 0.9203433  0.21665002 0.82737803]\n",
      "VE Training loss:0.9479628205299377\n",
      "check (1200,) ()\n",
      "epoch 433\n",
      "====================================\n",
      "Epoch:  433 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.76581170386703\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.008176819421350956\n",
      "Cross Entropy:[0.6025537  0.3273601  0.8221225  ... 1.2219818  0.1244671  0.31200224]\n",
      "VE Training loss:0.9402336478233337\n",
      "check (1200,) ()\n",
      "epoch 434\n",
      "====================================\n",
      "Epoch:  434 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.8147384050102\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005720684304833412\n",
      "Cross Entropy:[0.7622875  0.23336507 0.8186225  ... 0.14185533 0.31691608 0.66009784]\n",
      "VE Training loss:0.9353265166282654\n",
      "check (1138,) ()\n",
      "epoch 435\n",
      "====================================\n",
      "Epoch:  435 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1138.0\n",
      "Mean Reward of that batch 189.66666666666666\n",
      "Average Reward of all training: 178.83968536653126\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1138.0\n",
      "Training loss:0.004593970254063606\n",
      "Cross Entropy:[0.5952835  0.3182211  0.7732444  ... 0.54914767 1.1855676  0.1286777 ]\n",
      "VE Training loss:0.9612038731575012\n",
      "check (1200,) ()\n",
      "epoch 436\n",
      "====================================\n",
      "Epoch:  436 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.88821819825938\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.008248736150562763\n",
      "Cross Entropy:[0.65070164 0.30093688 0.7807814  ... 0.40288553 0.51800394 0.3544963 ]\n",
      "VE Training loss:0.9605482816696167\n",
      "check (1200,) ()\n",
      "epoch 437\n",
      "====================================\n",
      "Epoch:  437 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.9365289117645\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0036796831991523504\n",
      "Cross Entropy:[0.8128337  0.22740473 0.80445313 ... 0.07902756 0.20920785 0.55125415]\n",
      "VE Training loss:0.9700894355773926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 438\n",
      "====================================\n",
      "Epoch:  438 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 178.98461902840432\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.002897935686632991\n",
      "Cross Entropy:[0.37784377 0.857779   0.23083976 ... 0.34191784 0.8300946  1.6173806 ]\n",
      "VE Training loss:0.9745643138885498\n",
      "check (1200,) ()\n",
      "epoch 439\n",
      "====================================\n",
      "Epoch:  439 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.03249005567446\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011899157427251339\n",
      "Cross Entropy:[0.5775623  0.33244002 0.7861768  ... 0.23028183 0.47263953 0.5109935 ]\n",
      "VE Training loss:1.004057765007019\n",
      "check (1200,) ()\n",
      "epoch 440\n",
      "====================================\n",
      "Epoch:  440 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.08014348736612\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.003939531743526459\n",
      "Cross Entropy:[0.5795929  1.2204067  0.13326417 ... 2.1418276  0.04135099 0.09898409]\n",
      "VE Training loss:0.9761849045753479\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 441\n",
      "====================================\n",
      "Epoch:  441 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.1275808037213\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011052882298827171\n",
      "Cross Entropy:[0.6390038  0.32062143 0.6053073  ... 0.40072885 0.7830503  0.2788975 ]\n",
      "VE Training loss:0.9538525342941284\n",
      "check (1200,) ()\n",
      "epoch 442\n",
      "====================================\n",
      "Epoch:  442 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.1748034715862\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006000701803714037\n",
      "Cross Entropy:[0.9759046  0.17362072 0.41297373 ... 1.0041902  0.18222553 1.1631559 ]\n",
      "VE Training loss:0.9765545725822449\n",
      "check (1187,) ()\n",
      "epoch 443\n",
      "====================================\n",
      "Epoch:  443 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1187.0\n",
      "Mean Reward of that batch 197.83333333333334\n",
      "Average Reward of all training: 179.2169220491522\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1187.0\n",
      "Training loss:-0.010231917724013329\n",
      "Cross Entropy:[0.9476278  0.18726015 0.4574503  ... 0.1392385  0.32105458 0.7028982 ]\n",
      "VE Training loss:0.9663944840431213\n",
      "check (1104,) ()\n",
      "epoch 444\n",
      "====================================\n",
      "Epoch:  444 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1104.0\n",
      "Mean Reward of that batch 184.0\n",
      "Average Reward of all training: 179.2276947472397\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1104.0\n",
      "Training loss:-0.014089412987232208\n",
      "Cross Entropy:[0.66052353 1.2940444  0.12877716 ... 0.01792201 0.0255288  0.03718253]\n",
      "VE Training loss:0.9419082403182983\n",
      "check (1200,) ()\n",
      "epoch 445\n",
      "====================================\n",
      "Epoch:  445 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.27437408488635\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0034008510410785675\n",
      "Cross Entropy:[0.57640374 0.3812089  0.5196028  ... 0.20201275 0.5145377  1.1518507 ]\n",
      "VE Training loss:0.9819240570068359\n",
      "check (1200,) ()\n",
      "epoch 446\n",
      "====================================\n",
      "Epoch:  446 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.3208440981489\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0015471176011487842\n",
      "Cross Entropy:[0.6355247  1.2740533  0.13400406 ... 0.09586502 1.7248843  0.05881898]\n",
      "VE Training loss:0.9824292063713074\n",
      "check (1200,) ()\n",
      "epoch 447\n",
      "====================================\n",
      "Epoch:  447 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.3671061918891\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0006725430721417069\n",
      "Cross Entropy:[0.691255   0.2926071  0.7074538  ... 0.24898215 0.76419985 1.4672939 ]\n",
      "VE Training loss:0.9411725997924805\n",
      "check (1200,) ()\n",
      "epoch 448\n",
      "====================================\n",
      "Epoch:  448 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.41316175842505\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.010024345479905605\n",
      "Cross Entropy:[0.43939358 0.49484742 0.3963855  ... 0.25801033 0.52372086 0.45336133]\n",
      "VE Training loss:0.9534192681312561\n",
      "check (1200,) ()\n",
      "epoch 449\n",
      "====================================\n",
      "Epoch:  449 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.45901217767133\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.007448045536875725\n",
      "Cross Entropy:[0.76276743 0.24139467 0.54266435 ... 0.16404735 0.3714411  0.60338295]\n",
      "VE Training loss:0.9450755715370178\n",
      "check (1200,) ()\n",
      "epoch 450\n",
      "====================================\n",
      "Epoch:  450 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.5046588172765\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0036009217146784067\n",
      "Cross Entropy:[0.893683   1.659392   0.07956032 ... 0.74380106 1.4371964  0.0997379 ]\n",
      "VE Training loss:0.9446485638618469\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 451\n",
      "====================================\n",
      "Epoch:  451 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.55010303275924\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0038103186525404453\n",
      "Cross Entropy:[0.37618086 0.5806478  1.2616937  ... 1.6799862  0.08955842 0.18994254]\n",
      "VE Training loss:0.9695838689804077\n",
      "check (1200,) ()\n",
      "epoch 452\n",
      "====================================\n",
      "Epoch:  452 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.59534616764253\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.001801233272999525\n",
      "Cross Entropy:[0.40212056 0.86679876 0.23986545 ... 1.2684023  2.138996   0.04578289]\n",
      "VE Training loss:0.934647798538208\n",
      "check (1200,) ()\n",
      "epoch 453\n",
      "====================================\n",
      "Epoch:  453 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.64038955358592\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.006341472268104553\n",
      "Cross Entropy:[0.61088353 0.3421695  0.8226943  ... 0.23367134 0.8928207  0.18550062]\n",
      "VE Training loss:0.9222960472106934\n",
      "check (1200,) ()\n",
      "epoch 454\n",
      "====================================\n",
      "Epoch:  454 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.68523451051635\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011541738174855709\n",
      "Cross Entropy:[0.97499317 0.1761766  0.41483054 ... 0.43695614 0.46786362 0.4561581 ]\n",
      "VE Training loss:0.9548466205596924\n",
      "check (1200,) ()\n",
      "epoch 455\n",
      "====================================\n",
      "Epoch:  455 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.72988234675697\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.002250456716865301\n",
      "Cross Entropy:[0.533471   1.1359829  1.937226   ... 0.74741435 0.2686416  0.8116801 ]\n",
      "VE Training loss:0.9493061304092407\n",
      "check (1200,) ()\n",
      "epoch 456\n",
      "====================================\n",
      "Epoch:  456 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.77433435915444\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011331497691571712\n",
      "Cross Entropy:[0.8314026  0.22655341 0.869197   ... 0.5907112  0.35318685 0.57876587]\n",
      "VE Training loss:0.9451611042022705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 457\n",
      "====================================\n",
      "Epoch:  457 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.8185918332044\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0030764976982027292\n",
      "Cross Entropy:[0.39279258 0.55666435 0.35214978 ... 0.14687523 1.161823   0.15596227]\n",
      "VE Training loss:0.9407721161842346\n",
      "check (1200,) ()\n",
      "epoch 458\n",
      "====================================\n",
      "Epoch:  458 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.86265604317558\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005504713859409094\n",
      "Cross Entropy:[0.56316453 1.135895   0.16478261 ... 0.11216615 0.21921328 0.41874686]\n",
      "VE Training loss:0.9326401948928833\n",
      "check (1200,) ()\n",
      "epoch 459\n",
      "====================================\n",
      "Epoch:  459 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.90652825223185\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0006847762851975858\n",
      "Cross Entropy:[0.5376655  0.4132266  0.47944552 ... 0.28742993 0.71654934 0.2789956 ]\n",
      "VE Training loss:0.9498291015625\n",
      "check (1200,) ()\n",
      "epoch 460\n",
      "====================================\n",
      "Epoch:  460 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.9502097125531\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0019511246355250478\n",
      "Cross Entropy:[0.74973786 1.4545314  0.10188816 ... 0.36931187 0.5862055  0.33870262]\n",
      "VE Training loss:0.9256445169448853\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 461\n",
      "====================================\n",
      "Epoch:  461 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 179.99370166545427\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.00534697063267231\n",
      "Cross Entropy:[0.38928917 0.5441993  0.3736836  ... 0.16561744 0.38853815 0.5450574 ]\n",
      "VE Training loss:0.9884126782417297\n",
      "check (1175,) ()\n",
      "epoch 462\n",
      "====================================\n",
      "Epoch:  462 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1175.0\n",
      "Mean Reward of that batch 195.83333333333334\n",
      "Average Reward of all training: 180.02798658248435\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1175.0\n",
      "Training loss:-0.004767644219100475\n",
      "Cross Entropy:[0.37963748 0.5712578  1.2380918  ... 0.46070296 1.0543668  0.15112206]\n",
      "VE Training loss:0.955814003944397\n",
      "check (1200,) ()\n",
      "epoch 463\n",
      "====================================\n",
      "Epoch:  463 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.07112268057833\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.008090718649327755\n",
      "Cross Entropy:[0.7010212  0.29303476 0.73104775 ... 0.5481767  1.1586794  0.15023719]\n",
      "VE Training loss:1.0122100114822388\n",
      "check (1200,) ()\n",
      "epoch 464\n",
      "====================================\n",
      "Epoch:  464 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.114072847215\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0030498155392706394\n",
      "Cross Entropy:[0.60575056 0.31780806 0.7247646  ... 1.3579279  0.09711935 0.19514993]\n",
      "VE Training loss:0.9829313158988953\n",
      "check (1200,) ()\n",
      "epoch 465\n",
      "====================================\n",
      "Epoch:  465 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.1568382819522\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0017968241591006517\n",
      "Cross Entropy:[0.58381814 1.2693005  0.12310624 ... 0.5614574  0.3712819  0.5506046 ]\n",
      "VE Training loss:0.9516128301620483\n",
      "check (1200,) ()\n",
      "epoch 466\n",
      "====================================\n",
      "Epoch:  466 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.199420174051\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.009275984950363636\n",
      "Cross Entropy:[1.1378186  0.13334294 0.31943753 ... 0.19011062 0.4778888  0.4271633 ]\n",
      "VE Training loss:0.97811359167099\n",
      "check (1200,) ()\n",
      "epoch 467\n",
      "====================================\n",
      "Epoch:  467 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.2418197025862\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.008595853112637997\n",
      "Cross Entropy:[0.781269   0.22136126 0.5129102  ... 1.3723515  0.08681327 0.18889825]\n",
      "VE Training loss:0.9792155027389526\n",
      "check (1200,) ()\n",
      "epoch 468\n",
      "====================================\n",
      "Epoch:  468 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.28403803655505\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.009586079977452755\n",
      "Cross Entropy:[0.81124854 1.6064261  0.07914321 ... 0.25085202 0.49839467 0.48231894]\n",
      "VE Training loss:0.9673791527748108\n",
      "check (1200,) ()\n",
      "epoch 469\n",
      "====================================\n",
      "Epoch:  469 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.32607633498458\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011904044076800346\n",
      "Cross Entropy:[0.33271432 0.62032837 0.2953614  ... 0.16479333 0.39213425 0.56038415]\n",
      "VE Training loss:0.9781650900840759\n",
      "check (1200,) ()\n",
      "epoch 470\n",
      "====================================\n",
      "Epoch:  470 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.3679357470378\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004357691388577223\n",
      "Cross Entropy:[0.95380753 0.17724982 1.0296203  ... 0.18520944 0.40248242 0.57685983]\n",
      "VE Training loss:0.9824751615524292\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 471\n",
      "====================================\n",
      "Epoch:  471 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.4096174121184\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.004848279990255833\n",
      "Cross Entropy:[0.7323216  0.25246456 0.7939225  ... 0.32585618 0.7808353  0.23846932]\n",
      "VE Training loss:0.9385512471199036\n",
      "check (1200,) ()\n",
      "epoch 472\n",
      "====================================\n",
      "Epoch:  472 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.45112245997407\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005993973463773727\n",
      "Cross Entropy:[0.96113014 0.1787079  0.44817793 ... 0.6000219  0.3091545  0.6842124 ]\n",
      "VE Training loss:0.9208549857139587\n",
      "check (1200,) ()\n",
      "epoch 473\n",
      "====================================\n",
      "Epoch:  473 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.49245201079864\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005039169918745756\n",
      "Cross Entropy:[0.71172285 0.26662886 0.64420074 ... 0.73151195 0.28957707 0.6672318 ]\n",
      "VE Training loss:1.0129940509796143\n",
      "check (1200,) ()\n",
      "epoch 474\n",
      "====================================\n",
      "Epoch:  474 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.53360717533283\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005688242614269257\n",
      "Cross Entropy:[0.6749107  1.4490733  0.09485363 ... 0.541764   0.36149272 0.5562108 ]\n",
      "VE Training loss:0.9748374223709106\n",
      "check (1200,) ()\n",
      "epoch 475\n",
      "====================================\n",
      "Epoch:  475 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.57458905496372\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.003630115883424878\n",
      "Cross Entropy:[0.5015719  0.38386354 0.5480007  ... 1.046608   0.15225127 0.32320982]\n",
      "VE Training loss:0.91525799036026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 476\n",
      "====================================\n",
      "Epoch:  476 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.61539874182304\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.011585857719182968\n",
      "Cross Entropy:[0.8247249  0.22709748 0.5689227  ... 0.18191074 0.38635945 0.6174105 ]\n",
      "VE Training loss:0.924801230430603\n",
      "check (1168,) ()\n",
      "epoch 477\n",
      "====================================\n",
      "Epoch:  477 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1168.0\n",
      "Mean Reward of that batch 194.66666666666666\n",
      "Average Reward of all training: 180.6448563265711\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1168.0\n",
      "Training loss:-0.0004931018920615315\n",
      "Cross Entropy:[0.8502166  0.21590006 0.54750115 ... 2.5569952  0.02396497 0.03710729]\n",
      "VE Training loss:0.9765118956565857\n",
      "check (1200,) ()\n",
      "epoch 478\n",
      "====================================\n",
      "Epoch:  478 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.6853482589423\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.007512424141168594\n",
      "Cross Entropy:[0.64972705 0.30145526 0.73364586 ... 1.547006   0.08557887 0.19303437]\n",
      "VE Training loss:1.0231883525848389\n",
      "check (1200,) ()\n",
      "epoch 479\n",
      "====================================\n",
      "Epoch:  479 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.72567112270232\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0005643840413540602\n",
      "Cross Entropy:[0.692517   1.4246521  0.0995428  ... 0.2517892  0.78798944 0.23230366]\n",
      "VE Training loss:0.9767535328865051\n",
      "check (1200,) ()\n",
      "epoch 480\n",
      "====================================\n",
      "Epoch:  480 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.76582597453003\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0054983459413051605\n",
      "Cross Entropy:[0.9461701  0.18418756 0.98444366 ... 0.05465411 0.14398853 0.36514387]\n",
      "VE Training loss:0.9685103297233582\n",
      "Model saved\n",
      "check (1121,) ()\n",
      "epoch 481\n",
      "====================================\n",
      "Epoch:  481 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1121.0\n",
      "Mean Reward of that batch 186.83333333333334\n",
      "Average Reward of all training: 180.77844033494338\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1121.0\n",
      "Training loss:-0.0012888329802080989\n",
      "Cross Entropy:[0.7242482  0.2592     0.73599476 ... 0.42897797 0.9758211  0.16873513]\n",
      "VE Training loss:0.9324958920478821\n",
      "check (1200,) ()\n",
      "epoch 482\n",
      "====================================\n",
      "Epoch:  482 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.8183190894352\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006770188920199871\n",
      "Cross Entropy:[0.6814383  1.398039   0.10398461 ... 0.2592847  0.6259854  1.3126719 ]\n",
      "VE Training loss:0.9904914498329163\n",
      "check (1200,) ()\n",
      "epoch 483\n",
      "====================================\n",
      "Epoch:  483 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.85803271450882\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.001629832200706005\n",
      "Cross Entropy:[0.71316737 0.28074974 0.6500396  ... 0.8490586  0.21263695 0.5166057 ]\n",
      "VE Training loss:0.9299644827842712\n",
      "check (1200,) ()\n",
      "epoch 484\n",
      "====================================\n",
      "Epoch:  484 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.89758223369373\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.006716147996485233\n",
      "Cross Entropy:[0.9408306  0.1704711  1.0839205  ... 0.73327446 0.27361095 0.7245664 ]\n",
      "VE Training loss:0.9713109135627747\n",
      "check (1200,) ()\n",
      "epoch 485\n",
      "====================================\n",
      "Epoch:  485 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.93696866207787\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.004805825650691986\n",
      "Cross Entropy:[0.41786578 0.49943322 0.3694428  ... 0.30856395 0.7093309  0.2647325 ]\n",
      "VE Training loss:0.9414740800857544\n",
      "check (1200,) ()\n",
      "epoch 486\n",
      "====================================\n",
      "Epoch:  486 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 180.97619300639457\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.009711106307804585\n",
      "Cross Entropy:[0.989946   0.16019912 0.39527792 ... 0.0579745  0.12967598 0.3016079 ]\n",
      "VE Training loss:0.9724205732345581\n",
      "check (1200,) ()\n",
      "epoch 487\n",
      "====================================\n",
      "Epoch:  487 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.01525626510835\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011547870934009552\n",
      "Cross Entropy:[0.7670359  0.22935212 0.84698343 ... 1.2806736  0.11478836 0.29136264]\n",
      "VE Training loss:1.0385093688964844\n",
      "check (1200,) ()\n",
      "epoch 488\n",
      "====================================\n",
      "Epoch:  488 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.0541594284995\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.00356342107988894\n",
      "Cross Entropy:[0.6342482  0.32103226 0.5649071  ... 1.3315483  0.0978884  0.23062313]\n",
      "VE Training loss:0.9771516919136047\n",
      "check (1200,) ()\n",
      "epoch 489\n",
      "====================================\n",
      "Epoch:  489 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.09290347874798\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.00031960965134203434\n",
      "Cross Entropy:[0.6688361  0.28074667 0.6976569  ... 0.09997577 0.25044703 0.80208915]\n",
      "VE Training loss:0.9776153564453125\n",
      "check (1200,) ()\n",
      "epoch 490\n",
      "====================================\n",
      "Epoch:  490 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.13148939001584\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.008639969862997532\n",
      "Cross Entropy:[0.94711685 0.17402868 1.0511997  ... 0.26733673 0.6964126  1.4641438 ]\n",
      "VE Training loss:0.972659170627594\n",
      "Model saved\n",
      "check (1200,) ()\n",
      "epoch 491\n",
      "====================================\n",
      "Epoch:  491 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.16991812852905\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0051455190405249596\n",
      "Cross Entropy:[0.56403    1.1992992  0.14068024 ... 0.5398699  0.36128792 0.5509122 ]\n",
      "VE Training loss:1.021543025970459\n",
      "check (1200,) ()\n",
      "epoch 492\n",
      "====================================\n",
      "Epoch:  492 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.20819065265806\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.002786105964332819\n",
      "Cross Entropy:[0.60821086 0.3146493  0.7482452  ... 0.5209628  0.39395776 0.5194552 ]\n",
      "VE Training loss:1.0106748342514038\n",
      "check (1200,) ()\n",
      "epoch 493\n",
      "====================================\n",
      "Epoch:  493 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.24630791299748\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0032244285102933645\n",
      "Cross Entropy:[0.4030929  0.5103868  0.37805262 ... 0.6505209  0.34419635 0.87741655]\n",
      "VE Training loss:0.9700868725776672\n",
      "check (1200,) ()\n",
      "epoch 494\n",
      "====================================\n",
      "Epoch:  494 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.28427085244488\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:-0.0030738688074052334\n",
      "Cross Entropy:[0.77422124 1.5037416  0.09809765 ... 0.26595715 0.61320823 1.2514112 ]\n",
      "VE Training loss:1.0305935144424438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (1200,) ()\n",
      "epoch 495\n",
      "====================================\n",
      "Epoch:  495 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.3220804062783\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.0039510042406618595\n",
      "Cross Entropy:[0.6684302  0.28378874 0.7311922  ... 0.07962484 0.14701273 0.27921763]\n",
      "VE Training loss:1.020334243774414\n",
      "check (1200,) ()\n",
      "epoch 496\n",
      "====================================\n",
      "Epoch:  496 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.3597375022334\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.003392260055989027\n",
      "Cross Entropy:[0.6695649  0.30122763 0.6561282  ... 0.4801795  0.38902536 0.82368636]\n",
      "VE Training loss:0.9883935451507568\n",
      "check (1200,) ()\n",
      "epoch 497\n",
      "====================================\n",
      "Epoch:  497 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.397243060579\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006957101635634899\n",
      "Cross Entropy:[0.79989636 0.23865187 0.5749536  ... 0.20077895 0.49181056 0.41141087]\n",
      "VE Training loss:1.0574685335159302\n",
      "check (1200,) ()\n",
      "epoch 498\n",
      "====================================\n",
      "Epoch:  498 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.4345979941923\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.005966764874756336\n",
      "Cross Entropy:[0.65207255 0.29160535 0.7409874  ... 0.7456589  0.2761039  0.65041196]\n",
      "VE Training loss:1.0097728967666626\n",
      "check (1200,) ()\n",
      "epoch 499\n",
      "====================================\n",
      "Epoch:  499 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.4718032086328\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.006717161275446415\n",
      "Cross Entropy:[0.8230421  0.22536582 0.5046667  ... 0.92197806 0.2209582  0.5150602 ]\n",
      "VE Training loss:1.0368727445602417\n",
      "check (1200,) ()\n",
      "epoch 500\n",
      "====================================\n",
      "Epoch:  500 / 500\n",
      "------------\n",
      "Number of training episodes: 6\n",
      "Total reward:1200.0\n",
      "Mean Reward of that batch 200.0\n",
      "Average Reward of all training: 181.50885960221552\n",
      "Max reward for a batch so far: 1200.0\n",
      "check 1200.0\n",
      "Training loss:0.011496528051793575\n",
      "Cross Entropy:[0.63376933 1.276313   0.13257876 ... 0.57829    1.2099187  0.13245367]\n",
      "VE Training loss:1.0354831218719482\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# training and print sth\n",
    "allRewards = []\n",
    "\n",
    "total_rewards = 0\n",
    "maximumRewardRecorded = 0\n",
    "mean_reward_total = []\n",
    "average_reward = []\n",
    "epoch = 1\n",
    "# for plotting\n",
    "epoch_1 = []\n",
    "average_reward = []\n",
    "saver = tf.train.Saver()\n",
    "# while we have epoch/episode to train\n",
    "\n",
    "if training:\n",
    "    # number of iterations\n",
    "    while epoch < number_epoch +1:\n",
    "        states_mb, actions_mb, rewards_of_batch, discounted_rewards_mb, nb_episodes_mb = make_batch(batch_size)\n",
    "   \n",
    "        total_reward_of_that_batch = np.sum(rewards_of_batch)\n",
    "        print('check',rewards_of_batch.shape, np.array(total_reward_of_that_batch).shape)\n",
    "        allRewards.append(total_reward_of_that_batch)\n",
    "        \n",
    "        mean_reward_of_that_batch = np.divide(total_reward_of_that_batch, nb_episodes_mb)\n",
    "        mean_reward_total.append(mean_reward_of_that_batch)\n",
    "        average_reward_of_all_training = np.divide(np.sum(mean_reward_total), epoch)\n",
    "        maximumRewardRecorded = np.amax(allRewards)\n",
    "        print('epoch',epoch)\n",
    "        epoch_1.append(epoch)\n",
    "        print('====================================')\n",
    "        print(\"Epoch: \", epoch, '/', number_epoch)\n",
    "        print('------------')\n",
    "        print(\"Number of training episodes: {}\".format(nb_episodes_mb))\n",
    "        print(\"Total reward:{}\".format(total_reward_of_that_batch, nb_episodes_mb))\n",
    "        print(\"Mean Reward of that batch {}\".format(mean_reward_of_that_batch))\n",
    "        print(\"Average Reward of all training: {}\".format(average_reward_of_all_training))\n",
    "        print(\"Max reward for a batch so far: {}\".format(maximumRewardRecorded))\n",
    "\n",
    "        loss_, cross, _= sess.run([PGN.loss, PGN.cross_entropy, PGN.train_opt],feed_dict = {PGN.inputs: states_mb.reshape([len(states_mb), state_size]), PGN.actions: actions_mb,PGN.discounted_episode_rewards: discounted_rewards_mb})    \n",
    "        loss_VE, _= sess.run([VEN.loss, VEN.train_opt],feed_dict = {VEN.inputs: states_mb.reshape([len(states_mb), state_size]), VEN.discounted_episode_rewards: discounted_rewards_mb})    \n",
    "\n",
    "        print('check',total_reward_of_that_batch)\n",
    "        print('Training loss:{}'.format(loss_) )\n",
    "        print('Cross Entropy:{}'.format(cross) )\n",
    "        print('VE Training loss:{}'.format(loss_VE) )\n",
    "              \n",
    "        if epoch % 10 == 0:\n",
    "              saver.save(sess, \"./models/model.ckpt\")\n",
    "              print('Model saved')\n",
    "        epoch += 1\n",
    "        average_reward.append(mean_reward_of_that_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'average_reward_each_episode')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f991041a438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(epoch_1, average_reward)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('average_reward_each_episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pong game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the environment of the game\n",
    "import gym\n",
    "env = gym.make('Pong-v0')\n",
    "\n",
    "env.action_space.n\n",
    "env.unwrapped.get_action_meanings()\n",
    "\n",
    "# our agents only care about left and right move\n",
    "Right_ACTION = 2\n",
    "Left_ACTION = 3\n",
    "action_dict = { 0:Right_ACTION, 1:Left_ACTION}\n",
    "action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set up the training hyperparameters\n",
    "\n",
    "state_size = [80,80,1] # our input an image\n",
    "action_size = 2  # number of actions (push to left or push to right)\n",
    "#action_size = 1  # number of actions (push to left or push to right)\n",
    "# training hyperparameters\n",
    "learning_rate = 0.0001\n",
    "\n",
    "number_epoch = 10000 # number of epochs for training\n",
    "batch_size = 100 # defines number of samples work though\n",
    "hidden_size_1 = 53\n",
    "hidden_size_2 = 34\n",
    "\n",
    "training = True \n",
    "\n",
    "\n",
    "max_steps = 200 # Max steps per episode\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the discounted some of reward from current step onward\n",
    "def discount_rewards(r, gamma = 0.99, normalization = False):\n",
    "    discounted_r = np.zeros_like(r) #make a vector of zeros with the size of input\n",
    "    running_add = 0\n",
    "    for t in reversed(range(0, len(r))):\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "        \n",
    "    if normalization: # do normalization for reward to have more smooth gradient\n",
    "        mean = np.mean(discounted_r)\n",
    "        std = np.std(discounted_r)\n",
    "        discounted_r = (discounted_r - mean)/(std)\n",
    "        \n",
    "    return discounted_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 2D float array \"\"\"\n",
    "    image = image[35:195] # crop\n",
    "    image = image[::2,::2,0] # downsample by factor of 2\n",
    "    image[image == 144] = 0 # erase background (background type 1)\n",
    "    image[image == 109] = 0 # erase background (background type 2)\n",
    "    image[image != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    \n",
    "    return np.reshape(image.astype(np.float).ravel(), [80,80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the policy network \n",
    "\n",
    "class PGNetwork():\n",
    "    def __init__(self, state_size, action_size, learning_rate, hidden_size_1, hidden_size_2, name = 'PGNetwork'):\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        #self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_1 = 53\n",
    "        self.hidden_size_2 = 34\n",
    "        \n",
    "        # generate a network such that with a given state, the policy gives an action\n",
    "        with tf.variable_scope(name):\n",
    "            with tf.name_scope('inputs'):\n",
    "            # we create placeholder\n",
    "                self.inputs = tf.placeholder(tf.float32, shape = [None, *state_size], name = 'inputs')\n",
    "                self.actions = tf.placeholder(tf.int32, shape = [None, action_size], name = 'actions')\n",
    "                #self.actions = tf.placeholder(tf.float32, shape = [None, action_size], name = 'actions')\n",
    "                self.discounted_episode_rewards = tf.placeholder(tf.float32, shape = [None, ], name = 'discounted_episode_rewards')\n",
    "            # CNN is often used for image process\n",
    "            #with tf.name_scope('conv_layer1'):\n",
    "              \n",
    "                # filters gives the number of filters in the convolution nn\n",
    "            #    self.conv1 = tf.layers.conv2d(inputs = self.inputs,\n",
    "            #                    filters = 32,\n",
    "            #                    kernel_size = [3,3],\n",
    "            #                    strides = [1,1],\n",
    "            #                    padding = 'VALID',\n",
    "            #                    kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(), name = 'conv1')\n",
    "                \n",
    "            #    self.conv1_batchnorm = tf.layers.batch_normalization(self.conv1, training = True,\n",
    "            #                                                epsilon = 1e-5, name = 'batch_norm1')\n",
    "            #    \n",
    "            #    self.conv1_out = tf.nn.relu(self.conv1_batchnorm, name = 'conv1_out')\n",
    "            \n",
    "                \n",
    "            with tf.name_scope('layer1'):\n",
    "                # filters gives the number of filters in the hidden nn\n",
    "                #self.flatten = tf.contrib.layers.flatten(self.conv1_out)\n",
    "                self.flatten = tf.contrib.layers.flatten(self.inputs)\n",
    "                self.layer1 = tf.contrib.layers.fully_connected(inputs = self.flatten,\n",
    "                                             num_outputs = self.hidden_size_1,\n",
    "                                             activation_fn = tf.nn.elu,\n",
    "                                             weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            with tf.name_scope('layer2'):\n",
    "                # filters gives the number of filters in the hidden nn\n",
    "                self.layer2 = tf.contrib.layers.fully_connected(inputs = self.layer1,\n",
    "                                             num_outputs = self.hidden_size_2,\n",
    "                                             activation_fn = tf.nn.elu,\n",
    "                                             weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                                       \n",
    "                                          \n",
    "            with tf.name_scope('logits'):\n",
    "                # get the action distribution from the fully connected NN\n",
    "                self.logits = tf.layers.dense(inputs = self.layer2,\n",
    "                                             kernel_initializer = tf.contrib.layers.xavier_initializer(),      \n",
    "                                             units = self.action_size, \n",
    "                                             # units = 1, \n",
    "                                             activation = None)\n",
    "            \n",
    "               \n",
    "                #self.out = tf.sigmoid(self.logits, name=\"sigmoid\")\n",
    "                \n",
    "            with tf.name_scope('softmax'):\n",
    "                self.action_distribution = tf.nn.softmax(self.logits)\n",
    "                \n",
    "            # define the loss function\n",
    "            with tf.name_scope('loss'):\n",
    "                #self.cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits( labels = self.actions,logits = self.logits)\n",
    "                self.cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = self.logits, labels = self.actions)\n",
    "                #self.log_action_probability = tf.nn.softmax_cross_entropy_with_logits(logits = self.outputlayer, labels = self.actions)\n",
    "                self.weighted_likelihoods = tf.multiply(self.cross_entropy, self.discounted_episode_rewards)\n",
    "                self.loss = tf.reduce_mean(self.weighted_likelihoods)\n",
    "\n",
    "            with tf.name_scope('train'):\n",
    "                #self.optimizer = tf.train.RMSPropOptimizer(1e-3, decay = 0.99)\n",
    "                self.optimizer = tf.train.AdamOptimizer(self.learning_rate,  beta1=0.9, beta2=0.99)\n",
    "                self.train_opt = self.optimizer.minimize(self.loss)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value estimator network\n",
    "class VENetwork():\n",
    "    def __init__(self, state_size, learning_rate,  name = 'VENetwork'):\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.output_size = 1\n",
    "        self.learning_rate = learning_rate\n",
    "        self.hidden_size_1 = 150\n",
    "        #self.hidden_size_2 = hidden_size_2\n",
    "     \n",
    "        \n",
    "        # generate a network such that with a given state, the policy gives an action\n",
    "        with tf.variable_scope(name):\n",
    "            with tf.name_scope('inputs'):\n",
    "            # we create placeholder\n",
    "                self.inputs = tf.placeholder(tf.float32, shape = [None, *state_size], name = 'inputs')\n",
    "                self.discounted_episode_rewards = tf.placeholder(tf.float32, shape = [None, ], name = 'discounted_episode_rewards')\n",
    "                \n",
    "            #  we use general fully connected layers\n",
    "            with tf.name_scope('layer1'):\n",
    "              \n",
    "                self.inputs1 = tf.contrib.layers.flatten(self.inputs)\n",
    "                # filters gives the number of filters in the convolution nn\n",
    "                self.layer1 = tf.contrib.layers.fully_connected(inputs = self.inputs1,\n",
    "                                             num_outputs = self.hidden_size_1,\n",
    "                                             activation_fn = tf.nn.elu,\n",
    "                                             weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                                        \n",
    "            with tf.name_scope('output'):\n",
    "                # get the action distribution from the fully connected NN\n",
    "                self.output_layer = tf.layers.dense(inputs = self.layer1,\n",
    "                                             kernel_initializer = tf.contrib.layers.xavier_initializer(),      \n",
    "                                             units = self.output_size, \n",
    "                                             activation = None)\n",
    "                \n",
    "                self.state_value_estimation = tf.squeeze(self.output_layer)\n",
    "                \n",
    "            # define the loss function\n",
    "            with tf.name_scope('loss'):\n",
    "\n",
    "                self.loss = tf.reduce_mean(tf.squared_difference(self.state_value_estimation, self.discounted_episode_rewards))\n",
    "                \n",
    "           \n",
    "                \n",
    "            with tf.name_scope('train'):\n",
    "                #self.optimizer = tf.train.RMSPropOptimizer(1e-3, decay = 0.99)\n",
    "                self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "                self.train_opt = self.optimizer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-26ef2c77d108>:60: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    }
   ],
   "source": [
    "# sample from the environment \n",
    "# initialize network and session\n",
    "tf.reset_default_graph()\n",
    "PGN = PGNetwork(state_size, action_size, learning_rate,hidden_size_1, hidden_size_2)\n",
    "VEN = VENetwork(state_size, learning_rate)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the policy until it reached maximum batch number and outputs information of each step (batch number)\n",
    "# for each episode\n",
    "def make_batch(batch_size):\n",
    "    states, actions, rewards_of_episode, rewards_of_batch, rewards_of_episode0, discounted_rewards, discounted_rewards_est = [],[],[], [], [],[], []\n",
    "    \n",
    "    # keep track of how many episodes in our batch (useful when we need to calculate the average reward)\n",
    "    episode_num = 1\n",
    "    \n",
    "    # get a new state\n",
    "    state = env.reset()\n",
    "    #state = preprocess(state)\n",
    "    while True:\n",
    "        state = preprocess(state)\n",
    "        action_probability_distribution = sess.run(PGN.action_distribution, feed_dict = {PGN.inputs: state.reshape(1,*state_size)})\n",
    "        #action_probability = sess.run(PGN.out, feed_dict = {PGN.inputs: state.reshape(1,*state_size)})\n",
    "        state_value_estimation = sess.run(VEN.state_value_estimation, feed_dict = {VEN.inputs: state.reshape(1,*state_size)})\n",
    "        #action_probability = action_probability[0][0]\n",
    "                                                                                      \n",
    "        action = np.random.choice(range(action_probability_distribution.shape[1]), p = action_probability_distribution.ravel())\n",
    "        #action = np.random.choice(range(2,4), p = [1-action_probability, action_probability])\n",
    "        action_ = [0,0]\n",
    "        action_[action] = 1\n",
    "        \n",
    "        action = action_dict[action]\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action_)\n",
    "        rewards_of_episode.append(reward)\n",
    "        rewards_of_episode0.append(reward-state_value_estimation)\n",
    "        \n",
    "        if done:\n",
    "            rewards_of_batch.append(rewards_of_episode)\n",
    "            discounted_rewards.append(discount_rewards(rewards_of_episode0, gamma = 0.99, normalization = True))\n",
    "            #discounted_rewards_est.append(discount_rewards(rewards_of_episode, gamma = 0.99, normalization = False))\n",
    "            \n",
    "            if len(np.concatenate(rewards_of_batch)) > batch_size:\n",
    "                break\n",
    "                \n",
    "            rewards_of_episode = []\n",
    "            rewards_of_episode0 = []\n",
    "            episode_num +=1\n",
    "            \n",
    "            state = env.reset()\n",
    "        else:\n",
    "            state = next_state\n",
    "    return np.stack(np.array(states)), np.stack(np.array(actions)), np.concatenate(rewards_of_batch), np.concatenate(discounted_rewards), episode_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and print sth\n",
    "allRewards = []\n",
    "\n",
    "total_rewards = 0\n",
    "maximumRewardRecorded = 0\n",
    "mean_reward_total = []\n",
    "average_reward = []\n",
    "epoch = 1\n",
    "# for plotting\n",
    "epoch_1 = []\n",
    "saver = tf.train.Saver()\n",
    "# while we have epoch/episode to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check (7796,) ()\n",
      "epoch 4401\n",
      "====================================\n",
      "Epoch:  4401 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.276982503976368\n",
      "Max reward for a batch so far: -15.0\n",
      "check 4401 4402\n",
      "Training loss:-0.003728174604475498\n",
      "check (6729,) ()\n",
      "epoch 4402\n",
      "====================================\n",
      "Epoch:  4402 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.276919582008178\n",
      "Max reward for a batch so far: -14.0\n",
      "check 4402 4403\n",
      "Training loss:-0.0167434923350811\n",
      "check (8843,) ()\n",
      "epoch 4403\n",
      "====================================\n",
      "Epoch:  4403 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.276402452873041\n",
      "Max reward for a batch so far: -12.0\n",
      "check 4403 4404\n",
      "Training loss:-0.007856504991650581\n",
      "check (10000,) ()\n",
      "epoch 4404\n",
      "====================================\n",
      "Epoch:  4404 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.275658492279746\n",
      "Max reward for a batch so far: -11.0\n",
      "check 4404 4405\n",
      "Training loss:-0.005236556753516197\n",
      "check (9134,) ()\n",
      "epoch 4405\n",
      "====================================\n",
      "Epoch:  4405 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.274460839954598\n",
      "Max reward for a batch so far: -9.0\n",
      "check 4405 4406\n",
      "Training loss:-0.003851877758279443\n",
      "check (6704,) ()\n",
      "epoch 4406\n",
      "====================================\n",
      "Epoch:  4406 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.275079437131184\n",
      "Max reward for a batch so far: -9.0\n",
      "check 4406 4407\n",
      "Training loss:-0.007091797422617674\n",
      "check (10000,) ()\n",
      "epoch 4407\n",
      "====================================\n",
      "Epoch:  4407 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -14.27184025414114\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4407 4408\n",
      "Training loss:-0.003149396041408181\n",
      "check (8020,) ()\n",
      "epoch 4408\n",
      "====================================\n",
      "Epoch:  4408 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.271098003629763\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4408 4409\n",
      "Training loss:-0.00852155964821577\n",
      "check (8801,) ()\n",
      "epoch 4409\n",
      "====================================\n",
      "Epoch:  4409 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.270129281016104\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4409 4410\n",
      "Training loss:-0.008289379999041557\n",
      "check (9063,) ()\n",
      "epoch 4410\n",
      "====================================\n",
      "Epoch:  4410 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.269387755102041\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4410 4411\n",
      "Training loss:0.0020163794979453087\n",
      "check (7324,) ()\n",
      "epoch 4411\n",
      "====================================\n",
      "Epoch:  4411 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.269553389254137\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4411 4412\n",
      "Training loss:-0.007346246391534805\n",
      "check (9481,) ()\n",
      "epoch 4412\n",
      "====================================\n",
      "Epoch:  4412 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.268359020852222\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4412 4413\n",
      "Training loss:0.004741454962641001\n",
      "check (9046,) ()\n",
      "epoch 4413\n",
      "====================================\n",
      "Epoch:  4413 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -14.266485384092453\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4413 4414\n",
      "Training loss:-0.0019645935390144587\n",
      "check (8005,) ()\n",
      "epoch 4414\n",
      "====================================\n",
      "Epoch:  4414 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.267104666968736\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4414 4415\n",
      "Training loss:0.008419360965490341\n",
      "check (7795,) ()\n",
      "epoch 4415\n",
      "====================================\n",
      "Epoch:  4415 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.265911664779162\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4415 4416\n",
      "Training loss:-0.006729578133672476\n",
      "check (7619,) ()\n",
      "epoch 4416\n",
      "====================================\n",
      "Epoch:  4416 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.265398550724637\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4416 4417\n",
      "Training loss:-0.0009464980103075504\n",
      "check (7841,) ()\n",
      "epoch 4417\n",
      "====================================\n",
      "Epoch:  4417 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.264659270998415\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4417 4418\n",
      "Training loss:0.0013505341485142708\n",
      "check (9122,) ()\n",
      "epoch 4418\n",
      "====================================\n",
      "Epoch:  4418 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.264373019465822\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4418 4419\n",
      "Training loss:-0.00948520377278328\n",
      "check (10000,) ()\n",
      "epoch 4419\n",
      "====================================\n",
      "Epoch:  4419 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -14.261371350984385\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4419 4420\n",
      "Training loss:-0.008223206736147404\n",
      "check (9554,) ()\n",
      "epoch 4420\n",
      "====================================\n",
      "Epoch:  4420 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.259954751131222\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4420 4421\n",
      "Training loss:-0.005862788297235966\n",
      "check (9746,) ()\n",
      "epoch 4421\n",
      "====================================\n",
      "Epoch:  4421 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -14.257407826283647\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4421 4422\n",
      "Training loss:-0.0006174525478854775\n",
      "check (8642,) ()\n",
      "epoch 4422\n",
      "====================================\n",
      "Epoch:  4422 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.257575757575758\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4422 4423\n",
      "Training loss:-0.006509114988148212\n",
      "check (8525,) ()\n",
      "epoch 4423\n",
      "====================================\n",
      "Epoch:  4423 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.257517522043862\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4423 4424\n",
      "Training loss:-0.006358466111123562\n",
      "check (7557,) ()\n",
      "epoch 4424\n",
      "====================================\n",
      "Epoch:  4424 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.257007233273056\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4424 4425\n",
      "Training loss:0.003504214808344841\n",
      "check (8232,) ()\n",
      "epoch 4425\n",
      "====================================\n",
      "Epoch:  4425 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.254915254237288\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4425 4426\n",
      "Training loss:0.0011388127459213138\n",
      "check (8262,) ()\n",
      "epoch 4426\n",
      "====================================\n",
      "Epoch:  4426 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.253953908721193\n",
      "Max reward for a batch so far: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4426 4427\n",
      "Training loss:-0.0061822086572647095\n",
      "check (8742,) ()\n",
      "epoch 4427\n",
      "====================================\n",
      "Epoch:  4427 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.253218884120171\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4427 4428\n",
      "Training loss:0.00486203795298934\n",
      "check (8263,) ()\n",
      "epoch 4428\n",
      "====================================\n",
      "Epoch:  4428 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.25293586269196\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4428 4429\n",
      "Training loss:-0.006765007972717285\n",
      "check (9663,) ()\n",
      "epoch 4429\n",
      "====================================\n",
      "Epoch:  4429 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.25310453827049\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4429 4430\n",
      "Training loss:0.0029222199227660894\n",
      "check (9587,) ()\n",
      "epoch 4430\n",
      "====================================\n",
      "Epoch:  4430 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.251693002257337\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4430 4431\n",
      "Training loss:0.0018371796468272805\n",
      "check (8313,) ()\n",
      "epoch 4431\n",
      "====================================\n",
      "Epoch:  4431 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.251636199503498\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4431 4432\n",
      "Training loss:-0.005699925124645233\n",
      "check (10000,) ()\n",
      "epoch 4432\n",
      "====================================\n",
      "Epoch:  4432 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.25\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4432 4433\n",
      "Training loss:0.0019444481004029512\n",
      "check (8077,) ()\n",
      "epoch 4433\n",
      "====================================\n",
      "Epoch:  4433 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.249266862170089\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4433 4434\n",
      "Training loss:0.0010161877144128084\n",
      "check (8043,) ()\n",
      "epoch 4434\n",
      "====================================\n",
      "Epoch:  4434 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.24853405502932\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4434 4435\n",
      "Training loss:-0.002631192561239004\n",
      "check (9332,) ()\n",
      "epoch 4435\n",
      "====================================\n",
      "Epoch:  4435 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.247125140924464\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4435 4436\n",
      "Training loss:0.0022609590087085962\n",
      "check (7998,) ()\n",
      "epoch 4436\n",
      "====================================\n",
      "Epoch:  4436 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.245716862037872\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4436 4437\n",
      "Training loss:-0.002270164666697383\n",
      "check (10000,) ()\n",
      "epoch 4437\n",
      "====================================\n",
      "Epoch:  4437 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.244083840432724\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4437 4438\n",
      "Training loss:-0.001782720908522606\n",
      "check (7526,) ()\n",
      "epoch 4438\n",
      "====================================\n",
      "Epoch:  4438 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -14.244930148715637\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4438 4439\n",
      "Training loss:-0.009454901330173016\n",
      "check (8471,) ()\n",
      "epoch 4439\n",
      "====================================\n",
      "Epoch:  4439 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -14.245325523766613\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4439 4440\n",
      "Training loss:-0.0041889408603310585\n",
      "check (7474,) ()\n",
      "epoch 4440\n",
      "====================================\n",
      "Epoch:  4440 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.24527027027027\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4440 4441\n",
      "Training loss:0.0005256595904938877\n",
      "check (7254,) ()\n",
      "epoch 4441\n",
      "====================================\n",
      "Epoch:  4441 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.243863994595811\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4441 4442\n",
      "Training loss:-0.0055605098605155945\n",
      "check (8060,) ()\n",
      "epoch 4442\n",
      "====================================\n",
      "Epoch:  4442 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.24313372354795\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4442 4443\n",
      "Training loss:-0.007474126759916544\n",
      "check (10000,) ()\n",
      "epoch 4443\n",
      "====================================\n",
      "Epoch:  4443 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -14.241278415485032\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4443 4444\n",
      "Training loss:0.00032149581238627434\n",
      "check (9708,) ()\n",
      "epoch 4444\n",
      "====================================\n",
      "Epoch:  4444 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.239648964896489\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4444 4445\n",
      "Training loss:0.00228545512072742\n",
      "check (7198,) ()\n",
      "epoch 4445\n",
      "====================================\n",
      "Epoch:  4445 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.239370078740157\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4445 4446\n",
      "Training loss:0.00021825575095135719\n",
      "check (7130,) ()\n",
      "epoch 4446\n",
      "====================================\n",
      "Epoch:  4446 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.239991003148898\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4446 4447\n",
      "Training loss:-0.009260925464332104\n",
      "check (8409,) ()\n",
      "epoch 4447\n",
      "====================================\n",
      "Epoch:  4447 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.239487294805487\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4447 4448\n",
      "Training loss:-0.004113651812076569\n",
      "check (10000,) ()\n",
      "epoch 4448\n",
      "====================================\n",
      "Epoch:  4448 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -14.237634892086332\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4448 4449\n",
      "Training loss:-0.0015971935354173183\n",
      "check (9165,) ()\n",
      "epoch 4449\n",
      "====================================\n",
      "Epoch:  4449 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.236008091706001\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4449 4450\n",
      "Training loss:-0.004381420090794563\n",
      "check (10000,) ()\n",
      "epoch 4450\n",
      "====================================\n",
      "Epoch:  4450 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.234606741573034\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4450 4451\n",
      "Training loss:-0.003560674609616399\n",
      "Model saved\n",
      "check (8192,) ()\n",
      "epoch 4451\n",
      "====================================\n",
      "Epoch:  4451 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.234778701415411\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4451 4452\n",
      "Training loss:0.0023523420095443726\n",
      "check (9514,) ()\n",
      "epoch 4452\n",
      "====================================\n",
      "Epoch:  4452 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.23360287511231\n",
      "Max reward for a batch so far: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4452 4453\n",
      "Training loss:-0.0033221349585801363\n",
      "check (7267,) ()\n",
      "epoch 4453\n",
      "====================================\n",
      "Epoch:  4453 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.233550415450258\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4453 4454\n",
      "Training loss:0.004147081635892391\n",
      "check (9056,) ()\n",
      "epoch 4454\n",
      "====================================\n",
      "Epoch:  4454 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.231926358329591\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4454 4455\n",
      "Training loss:-0.009169437922537327\n",
      "check (7332,) ()\n",
      "epoch 4455\n",
      "====================================\n",
      "Epoch:  4455 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.232098765432099\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4455 4456\n",
      "Training loss:-0.004241522867232561\n",
      "check (7304,) ()\n",
      "epoch 4456\n",
      "====================================\n",
      "Epoch:  4456 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.232271095152603\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4456 4457\n",
      "Training loss:-0.004746261518448591\n",
      "check (8667,) ()\n",
      "epoch 4457\n",
      "====================================\n",
      "Epoch:  4457 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.231994615212026\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4457 4458\n",
      "Training loss:0.0004422126221470535\n",
      "check (9407,) ()\n",
      "epoch 4458\n",
      "====================================\n",
      "Epoch:  4458 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.23149394347241\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4458 4459\n",
      "Training loss:0.0013088779523968697\n",
      "check (9523,) ()\n",
      "epoch 4459\n",
      "====================================\n",
      "Epoch:  4459 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.231217761830006\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4459 4460\n",
      "Training loss:-0.009720638394355774\n",
      "check (10000,) ()\n",
      "epoch 4460\n",
      "====================================\n",
      "Epoch:  4460 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.22982062780269\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4460 4461\n",
      "Training loss:-0.00655539333820343\n",
      "check (8156,) ()\n",
      "epoch 4461\n",
      "====================================\n",
      "Epoch:  4461 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.230441605021296\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4461 4462\n",
      "Training loss:-0.0015919822035357356\n",
      "check (7880,) ()\n",
      "epoch 4462\n",
      "====================================\n",
      "Epoch:  4462 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.229493500672344\n",
      "Max reward for a batch so far: 0.0\n",
      "check 4462 4463\n",
      "Training loss:-0.003182575572282076\n",
      "check (9262,) ()\n",
      "epoch 4463\n",
      "====================================\n",
      "Epoch:  4463 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:5.0\n",
      "Mean Reward of that batch 5.0\n",
      "Average Reward of all training: -14.225184853237732\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4463 4464\n",
      "Training loss:-0.0037635741755366325\n",
      "check (7938,) ()\n",
      "epoch 4464\n",
      "====================================\n",
      "Epoch:  4464 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.224910394265233\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4464 4465\n",
      "Training loss:-0.0047181760892271996\n",
      "check (8276,) ()\n",
      "epoch 4465\n",
      "====================================\n",
      "Epoch:  4465 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.224188129899217\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4465 4466\n",
      "Training loss:-0.012520997785031796\n",
      "check (7457,) ()\n",
      "epoch 4466\n",
      "====================================\n",
      "Epoch:  4466 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.2243618450515\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4466 4467\n",
      "Training loss:-0.0017056743381544948\n",
      "check (7910,) ()\n",
      "epoch 4467\n",
      "====================================\n",
      "Epoch:  4467 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.223640026863666\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4467 4468\n",
      "Training loss:0.00371281779371202\n",
      "check (8602,) ()\n",
      "epoch 4468\n",
      "====================================\n",
      "Epoch:  4468 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.222470904207698\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4468 4469\n",
      "Training loss:-0.004486180376261473\n",
      "check (7091,) ()\n",
      "epoch 4469\n",
      "====================================\n",
      "Epoch:  4469 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -14.223539941821437\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4469 4470\n",
      "Training loss:-0.0035483355168253183\n",
      "check (8287,) ()\n",
      "epoch 4470\n",
      "====================================\n",
      "Epoch:  4470 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.222371364653243\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4470 4471\n",
      "Training loss:-0.008593826554715633\n",
      "check (8681,) ()\n",
      "epoch 4471\n",
      "====================================\n",
      "Epoch:  4471 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.220979646611497\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4471 4472\n",
      "Training loss:-0.0068174805492162704\n",
      "check (7939,) ()\n",
      "epoch 4472\n",
      "====================================\n",
      "Epoch:  4472 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -14.221377459749553\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4472 4473\n",
      "Training loss:-0.006331757642328739\n",
      "check (9523,) ()\n",
      "epoch 4473\n",
      "====================================\n",
      "Epoch:  4473 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.220210149787615\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4473 4474\n",
      "Training loss:-0.0005102496943436563\n",
      "check (8401,) ()\n",
      "epoch 4474\n",
      "====================================\n",
      "Epoch:  4474 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -14.220607957085383\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4474 4475\n",
      "Training loss:0.0031023737974464893\n",
      "check (9861,) ()\n",
      "epoch 4475\n",
      "====================================\n",
      "Epoch:  4475 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.219664804469273\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4475 4476\n",
      "Training loss:0.00032549453317187726\n",
      "check (10000,) ()\n",
      "epoch 4476\n",
      "====================================\n",
      "Epoch:  4476 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -14.217828418230564\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4476 4477\n",
      "Training loss:-0.0028551325667649508\n",
      "check (9334,) ()\n",
      "epoch 4477\n",
      "====================================\n",
      "Epoch:  4477 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.216216216216216\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4477 4478\n",
      "Training loss:-0.01262699905782938\n",
      "check (8508,) ()\n",
      "epoch 4478\n",
      "====================================\n",
      "Epoch:  4478 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.215944618133095\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4478 4479\n",
      "Training loss:-0.00857619009912014\n",
      "check (9917,) ()\n",
      "epoch 4479\n",
      "====================================\n",
      "Epoch:  4479 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.215673141326189\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4479 4480\n",
      "Training loss:-0.003917686175554991\n",
      "check (8404,) ()\n",
      "epoch 4480\n",
      "====================================\n",
      "Epoch:  4480 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.2140625\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4480 4481\n",
      "Training loss:-0.010276724584400654\n",
      "check (7311,) ()\n",
      "epoch 4481\n",
      "====================================\n",
      "Epoch:  4481 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -14.214461057799598\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4481 4482\n",
      "Training loss:-0.006344915367662907\n",
      "check (9105,) ()\n",
      "epoch 4482\n",
      "====================================\n",
      "Epoch:  4482 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.213297634984382\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4482 4483\n",
      "Training loss:4.485715180635452e-05\n",
      "check (9160,) ()\n",
      "epoch 4483\n",
      "====================================\n",
      "Epoch:  4483 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.212134731206781\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4483 4484\n",
      "Training loss:0.004200688097625971\n",
      "check (7796,) ()\n",
      "epoch 4484\n",
      "====================================\n",
      "Epoch:  4484 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.210526315789474\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4484 4485\n",
      "Training loss:-0.005908453371375799\n",
      "check (8749,) ()\n",
      "epoch 4485\n",
      "====================================\n",
      "Epoch:  4485 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.20891861761427\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4485 4486\n",
      "Training loss:-0.00025726467720232904\n",
      "check (9129,) ()\n",
      "epoch 4486\n",
      "====================================\n",
      "Epoch:  4486 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.207311636201515\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4486 4487\n",
      "Training loss:-0.0010404454078525305\n",
      "check (10000,) ()\n",
      "epoch 4487\n",
      "====================================\n",
      "Epoch:  4487 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.205036772899488\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4487 4488\n",
      "Training loss:0.0008004375267773867\n",
      "check (8465,) ()\n",
      "epoch 4488\n",
      "====================================\n",
      "Epoch:  4488 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.204322638146168\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4488 4489\n",
      "Training loss:-0.004956194199621677\n",
      "check (8988,) ()\n",
      "epoch 4489\n",
      "====================================\n",
      "Epoch:  4489 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.203608821563822\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4489 4490\n",
      "Training loss:-0.00714443065226078\n",
      "check (10000,) ()\n",
      "epoch 4490\n",
      "====================================\n",
      "Epoch:  4490 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.201336302895323\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4490 4491\n",
      "Training loss:-0.002114598173648119\n",
      "check (7389,) ()\n",
      "epoch 4491\n",
      "====================================\n",
      "Epoch:  4491 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.201068804275216\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4491 4492\n",
      "Training loss:0.006375160068273544\n",
      "check (10000,) ()\n",
      "epoch 4492\n",
      "====================================\n",
      "Epoch:  4492 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.199688334817454\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4492 4493\n",
      "Training loss:-0.006575745530426502\n",
      "check (8230,) ()\n",
      "epoch 4493\n",
      "====================================\n",
      "Epoch:  4493 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.198976185176942\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4493 4494\n",
      "Training loss:-0.005602986551821232\n",
      "check (10000,) ()\n",
      "epoch 4494\n",
      "====================================\n",
      "Epoch:  4494 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.197596795727637\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4494 4495\n",
      "Training loss:0.0011611484223976731\n",
      "check (10000,) ()\n",
      "epoch 4495\n",
      "====================================\n",
      "Epoch:  4495 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -14.194883203559511\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4495 4496\n",
      "Training loss:-0.00485599460080266\n",
      "check (9129,) ()\n",
      "epoch 4496\n",
      "====================================\n",
      "Epoch:  4496 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.19461743772242\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4496 4497\n",
      "Training loss:-0.0020271490793675184\n",
      "check (8748,) ()\n",
      "epoch 4497\n",
      "====================================\n",
      "Epoch:  4497 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.194351790082276\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4497 4498\n",
      "Training loss:-0.0012343780836090446\n",
      "check (7870,) ()\n",
      "epoch 4498\n",
      "====================================\n",
      "Epoch:  4498 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.193641618497109\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4498 4499\n",
      "Training loss:-0.0027788523584604263\n",
      "check (7976,) ()\n",
      "epoch 4499\n",
      "====================================\n",
      "Epoch:  4499 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -14.194487663925317\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4499 4500\n",
      "Training loss:-0.0059302193112671375\n",
      "check (9165,) ()\n",
      "epoch 4500\n",
      "====================================\n",
      "Epoch:  4500 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.192222222222222\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4500 4501\n",
      "Training loss:-0.001357624540105462\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 4501\n",
      "====================================\n",
      "Epoch:  4501 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.19084647856032\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4501 4502\n",
      "Training loss:-0.01208684965968132\n",
      "check (9313,) ()\n",
      "epoch 4502\n",
      "====================================\n",
      "Epoch:  4502 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.19035984007108\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4502 4503\n",
      "Training loss:-0.002907518530264497\n",
      "check (10000,) ()\n",
      "epoch 4503\n",
      "====================================\n",
      "Epoch:  4503 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.18876304685765\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4503 4504\n",
      "Training loss:-0.0029431763105094433\n",
      "check (8826,) ()\n",
      "epoch 4504\n",
      "====================================\n",
      "Epoch:  4504 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.188055062166963\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4504 4505\n",
      "Training loss:-0.0026756906881928444\n",
      "check (10000,) ()\n",
      "epoch 4505\n",
      "====================================\n",
      "Epoch:  4505 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.18645948945616\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4505 4506\n",
      "Training loss:-0.0036658630706369877\n",
      "check (8344,) ()\n",
      "epoch 4506\n",
      "====================================\n",
      "Epoch:  4506 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.186196182867288\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4506 4507\n",
      "Training loss:-0.002586440183222294\n",
      "check (10000,) ()\n",
      "epoch 4507\n",
      "====================================\n",
      "Epoch:  4507 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.183936099400931\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4507 4508\n",
      "Training loss:-0.009067807346582413\n",
      "check (7908,) ()\n",
      "epoch 4508\n",
      "====================================\n",
      "Epoch:  4508 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.183895297249334\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4508 4509\n",
      "Training loss:-0.005044407676905394\n",
      "check (8997,) ()\n",
      "epoch 4509\n",
      "====================================\n",
      "Epoch:  4509 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.182302062541584\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4509 4510\n",
      "Training loss:-0.003012774745002389\n",
      "check (8539,) ()\n",
      "epoch 4510\n",
      "====================================\n",
      "Epoch:  4510 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.182261640798226\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4510 4511\n",
      "Training loss:-0.004942030180245638\n",
      "check (9078,) ()\n",
      "epoch 4511\n",
      "====================================\n",
      "Epoch:  4511 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.181556195965419\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4511 4512\n",
      "Training loss:-0.0042560468427836895\n",
      "check (8752,) ()\n",
      "epoch 4512\n",
      "====================================\n",
      "Epoch:  4512 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.181737588652481\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4512 4513\n",
      "Training loss:-0.0056257289834320545\n",
      "check (7703,) ()\n",
      "epoch 4513\n",
      "====================================\n",
      "Epoch:  4513 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -14.18280522933747\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4513 4514\n",
      "Training loss:0.0032329417299479246\n",
      "check (6079,) ()\n",
      "epoch 4514\n",
      "====================================\n",
      "Epoch:  4514 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.182100132919805\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4514 4515\n",
      "Training loss:-0.0079309968277812\n",
      "check (6018,) ()\n",
      "epoch 4515\n",
      "====================================\n",
      "Epoch:  4515 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.182281284606866\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4515 4516\n",
      "Training loss:-0.0034057607408612967\n",
      "check (9656,) ()\n",
      "epoch 4516\n",
      "====================================\n",
      "Epoch:  4516 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.181133746678476\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4516 4517\n",
      "Training loss:0.0032180543057620525\n",
      "check (8225,) ()\n",
      "epoch 4517\n",
      "====================================\n",
      "Epoch:  4517 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.180429488598627\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4517 4518\n",
      "Training loss:0.0013416251167654991\n",
      "check (9767,) ()\n",
      "epoch 4518\n",
      "====================================\n",
      "Epoch:  4518 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.17884019477645\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4518 4519\n",
      "Training loss:-0.0014053029008209705\n",
      "check (10000,) ()\n",
      "epoch 4519\n",
      "====================================\n",
      "Epoch:  4519 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.1779154680239\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4519 4520\n",
      "Training loss:-0.005484700668603182\n",
      "check (9059,) ()\n",
      "epoch 4520\n",
      "====================================\n",
      "Epoch:  4520 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.177654867256637\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4520 4521\n",
      "Training loss:0.006893819663673639\n",
      "check (7244,) ()\n",
      "epoch 4521\n",
      "====================================\n",
      "Epoch:  4521 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -14.178721521787216\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4521 4522\n",
      "Training loss:0.003618173534050584\n",
      "check (8910,) ()\n",
      "epoch 4522\n",
      "====================================\n",
      "Epoch:  4522 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.177576293675365\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4522 4523\n",
      "Training loss:-0.006144170183688402\n",
      "check (8517,) ()\n",
      "epoch 4523\n",
      "====================================\n",
      "Epoch:  4523 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.177758125138183\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4523 4524\n",
      "Training loss:-0.0030164446216076612\n",
      "check (10000,) ()\n",
      "epoch 4524\n",
      "====================================\n",
      "Epoch:  4524 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -14.175066312997348\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4524 4525\n",
      "Training loss:-0.0021742575336247683\n",
      "check (10000,) ()\n",
      "epoch 4525\n",
      "====================================\n",
      "Epoch:  4525 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.17303867403315\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4525 4526\n",
      "Training loss:-0.004171406384557486\n",
      "check (9900,) ()\n",
      "epoch 4526\n",
      "====================================\n",
      "Epoch:  4526 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.1714538223597\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4526 4527\n",
      "Training loss:-0.0038719261065125465\n",
      "check (7464,) ()\n",
      "epoch 4527\n",
      "====================================\n",
      "Epoch:  4527 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -14.172299536116634\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4527 4528\n",
      "Training loss:0.002089745132252574\n",
      "check (10000,) ()\n",
      "epoch 4528\n",
      "====================================\n",
      "Epoch:  4528 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.170273851590107\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4528 4529\n",
      "Training loss:-0.004632195923477411\n",
      "check (10000,) ()\n",
      "epoch 4529\n",
      "====================================\n",
      "Epoch:  4529 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.168690660189887\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4529 4530\n",
      "Training loss:0.0025563312228769064\n",
      "check (8465,) ()\n",
      "epoch 4530\n",
      "====================================\n",
      "Epoch:  4530 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.167328918322296\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4530 4531\n",
      "Training loss:0.0004513559688348323\n",
      "check (10000,) ()\n",
      "epoch 4531\n",
      "====================================\n",
      "Epoch:  4531 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.165305672037078\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4531 4532\n",
      "Training loss:0.006055037956684828\n",
      "check (10000,) ()\n",
      "epoch 4532\n",
      "====================================\n",
      "Epoch:  4532 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.163945278022949\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4532 4533\n",
      "Training loss:-0.00798210222274065\n",
      "check (9100,) ()\n",
      "epoch 4533\n",
      "====================================\n",
      "Epoch:  4533 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.162364879770571\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4533 4534\n",
      "Training loss:-0.0003551919071469456\n",
      "check (7142,) ()\n",
      "epoch 4534\n",
      "====================================\n",
      "Epoch:  4534 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -14.162770180855757\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4534 4535\n",
      "Training loss:-0.0016047240933403373\n",
      "check (9501,) ()\n",
      "epoch 4535\n",
      "====================================\n",
      "Epoch:  4535 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.161631753031974\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4535 4536\n",
      "Training loss:0.0010260238777846098\n",
      "check (8325,) ()\n",
      "epoch 4536\n",
      "====================================\n",
      "Epoch:  4536 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.16005291005291\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4536 4537\n",
      "Training loss:0.0019271631026640534\n",
      "check (9537,) ()\n",
      "epoch 4537\n",
      "====================================\n",
      "Epoch:  4537 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.15847476305929\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4537 4538\n",
      "Training loss:-0.011293791234493256\n",
      "check (8089,) ()\n",
      "epoch 4538\n",
      "====================================\n",
      "Epoch:  4538 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.15866020273248\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4538 4539\n",
      "Training loss:-0.006381476763635874\n",
      "check (10000,) ()\n",
      "epoch 4539\n",
      "====================================\n",
      "Epoch:  4539 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.157303370786517\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4539 4540\n",
      "Training loss:-0.001795818330720067\n",
      "check (9914,) ()\n",
      "epoch 4540\n",
      "====================================\n",
      "Epoch:  4540 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -14.155506607929516\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4540 4541\n",
      "Training loss:-0.0039313314482569695\n",
      "check (8643,) ()\n",
      "epoch 4541\n",
      "====================================\n",
      "Epoch:  4541 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.154591499669676\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4541 4542\n",
      "Training loss:-0.002152683911845088\n",
      "check (10000,) ()\n",
      "epoch 4542\n",
      "====================================\n",
      "Epoch:  4542 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.154117129018054\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4542 4543\n",
      "Training loss:-0.00396167766302824\n",
      "check (8883,) ()\n",
      "epoch 4543\n",
      "====================================\n",
      "Epoch:  4543 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.152762491745543\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4543 4544\n",
      "Training loss:-0.001898320158943534\n",
      "check (9063,) ()\n",
      "epoch 4544\n",
      "====================================\n",
      "Epoch:  4544 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.15206866197183\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4544 4545\n",
      "Training loss:0.004705560859292746\n",
      "check (8701,) ()\n",
      "epoch 4545\n",
      "====================================\n",
      "Epoch:  4545 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.152035203520352\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4545 4546\n",
      "Training loss:-0.009341244585812092\n",
      "check (10000,) ()\n",
      "epoch 4546\n",
      "====================================\n",
      "Epoch:  4546 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.15068191816982\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4546 4547\n",
      "Training loss:-0.0013000603066757321\n",
      "check (7914,) ()\n",
      "epoch 4547\n",
      "====================================\n",
      "Epoch:  4547 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.150428854189576\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4547 4548\n",
      "Training loss:-0.00021533783001359552\n",
      "check (8401,) ()\n",
      "epoch 4548\n",
      "====================================\n",
      "Epoch:  4548 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.150175901495162\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4548 4549\n",
      "Training loss:-0.005621719639748335\n",
      "check (9150,) ()\n",
      "epoch 4549\n",
      "====================================\n",
      "Epoch:  4549 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.14926357441196\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4549 4550\n",
      "Training loss:-0.006426929496228695\n",
      "check (8800,) ()\n",
      "epoch 4550\n",
      "====================================\n",
      "Epoch:  4550 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.14901098901099\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4550 4551\n",
      "Training loss:0.005146416835486889\n",
      "Model saved\n",
      "check (8792,) ()\n",
      "epoch 4551\n",
      "====================================\n",
      "Epoch:  4551 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.147879586903978\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4551 4552\n",
      "Training loss:-0.0014723256463184953\n",
      "check (8469,) ()\n",
      "epoch 4552\n",
      "====================================\n",
      "Epoch:  4552 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.14762741652021\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4552 4553\n",
      "Training loss:-0.0024688562843948603\n",
      "check (10000,) ()\n",
      "epoch 4553\n",
      "====================================\n",
      "Epoch:  4553 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.146716450691851\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4553 4554\n",
      "Training loss:-0.00913739949464798\n",
      "check (7283,) ()\n",
      "epoch 4554\n",
      "====================================\n",
      "Epoch:  4554 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.146903820816865\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4554 4555\n",
      "Training loss:0.004913656506687403\n",
      "check (8862,) ()\n",
      "epoch 4555\n",
      "====================================\n",
      "Epoch:  4555 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.145993413830954\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4555 4556\n",
      "Training loss:-0.00047726157936267555\n",
      "check (9371,) ()\n",
      "epoch 4556\n",
      "====================================\n",
      "Epoch:  4556 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.143985952589992\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4556 4557\n",
      "Training loss:-0.01197855919599533\n",
      "check (7225,) ()\n",
      "epoch 4557\n",
      "====================================\n",
      "Epoch:  4557 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.143515470704411\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4557 4558\n",
      "Training loss:-0.006188968196511269\n",
      "check (9894,) ()\n",
      "epoch 4558\n",
      "====================================\n",
      "Epoch:  4558 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -14.141728828433523\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4558 4559\n",
      "Training loss:-0.005476399790495634\n",
      "check (8067,) ()\n",
      "epoch 4559\n",
      "====================================\n",
      "Epoch:  4559 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.141697740732617\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4559 4560\n",
      "Training loss:0.003912582062184811\n",
      "check (8960,) ()\n",
      "epoch 4560\n",
      "====================================\n",
      "Epoch:  4560 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.14078947368421\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4560 4561\n",
      "Training loss:-0.005810072645545006\n",
      "check (8757,) ()\n",
      "epoch 4561\n",
      "====================================\n",
      "Epoch:  4561 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.138566103924578\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4561 4562\n",
      "Training loss:-0.0030582223553210497\n",
      "check (8922,) ()\n",
      "epoch 4562\n",
      "====================================\n",
      "Epoch:  4562 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.137878123629987\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4562 4563\n",
      "Training loss:-0.003299571108072996\n",
      "check (8735,) ()\n",
      "epoch 4563\n",
      "====================================\n",
      "Epoch:  4563 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.137190444882753\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4563 4564\n",
      "Training loss:0.00748803885653615\n",
      "check (7457,) ()\n",
      "epoch 4564\n",
      "====================================\n",
      "Epoch:  4564 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.13737949167397\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4564 4565\n",
      "Training loss:0.0001649701880523935\n",
      "check (8273,) ()\n",
      "epoch 4565\n",
      "====================================\n",
      "Epoch:  4565 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.136254107338445\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4565 4566\n",
      "Training loss:0.008909288793802261\n",
      "check (10000,) ()\n",
      "epoch 4566\n",
      "====================================\n",
      "Epoch:  4566 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.13425317564608\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4566 4567\n",
      "Training loss:-0.0009663127711974084\n",
      "check (7713,) ()\n",
      "epoch 4567\n",
      "====================================\n",
      "Epoch:  4567 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.133566892927524\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4567 4568\n",
      "Training loss:0.0015689939027652144\n",
      "check (8733,) ()\n",
      "epoch 4568\n",
      "====================================\n",
      "Epoch:  4568 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.132880910683012\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4568 4569\n",
      "Training loss:0.0029085788410156965\n",
      "check (7739,) ()\n",
      "epoch 4569\n",
      "====================================\n",
      "Epoch:  4569 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.132414094987963\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4569 4570\n",
      "Training loss:-0.013986572623252869\n",
      "check (9036,) ()\n",
      "epoch 4570\n",
      "====================================\n",
      "Epoch:  4570 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.131509846827134\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4570 4571\n",
      "Training loss:-0.000934575917199254\n",
      "check (7687,) ()\n",
      "epoch 4571\n",
      "====================================\n",
      "Epoch:  4571 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -14.131918617370378\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4571 4572\n",
      "Training loss:-0.005413798149675131\n",
      "check (7838,) ()\n",
      "epoch 4572\n",
      "====================================\n",
      "Epoch:  4572 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.131452318460193\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4572 4573\n",
      "Training loss:7.288515189429745e-05\n",
      "check (8936,) ()\n",
      "epoch 4573\n",
      "====================================\n",
      "Epoch:  4573 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.130330198994097\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4573 4574\n",
      "Training loss:-0.001990663120523095\n",
      "check (10000,) ()\n",
      "epoch 4574\n",
      "====================================\n",
      "Epoch:  4574 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.128989943156974\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4574 4575\n",
      "Training loss:-0.0016465907683596015\n",
      "check (7812,) ()\n",
      "epoch 4575\n",
      "====================================\n",
      "Epoch:  4575 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.127650273224043\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4575 4576\n",
      "Training loss:-0.008599256165325642\n",
      "check (7967,) ()\n",
      "epoch 4576\n",
      "====================================\n",
      "Epoch:  4576 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.127840909090908\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4576 4577\n",
      "Training loss:0.0014589508064091206\n",
      "check (7771,) ()\n",
      "epoch 4577\n",
      "====================================\n",
      "Epoch:  4577 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.126720559318331\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4577 4578\n",
      "Training loss:0.0031692050397396088\n",
      "check (6869,) ()\n",
      "epoch 4578\n",
      "====================================\n",
      "Epoch:  4578 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.126474442988204\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4578 4579\n",
      "Training loss:0.0014355112798511982\n",
      "check (9530,) ()\n",
      "epoch 4579\n",
      "====================================\n",
      "Epoch:  4579 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.12535488097838\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4579 4580\n",
      "Training loss:-0.000895864621270448\n",
      "check (7938,) ()\n",
      "epoch 4580\n",
      "====================================\n",
      "Epoch:  4580 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.125545851528384\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4580 4581\n",
      "Training loss:2.5551455564709613e-06\n",
      "check (7633,) ()\n",
      "epoch 4581\n",
      "====================================\n",
      "Epoch:  4581 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.125518445754203\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4581 4582\n",
      "Training loss:-0.0029814541339874268\n",
      "check (6736,) ()\n",
      "epoch 4582\n",
      "====================================\n",
      "Epoch:  4582 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.124399825403755\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4582 4583\n",
      "Training loss:-0.001116556697525084\n",
      "check (6883,) ()\n",
      "epoch 4583\n",
      "====================================\n",
      "Epoch:  4583 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.12415448396247\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4583 4584\n",
      "Training loss:-0.004211734049022198\n",
      "check (9322,) ()\n",
      "epoch 4584\n",
      "====================================\n",
      "Epoch:  4584 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.1239092495637\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4584 4585\n",
      "Training loss:-0.0007102318340912461\n",
      "check (9650,) ()\n",
      "epoch 4585\n",
      "====================================\n",
      "Epoch:  4585 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.122573609596511\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4585 4586\n",
      "Training loss:-0.0021823104470968246\n",
      "check (7765,) ()\n",
      "epoch 4586\n",
      "====================================\n",
      "Epoch:  4586 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.122546881814218\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4586 4587\n",
      "Training loss:-0.005922877229750156\n",
      "check (10000,) ()\n",
      "epoch 4587\n",
      "====================================\n",
      "Epoch:  4587 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.120558098975366\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4587 4588\n",
      "Training loss:0.0006265667034313083\n",
      "check (7097,) ()\n",
      "epoch 4588\n",
      "====================================\n",
      "Epoch:  4588 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.120313862249347\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4588 4589\n",
      "Training loss:-0.002036205492913723\n",
      "check (9454,) ()\n",
      "epoch 4589\n",
      "====================================\n",
      "Epoch:  4589 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.119415994770103\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4589 4590\n",
      "Training loss:-0.00491483137011528\n",
      "check (8876,) ()\n",
      "epoch 4590\n",
      "====================================\n",
      "Epoch:  4590 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.118736383442267\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4590 4591\n",
      "Training loss:-0.0076570333912968636\n",
      "check (7675,) ()\n",
      "epoch 4591\n",
      "====================================\n",
      "Epoch:  4591 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.118928338052712\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4591 4592\n",
      "Training loss:-0.0004603979177772999\n",
      "check (7432,) ()\n",
      "epoch 4592\n",
      "====================================\n",
      "Epoch:  4592 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.119120209059233\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4592 4593\n",
      "Training loss:0.003766613081097603\n",
      "check (9830,) ()\n",
      "epoch 4593\n",
      "====================================\n",
      "Epoch:  4593 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.118441106030916\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4593 4594\n",
      "Training loss:-0.001900032046250999\n",
      "check (8478,) ()\n",
      "epoch 4594\n",
      "====================================\n",
      "Epoch:  4594 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.117979973878972\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4594 4595\n",
      "Training loss:0.001533489441499114\n",
      "check (9193,) ()\n",
      "epoch 4595\n",
      "====================================\n",
      "Epoch:  4595 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.116866158868335\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4595 4596\n",
      "Training loss:-0.011275098659098148\n",
      "check (10000,) ()\n",
      "epoch 4596\n",
      "====================================\n",
      "Epoch:  4596 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -14.113577023498694\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4596 4597\n",
      "Training loss:-0.007795610930770636\n",
      "check (8452,) ()\n",
      "epoch 4597\n",
      "====================================\n",
      "Epoch:  4597 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.113334783554492\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4597 4598\n",
      "Training loss:-0.009390486404299736\n",
      "check (9973,) ()\n",
      "epoch 4598\n",
      "====================================\n",
      "Epoch:  4598 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -14.111570247933884\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4598 4599\n",
      "Training loss:-0.011131348088383675\n",
      "check (9388,) ()\n",
      "epoch 4599\n",
      "====================================\n",
      "Epoch:  4599 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.11176342683192\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4599 4600\n",
      "Training loss:0.00015538187290076166\n",
      "check (8959,) ()\n",
      "epoch 4600\n",
      "====================================\n",
      "Epoch:  4600 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.112391304347826\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4600 4601\n",
      "Training loss:0.0033921748399734497\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 4601\n",
      "====================================\n",
      "Epoch:  4601 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.110410780265159\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4601 4602\n",
      "Training loss:-0.008380359970033169\n",
      "check (8673,) ()\n",
      "epoch 4602\n",
      "====================================\n",
      "Epoch:  4602 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.111038678835289\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4602 4603\n",
      "Training loss:-0.0013499598717316985\n",
      "check (7650,) ()\n",
      "epoch 4603\n",
      "====================================\n",
      "Epoch:  4603 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.110362806865089\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4603 4604\n",
      "Training loss:-0.0031284098513424397\n",
      "check (7410,) ()\n",
      "epoch 4604\n",
      "====================================\n",
      "Epoch:  4604 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.10881841876629\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4604 4605\n",
      "Training loss:0.005648721940815449\n",
      "check (6871,) ()\n",
      "epoch 4605\n",
      "====================================\n",
      "Epoch:  4605 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.1085776330076\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4605 4606\n",
      "Training loss:-0.00851875264197588\n",
      "check (10000,) ()\n",
      "epoch 4606\n",
      "====================================\n",
      "Epoch:  4606 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.107251411202778\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4606 4607\n",
      "Training loss:0.002028038026764989\n",
      "check (8597,) ()\n",
      "epoch 4607\n",
      "====================================\n",
      "Epoch:  4607 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.106142826134144\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4607 4608\n",
      "Training loss:-0.006531459279358387\n",
      "check (8554,) ()\n",
      "epoch 4608\n",
      "====================================\n",
      "Epoch:  4608 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.104817708333334\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4608 4609\n",
      "Training loss:0.0014416987542062998\n",
      "check (8475,) ()\n",
      "epoch 4609\n",
      "====================================\n",
      "Epoch:  4609 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.104361032761988\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4609 4610\n",
      "Training loss:-0.007442880421876907\n",
      "check (8035,) ()\n",
      "epoch 4610\n",
      "====================================\n",
      "Epoch:  4610 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.10347071583514\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4610 4611\n",
      "Training loss:0.003559988923370838\n",
      "check (10000,) ()\n",
      "epoch 4611\n",
      "====================================\n",
      "Epoch:  4611 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -14.10062893081761\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4611 4612\n",
      "Training loss:-0.0054375184699893\n",
      "check (8559,) ()\n",
      "epoch 4612\n",
      "====================================\n",
      "Epoch:  4612 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.099739809193409\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4612 4613\n",
      "Training loss:0.0030385006684809923\n",
      "check (7940,) ()\n",
      "epoch 4613\n",
      "====================================\n",
      "Epoch:  4613 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.100368523737265\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4613 4614\n",
      "Training loss:-0.011158146895468235\n",
      "check (10000,) ()\n",
      "epoch 4614\n",
      "====================================\n",
      "Epoch:  4614 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.099046380580841\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4614 4615\n",
      "Training loss:0.0010930305579677224\n",
      "check (9275,) ()\n",
      "epoch 4615\n",
      "====================================\n",
      "Epoch:  4615 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.097724810400866\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4615 4616\n",
      "Training loss:-0.0040041059255599976\n",
      "check (8807,) ()\n",
      "epoch 4616\n",
      "====================================\n",
      "Epoch:  4616 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.097270363951473\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4616 4617\n",
      "Training loss:-0.0007044901722110808\n",
      "check (9020,) ()\n",
      "epoch 4617\n",
      "====================================\n",
      "Epoch:  4617 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.09746588693957\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4617 4618\n",
      "Training loss:-0.0058679645881056786\n",
      "check (8320,) ()\n",
      "epoch 4618\n",
      "====================================\n",
      "Epoch:  4618 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.096578605456907\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4618 4619\n",
      "Training loss:-0.003049596445634961\n",
      "check (9482,) ()\n",
      "epoch 4619\n",
      "====================================\n",
      "Epoch:  4619 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.09590820523923\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4619 4620\n",
      "Training loss:-0.00471168477088213\n",
      "check (8948,) ()\n",
      "epoch 4620\n",
      "====================================\n",
      "Epoch:  4620 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.094805194805195\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4620 4621\n",
      "Training loss:-0.0024293747264891863\n",
      "check (7926,) ()\n",
      "epoch 4621\n",
      "====================================\n",
      "Epoch:  4621 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.09500108201688\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4621 4622\n",
      "Training loss:-0.010306433774530888\n",
      "check (7638,) ()\n",
      "epoch 4622\n",
      "====================================\n",
      "Epoch:  4622 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.095196884465599\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4622 4623\n",
      "Training loss:-0.003999451175332069\n",
      "check (8694,) ()\n",
      "epoch 4623\n",
      "====================================\n",
      "Epoch:  4623 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.09322950465066\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4623 4624\n",
      "Training loss:0.0024234086740761995\n",
      "check (10000,) ()\n",
      "epoch 4624\n",
      "====================================\n",
      "Epoch:  4624 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -14.091479238754324\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4624 4625\n",
      "Training loss:-0.006940288469195366\n",
      "check (8350,) ()\n",
      "epoch 4625\n",
      "====================================\n",
      "Epoch:  4625 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.091243243243243\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4625 4626\n",
      "Training loss:-0.001047512050718069\n",
      "check (6468,) ()\n",
      "epoch 4626\n",
      "====================================\n",
      "Epoch:  4626 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.091872027669693\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4626 4627\n",
      "Training loss:-0.007939860224723816\n",
      "check (8599,) ()\n",
      "epoch 4627\n",
      "====================================\n",
      "Epoch:  4627 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.091203803760536\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4627 4628\n",
      "Training loss:-0.008266149088740349\n",
      "check (6584,) ()\n",
      "epoch 4628\n",
      "====================================\n",
      "Epoch:  4628 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.090968020743302\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4628 4629\n",
      "Training loss:-0.005655554588884115\n",
      "check (8872,) ()\n",
      "epoch 4629\n",
      "====================================\n",
      "Epoch:  4629 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.089436163318211\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4629 4630\n",
      "Training loss:-0.007939144037663937\n",
      "check (7776,) ()\n",
      "epoch 4630\n",
      "====================================\n",
      "Epoch:  4630 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.089200863930886\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4630 4631\n",
      "Training loss:-0.0038969821762293577\n",
      "check (6620,) ()\n",
      "epoch 4631\n",
      "====================================\n",
      "Epoch:  4631 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -14.090261282660332\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4631 4632\n",
      "Training loss:-0.0017451808089390397\n",
      "check (7795,) ()\n",
      "epoch 4632\n",
      "====================================\n",
      "Epoch:  4632 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.090241796200345\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4632 4633\n",
      "Training loss:-0.005861230660229921\n",
      "check (8612,) ()\n",
      "epoch 4633\n",
      "====================================\n",
      "Epoch:  4633 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.089143103820419\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4633 4634\n",
      "Training loss:-0.003817469347268343\n",
      "check (9679,) ()\n",
      "epoch 4634\n",
      "====================================\n",
      "Epoch:  4634 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.087181700474751\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4634 4635\n",
      "Training loss:-0.011351586319506168\n",
      "check (8881,) ()\n",
      "epoch 4635\n",
      "====================================\n",
      "Epoch:  4635 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.085005393743257\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4635 4636\n",
      "Training loss:-0.0038857164327055216\n",
      "check (7087,) ()\n",
      "epoch 4636\n",
      "====================================\n",
      "Epoch:  4636 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.08455565142364\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4636 4637\n",
      "Training loss:-0.0033570530358701944\n",
      "check (6768,) ()\n",
      "epoch 4637\n",
      "====================================\n",
      "Epoch:  4637 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.085184386456762\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4637 4638\n",
      "Training loss:-0.009425110183656216\n",
      "check (10000,) ()\n",
      "epoch 4638\n",
      "====================================\n",
      "Epoch:  4638 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -14.081931867184132\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4638 4639\n",
      "Training loss:-0.00533230509608984\n",
      "check (8377,) ()\n",
      "epoch 4639\n",
      "====================================\n",
      "Epoch:  4639 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.081483078249622\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4639 4640\n",
      "Training loss:-0.0035056353081017733\n",
      "check (9253,) ()\n",
      "epoch 4640\n",
      "====================================\n",
      "Epoch:  4640 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.080387931034483\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4640 4641\n",
      "Training loss:-0.007455113343894482\n",
      "check (9100,) ()\n",
      "epoch 4641\n",
      "====================================\n",
      "Epoch:  4641 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.079724197371256\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4641 4642\n",
      "Training loss:-0.004434545524418354\n",
      "check (7755,) ()\n",
      "epoch 4642\n",
      "====================================\n",
      "Epoch:  4642 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.079491598448945\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4642 4643\n",
      "Training loss:-0.004049255046993494\n",
      "check (9441,) ()\n",
      "epoch 4643\n",
      "====================================\n",
      "Epoch:  4643 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.07882834374327\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4643 4644\n",
      "Training loss:-0.008447259664535522\n",
      "check (9502,) ()\n",
      "epoch 4644\n",
      "====================================\n",
      "Epoch:  4644 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.078165374677003\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4644 4645\n",
      "Training loss:-0.0038194083608686924\n",
      "check (10000,) ()\n",
      "epoch 4645\n",
      "====================================\n",
      "Epoch:  4645 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -14.075349838536061\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4645 4646\n",
      "Training loss:-0.005604844074696302\n",
      "check (6474,) ()\n",
      "epoch 4646\n",
      "====================================\n",
      "Epoch:  4646 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.075118381403358\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4646 4647\n",
      "Training loss:0.00022140092914924026\n",
      "check (10000,) ()\n",
      "epoch 4647\n",
      "====================================\n",
      "Epoch:  4647 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.072950290510006\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4647 4648\n",
      "Training loss:-0.0003873262321576476\n",
      "check (8492,) ()\n",
      "epoch 4648\n",
      "====================================\n",
      "Epoch:  4648 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.072074010327022\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4648 4649\n",
      "Training loss:-0.007357691414654255\n",
      "check (9812,) ()\n",
      "epoch 4649\n",
      "====================================\n",
      "Epoch:  4649 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.07119810711981\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4649 4650\n",
      "Training loss:-0.006330127362161875\n",
      "check (6622,) ()\n",
      "epoch 4650\n",
      "====================================\n",
      "Epoch:  4650 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.071827956989248\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4650 4651\n",
      "Training loss:-0.005364387761801481\n",
      "Model saved\n",
      "check (9175,) ()\n",
      "epoch 4651\n",
      "====================================\n",
      "Epoch:  4651 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.072027520963234\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4651 4652\n",
      "Training loss:0.0017632187809795141\n",
      "check (8668,) ()\n",
      "epoch 4652\n",
      "====================================\n",
      "Epoch:  4652 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.070507308684437\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4652 4653\n",
      "Training loss:-0.0018911779625341296\n",
      "check (8344,) ()\n",
      "epoch 4653\n",
      "====================================\n",
      "Epoch:  4653 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.070707070707071\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4653 4654\n",
      "Training loss:-0.008348491974174976\n",
      "check (5717,) ()\n",
      "epoch 4654\n",
      "====================================\n",
      "Epoch:  4654 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.071336484744306\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4654 4655\n",
      "Training loss:-0.0008818358764983714\n",
      "check (7289,) ()\n",
      "epoch 4655\n",
      "====================================\n",
      "Epoch:  4655 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -14.071321160042965\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4655 4656\n",
      "Training loss:-0.00038472338928841054\n",
      "check (8304,) ()\n",
      "epoch 4656\n",
      "====================================\n",
      "Epoch:  4656 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.070661512027492\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4656 4657\n",
      "Training loss:-0.0030022412538528442\n",
      "check (7056,) ()\n",
      "epoch 4657\n",
      "====================================\n",
      "Epoch:  4657 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.070431608331544\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4657 4658\n",
      "Training loss:-0.004884326830506325\n",
      "check (8343,) ()\n",
      "epoch 4658\n",
      "====================================\n",
      "Epoch:  4658 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.070201803349077\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4658 4659\n",
      "Training loss:0.001001761993393302\n",
      "check (6839,) ()\n",
      "epoch 4659\n",
      "====================================\n",
      "Epoch:  4659 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.069972097016526\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4659 4660\n",
      "Training loss:-0.0012730574235320091\n",
      "check (9055,) ()\n",
      "epoch 4660\n",
      "====================================\n",
      "Epoch:  4660 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.067811158798284\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4660 4661\n",
      "Training loss:-0.00708341971039772\n",
      "check (9320,) ()\n",
      "epoch 4661\n",
      "====================================\n",
      "Epoch:  4661 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.066723878995923\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4661 4662\n",
      "Training loss:0.002591134747490287\n",
      "check (9632,) ()\n",
      "epoch 4662\n",
      "====================================\n",
      "Epoch:  4662 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.066280566280566\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4662 4663\n",
      "Training loss:0.004688291344791651\n",
      "check (8050,) ()\n",
      "epoch 4663\n",
      "====================================\n",
      "Epoch:  4663 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.065194081063693\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4663 4664\n",
      "Training loss:-0.00472295144572854\n",
      "check (7047,) ()\n",
      "epoch 4664\n",
      "====================================\n",
      "Epoch:  4664 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.064965694682677\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4664 4665\n",
      "Training loss:0.00011047843872802332\n",
      "check (7892,) ()\n",
      "epoch 4665\n",
      "====================================\n",
      "Epoch:  4665 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.064094319399786\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4665 4666\n",
      "Training loss:-0.0023095363285392523\n",
      "check (8949,) ()\n",
      "epoch 4666\n",
      "====================================\n",
      "Epoch:  4666 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.06258036862409\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4666 4667\n",
      "Training loss:-0.0015401288401335478\n",
      "check (9065,) ()\n",
      "epoch 4667\n",
      "====================================\n",
      "Epoch:  4667 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.061709877865868\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4667 4668\n",
      "Training loss:0.0014153822558000684\n",
      "check (8535,) ()\n",
      "epoch 4668\n",
      "====================================\n",
      "Epoch:  4668 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.060625535561268\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4668 4669\n",
      "Training loss:-0.007192921359091997\n",
      "check (8498,) ()\n",
      "epoch 4669\n",
      "====================================\n",
      "Epoch:  4669 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.060184193617477\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4669 4670\n",
      "Training loss:0.0009950550738722086\n",
      "check (8769,) ()\n",
      "epoch 4670\n",
      "====================================\n",
      "Epoch:  4670 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.058672376873663\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4670 4671\n",
      "Training loss:-0.008756023831665516\n",
      "check (9543,) ()\n",
      "epoch 4671\n",
      "====================================\n",
      "Epoch:  4671 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -14.057161207450225\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4671 4672\n",
      "Training loss:-0.003095281543210149\n",
      "check (7749,) ()\n",
      "epoch 4672\n",
      "====================================\n",
      "Epoch:  4672 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.05736301369863\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4672 4673\n",
      "Training loss:0.0017853304743766785\n",
      "check (9730,) ()\n",
      "epoch 4673\n",
      "====================================\n",
      "Epoch:  4673 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -14.054568799486411\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4673 4674\n",
      "Training loss:-0.0054248939268291\n",
      "check (7173,) ()\n",
      "epoch 4674\n",
      "====================================\n",
      "Epoch:  4674 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.055198973042362\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4674 4675\n",
      "Training loss:0.00010709019261412323\n",
      "check (7912,) ()\n",
      "epoch 4675\n",
      "====================================\n",
      "Epoch:  4675 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.055401069518716\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4675 4676\n",
      "Training loss:-0.008487613871693611\n",
      "check (9495,) ()\n",
      "epoch 4676\n",
      "====================================\n",
      "Epoch:  4676 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.054319931565441\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4676 4677\n",
      "Training loss:-0.005189924966543913\n",
      "check (8381,) ()\n",
      "epoch 4677\n",
      "====================================\n",
      "Epoch:  4677 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.05323925593329\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4677 4678\n",
      "Training loss:-0.0065841651521623135\n",
      "check (7817,) ()\n",
      "epoch 4678\n",
      "====================================\n",
      "Epoch:  4678 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.053014108593416\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4678 4679\n",
      "Training loss:-0.011129620485007763\n",
      "check (9000,) ()\n",
      "epoch 4679\n",
      "====================================\n",
      "Epoch:  4679 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.051934173968796\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4679 4680\n",
      "Training loss:0.00033531145891174674\n",
      "check (10000,) ()\n",
      "epoch 4680\n",
      "====================================\n",
      "Epoch:  4680 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.051068376068375\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4680 4681\n",
      "Training loss:-0.010423069819808006\n",
      "check (8766,) ()\n",
      "epoch 4681\n",
      "====================================\n",
      "Epoch:  4681 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.049989318521684\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4681 4682\n",
      "Training loss:-0.00011934788926737383\n",
      "check (9394,) ()\n",
      "epoch 4682\n",
      "====================================\n",
      "Epoch:  4682 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -14.047629218282784\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4682 4683\n",
      "Training loss:-0.0017771408893167973\n",
      "check (8418,) ()\n",
      "epoch 4683\n",
      "====================================\n",
      "Epoch:  4683 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.046978432628658\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4683 4684\n",
      "Training loss:-0.0028910371474921703\n",
      "check (8394,) ()\n",
      "epoch 4684\n",
      "====================================\n",
      "Epoch:  4684 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.046754910333048\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4684 4685\n",
      "Training loss:-0.0005256672156974673\n",
      "check (7997,) ()\n",
      "epoch 4685\n",
      "====================================\n",
      "Epoch:  4685 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.04546424759872\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4685 4686\n",
      "Training loss:8.527997124474496e-05\n",
      "check (9531,) ()\n",
      "epoch 4686\n",
      "====================================\n",
      "Epoch:  4686 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.043320529236022\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4686 4687\n",
      "Training loss:0.002398798242211342\n",
      "check (10000,) ()\n",
      "epoch 4687\n",
      "====================================\n",
      "Epoch:  4687 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.041391081715384\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4687 4688\n",
      "Training loss:-0.008848749101161957\n",
      "check (9793,) ()\n",
      "epoch 4688\n",
      "====================================\n",
      "Epoch:  4688 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.039462457337883\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4688 4689\n",
      "Training loss:-0.009943529032170773\n",
      "check (9016,) ()\n",
      "epoch 4689\n",
      "====================================\n",
      "Epoch:  4689 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.037321390488376\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4689 4690\n",
      "Training loss:-0.007917795330286026\n",
      "check (8336,) ()\n",
      "epoch 4690\n",
      "====================================\n",
      "Epoch:  4690 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.037100213219617\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4690 4691\n",
      "Training loss:-0.0019600405357778072\n",
      "check (9894,) ()\n",
      "epoch 4691\n",
      "====================================\n",
      "Epoch:  4691 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.036026433596248\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4691 4692\n",
      "Training loss:-0.0033506606705486774\n",
      "check (6297,) ()\n",
      "epoch 4692\n",
      "====================================\n",
      "Epoch:  4692 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.03623188405797\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4692 4693\n",
      "Training loss:-0.005965685937553644\n",
      "check (9487,) ()\n",
      "epoch 4693\n",
      "====================================\n",
      "Epoch:  4693 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.035158747070104\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4693 4694\n",
      "Training loss:-0.00569424731656909\n",
      "check (10000,) ()\n",
      "epoch 4694\n",
      "====================================\n",
      "Epoch:  4694 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -14.032594801874733\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4694 4695\n",
      "Training loss:-0.005783602129667997\n",
      "check (8480,) ()\n",
      "epoch 4695\n",
      "====================================\n",
      "Epoch:  4695 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.032161874334399\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4695 4696\n",
      "Training loss:-0.007940275594592094\n",
      "check (10000,) ()\n",
      "epoch 4696\n",
      "====================================\n",
      "Epoch:  4696 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.03023850085179\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4696 4697\n",
      "Training loss:-0.004079905338585377\n",
      "check (7935,) ()\n",
      "epoch 4697\n",
      "====================================\n",
      "Epoch:  4697 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.030019161166702\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4697 4698\n",
      "Training loss:-0.007658532354980707\n",
      "check (10000,) ()\n",
      "epoch 4698\n",
      "====================================\n",
      "Epoch:  4698 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.027884206045126\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4698 4699\n",
      "Training loss:-0.007505669258534908\n",
      "check (8147,) ()\n",
      "epoch 4699\n",
      "====================================\n",
      "Epoch:  4699 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.027665460736326\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4699 4700\n",
      "Training loss:-0.010231895372271538\n",
      "check (10000,) ()\n",
      "epoch 4700\n",
      "====================================\n",
      "Epoch:  4700 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.025744680851064\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4700 4701\n",
      "Training loss:-0.008955652825534344\n",
      "Model saved\n",
      "check (9573,) ()\n",
      "epoch 4701\n",
      "====================================\n",
      "Epoch:  4701 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -14.023186556051904\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4701 4702\n",
      "Training loss:-0.005555725656449795\n",
      "check (10000,) ()\n",
      "epoch 4702\n",
      "====================================\n",
      "Epoch:  4702 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.021054870267971\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4702 4703\n",
      "Training loss:-0.0009296127245761454\n",
      "check (7826,) ()\n",
      "epoch 4703\n",
      "====================================\n",
      "Epoch:  4703 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.021263023601955\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4703 4704\n",
      "Training loss:0.0026021499652415514\n",
      "check (7451,) ()\n",
      "epoch 4704\n",
      "====================================\n",
      "Epoch:  4704 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.021896258503402\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4704 4705\n",
      "Training loss:-0.007836507633328438\n",
      "check (10000,) ()\n",
      "epoch 4705\n",
      "====================================\n",
      "Epoch:  4705 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.021466524973432\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4705 4706\n",
      "Training loss:-0.004558023065328598\n",
      "check (7951,) ()\n",
      "epoch 4706\n",
      "====================================\n",
      "Epoch:  4706 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.021249468763282\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4706 4707\n",
      "Training loss:-0.0017128377221524715\n",
      "check (9388,) ()\n",
      "epoch 4707\n",
      "====================================\n",
      "Epoch:  4707 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.019120458891013\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4707 4708\n",
      "Training loss:-0.012960009276866913\n",
      "check (7815,) ()\n",
      "epoch 4708\n",
      "====================================\n",
      "Epoch:  4708 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.018479184367035\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4708 4709\n",
      "Training loss:0.0006559224566444755\n",
      "check (8710,) ()\n",
      "epoch 4709\n",
      "====================================\n",
      "Epoch:  4709 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.018050541516246\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4709 4710\n",
      "Training loss:-0.0022534735035151243\n",
      "check (6947,) ()\n",
      "epoch 4710\n",
      "====================================\n",
      "Epoch:  4710 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -14.017834394904458\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4710 4711\n",
      "Training loss:-0.011650027707219124\n",
      "check (7602,) ()\n",
      "epoch 4711\n",
      "====================================\n",
      "Epoch:  4711 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -14.018042878369773\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4711 4712\n",
      "Training loss:-0.0020308319944888353\n",
      "check (9923,) ()\n",
      "epoch 4712\n",
      "====================================\n",
      "Epoch:  4712 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.017190152801358\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4712 4713\n",
      "Training loss:-0.010131662711501122\n",
      "check (8645,) ()\n",
      "epoch 4713\n",
      "====================================\n",
      "Epoch:  4713 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.016762147252281\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4713 4714\n",
      "Training loss:-0.001174103352241218\n",
      "check (6517,) ()\n",
      "epoch 4714\n",
      "====================================\n",
      "Epoch:  4714 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.017394993635978\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4714 4715\n",
      "Training loss:-0.002113139955326915\n",
      "check (10000,) ()\n",
      "epoch 4715\n",
      "====================================\n",
      "Epoch:  4715 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -14.016967126193\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4715 4716\n",
      "Training loss:0.00023618011618964374\n",
      "check (10000,) ()\n",
      "epoch 4716\n",
      "====================================\n",
      "Epoch:  4716 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.014843087362172\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4716 4717\n",
      "Training loss:-0.010119701735675335\n",
      "check (7578,) ()\n",
      "epoch 4717\n",
      "====================================\n",
      "Epoch:  4717 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.014203943184228\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4717 4718\n",
      "Training loss:-0.007854224182665348\n",
      "check (8429,) ()\n",
      "epoch 4718\n",
      "====================================\n",
      "Epoch:  4718 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.013565069944892\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4718 4719\n",
      "Training loss:-0.0015426484169438481\n",
      "check (10000,) ()\n",
      "epoch 4719\n",
      "====================================\n",
      "Epoch:  4719 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.011655011655012\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4719 4720\n",
      "Training loss:-0.006134186405688524\n",
      "check (9837,) ()\n",
      "epoch 4720\n",
      "====================================\n",
      "Epoch:  4720 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -14.010381355932203\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4720 4721\n",
      "Training loss:-0.0027402061969041824\n",
      "check (10000,) ()\n",
      "epoch 4721\n",
      "====================================\n",
      "Epoch:  4721 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -14.008472781190425\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4721 4722\n",
      "Training loss:-0.0019138988573104143\n",
      "check (5641,) ()\n",
      "epoch 4722\n",
      "====================================\n",
      "Epoch:  4722 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -14.009106310885219\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4722 4723\n",
      "Training loss:-0.005261402111500502\n",
      "check (9354,) ()\n",
      "epoch 4723\n",
      "====================================\n",
      "Epoch:  4723 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -14.008257463476603\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4723 4724\n",
      "Training loss:0.003844447433948517\n",
      "check (9691,) ()\n",
      "epoch 4724\n",
      "====================================\n",
      "Epoch:  4724 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -14.007197290431838\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4724 4725\n",
      "Training loss:-0.0032332446426153183\n",
      "check (9126,) ()\n",
      "epoch 4725\n",
      "====================================\n",
      "Epoch:  4725 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -14.006560846560847\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4725 4726\n",
      "Training loss:-0.01152457483112812\n",
      "check (10000,) ()\n",
      "epoch 4726\n",
      "====================================\n",
      "Epoch:  4726 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -14.004443504020314\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4726 4727\n",
      "Training loss:-0.00249834218993783\n",
      "check (10000,) ()\n",
      "epoch 4727\n",
      "====================================\n",
      "Epoch:  4727 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -14.000846202665539\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4727 4728\n",
      "Training loss:-0.003955683205276728\n",
      "check (9737,) ()\n",
      "epoch 4728\n",
      "====================================\n",
      "Epoch:  4728 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.999788494077833\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4728 4729\n",
      "Training loss:-0.004566398449242115\n",
      "check (7535,) ()\n",
      "epoch 4729\n",
      "====================================\n",
      "Epoch:  4729 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.99957707760626\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4729 4730\n",
      "Training loss:-0.015454500913619995\n",
      "check (8502,) ()\n",
      "epoch 4730\n",
      "====================================\n",
      "Epoch:  4730 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.998942917547568\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4730 4731\n",
      "Training loss:-0.008110038936138153\n",
      "check (8395,) ()\n",
      "epoch 4731\n",
      "====================================\n",
      "Epoch:  4731 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.99873176918199\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4731 4732\n",
      "Training loss:-0.009165875613689423\n",
      "check (9287,) ()\n",
      "epoch 4732\n",
      "====================================\n",
      "Epoch:  4732 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.998732037193575\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4732 4733\n",
      "Training loss:-0.0038879935164004564\n",
      "check (9275,) ()\n",
      "epoch 4733\n",
      "====================================\n",
      "Epoch:  4733 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.998521022607227\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4733 4734\n",
      "Training loss:-4.208917016512714e-05\n",
      "check (9544,) ()\n",
      "epoch 4734\n",
      "====================================\n",
      "Epoch:  4734 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.997042670046472\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4734 4735\n",
      "Training loss:-0.009887325577437878\n",
      "check (9145,) ()\n",
      "epoch 4735\n",
      "====================================\n",
      "Epoch:  4735 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.99598732840549\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4735 4736\n",
      "Training loss:-0.006394532043486834\n",
      "check (9564,) ()\n",
      "epoch 4736\n",
      "====================================\n",
      "Epoch:  4736 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.995565878378379\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4736 4737\n",
      "Training loss:-0.001174414181150496\n",
      "check (8242,) ()\n",
      "epoch 4737\n",
      "====================================\n",
      "Epoch:  4737 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.996200126662444\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4737 4738\n",
      "Training loss:-0.003976763226091862\n",
      "check (10000,) ()\n",
      "epoch 4738\n",
      "====================================\n",
      "Epoch:  4738 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.994301392992824\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4738 4739\n",
      "Training loss:-0.002506351564079523\n",
      "check (9351,) ()\n",
      "epoch 4739\n",
      "====================================\n",
      "Epoch:  4739 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.994091580502216\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4739 4740\n",
      "Training loss:-0.003239687532186508\n",
      "check (7504,) ()\n",
      "epoch 4740\n",
      "====================================\n",
      "Epoch:  4740 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.993881856540085\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4740 4741\n",
      "Training loss:0.005468522664159536\n",
      "check (9825,) ()\n",
      "epoch 4741\n",
      "====================================\n",
      "Epoch:  4741 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.992406665260493\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4741 4742\n",
      "Training loss:-0.00787592027336359\n",
      "check (9517,) ()\n",
      "epoch 4742\n",
      "====================================\n",
      "Epoch:  4742 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.991775622100379\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4742 4743\n",
      "Training loss:-0.0077040852047502995\n",
      "check (10000,) ()\n",
      "epoch 4743\n",
      "====================================\n",
      "Epoch:  4743 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.989879822896901\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4743 4744\n",
      "Training loss:-0.007063178811222315\n",
      "check (7904,) ()\n",
      "epoch 4744\n",
      "====================================\n",
      "Epoch:  4744 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.990092748735245\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4744 4745\n",
      "Training loss:-0.007123187649995089\n",
      "check (10000,) ()\n",
      "epoch 4745\n",
      "====================================\n",
      "Epoch:  4745 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.98840885142255\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4745 4746\n",
      "Training loss:0.0005916630034334958\n",
      "check (10000,) ()\n",
      "epoch 4746\n",
      "====================================\n",
      "Epoch:  4746 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.986725663716815\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4746 4747\n",
      "Training loss:-0.0062738144770264626\n",
      "check (10000,) ()\n",
      "epoch 4747\n",
      "====================================\n",
      "Epoch:  4747 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.985464503897198\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4747 4748\n",
      "Training loss:-0.0054046656005084515\n",
      "check (8170,) ()\n",
      "epoch 4748\n",
      "====================================\n",
      "Epoch:  4748 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.985046335299073\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4748 4749\n",
      "Training loss:-0.0021575819700956345\n",
      "check (6887,) ()\n",
      "epoch 4749\n",
      "====================================\n",
      "Epoch:  4749 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.98441777216256\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4749 4750\n",
      "Training loss:-0.008293268270790577\n",
      "check (6853,) ()\n",
      "epoch 4750\n",
      "====================================\n",
      "Epoch:  4750 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -13.985263157894737\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4750 4751\n",
      "Training loss:-0.004966276232153177\n",
      "Model saved\n",
      "check (8012,) ()\n",
      "epoch 4751\n",
      "====================================\n",
      "Epoch:  4751 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.985476741738582\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4751 4752\n",
      "Training loss:0.0006221451330929995\n",
      "check (9268,) ()\n",
      "epoch 4752\n",
      "====================================\n",
      "Epoch:  4752 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.984006734006734\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4752 4753\n",
      "Training loss:-0.002849145792424679\n",
      "check (8345,) ()\n",
      "epoch 4753\n",
      "====================================\n",
      "Epoch:  4753 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.98295813170629\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4753 4754\n",
      "Training loss:-0.009270355105400085\n",
      "check (7907,) ()\n",
      "epoch 4754\n",
      "====================================\n",
      "Epoch:  4754 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.982751367269667\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4754 4755\n",
      "Training loss:-0.005441764369606972\n",
      "check (8288,) ()\n",
      "epoch 4755\n",
      "====================================\n",
      "Epoch:  4755 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.982334384858044\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4755 4756\n",
      "Training loss:-0.0011472443584352732\n",
      "check (8878,) ()\n",
      "epoch 4756\n",
      "====================================\n",
      "Epoch:  4756 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.981497056349873\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4756 4757\n",
      "Training loss:-0.004160613752901554\n",
      "check (8437,) ()\n",
      "epoch 4757\n",
      "====================================\n",
      "Epoch:  4757 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.981290729451334\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4757 4758\n",
      "Training loss:0.0008735851151868701\n",
      "check (8838,) ()\n",
      "epoch 4758\n",
      "====================================\n",
      "Epoch:  4758 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.98024379991593\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4758 4759\n",
      "Training loss:-0.010473780333995819\n",
      "check (8245,) ()\n",
      "epoch 4759\n",
      "====================================\n",
      "Epoch:  4759 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.978777054002942\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4759 4760\n",
      "Training loss:-0.012229735031723976\n",
      "check (8139,) ()\n",
      "epoch 4760\n",
      "====================================\n",
      "Epoch:  4760 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.978151260504202\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4760 4761\n",
      "Training loss:-0.004674187861382961\n",
      "check (10000,) ()\n",
      "epoch 4761\n",
      "====================================\n",
      "Epoch:  4761 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.976685570258349\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4761 4762\n",
      "Training loss:-0.001279890420846641\n",
      "check (9793,) ()\n",
      "epoch 4762\n",
      "====================================\n",
      "Epoch:  4762 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.974380512389752\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4762 4763\n",
      "Training loss:-0.004035529680550098\n",
      "check (7709,) ()\n",
      "epoch 4763\n",
      "====================================\n",
      "Epoch:  4763 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.974175939533907\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4763 4764\n",
      "Training loss:-0.005680568516254425\n",
      "check (9601,) ()\n",
      "epoch 4764\n",
      "====================================\n",
      "Epoch:  4764 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:5.0\n",
      "Mean Reward of that batch 5.0\n",
      "Average Reward of all training: -13.970193115029387\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4764 4765\n",
      "Training loss:-0.008478505536913872\n",
      "check (9137,) ()\n",
      "epoch 4765\n",
      "====================================\n",
      "Epoch:  4765 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.969150052465897\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4765 4766\n",
      "Training loss:0.0016357306158170104\n",
      "check (9908,) ()\n",
      "epoch 4766\n",
      "====================================\n",
      "Epoch:  4766 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.968107427612253\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4766 4767\n",
      "Training loss:-0.0037443803157657385\n",
      "check (7512,) ()\n",
      "epoch 4767\n",
      "====================================\n",
      "Epoch:  4767 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.96874344451437\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4767 4768\n",
      "Training loss:-0.0063792564906179905\n",
      "check (9869,) ()\n",
      "epoch 4768\n",
      "====================================\n",
      "Epoch:  4768 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.968120805369127\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4768 4769\n",
      "Training loss:0.0022452359553426504\n",
      "check (10000,) ()\n",
      "epoch 4769\n",
      "====================================\n",
      "Epoch:  4769 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.96582092681904\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4769 4770\n",
      "Training loss:-0.005698378197848797\n",
      "check (7990,) ()\n",
      "epoch 4770\n",
      "====================================\n",
      "Epoch:  4770 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.964779874213836\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4770 4771\n",
      "Training loss:-0.003862240118905902\n",
      "check (7614,) ()\n",
      "epoch 4771\n",
      "====================================\n",
      "Epoch:  4771 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.965206455669671\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4771 4772\n",
      "Training loss:-0.005289072170853615\n",
      "check (8073,) ()\n",
      "epoch 4772\n",
      "====================================\n",
      "Epoch:  4772 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.964585079631181\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4772 4773\n",
      "Training loss:-0.005339921917766333\n",
      "check (8982,) ()\n",
      "epoch 4773\n",
      "====================================\n",
      "Epoch:  4773 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.96291640477687\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4773 4774\n",
      "Training loss:-0.0020665032789111137\n",
      "check (6971,) ()\n",
      "epoch 4774\n",
      "====================================\n",
      "Epoch:  4774 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.962714704650189\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4774 4775\n",
      "Training loss:-0.0020701454486697912\n",
      "check (7644,) ()\n",
      "epoch 4775\n",
      "====================================\n",
      "Epoch:  4775 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.962722513089005\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4775 4776\n",
      "Training loss:-0.003549630753695965\n",
      "check (9693,) ()\n",
      "epoch 4776\n",
      "====================================\n",
      "Epoch:  4776 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.962102177554438\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4776 4777\n",
      "Training loss:-0.0029905966948717833\n",
      "check (8458,) ()\n",
      "epoch 4777\n",
      "====================================\n",
      "Epoch:  4777 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.962319447351895\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4777 4778\n",
      "Training loss:-0.004358087200671434\n",
      "check (8214,) ()\n",
      "epoch 4778\n",
      "====================================\n",
      "Epoch:  4778 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.962118041021348\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4778 4779\n",
      "Training loss:-0.0033869845792651176\n",
      "check (9259,) ()\n",
      "epoch 4779\n",
      "====================================\n",
      "Epoch:  4779 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.96066122619795\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4779 4780\n",
      "Training loss:-0.004575266968458891\n",
      "check (8410,) ()\n",
      "epoch 4780\n",
      "====================================\n",
      "Epoch:  4780 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.959832635983263\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4780 4781\n",
      "Training loss:-0.0006876327679492533\n",
      "check (7228,) ()\n",
      "epoch 4781\n",
      "====================================\n",
      "Epoch:  4781 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.959631876176532\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4781 4782\n",
      "Training loss:-0.0048569608479738235\n",
      "check (9703,) ()\n",
      "epoch 4782\n",
      "====================================\n",
      "Epoch:  4782 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.958803847762443\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4782 4783\n",
      "Training loss:-0.008476742543280125\n",
      "check (10000,) ()\n",
      "epoch 4783\n",
      "====================================\n",
      "Epoch:  4783 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.957558017980347\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4783 4784\n",
      "Training loss:-0.008066865615546703\n",
      "check (9464,) ()\n",
      "epoch 4784\n",
      "====================================\n",
      "Epoch:  4784 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.956103678929766\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4784 4785\n",
      "Training loss:-0.015254647471010685\n",
      "check (7946,) ()\n",
      "epoch 4785\n",
      "====================================\n",
      "Epoch:  4785 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.955485893416927\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4785 4786\n",
      "Training loss:-0.004148920997977257\n",
      "check (6921,) ()\n",
      "epoch 4786\n",
      "====================================\n",
      "Epoch:  4786 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.955495194316757\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4786 4787\n",
      "Training loss:-0.004255019593983889\n",
      "check (9603,) ()\n",
      "epoch 4787\n",
      "====================================\n",
      "Epoch:  4787 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.954459995822019\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4787 4788\n",
      "Training loss:-0.001317148213274777\n",
      "check (8172,) ()\n",
      "epoch 4788\n",
      "====================================\n",
      "Epoch:  4788 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.954887218045112\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4788 4789\n",
      "Training loss:-0.0055572763085365295\n",
      "check (8779,) ()\n",
      "epoch 4789\n",
      "====================================\n",
      "Epoch:  4789 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.95343495510545\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4789 4790\n",
      "Training loss:-0.007550232578068972\n",
      "check (9546,) ()\n",
      "epoch 4790\n",
      "====================================\n",
      "Epoch:  4790 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.952818371607515\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4790 4791\n",
      "Training loss:0.0026376566383987665\n",
      "check (8830,) ()\n",
      "epoch 4791\n",
      "====================================\n",
      "Epoch:  4791 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.952828219578375\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4791 4792\n",
      "Training loss:-0.0053450544364750385\n",
      "check (8146,) ()\n",
      "epoch 4792\n",
      "====================================\n",
      "Epoch:  4792 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.952420701168615\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4792 4793\n",
      "Training loss:-0.0020014592446386814\n",
      "check (10000,) ()\n",
      "epoch 4793\n",
      "====================================\n",
      "Epoch:  4793 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.95138744001669\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4793 4794\n",
      "Training loss:-0.0013940399512648582\n",
      "check (9417,) ()\n",
      "epoch 4794\n",
      "====================================\n",
      "Epoch:  4794 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.949311639549437\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4794 4795\n",
      "Training loss:0.005555389449000359\n",
      "check (8276,) ()\n",
      "epoch 4795\n",
      "====================================\n",
      "Epoch:  4795 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.949113660062565\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4795 4796\n",
      "Training loss:-0.006121031939983368\n",
      "check (8495,) ()\n",
      "epoch 4796\n",
      "====================================\n",
      "Epoch:  4796 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.948498748957464\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4796 4797\n",
      "Training loss:-0.0035564301069825888\n",
      "check (10000,) ()\n",
      "epoch 4797\n",
      "====================================\n",
      "Epoch:  4797 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.946007921617678\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4797 4798\n",
      "Training loss:-0.0039529562927782536\n",
      "check (9399,) ()\n",
      "epoch 4798\n",
      "====================================\n",
      "Epoch:  4798 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.945393914130888\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4798 4799\n",
      "Training loss:-0.0067938570864498615\n",
      "check (10000,) ()\n",
      "epoch 4799\n",
      "====================================\n",
      "Epoch:  4799 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.94436340904355\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4799 4800\n",
      "Training loss:-0.002628319663926959\n",
      "check (9252,) ()\n",
      "epoch 4800\n",
      "====================================\n",
      "Epoch:  4800 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.942708333333334\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4800 4801\n",
      "Training loss:-0.00637629721313715\n",
      "Model saved\n",
      "check (9458,) ()\n",
      "epoch 4801\n",
      "====================================\n",
      "Epoch:  4801 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.94188710685274\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4801 4802\n",
      "Training loss:-0.006673458963632584\n",
      "check (9428,) ()\n",
      "epoch 4802\n",
      "====================================\n",
      "Epoch:  4802 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.940441482715535\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4802 4803\n",
      "Training loss:-0.011339563876390457\n",
      "check (7018,) ()\n",
      "epoch 4803\n",
      "====================================\n",
      "Epoch:  4803 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.940453882989798\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4803 4804\n",
      "Training loss:-0.0024717433843761683\n",
      "check (7778,) ()\n",
      "epoch 4804\n",
      "====================================\n",
      "Epoch:  4804 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.939841798501249\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4804 4805\n",
      "Training loss:-0.010563796386122704\n",
      "check (8607,) ()\n",
      "epoch 4805\n",
      "====================================\n",
      "Epoch:  4805 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.939438085327783\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4805 4806\n",
      "Training loss:-0.0038643016014248133\n",
      "check (9575,) ()\n",
      "epoch 4806\n",
      "====================================\n",
      "Epoch:  4806 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.938826466916355\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4806 4807\n",
      "Training loss:-0.006667060777544975\n",
      "check (8290,) ()\n",
      "epoch 4807\n",
      "====================================\n",
      "Epoch:  4807 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.938007073018515\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4807 4808\n",
      "Training loss:-0.010286918841302395\n",
      "check (7348,) ()\n",
      "epoch 4808\n",
      "====================================\n",
      "Epoch:  4808 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.93801996672213\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4808 4809\n",
      "Training loss:-0.005996638908982277\n",
      "check (7617,) ()\n",
      "epoch 4809\n",
      "====================================\n",
      "Epoch:  4809 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.937616968184654\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4809 4810\n",
      "Training loss:-0.0018855591770261526\n",
      "check (8136,) ()\n",
      "epoch 4810\n",
      "====================================\n",
      "Epoch:  4810 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.936174636174636\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4810 4811\n",
      "Training loss:-0.004326884169131517\n",
      "check (9741,) ()\n",
      "epoch 4811\n",
      "====================================\n",
      "Epoch:  4811 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.935564331739762\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4811 4812\n",
      "Training loss:-0.001146382070146501\n",
      "check (9724,) ()\n",
      "epoch 4812\n",
      "====================================\n",
      "Epoch:  4812 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.933499584372402\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4812 4813\n",
      "Training loss:-0.00902305357158184\n",
      "check (7830,) ()\n",
      "epoch 4813\n",
      "====================================\n",
      "Epoch:  4813 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.933721171826305\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4813 4814\n",
      "Training loss:-0.009486788883805275\n",
      "check (10000,) ()\n",
      "epoch 4814\n",
      "====================================\n",
      "Epoch:  4814 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.932280847528043\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4814 4815\n",
      "Training loss:0.0020683195907622576\n",
      "check (8679,) ()\n",
      "epoch 4815\n",
      "====================================\n",
      "Epoch:  4815 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.930841121495327\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4815 4816\n",
      "Training loss:-0.005666281562298536\n",
      "check (10000,) ()\n",
      "epoch 4816\n",
      "====================================\n",
      "Epoch:  4816 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.930232558139535\n",
      "Max reward for a batch so far: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4816 4817\n",
      "Training loss:-0.0004898693296127021\n",
      "check (7626,) ()\n",
      "epoch 4817\n",
      "====================================\n",
      "Epoch:  4817 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.930247041727217\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4817 4818\n",
      "Training loss:-0.009792912751436234\n",
      "check (8697,) ()\n",
      "epoch 4818\n",
      "====================================\n",
      "Epoch:  4818 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.929638854296389\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4818 4819\n",
      "Training loss:0.005592549219727516\n",
      "check (9784,) ()\n",
      "epoch 4819\n",
      "====================================\n",
      "Epoch:  4819 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.929445943141731\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4819 4820\n",
      "Training loss:-0.009258663281798363\n",
      "check (7712,) ()\n",
      "epoch 4820\n",
      "====================================\n",
      "Epoch:  4820 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.929253112033194\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4820 4821\n",
      "Training loss:-0.008599234744906425\n",
      "check (9257,) ()\n",
      "epoch 4821\n",
      "====================================\n",
      "Epoch:  4821 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.92823065753993\n",
      "Max reward for a batch so far: 5.0\n",
      "check 4821 4822\n",
      "Training loss:-0.006694662384688854\n",
      "check (10000,) ()\n",
      "epoch 4822\n",
      "====================================\n",
      "Epoch:  4822 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:7.0\n",
      "Mean Reward of that batch 7.0\n",
      "Average Reward of all training: -13.923890501866445\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4822 4823\n",
      "Training loss:-0.0049956561997532845\n",
      "check (10000,) ()\n",
      "epoch 4823\n",
      "====================================\n",
      "Epoch:  4823 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.92266224341696\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4823 4824\n",
      "Training loss:-0.007580576930195093\n",
      "check (9095,) ()\n",
      "epoch 4824\n",
      "====================================\n",
      "Epoch:  4824 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.92226368159204\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4824 4825\n",
      "Training loss:-0.0003732783079613\n",
      "check (8117,) ()\n",
      "epoch 4825\n",
      "====================================\n",
      "Epoch:  4825 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.923316062176166\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4825 4826\n",
      "Training loss:-0.006550481077283621\n",
      "check (8680,) ()\n",
      "epoch 4826\n",
      "====================================\n",
      "Epoch:  4826 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.92271031910485\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4826 4827\n",
      "Training loss:-0.00729795265942812\n",
      "check (8425,) ()\n",
      "epoch 4827\n",
      "====================================\n",
      "Epoch:  4827 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.922104827014708\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4827 4828\n",
      "Training loss:-0.011839996092021465\n",
      "check (8416,) ()\n",
      "epoch 4828\n",
      "====================================\n",
      "Epoch:  4828 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.921499585749793\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4828 4829\n",
      "Training loss:-0.0024431287311017513\n",
      "check (9734,) ()\n",
      "epoch 4829\n",
      "====================================\n",
      "Epoch:  4829 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.920480430731\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4829 4830\n",
      "Training loss:0.0005117153632454574\n",
      "check (10000,) ()\n",
      "epoch 4830\n",
      "====================================\n",
      "Epoch:  4830 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.918219461697722\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4830 4831\n",
      "Training loss:-0.002217409433797002\n",
      "check (10000,) ()\n",
      "epoch 4831\n",
      "====================================\n",
      "Epoch:  4831 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.91740840405713\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4831 4832\n",
      "Training loss:0.0013080596690997481\n",
      "check (10000,) ()\n",
      "epoch 4832\n",
      "====================================\n",
      "Epoch:  4832 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.915149006622517\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4832 4833\n",
      "Training loss:-0.004959544632583857\n",
      "check (8204,) ()\n",
      "epoch 4833\n",
      "====================================\n",
      "Epoch:  4833 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.91495965238982\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4833 4834\n",
      "Training loss:-0.0033562975004315376\n",
      "check (6710,) ()\n",
      "epoch 4834\n",
      "====================================\n",
      "Epoch:  4834 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.915597848572611\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4834 4835\n",
      "Training loss:-0.0006531182443723083\n",
      "check (7073,) ()\n",
      "epoch 4835\n",
      "====================================\n",
      "Epoch:  4835 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.915822130299897\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4835 4836\n",
      "Training loss:0.0029948356095701456\n",
      "check (8216,) ()\n",
      "epoch 4836\n",
      "====================================\n",
      "Epoch:  4836 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.915425971877585\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4836 4837\n",
      "Training loss:0.0046990253031253815\n",
      "check (8327,) ()\n",
      "epoch 4837\n",
      "====================================\n",
      "Epoch:  4837 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.914823237543931\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4837 4838\n",
      "Training loss:-0.00255780597217381\n",
      "check (7952,) ()\n",
      "epoch 4838\n",
      "====================================\n",
      "Epoch:  4838 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.914634146341463\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4838 4839\n",
      "Training loss:-0.001454956829547882\n",
      "check (9229,) ()\n",
      "epoch 4839\n",
      "====================================\n",
      "Epoch:  4839 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.912998553420127\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4839 4840\n",
      "Training loss:-0.0004265558090992272\n",
      "check (8158,) ()\n",
      "epoch 4840\n",
      "====================================\n",
      "Epoch:  4840 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.912809917355371\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4840 4841\n",
      "Training loss:-0.007518628146499395\n",
      "check (6368,) ()\n",
      "epoch 4841\n",
      "====================================\n",
      "Epoch:  4841 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.912621359223301\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4841 4842\n",
      "Training loss:-0.005255349911749363\n",
      "check (9904,) ()\n",
      "epoch 4842\n",
      "====================================\n",
      "Epoch:  4842 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.911606774060306\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4842 4843\n",
      "Training loss:-0.004516530781984329\n",
      "check (8602,) ()\n",
      "epoch 4843\n",
      "====================================\n",
      "Epoch:  4843 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.910179640718562\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4843 4844\n",
      "Training loss:-0.004726039245724678\n",
      "check (10000,) ()\n",
      "epoch 4844\n",
      "====================================\n",
      "Epoch:  4844 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.908959537572255\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4844 4845\n",
      "Training loss:-0.0026889198925346136\n",
      "check (9165,) ()\n",
      "epoch 4845\n",
      "====================================\n",
      "Epoch:  4845 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.908152734778122\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4845 4846\n",
      "Training loss:-0.009193368256092072\n",
      "check (9955,) ()\n",
      "epoch 4846\n",
      "====================================\n",
      "Epoch:  4846 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.906314486174164\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4846 4847\n",
      "Training loss:-0.011065894737839699\n",
      "check (9845,) ()\n",
      "epoch 4847\n",
      "====================================\n",
      "Epoch:  4847 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.90612750154735\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4847 4848\n",
      "Training loss:-0.0045377579517662525\n",
      "check (8001,) ()\n",
      "epoch 4848\n",
      "====================================\n",
      "Epoch:  4848 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.907178217821782\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4848 4849\n",
      "Training loss:-0.00234748306684196\n",
      "check (8218,) ()\n",
      "epoch 4849\n",
      "====================================\n",
      "Epoch:  4849 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.90719736028047\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4849 4850\n",
      "Training loss:-0.005950557067990303\n",
      "check (10000,) ()\n",
      "epoch 4850\n",
      "====================================\n",
      "Epoch:  4850 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.90577319587629\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4850 4851\n",
      "Training loss:-0.0009789523901417851\n",
      "Model saved\n",
      "check (8663,) ()\n",
      "epoch 4851\n",
      "====================================\n",
      "Epoch:  4851 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.905174190888477\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4851 4852\n",
      "Training loss:-0.005053875967860222\n",
      "check (8260,) ()\n",
      "epoch 4852\n",
      "====================================\n",
      "Epoch:  4852 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.904987633965375\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4852 4853\n",
      "Training loss:-3.240876321797259e-05\n",
      "check (9905,) ()\n",
      "epoch 4853\n",
      "====================================\n",
      "Epoch:  4853 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.903152689058315\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4853 4854\n",
      "Training loss:-0.0074966223910450935\n",
      "check (10000,) ()\n",
      "epoch 4854\n",
      "====================================\n",
      "Epoch:  4854 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.901318500206015\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4854 4855\n",
      "Training loss:0.000563739042263478\n",
      "check (7097,) ()\n",
      "epoch 4855\n",
      "====================================\n",
      "Epoch:  4855 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.901544799176108\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4855 4856\n",
      "Training loss:0.002080179052427411\n",
      "check (9491,) ()\n",
      "epoch 4856\n",
      "====================================\n",
      "Epoch:  4856 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.899505766062603\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4856 4857\n",
      "Training loss:-0.005426416639238596\n",
      "check (8359,) ()\n",
      "epoch 4857\n",
      "====================================\n",
      "Epoch:  4857 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.900144121885937\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4857 4858\n",
      "Training loss:-0.002835506107658148\n",
      "check (8204,) ()\n",
      "epoch 4858\n",
      "====================================\n",
      "Epoch:  4858 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.90037052284891\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4858 4859\n",
      "Training loss:-0.009790313430130482\n",
      "check (8777,) ()\n",
      "epoch 4859\n",
      "====================================\n",
      "Epoch:  4859 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.900596830623584\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4859 4860\n",
      "Training loss:-0.010674652643501759\n",
      "check (8735,) ()\n",
      "epoch 4860\n",
      "====================================\n",
      "Epoch:  4860 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.899588477366255\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4860 4861\n",
      "Training loss:-0.006053972989320755\n",
      "check (8752,) ()\n",
      "epoch 4861\n",
      "====================================\n",
      "Epoch:  4861 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.898580538983747\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4861 4862\n",
      "Training loss:-0.000519032881129533\n",
      "check (9088,) ()\n",
      "epoch 4862\n",
      "====================================\n",
      "Epoch:  4862 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.897573015220074\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4862 4863\n",
      "Training loss:-0.007164669688791037\n",
      "check (10000,) ()\n",
      "epoch 4863\n",
      "====================================\n",
      "Epoch:  4863 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.896360271437384\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4863 4864\n",
      "Training loss:-0.0045966836623847485\n",
      "check (6750,) ()\n",
      "epoch 4864\n",
      "====================================\n",
      "Epoch:  4864 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.896792763157896\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4864 4865\n",
      "Training loss:-0.007012868300080299\n",
      "check (7431,) ()\n",
      "epoch 4865\n",
      "====================================\n",
      "Epoch:  4865 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.896813977389517\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4865 4866\n",
      "Training loss:-0.004808805882930756\n",
      "check (8120,) ()\n",
      "epoch 4866\n",
      "====================================\n",
      "Epoch:  4866 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.896424167694205\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4866 4867\n",
      "Training loss:-0.004706891253590584\n",
      "check (10000,) ()\n",
      "epoch 4867\n",
      "====================================\n",
      "Epoch:  4867 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.893568933634683\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4867 4868\n",
      "Training loss:-0.001263321260921657\n",
      "check (7191,) ()\n",
      "epoch 4868\n",
      "====================================\n",
      "Epoch:  4868 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.893385373870172\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4868 4869\n",
      "Training loss:-0.0033112617675215006\n",
      "check (8996,) ()\n",
      "epoch 4869\n",
      "====================================\n",
      "Epoch:  4869 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.892174984596426\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4869 4870\n",
      "Training loss:-0.0026826965622603893\n",
      "check (7632,) ()\n",
      "epoch 4870\n",
      "====================================\n",
      "Epoch:  4870 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.892607802874743\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4870 4871\n",
      "Training loss:-0.0002747958933468908\n",
      "check (8522,) ()\n",
      "epoch 4871\n",
      "====================================\n",
      "Epoch:  4871 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.891398070211455\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4871 4872\n",
      "Training loss:-0.004056564066559076\n",
      "check (5961,) ()\n",
      "epoch 4872\n",
      "====================================\n",
      "Epoch:  4872 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.891830870279145\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4872 4873\n",
      "Training loss:0.0033343653194606304\n",
      "check (10000,) ()\n",
      "epoch 4873\n",
      "====================================\n",
      "Epoch:  4873 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.889390519187359\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4873 4874\n",
      "Training loss:-0.0030732029117643833\n",
      "check (7498,) ()\n",
      "epoch 4874\n",
      "====================================\n",
      "Epoch:  4874 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.889823553549446\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4874 4875\n",
      "Training loss:-0.007985569536685944\n",
      "check (7998,) ()\n",
      "epoch 4875\n",
      "====================================\n",
      "Epoch:  4875 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.890051282051282\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4875 4876\n",
      "Training loss:-0.008652904070913792\n",
      "check (7297,) ()\n",
      "epoch 4876\n",
      "====================================\n",
      "Epoch:  4876 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.889868744872846\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4876 4877\n",
      "Training loss:-0.011514768935739994\n",
      "check (7801,) ()\n",
      "epoch 4877\n",
      "====================================\n",
      "Epoch:  4877 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.889276194381791\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4877 4878\n",
      "Training loss:0.004256109707057476\n",
      "check (7602,) ()\n",
      "epoch 4878\n",
      "====================================\n",
      "Epoch:  4878 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.88888888888889\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4878 4879\n",
      "Training loss:-0.011693415232002735\n",
      "check (9612,) ()\n",
      "epoch 4879\n",
      "====================================\n",
      "Epoch:  4879 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.887067021930724\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4879 4880\n",
      "Training loss:0.0017219814471900463\n",
      "check (6443,) ()\n",
      "epoch 4880\n",
      "====================================\n",
      "Epoch:  4880 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.88811475409836\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4880 4881\n",
      "Training loss:0.0016184159321710467\n",
      "check (7590,) ()\n",
      "epoch 4881\n",
      "====================================\n",
      "Epoch:  4881 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.888342552755583\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4881 4882\n",
      "Training loss:-6.980141915846616e-05\n",
      "check (10000,) ()\n",
      "epoch 4882\n",
      "====================================\n",
      "Epoch:  4882 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.885907414993856\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4882 4883\n",
      "Training loss:-0.001514548435807228\n",
      "check (8775,) ()\n",
      "epoch 4883\n",
      "====================================\n",
      "Epoch:  4883 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.8840876510342\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4883 4884\n",
      "Training loss:-0.0021853125654160976\n",
      "check (9241,) ()\n",
      "epoch 4884\n",
      "====================================\n",
      "Epoch:  4884 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.882882882882884\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4884 4885\n",
      "Training loss:-0.009192738682031631\n",
      "check (9322,) ()\n",
      "epoch 4885\n",
      "====================================\n",
      "Epoch:  4885 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.881883316274308\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4885 4886\n",
      "Training loss:0.0030084485188126564\n",
      "check (10000,) ()\n",
      "epoch 4886\n",
      "====================================\n",
      "Epoch:  4886 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.879451494064675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4886 4887\n",
      "Training loss:-0.004976343363523483\n",
      "check (7341,) ()\n",
      "epoch 4887\n",
      "====================================\n",
      "Epoch:  4887 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.8792715367301\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4887 4888\n",
      "Training loss:-0.013217076659202576\n",
      "check (7512,) ()\n",
      "epoch 4888\n",
      "====================================\n",
      "Epoch:  4888 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.879091653027823\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4888 4889\n",
      "Training loss:-0.0043830652721226215\n",
      "check (7979,) ()\n",
      "epoch 4889\n",
      "====================================\n",
      "Epoch:  4889 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.878911842912661\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4889 4890\n",
      "Training loss:-0.003541944781318307\n",
      "check (8839,) ()\n",
      "epoch 4890\n",
      "====================================\n",
      "Epoch:  4890 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.877914110429447\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4890 4891\n",
      "Training loss:-0.005426441319286823\n",
      "check (9869,) ()\n",
      "epoch 4891\n",
      "====================================\n",
      "Epoch:  4891 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.876098957268452\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4891 4892\n",
      "Training loss:-0.011788154020905495\n",
      "check (7753,) ()\n",
      "epoch 4892\n",
      "====================================\n",
      "Epoch:  4892 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.87551103843009\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4892 4893\n",
      "Training loss:-0.0031188945285975933\n",
      "check (9296,) ()\n",
      "epoch 4893\n",
      "====================================\n",
      "Epoch:  4893 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.875127733496832\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4893 4894\n",
      "Training loss:-0.013156445696949959\n",
      "check (9291,) ()\n",
      "epoch 4894\n",
      "====================================\n",
      "Epoch:  4894 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.874131589701676\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4894 4895\n",
      "Training loss:-0.007168975193053484\n",
      "check (7593,) ()\n",
      "epoch 4895\n",
      "====================================\n",
      "Epoch:  4895 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.874770173646578\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4895 4896\n",
      "Training loss:0.000692595902364701\n",
      "check (8683,) ()\n",
      "epoch 4896\n",
      "====================================\n",
      "Epoch:  4896 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.874183006535947\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4896 4897\n",
      "Training loss:-0.008679788559675217\n",
      "check (9095,) ()\n",
      "epoch 4897\n",
      "====================================\n",
      "Epoch:  4897 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.872779252603635\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4897 4898\n",
      "Training loss:-0.0019202170660719275\n",
      "check (6714,) ()\n",
      "epoch 4898\n",
      "====================================\n",
      "Epoch:  4898 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.87260106165782\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4898 4899\n",
      "Training loss:-0.008261936716735363\n",
      "check (8665,) ()\n",
      "epoch 4899\n",
      "====================================\n",
      "Epoch:  4899 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.872014696876914\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4899 4900\n",
      "Training loss:-0.006564239971339703\n",
      "check (8798,) ()\n",
      "epoch 4900\n",
      "====================================\n",
      "Epoch:  4900 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.87122448979592\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4900 4901\n",
      "Training loss:-0.004819441121071577\n",
      "Model saved\n",
      "check (6661,) ()\n",
      "epoch 4901\n",
      "====================================\n",
      "Epoch:  4901 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.87125076514997\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4901 4902\n",
      "Training loss:-0.00843267422169447\n",
      "check (7676,) ()\n",
      "epoch 4902\n",
      "====================================\n",
      "Epoch:  4902 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.870665034679723\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4902 4903\n",
      "Training loss:-0.0010863522766157985\n",
      "check (7842,) ()\n",
      "epoch 4903\n",
      "====================================\n",
      "Epoch:  4903 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.870079543136855\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4903 4904\n",
      "Training loss:-0.003644829848781228\n",
      "check (7893,) ()\n",
      "epoch 4904\n",
      "====================================\n",
      "Epoch:  4904 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.869494290375204\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4904 4905\n",
      "Training loss:0.0018345332937315106\n",
      "check (8727,) ()\n",
      "epoch 4905\n",
      "====================================\n",
      "Epoch:  4905 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.869113149847095\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4905 4906\n",
      "Training loss:0.0038017183542251587\n",
      "check (8753,) ()\n",
      "epoch 4906\n",
      "====================================\n",
      "Epoch:  4906 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.868324500611497\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4906 4907\n",
      "Training loss:-0.004291714169085026\n",
      "check (8023,) ()\n",
      "epoch 4907\n",
      "====================================\n",
      "Epoch:  4907 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.868147544324435\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4907 4908\n",
      "Training loss:-0.000563159235753119\n",
      "check (8869,) ()\n",
      "epoch 4908\n",
      "====================================\n",
      "Epoch:  4908 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.86674816625917\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4908 4909\n",
      "Training loss:-0.004946645349264145\n",
      "check (9278,) ()\n",
      "epoch 4909\n",
      "====================================\n",
      "Epoch:  4909 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.86534935832145\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4909 4910\n",
      "Training loss:-0.008282219991087914\n",
      "check (7704,) ()\n",
      "epoch 4910\n",
      "====================================\n",
      "Epoch:  4910 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.865580448065174\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4910 4911\n",
      "Training loss:0.0002461301628500223\n",
      "check (7692,) ()\n",
      "epoch 4911\n",
      "====================================\n",
      "Epoch:  4911 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.866015068214214\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4911 4912\n",
      "Training loss:-0.004086237866431475\n",
      "check (9063,) ()\n",
      "epoch 4912\n",
      "====================================\n",
      "Epoch:  4912 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.865431596091206\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4912 4913\n",
      "Training loss:0.0004559891240205616\n",
      "check (9549,) ()\n",
      "epoch 4913\n",
      "====================================\n",
      "Epoch:  4913 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.863830653368614\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4913 4914\n",
      "Training loss:-0.010604255832731724\n",
      "check (8054,) ()\n",
      "epoch 4914\n",
      "====================================\n",
      "Epoch:  4914 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.863654863654864\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4914 4915\n",
      "Training loss:-0.006743796169757843\n",
      "check (6274,) ()\n",
      "epoch 4915\n",
      "====================================\n",
      "Epoch:  4915 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.863886063072227\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4915 4916\n",
      "Training loss:0.0002819832880049944\n",
      "check (8978,) ()\n",
      "epoch 4916\n",
      "====================================\n",
      "Epoch:  4916 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.863710333604557\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4916 4917\n",
      "Training loss:-0.006161827594041824\n",
      "check (8193,) ()\n",
      "epoch 4917\n",
      "====================================\n",
      "Epoch:  4917 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.862924547488307\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4917 4918\n",
      "Training loss:0.000509483041241765\n",
      "check (7477,) ()\n",
      "epoch 4918\n",
      "====================================\n",
      "Epoch:  4918 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.863155754371697\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4918 4919\n",
      "Training loss:0.006060320883989334\n",
      "check (9032,) ()\n",
      "epoch 4919\n",
      "====================================\n",
      "Epoch:  4919 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.862573693840211\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4919 4920\n",
      "Training loss:-0.009812329895794392\n",
      "check (8978,) ()\n",
      "epoch 4920\n",
      "====================================\n",
      "Epoch:  4920 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.861382113821138\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4920 4921\n",
      "Training loss:-0.004942714236676693\n",
      "check (8900,) ()\n",
      "epoch 4921\n",
      "====================================\n",
      "Epoch:  4921 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.859987807356228\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4921 4922\n",
      "Training loss:0.0006590562406927347\n",
      "check (7929,) ()\n",
      "epoch 4922\n",
      "====================================\n",
      "Epoch:  4922 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.859406745225519\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4922 4923\n",
      "Training loss:-0.0031295304652303457\n",
      "check (9300,) ()\n",
      "epoch 4923\n",
      "====================================\n",
      "Epoch:  4923 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.858013406459476\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4923 4924\n",
      "Training loss:-0.0003517109726089984\n",
      "check (10000,) ()\n",
      "epoch 4924\n",
      "====================================\n",
      "Epoch:  4924 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.85621445978879\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4924 4925\n",
      "Training loss:-0.009703019633889198\n",
      "check (7143,) ()\n",
      "epoch 4925\n",
      "====================================\n",
      "Epoch:  4925 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.857258883248731\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4925 4926\n",
      "Training loss:0.0025311897043138742\n",
      "check (10000,) ()\n",
      "epoch 4926\n",
      "====================================\n",
      "Epoch:  4926 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.856678846934633\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4926 4927\n",
      "Training loss:-0.0011752814752981067\n",
      "check (8940,) ()\n",
      "epoch 4927\n",
      "====================================\n",
      "Epoch:  4927 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -13.857519788918205\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4927 4928\n",
      "Training loss:0.004506984725594521\n",
      "check (10000,) ()\n",
      "epoch 4928\n",
      "====================================\n",
      "Epoch:  4928 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.855113636363637\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4928 4929\n",
      "Training loss:-0.004236317705363035\n",
      "check (7893,) ()\n",
      "epoch 4929\n",
      "====================================\n",
      "Epoch:  4929 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.854737269222966\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4929 4930\n",
      "Training loss:0.0005252595874480903\n",
      "check (10000,) ()\n",
      "epoch 4930\n",
      "====================================\n",
      "Epoch:  4930 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.85395537525355\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4930 4931\n",
      "Training loss:0.003604360856115818\n",
      "check (7317,) ()\n",
      "epoch 4931\n",
      "====================================\n",
      "Epoch:  4931 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.854187791523017\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4931 4932\n",
      "Training loss:-0.0029443257953971624\n",
      "check (8989,) ()\n",
      "epoch 4932\n",
      "====================================\n",
      "Epoch:  4932 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.85360908353609\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4932 4933\n",
      "Training loss:-0.008958506397902966\n",
      "check (7365,) ()\n",
      "epoch 4933\n",
      "====================================\n",
      "Epoch:  4933 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.854246908574904\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4933 4934\n",
      "Training loss:-0.004815715365111828\n",
      "check (8943,) ()\n",
      "epoch 4934\n",
      "====================================\n",
      "Epoch:  4934 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.853465747871908\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4934 4935\n",
      "Training loss:-0.005687004420906305\n",
      "check (9834,) ()\n",
      "epoch 4935\n",
      "====================================\n",
      "Epoch:  4935 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.851671732522796\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4935 4936\n",
      "Training loss:0.0007542929379269481\n",
      "check (8499,) ()\n",
      "epoch 4936\n",
      "====================================\n",
      "Epoch:  4936 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.851701782820097\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4936 4937\n",
      "Training loss:-0.005501609295606613\n",
      "check (7863,) ()\n",
      "epoch 4937\n",
      "====================================\n",
      "Epoch:  4937 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.851529268786713\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4937 4938\n",
      "Training loss:-0.0005857653450220823\n",
      "check (8265,) ()\n",
      "epoch 4938\n",
      "====================================\n",
      "Epoch:  4938 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.851964358039693\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4938 4939\n",
      "Training loss:-0.004444995895028114\n",
      "check (7870,) ()\n",
      "epoch 4939\n",
      "====================================\n",
      "Epoch:  4939 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.852196800971857\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4939 4940\n",
      "Training loss:-0.006517680361866951\n",
      "check (9760,) ()\n",
      "epoch 4940\n",
      "====================================\n",
      "Epoch:  4940 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.851214574898785\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4940 4941\n",
      "Training loss:-0.0037491510156542063\n",
      "check (9260,) ()\n",
      "epoch 4941\n",
      "====================================\n",
      "Epoch:  4941 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.85063752276867\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4941 4942\n",
      "Training loss:-0.002719666576012969\n",
      "check (8574,) ()\n",
      "epoch 4942\n",
      "====================================\n",
      "Epoch:  4942 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.84925131525698\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4942 4943\n",
      "Training loss:-0.004511791747063398\n",
      "check (10000,) ()\n",
      "epoch 4943\n",
      "====================================\n",
      "Epoch:  4943 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.847461056038842\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4943 4944\n",
      "Training loss:-0.001705413800664246\n",
      "check (7680,) ()\n",
      "epoch 4944\n",
      "====================================\n",
      "Epoch:  4944 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.847087378640778\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4944 4945\n",
      "Training loss:0.004268942400813103\n",
      "check (8170,) ()\n",
      "epoch 4945\n",
      "====================================\n",
      "Epoch:  4945 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.846107178968655\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4945 4946\n",
      "Training loss:-0.0006871166406199336\n",
      "check (9333,) ()\n",
      "epoch 4946\n",
      "====================================\n",
      "Epoch:  4946 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.845127375657096\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4946 4947\n",
      "Training loss:0.0018359095556661487\n",
      "check (10000,) ()\n",
      "epoch 4947\n",
      "====================================\n",
      "Epoch:  4947 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -13.841722255912675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4947 4948\n",
      "Training loss:-0.00043026733328588307\n",
      "check (8248,) ()\n",
      "epoch 4948\n",
      "====================================\n",
      "Epoch:  4948 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.840339531123686\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4948 4949\n",
      "Training loss:0.0034144376404583454\n",
      "check (7280,) ()\n",
      "epoch 4949\n",
      "====================================\n",
      "Epoch:  4949 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.840977975348554\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4949 4950\n",
      "Training loss:-0.0012655069585889578\n",
      "check (8940,) ()\n",
      "epoch 4950\n",
      "====================================\n",
      "Epoch:  4950 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.839191919191919\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4950 4951\n",
      "Training loss:-0.0030579939484596252\n",
      "Model saved\n",
      "check (8280,) ()\n",
      "epoch 4951\n",
      "====================================\n",
      "Epoch:  4951 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.838820440315088\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4951 4952\n",
      "Training loss:0.0004657957179006189\n",
      "check (7753,) ()\n",
      "epoch 4952\n",
      "====================================\n",
      "Epoch:  4952 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.8390549273021\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4952 4953\n",
      "Training loss:0.00012528226943686604\n",
      "check (7035,) ()\n",
      "epoch 4953\n",
      "====================================\n",
      "Epoch:  4953 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.838481728245508\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4953 4954\n",
      "Training loss:-0.0040062000043690205\n",
      "check (9731,) ()\n",
      "epoch 4954\n",
      "====================================\n",
      "Epoch:  4954 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.837303189341945\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4954 4955\n",
      "Training loss:-0.001312348758801818\n",
      "check (9199,) ()\n",
      "epoch 4955\n",
      "====================================\n",
      "Epoch:  4955 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.836528758829465\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4955 4956\n",
      "Training loss:-0.002138047944754362\n",
      "check (8871,) ()\n",
      "epoch 4956\n",
      "====================================\n",
      "Epoch:  4956 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.834745762711865\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4956 4957\n",
      "Training loss:-0.0010867711389437318\n",
      "check (8445,) ()\n",
      "epoch 4957\n",
      "====================================\n",
      "Epoch:  4957 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.834375630421626\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4957 4958\n",
      "Training loss:-0.0046559786424040794\n",
      "check (7153,) ()\n",
      "epoch 4958\n",
      "====================================\n",
      "Epoch:  4958 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.834207341670028\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4958 4959\n",
      "Training loss:-0.0049193259328603745\n",
      "check (9015,) ()\n",
      "epoch 4959\n",
      "====================================\n",
      "Epoch:  4959 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.833837467231296\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4959 4960\n",
      "Training loss:-0.0035932098980993032\n",
      "check (8468,) ()\n",
      "epoch 4960\n",
      "====================================\n",
      "Epoch:  4960 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.833467741935484\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4960 4961\n",
      "Training loss:0.002112553920596838\n",
      "check (10000,) ()\n",
      "epoch 4961\n",
      "====================================\n",
      "Epoch:  4961 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.830880870792178\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4961 4962\n",
      "Training loss:-0.01143681537359953\n",
      "check (7862,) ()\n",
      "epoch 4962\n",
      "====================================\n",
      "Epoch:  4962 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.830108827085853\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4962 4963\n",
      "Training loss:0.0021766580175608397\n",
      "check (9339,) ()\n",
      "epoch 4963\n",
      "====================================\n",
      "Epoch:  4963 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.829135603465646\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4963 4964\n",
      "Training loss:-5.561966827372089e-05\n",
      "check (8389,) ()\n",
      "epoch 4964\n",
      "====================================\n",
      "Epoch:  4964 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.829170024174053\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4964 4965\n",
      "Training loss:-0.00526337930932641\n",
      "check (9189,) ()\n",
      "epoch 4965\n",
      "====================================\n",
      "Epoch:  4965 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.828197381671702\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4965 4966\n",
      "Training loss:-0.00464559206739068\n",
      "check (7537,) ()\n",
      "epoch 4966\n",
      "====================================\n",
      "Epoch:  4966 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.828231977446638\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4966 4967\n",
      "Training loss:-0.009314801543951035\n",
      "check (9013,) ()\n",
      "epoch 4967\n",
      "====================================\n",
      "Epoch:  4967 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.827662572981678\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4967 4968\n",
      "Training loss:-0.0007259073317982256\n",
      "check (9301,) ()\n",
      "epoch 4968\n",
      "====================================\n",
      "Epoch:  4968 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.827093397745571\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4968 4969\n",
      "Training loss:-0.0027781440876424313\n",
      "check (7709,) ()\n",
      "epoch 4969\n",
      "====================================\n",
      "Epoch:  4969 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.82652445159992\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4969 4970\n",
      "Training loss:-0.0018580282339826226\n",
      "check (9133,) ()\n",
      "epoch 4970\n",
      "====================================\n",
      "Epoch:  4970 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.825352112676056\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4970 4971\n",
      "Training loss:-0.00965543556958437\n",
      "check (8984,) ()\n",
      "epoch 4971\n",
      "====================================\n",
      "Epoch:  4971 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.824582578957957\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4971 4972\n",
      "Training loss:-0.0021756915375590324\n",
      "check (8720,) ()\n",
      "epoch 4972\n",
      "====================================\n",
      "Epoch:  4972 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.823209975864843\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4972 4973\n",
      "Training loss:0.004092514049261808\n",
      "check (10000,) ()\n",
      "epoch 4973\n",
      "====================================\n",
      "Epoch:  4973 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.821636838930223\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4973 4974\n",
      "Training loss:0.0027161811012774706\n",
      "check (10000,) ()\n",
      "epoch 4974\n",
      "====================================\n",
      "Epoch:  4974 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.819059107358264\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4974 4975\n",
      "Training loss:-0.0057048797607421875\n",
      "check (10000,) ()\n",
      "epoch 4975\n",
      "====================================\n",
      "Epoch:  4975 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.816281407035175\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4975 4976\n",
      "Training loss:-0.008135092444717884\n",
      "check (8178,) ()\n",
      "epoch 4976\n",
      "====================================\n",
      "Epoch:  4976 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.816117363344052\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4976 4977\n",
      "Training loss:-0.004178096540272236\n",
      "check (6968,) ()\n",
      "epoch 4977\n",
      "====================================\n",
      "Epoch:  4977 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.81595338557364\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4977 4978\n",
      "Training loss:-0.0081946337595582\n",
      "check (10000,) ()\n",
      "epoch 4978\n",
      "====================================\n",
      "Epoch:  4978 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.813177983125753\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4978 4979\n",
      "Training loss:-0.0073521812446415424\n",
      "check (10000,) ()\n",
      "epoch 4979\n",
      "====================================\n",
      "Epoch:  4979 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.81120706969271\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4979 4980\n",
      "Training loss:-0.0064594498835504055\n",
      "check (10000,) ()\n",
      "epoch 4980\n",
      "====================================\n",
      "Epoch:  4980 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.809236947791165\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4980 4981\n",
      "Training loss:-0.006529455538839102\n",
      "check (6618,) ()\n",
      "epoch 4981\n",
      "====================================\n",
      "Epoch:  4981 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.808472194338487\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4981 4982\n",
      "Training loss:0.0015899580903351307\n",
      "check (8643,) ()\n",
      "epoch 4982\n",
      "====================================\n",
      "Epoch:  4982 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.807507025291049\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4982 4983\n",
      "Training loss:-0.008912242017686367\n",
      "check (8108,) ()\n",
      "epoch 4983\n",
      "====================================\n",
      "Epoch:  4983 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.806140878988561\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4983 4984\n",
      "Training loss:0.0029753707349300385\n",
      "check (7617,) ()\n",
      "epoch 4984\n",
      "====================================\n",
      "Epoch:  4984 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.805577849117174\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4984 4985\n",
      "Training loss:-0.0004945932305417955\n",
      "check (6957,) ()\n",
      "epoch 4985\n",
      "====================================\n",
      "Epoch:  4985 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.805416248746239\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4985 4986\n",
      "Training loss:-0.002785333199426532\n",
      "check (8190,) ()\n",
      "epoch 4986\n",
      "====================================\n",
      "Epoch:  4986 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.804853590052145\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4986 4987\n",
      "Training loss:-0.000434216286521405\n",
      "check (7777,) ()\n",
      "epoch 4987\n",
      "====================================\n",
      "Epoch:  4987 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.803689592941648\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4987 4988\n",
      "Training loss:0.0013730330392718315\n",
      "check (8538,) ()\n",
      "epoch 4988\n",
      "====================================\n",
      "Epoch:  4988 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.802927024859663\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4988 4989\n",
      "Training loss:-0.0026819217018783092\n",
      "check (8501,) ()\n",
      "epoch 4989\n",
      "====================================\n",
      "Epoch:  4989 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.803166967328123\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4989 4990\n",
      "Training loss:-0.005870891269296408\n",
      "check (8633,) ()\n",
      "epoch 4990\n",
      "====================================\n",
      "Epoch:  4990 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.802404809619238\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4990 4991\n",
      "Training loss:-0.0011420438531786203\n",
      "check (6902,) ()\n",
      "epoch 4991\n",
      "====================================\n",
      "Epoch:  4991 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.802244039270688\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4991 4992\n",
      "Training loss:-0.0002877205843105912\n",
      "check (8240,) ()\n",
      "epoch 4992\n",
      "====================================\n",
      "Epoch:  4992 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.802684294871796\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4992 4993\n",
      "Training loss:-0.008603982627391815\n",
      "check (9791,) ()\n",
      "epoch 4993\n",
      "====================================\n",
      "Epoch:  4993 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.801922691768477\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4993 4994\n",
      "Training loss:-0.009257761761546135\n",
      "check (9433,) ()\n",
      "epoch 4994\n",
      "====================================\n",
      "Epoch:  4994 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.800560672807368\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4994 4995\n",
      "Training loss:-0.007045470643788576\n",
      "check (7666,) ()\n",
      "epoch 4995\n",
      "====================================\n",
      "Epoch:  4995 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.800600600600601\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4995 4996\n",
      "Training loss:-0.0007911247084848583\n",
      "check (9963,) ()\n",
      "epoch 4996\n",
      "====================================\n",
      "Epoch:  4996 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.80004003202562\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4996 4997\n",
      "Training loss:-0.005977392662316561\n",
      "check (6231,) ()\n",
      "epoch 4997\n",
      "====================================\n",
      "Epoch:  4997 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.80028016810086\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4997 4998\n",
      "Training loss:-0.001626221346668899\n",
      "check (9502,) ()\n",
      "epoch 4998\n",
      "====================================\n",
      "Epoch:  4998 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.799119647859143\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 4998 4999\n",
      "Training loss:-0.0111993458122015\n",
      "check (10000,) ()\n",
      "epoch 4999\n",
      "====================================\n",
      "Epoch:  4999 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.796759351870374\n",
      "Max reward for a batch so far: 7.0\n",
      "check 4999 5000\n",
      "Training loss:-0.004705522209405899\n",
      "check (9389,) ()\n",
      "epoch 5000\n",
      "====================================\n",
      "Epoch:  5000 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.7964\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5000 5001\n",
      "Training loss:-0.00029713520780205727\n",
      "Model saved\n",
      "check (8648,) ()\n",
      "epoch 5001\n",
      "====================================\n",
      "Epoch:  5001 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.79504099180164\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5001 5002\n",
      "Training loss:0.0008754668524488807\n",
      "check (9452,) ()\n",
      "epoch 5002\n",
      "====================================\n",
      "Epoch:  5002 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.794482207117154\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5002 5003\n",
      "Training loss:0.0035077815409749746\n",
      "check (7671,) ()\n",
      "epoch 5003\n",
      "====================================\n",
      "Epoch:  5003 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.793124125524685\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5003 5004\n",
      "Training loss:-0.0016487836837768555\n",
      "check (8679,) ()\n",
      "epoch 5004\n",
      "====================================\n",
      "Epoch:  5004 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.791566746602717\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5004 5005\n",
      "Training loss:-0.006229647900909185\n",
      "check (8830,) ()\n",
      "epoch 5005\n",
      "====================================\n",
      "Epoch:  5005 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.79080919080919\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5005 5006\n",
      "Training loss:-0.004838171880692244\n",
      "check (10000,) ()\n",
      "epoch 5006\n",
      "====================================\n",
      "Epoch:  5006 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.788853375948861\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5006 5007\n",
      "Training loss:-0.0035515488125383854\n",
      "check (8416,) ()\n",
      "epoch 5007\n",
      "====================================\n",
      "Epoch:  5007 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.788695825843819\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5007 5008\n",
      "Training loss:-0.004021128639578819\n",
      "check (7689,) ()\n",
      "epoch 5008\n",
      "====================================\n",
      "Epoch:  5008 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.788138977635782\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5008 5009\n",
      "Training loss:-0.009438364766538143\n",
      "check (9826,) ()\n",
      "epoch 5009\n",
      "====================================\n",
      "Epoch:  5009 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.78758235176682\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5009 5010\n",
      "Training loss:0.0025928481481969357\n",
      "check (7665,) ()\n",
      "epoch 5010\n",
      "====================================\n",
      "Epoch:  5010 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.78682634730539\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5010 5011\n",
      "Training loss:0.0005581932491622865\n",
      "check (6389,) ()\n",
      "epoch 5011\n",
      "====================================\n",
      "Epoch:  5011 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.786669327479546\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5011 5012\n",
      "Training loss:-0.005280980374664068\n",
      "check (8220,) ()\n",
      "epoch 5012\n",
      "====================================\n",
      "Epoch:  5012 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.786911412609737\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5012 5013\n",
      "Training loss:1.7414417015970685e-05\n",
      "check (9013,) ()\n",
      "epoch 5013\n",
      "====================================\n",
      "Epoch:  5013 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.78655495711151\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5013 5014\n",
      "Training loss:0.0005105299060232937\n",
      "check (9324,) ()\n",
      "epoch 5014\n",
      "====================================\n",
      "Epoch:  5014 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.786198643797368\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5014 5015\n",
      "Training loss:0.003486369038000703\n",
      "check (6956,) ()\n",
      "epoch 5015\n",
      "====================================\n",
      "Epoch:  5015 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.786839481555335\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5015 5016\n",
      "Training loss:-0.002340890234336257\n",
      "check (8069,) ()\n",
      "epoch 5016\n",
      "====================================\n",
      "Epoch:  5016 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.787081339712918\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5016 5017\n",
      "Training loss:-0.0057451482862234116\n",
      "check (8168,) ()\n",
      "epoch 5017\n",
      "====================================\n",
      "Epoch:  5017 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.787323101455053\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5017 5018\n",
      "Training loss:-0.001486356952227652\n",
      "check (8172,) ()\n",
      "epoch 5018\n",
      "====================================\n",
      "Epoch:  5018 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.787564766839377\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5018 5019\n",
      "Training loss:-0.005832672119140625\n",
      "check (6809,) ()\n",
      "epoch 5019\n",
      "====================================\n",
      "Epoch:  5019 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.787009364415223\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5019 5020\n",
      "Training loss:-0.0014468795852735639\n",
      "check (9403,) ()\n",
      "epoch 5020\n",
      "====================================\n",
      "Epoch:  5020 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.78605577689243\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5020 5021\n",
      "Training loss:-0.0024788992013782263\n",
      "check (8388,) ()\n",
      "epoch 5021\n",
      "====================================\n",
      "Epoch:  5021 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.786297550288786\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5021 5022\n",
      "Training loss:-0.0001299714349443093\n",
      "check (7028,) ()\n",
      "epoch 5022\n",
      "====================================\n",
      "Epoch:  5022 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.786539227399443\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5022 5023\n",
      "Training loss:-0.008253046311438084\n",
      "check (8456,) ()\n",
      "epoch 5023\n",
      "====================================\n",
      "Epoch:  5023 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.78638263985666\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5023 5024\n",
      "Training loss:-0.0005955384694971144\n",
      "check (9298,) ()\n",
      "epoch 5024\n",
      "====================================\n",
      "Epoch:  5024 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.785828025477707\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5024 5025\n",
      "Training loss:0.005779338534921408\n",
      "check (7155,) ()\n",
      "epoch 5025\n",
      "====================================\n",
      "Epoch:  5025 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.785273631840797\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5025 5026\n",
      "Training loss:-0.007249312940984964\n",
      "check (8459,) ()\n",
      "epoch 5026\n",
      "====================================\n",
      "Epoch:  5026 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.783923597294072\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5026 5027\n",
      "Training loss:-0.0025938742328435183\n",
      "check (8953,) ()\n",
      "epoch 5027\n",
      "====================================\n",
      "Epoch:  5027 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.783369803063458\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5027 5028\n",
      "Training loss:-1.4465427739196457e-05\n",
      "check (9151,) ()\n",
      "epoch 5028\n",
      "====================================\n",
      "Epoch:  5028 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.7824184566428\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5028 5029\n",
      "Training loss:-0.01042742095887661\n",
      "check (10000,) ()\n",
      "epoch 5029\n",
      "====================================\n",
      "Epoch:  5029 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.781268641877112\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5029 5030\n",
      "Training loss:-0.0011344138765707612\n",
      "check (10000,) ()\n",
      "epoch 5030\n",
      "====================================\n",
      "Epoch:  5030 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.779522862823061\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5030 5031\n",
      "Training loss:-0.0006892257952131331\n",
      "check (9273,) ()\n",
      "epoch 5031\n",
      "====================================\n",
      "Epoch:  5031 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.778771615980919\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5031 5032\n",
      "Training loss:-0.007251854985952377\n",
      "check (6563,) ()\n",
      "epoch 5032\n",
      "====================================\n",
      "Epoch:  5032 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.77841812400636\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5032 5033\n",
      "Training loss:-0.0031810838263481855\n",
      "check (9126,) ()\n",
      "epoch 5033\n",
      "====================================\n",
      "Epoch:  5033 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.778660838466124\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5033 5034\n",
      "Training loss:-0.00467129098251462\n",
      "check (9622,) ()\n",
      "epoch 5034\n",
      "====================================\n",
      "Epoch:  5034 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.778108859753676\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5034 5035\n",
      "Training loss:-0.0040612611919641495\n",
      "check (7732,) ()\n",
      "epoch 5035\n",
      "====================================\n",
      "Epoch:  5035 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.776365441906654\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5035 5036\n",
      "Training loss:-0.00402914360165596\n",
      "check (7538,) ()\n",
      "epoch 5036\n",
      "====================================\n",
      "Epoch:  5036 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.77660841938046\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5036 5037\n",
      "Training loss:-0.001020812545903027\n",
      "check (7785,) ()\n",
      "epoch 5037\n",
      "====================================\n",
      "Epoch:  5037 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.775263053404805\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5037 5038\n",
      "Training loss:0.007174985017627478\n",
      "check (8375,) ()\n",
      "epoch 5038\n",
      "====================================\n",
      "Epoch:  5038 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.774712187375943\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5038 5039\n",
      "Training loss:-0.0032271663658320904\n",
      "check (8552,) ()\n",
      "epoch 5039\n",
      "====================================\n",
      "Epoch:  5039 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.77455844413574\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5039 5040\n",
      "Training loss:-0.0054214512929320335\n",
      "check (10000,) ()\n",
      "epoch 5040\n",
      "====================================\n",
      "Epoch:  5040 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.773214285714285\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5040 5041\n",
      "Training loss:-0.0013157268986105919\n",
      "check (7413,) ()\n",
      "epoch 5041\n",
      "====================================\n",
      "Epoch:  5041 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.773656020630828\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5041 5042\n",
      "Training loss:-0.009113417007029057\n",
      "check (8278,) ()\n",
      "epoch 5042\n",
      "====================================\n",
      "Epoch:  5042 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.771717572391909\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5042 5043\n",
      "Training loss:-0.006803622003644705\n",
      "check (9747,) ()\n",
      "epoch 5043\n",
      "====================================\n",
      "Epoch:  5043 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.770771366250248\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5043 5044\n",
      "Training loss:0.0026895140763372183\n",
      "check (10000,) ()\n",
      "epoch 5044\n",
      "====================================\n",
      "Epoch:  5044 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.768636003172086\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5044 5045\n",
      "Training loss:-0.00047127684229053557\n",
      "check (7086,) ()\n",
      "epoch 5045\n",
      "====================================\n",
      "Epoch:  5045 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.768681863230922\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5045 5046\n",
      "Training loss:0.000538268534000963\n",
      "check (10000,) ()\n",
      "epoch 5046\n",
      "====================================\n",
      "Epoch:  5046 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.766547760602457\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5046 5047\n",
      "Training loss:-0.007805767003446817\n",
      "check (9066,) ()\n",
      "epoch 5047\n",
      "====================================\n",
      "Epoch:  5047 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.765603328710124\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5047 5048\n",
      "Training loss:-0.0055428966879844666\n",
      "check (9740,) ()\n",
      "epoch 5048\n",
      "====================================\n",
      "Epoch:  5048 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.76446117274168\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5048 5049\n",
      "Training loss:0.003852640511468053\n",
      "check (7345,) ()\n",
      "epoch 5049\n",
      "====================================\n",
      "Epoch:  5049 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.765102000396118\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5049 5050\n",
      "Training loss:0.0027809489984065294\n",
      "check (8409,) ()\n",
      "epoch 5050\n",
      "====================================\n",
      "Epoch:  5050 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.764554455445545\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5050 5051\n",
      "Training loss:-0.008029348216950893\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 5051\n",
      "====================================\n",
      "Epoch:  5051 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.763611166105722\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5051 5052\n",
      "Training loss:-0.0020593167282640934\n",
      "check (9233,) ()\n",
      "epoch 5052\n",
      "====================================\n",
      "Epoch:  5052 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.761480601741884\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5052 5053\n",
      "Training loss:-0.004165948368608952\n",
      "check (8268,) ()\n",
      "epoch 5053\n",
      "====================================\n",
      "Epoch:  5053 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.760736196319018\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5053 5054\n",
      "Training loss:-0.008742795325815678\n",
      "check (7954,) ()\n",
      "epoch 5054\n",
      "====================================\n",
      "Epoch:  5054 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.761179263949346\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5054 5055\n",
      "Training loss:0.0010300478897988796\n",
      "check (8712,) ()\n",
      "epoch 5055\n",
      "====================================\n",
      "Epoch:  5055 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.761424332344214\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5055 5056\n",
      "Training loss:-0.005541883874684572\n",
      "check (9275,) ()\n",
      "epoch 5056\n",
      "====================================\n",
      "Epoch:  5056 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.76048259493671\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5056 5057\n",
      "Training loss:-0.013238834217190742\n",
      "check (10000,) ()\n",
      "epoch 5057\n",
      "====================================\n",
      "Epoch:  5057 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.759343484279217\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5057 5058\n",
      "Training loss:-0.005440562963485718\n",
      "check (6813,) ()\n",
      "epoch 5058\n",
      "====================================\n",
      "Epoch:  5058 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.759786476868328\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5058 5059\n",
      "Training loss:-0.010009747929871082\n",
      "check (6917,) ()\n",
      "epoch 5059\n",
      "====================================\n",
      "Epoch:  5059 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.760426961850168\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5059 5060\n",
      "Training loss:-0.002992470981553197\n",
      "check (9306,) ()\n",
      "epoch 5060\n",
      "====================================\n",
      "Epoch:  5060 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.7598814229249\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5060 5061\n",
      "Training loss:-0.0022586779668927193\n",
      "check (8735,) ()\n",
      "epoch 5061\n",
      "====================================\n",
      "Epoch:  5061 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.760521636040309\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5061 5062\n",
      "Training loss:-0.010694153606891632\n",
      "check (8338,) ()\n",
      "epoch 5062\n",
      "====================================\n",
      "Epoch:  5062 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.76037139470565\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5062 5063\n",
      "Training loss:-0.004983716644346714\n",
      "check (8294,) ()\n",
      "epoch 5063\n",
      "====================================\n",
      "Epoch:  5063 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.760418724076635\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5063 5064\n",
      "Training loss:-0.001984324771910906\n",
      "check (7908,) ()\n",
      "epoch 5064\n",
      "====================================\n",
      "Epoch:  5064 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.760663507109005\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5064 5065\n",
      "Training loss:-0.009041313081979752\n",
      "check (8444,) ()\n",
      "epoch 5065\n",
      "====================================\n",
      "Epoch:  5065 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.759131293188549\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5065 5066\n",
      "Training loss:-0.0037324423901736736\n",
      "check (7461,) ()\n",
      "epoch 5066\n",
      "====================================\n",
      "Epoch:  5066 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.758586656138966\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5066 5067\n",
      "Training loss:-0.008245925419032574\n",
      "check (7701,) ()\n",
      "epoch 5067\n",
      "====================================\n",
      "Epoch:  5067 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.757252812314979\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5067 5068\n",
      "Training loss:-0.004664007108658552\n",
      "check (8856,) ()\n",
      "epoch 5068\n",
      "====================================\n",
      "Epoch:  5068 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.75611681136543\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5068 5069\n",
      "Training loss:-0.005469941068440676\n",
      "check (9821,) ()\n",
      "epoch 5069\n",
      "====================================\n",
      "Epoch:  5069 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.754586703491812\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5069 5070\n",
      "Training loss:-0.0011197057319805026\n",
      "check (10000,) ()\n",
      "epoch 5070\n",
      "====================================\n",
      "Epoch:  5070 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.753254437869822\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5070 5071\n",
      "Training loss:-0.006928191985934973\n",
      "check (10000,) ()\n",
      "epoch 5071\n",
      "====================================\n",
      "Epoch:  5071 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.751922697692763\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5071 5072\n",
      "Training loss:-0.005919718183577061\n",
      "check (8275,) ()\n",
      "epoch 5072\n",
      "====================================\n",
      "Epoch:  5072 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.751774447949527\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5072 5073\n",
      "Training loss:0.003391799982637167\n",
      "check (7403,) ()\n",
      "epoch 5073\n",
      "====================================\n",
      "Epoch:  5073 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.752414744726986\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5073 5074\n",
      "Training loss:-0.00595683790743351\n",
      "check (8297,) ()\n",
      "epoch 5074\n",
      "====================================\n",
      "Epoch:  5074 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.75226645644462\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5074 5075\n",
      "Training loss:-0.006693231873214245\n",
      "check (9916,) ()\n",
      "epoch 5075\n",
      "====================================\n",
      "Epoch:  5075 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.749950738916256\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5075 5076\n",
      "Training loss:-0.006411078851670027\n",
      "check (8660,) ()\n",
      "epoch 5076\n",
      "====================================\n",
      "Epoch:  5076 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.749408983451536\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5076 5077\n",
      "Training loss:-0.004958225879818201\n",
      "check (7903,) ()\n",
      "epoch 5077\n",
      "====================================\n",
      "Epoch:  5077 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.74945834154028\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5077 5078\n",
      "Training loss:0.0013504602247849107\n",
      "check (9899,) ()\n",
      "epoch 5078\n",
      "====================================\n",
      "Epoch:  5078 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.747341473020875\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5078 5079\n",
      "Training loss:-0.004393985494971275\n",
      "check (6898,) ()\n",
      "epoch 5079\n",
      "====================================\n",
      "Epoch:  5079 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.747588107895256\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5079 5080\n",
      "Training loss:-0.0018200400518253446\n",
      "check (10000,) ()\n",
      "epoch 5080\n",
      "====================================\n",
      "Epoch:  5080 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.746456692913386\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5080 5081\n",
      "Training loss:-0.0008711677510291338\n",
      "check (9501,) ()\n",
      "epoch 5081\n",
      "====================================\n",
      "Epoch:  5081 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.745128911631568\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5081 5082\n",
      "Training loss:-0.003290205029770732\n",
      "check (9208,) ()\n",
      "epoch 5082\n",
      "====================================\n",
      "Epoch:  5082 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.7443919716647\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5082 5083\n",
      "Training loss:0.002978615229949355\n",
      "check (10000,) ()\n",
      "epoch 5083\n",
      "====================================\n",
      "Epoch:  5083 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.74247491638796\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5083 5084\n",
      "Training loss:-0.008632959797978401\n",
      "check (8810,) ()\n",
      "epoch 5084\n",
      "====================================\n",
      "Epoch:  5084 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.741935483870968\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5084 5085\n",
      "Training loss:-0.0012026714393869042\n",
      "check (8737,) ()\n",
      "epoch 5085\n",
      "====================================\n",
      "Epoch:  5085 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.742182890855457\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5085 5086\n",
      "Training loss:-0.005659668240696192\n",
      "check (8732,) ()\n",
      "epoch 5086\n",
      "====================================\n",
      "Epoch:  5086 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.741447109712938\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5086 5087\n",
      "Training loss:-0.0038027979899197817\n",
      "check (7289,) ()\n",
      "epoch 5087\n",
      "====================================\n",
      "Epoch:  5087 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.740908197365835\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5087 5088\n",
      "Training loss:-0.004730079788714647\n",
      "check (9479,) ()\n",
      "epoch 5088\n",
      "====================================\n",
      "Epoch:  5088 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.740762578616351\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5088 5089\n",
      "Training loss:0.0004576779610943049\n",
      "check (7262,) ()\n",
      "epoch 5089\n",
      "====================================\n",
      "Epoch:  5089 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.74101002161525\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5089 5090\n",
      "Training loss:-0.008257785812020302\n",
      "check (8511,) ()\n",
      "epoch 5090\n",
      "====================================\n",
      "Epoch:  5090 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.740471512770137\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5090 5091\n",
      "Training loss:0.0007681332645006478\n",
      "check (8605,) ()\n",
      "epoch 5091\n",
      "====================================\n",
      "Epoch:  5091 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.740326065605972\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5091 5092\n",
      "Training loss:-0.004113886971026659\n",
      "check (9597,) ()\n",
      "epoch 5092\n",
      "====================================\n",
      "Epoch:  5092 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.739395129615083\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5092 5093\n",
      "Training loss:-0.007804637774825096\n",
      "check (7865,) ()\n",
      "epoch 5093\n",
      "====================================\n",
      "Epoch:  5093 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.73885725505596\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5093 5094\n",
      "Training loss:-0.004212658852338791\n",
      "check (7963,) ()\n",
      "epoch 5094\n",
      "====================================\n",
      "Epoch:  5094 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.738712210443659\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5094 5095\n",
      "Training loss:-0.007841838523745537\n",
      "check (8185,) ()\n",
      "epoch 5095\n",
      "====================================\n",
      "Epoch:  5095 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.738174681059862\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5095 5096\n",
      "Training loss:-0.0022062177304178476\n",
      "check (8111,) ()\n",
      "epoch 5096\n",
      "====================================\n",
      "Epoch:  5096 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.738029827315541\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5096 5097\n",
      "Training loss:-0.0005202192696742713\n",
      "check (10000,) ()\n",
      "epoch 5097\n",
      "====================================\n",
      "Epoch:  5097 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.736904061212478\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5097 5098\n",
      "Training loss:0.006280399858951569\n",
      "check (7631,) ()\n",
      "epoch 5098\n",
      "====================================\n",
      "Epoch:  5098 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.73675951353472\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5098 5099\n",
      "Training loss:-0.003990880213677883\n",
      "check (7696,) ()\n",
      "epoch 5099\n",
      "====================================\n",
      "Epoch:  5099 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.73700725632477\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5099 5100\n",
      "Training loss:-0.005329316481947899\n",
      "check (8003,) ()\n",
      "epoch 5100\n",
      "====================================\n",
      "Epoch:  5100 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.736470588235294\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5100 5101\n",
      "Training loss:-0.003535857889801264\n",
      "Model saved\n",
      "check (9429,) ()\n",
      "epoch 5101\n",
      "====================================\n",
      "Epoch:  5101 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.735934130562635\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5101 5102\n",
      "Training loss:-0.0027375533245503902\n",
      "check (8066,) ()\n",
      "epoch 5102\n",
      "====================================\n",
      "Epoch:  5102 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.736181889455116\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5102 5103\n",
      "Training loss:-0.007284378632903099\n",
      "check (10000,) ()\n",
      "epoch 5103\n",
      "====================================\n",
      "Epoch:  5103 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.734665882814031\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5103 5104\n",
      "Training loss:-0.004369579255580902\n",
      "check (10000,) ()\n",
      "epoch 5104\n",
      "====================================\n",
      "Epoch:  5104 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.732366771159874\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5104 5105\n",
      "Training loss:-0.00488436222076416\n",
      "check (10000,) ()\n",
      "epoch 5105\n",
      "====================================\n",
      "Epoch:  5105 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.730656219392753\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5105 5106\n",
      "Training loss:-0.0075234174728393555\n",
      "check (8476,) ()\n",
      "epoch 5106\n",
      "====================================\n",
      "Epoch:  5106 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.72972972972973\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5106 5107\n",
      "Training loss:0.0027678459882736206\n",
      "check (7163,) ()\n",
      "epoch 5107\n",
      "====================================\n",
      "Epoch:  5107 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.729195222243979\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5107 5108\n",
      "Training loss:0.0008892979240044951\n",
      "check (7526,) ()\n",
      "epoch 5108\n",
      "====================================\n",
      "Epoch:  5108 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.728465152701645\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5108 5109\n",
      "Training loss:-0.0039037216920405626\n",
      "check (9667,) ()\n",
      "epoch 5109\n",
      "====================================\n",
      "Epoch:  5109 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.72675670385594\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5109 5110\n",
      "Training loss:0.0015666366089135408\n",
      "check (9336,) ()\n",
      "epoch 5110\n",
      "====================================\n",
      "Epoch:  5110 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.72641878669276\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5110 5111\n",
      "Training loss:-0.004887533374130726\n",
      "check (7869,) ()\n",
      "epoch 5111\n",
      "====================================\n",
      "Epoch:  5111 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.726667971042849\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5111 5112\n",
      "Training loss:-0.0018225745297968388\n",
      "check (7704,) ()\n",
      "epoch 5112\n",
      "====================================\n",
      "Epoch:  5112 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.726134585289515\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5112 5113\n",
      "Training loss:-0.0009879681747406721\n",
      "check (8529,) ()\n",
      "epoch 5113\n",
      "====================================\n",
      "Epoch:  5113 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.7261881478584\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5113 5114\n",
      "Training loss:-0.001019629300571978\n",
      "check (9994,) ()\n",
      "epoch 5114\n",
      "====================================\n",
      "Epoch:  5114 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.72487289792726\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5114 5115\n",
      "Training loss:-0.0016983357490971684\n",
      "check (9088,) ()\n",
      "epoch 5115\n",
      "====================================\n",
      "Epoch:  5115 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.724731182795699\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5115 5116\n",
      "Training loss:-0.003732943208888173\n",
      "check (9971,) ()\n",
      "epoch 5116\n",
      "====================================\n",
      "Epoch:  5116 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.72302580140735\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5116 5117\n",
      "Training loss:-0.0018929101061075926\n",
      "check (9023,) ()\n",
      "epoch 5117\n",
      "====================================\n",
      "Epoch:  5117 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.72249364862224\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5117 5118\n",
      "Training loss:-0.009462106972932816\n",
      "check (8788,) ()\n",
      "epoch 5118\n",
      "====================================\n",
      "Epoch:  5118 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.721180148495506\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5118 5119\n",
      "Training loss:-0.00416340259835124\n",
      "check (8188,) ()\n",
      "epoch 5119\n",
      "====================================\n",
      "Epoch:  5119 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.72064856417269\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5119 5120\n",
      "Training loss:-0.00026049703592434525\n",
      "check (8676,) ()\n",
      "epoch 5120\n",
      "====================================\n",
      "Epoch:  5120 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.719140625\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5120 5121\n",
      "Training loss:-0.004549082368612289\n",
      "check (10000,) ()\n",
      "epoch 5121\n",
      "====================================\n",
      "Epoch:  5121 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.718219097832455\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5121 5122\n",
      "Training loss:-0.007712342776358128\n",
      "check (8835,) ()\n",
      "epoch 5122\n",
      "====================================\n",
      "Epoch:  5122 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.7172979304959\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5122 5123\n",
      "Training loss:-0.01309640146791935\n",
      "check (9273,) ()\n",
      "epoch 5123\n",
      "====================================\n",
      "Epoch:  5123 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.716767519031817\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5123 5124\n",
      "Training loss:-0.0012481221929192543\n",
      "check (9286,) ()\n",
      "epoch 5124\n",
      "====================================\n",
      "Epoch:  5124 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.716432474629196\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5124 5125\n",
      "Training loss:-0.004248773213475943\n",
      "check (8266,) ()\n",
      "epoch 5125\n",
      "====================================\n",
      "Epoch:  5125 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.716292682926829\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5125 5126\n",
      "Training loss:-0.004327450878918171\n",
      "check (10000,) ()\n",
      "epoch 5126\n",
      "====================================\n",
      "Epoch:  5126 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.7140070230199\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5126 5127\n",
      "Training loss:-0.0031265541911125183\n",
      "check (8251,) ()\n",
      "epoch 5127\n",
      "====================================\n",
      "Epoch:  5127 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.713477667251805\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5127 5128\n",
      "Training loss:-0.002294881734997034\n",
      "check (9161,) ()\n",
      "epoch 5128\n",
      "====================================\n",
      "Epoch:  5128 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.712363494539781\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5128 5129\n",
      "Training loss:-0.0010586786083877087\n",
      "check (6950,) ()\n",
      "epoch 5129\n",
      "====================================\n",
      "Epoch:  5129 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.712809514525249\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5129 5130\n",
      "Training loss:0.001901027513667941\n",
      "check (10000,) ()\n",
      "epoch 5130\n",
      "====================================\n",
      "Epoch:  5130 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.710526315789474\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5130 5131\n",
      "Training loss:0.005534886848181486\n",
      "check (9382,) ()\n",
      "epoch 5131\n",
      "====================================\n",
      "Epoch:  5131 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.709998051062172\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5131 5132\n",
      "Training loss:-0.005103759001940489\n",
      "check (8798,) ()\n",
      "epoch 5132\n",
      "====================================\n",
      "Epoch:  5132 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.708690568978955\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5132 5133\n",
      "Training loss:-0.0014563055010512471\n",
      "check (9088,) ()\n",
      "epoch 5133\n",
      "====================================\n",
      "Epoch:  5133 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.706409507110852\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5133 5134\n",
      "Training loss:-0.0030630347318947315\n",
      "check (8758,) ()\n",
      "epoch 5134\n",
      "====================================\n",
      "Epoch:  5134 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.705492793143748\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5134 5135\n",
      "Training loss:-0.002521310467272997\n",
      "check (8914,) ()\n",
      "epoch 5135\n",
      "====================================\n",
      "Epoch:  5135 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.704965920155793\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5135 5136\n",
      "Training loss:-0.0018479019636288285\n",
      "check (8291,) ()\n",
      "epoch 5136\n",
      "====================================\n",
      "Epoch:  5136 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.704828660436137\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5136 5137\n",
      "Training loss:-0.002160930074751377\n",
      "check (6212,) ()\n",
      "epoch 5137\n",
      "====================================\n",
      "Epoch:  5137 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.705080786451235\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5137 5138\n",
      "Training loss:-0.004354821518063545\n",
      "check (9223,) ()\n",
      "epoch 5138\n",
      "====================================\n",
      "Epoch:  5138 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.7041650447645\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5138 5139\n",
      "Training loss:-0.008336452767252922\n",
      "check (10000,) ()\n",
      "epoch 5139\n",
      "====================================\n",
      "Epoch:  5139 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.702860478692353\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5139 5140\n",
      "Training loss:-0.004528275225311518\n",
      "check (6877,) ()\n",
      "epoch 5140\n",
      "====================================\n",
      "Epoch:  5140 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.70272373540856\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5140 5141\n",
      "Training loss:-0.00234308117069304\n",
      "check (5979,) ()\n",
      "epoch 5141\n",
      "====================================\n",
      "Epoch:  5141 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.703365104065357\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5141 5142\n",
      "Training loss:0.0007150053279474378\n",
      "check (7347,) ()\n",
      "epoch 5142\n",
      "====================================\n",
      "Epoch:  5142 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.70439517697394\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5142 5143\n",
      "Training loss:-0.0093110091984272\n",
      "check (8333,) ()\n",
      "epoch 5143\n",
      "====================================\n",
      "Epoch:  5143 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.703480458876143\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5143 5144\n",
      "Training loss:-0.0038451135624200106\n",
      "check (10000,) ()\n",
      "epoch 5144\n",
      "====================================\n",
      "Epoch:  5144 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -13.70042768273717\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5144 5145\n",
      "Training loss:-0.010239263996481895\n",
      "check (6077,) ()\n",
      "epoch 5145\n",
      "====================================\n",
      "Epoch:  5145 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.701068999028182\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5145 5146\n",
      "Training loss:-0.0043669831939041615\n",
      "check (7955,) ()\n",
      "epoch 5146\n",
      "====================================\n",
      "Epoch:  5146 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.699766809172173\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5146 5147\n",
      "Training loss:-0.0033922982402145863\n",
      "check (9203,) ()\n",
      "epoch 5147\n",
      "====================================\n",
      "Epoch:  5147 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.698465125315717\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5147 5148\n",
      "Training loss:-0.0007631657645106316\n",
      "check (8845,) ()\n",
      "epoch 5148\n",
      "====================================\n",
      "Epoch:  5148 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.697940947940948\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5148 5149\n",
      "Training loss:-0.001953846076503396\n",
      "check (8307,) ()\n",
      "epoch 5149\n",
      "====================================\n",
      "Epoch:  5149 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.697611186638182\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5149 5150\n",
      "Training loss:-0.004064412787556648\n",
      "check (9553,) ()\n",
      "epoch 5150\n",
      "====================================\n",
      "Epoch:  5150 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.696310679611651\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5150 5151\n",
      "Training loss:-0.004288426134735346\n",
      "Model saved\n",
      "check (7358,) ()\n",
      "epoch 5151\n",
      "====================================\n",
      "Epoch:  5151 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.696175499902932\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5151 5152\n",
      "Training loss:-0.0006623388617299497\n",
      "check (8588,) ()\n",
      "epoch 5152\n",
      "====================================\n",
      "Epoch:  5152 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.696040372670808\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5152 5153\n",
      "Training loss:-0.001532157533802092\n",
      "check (10000,) ()\n",
      "epoch 5153\n",
      "====================================\n",
      "Epoch:  5153 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.69415874248011\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5153 5154\n",
      "Training loss:-0.007367883343249559\n",
      "check (7092,) ()\n",
      "epoch 5154\n",
      "====================================\n",
      "Epoch:  5154 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.694218083042298\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5154 5155\n",
      "Training loss:-0.009495408274233341\n",
      "check (8055,) ()\n",
      "epoch 5155\n",
      "====================================\n",
      "Epoch:  5155 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.694083414161009\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5155 5156\n",
      "Training loss:-0.004077370278537273\n",
      "check (8968,) ()\n",
      "epoch 5156\n",
      "====================================\n",
      "Epoch:  5156 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.693366951124903\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5156 5157\n",
      "Training loss:-0.0068498519249260426\n",
      "check (9290,) ()\n",
      "epoch 5157\n",
      "====================================\n",
      "Epoch:  5157 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.692069032383168\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5157 5158\n",
      "Training loss:0.0007433691062033176\n",
      "check (9156,) ()\n",
      "epoch 5158\n",
      "====================================\n",
      "Epoch:  5158 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.69115936409461\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5158 5159\n",
      "Training loss:-0.003942830488085747\n",
      "check (7145,) ()\n",
      "epoch 5159\n",
      "====================================\n",
      "Epoch:  5159 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.691413064547392\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5159 5160\n",
      "Training loss:-0.0032043701503425837\n",
      "check (7982,) ()\n",
      "epoch 5160\n",
      "====================================\n",
      "Epoch:  5160 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.689922480620154\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5160 5161\n",
      "Training loss:0.001292231841944158\n",
      "check (9316,) ()\n",
      "epoch 5161\n",
      "====================================\n",
      "Epoch:  5161 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.690176322418136\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5161 5162\n",
      "Training loss:-0.0046373638324439526\n",
      "check (8824,) ()\n",
      "epoch 5162\n",
      "====================================\n",
      "Epoch:  5162 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.688686555598606\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5162 5163\n",
      "Training loss:-0.012277867645025253\n",
      "check (10000,) ()\n",
      "epoch 5163\n",
      "====================================\n",
      "Epoch:  5163 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.687584737555685\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5163 5164\n",
      "Training loss:-0.004772575572133064\n",
      "check (8489,) ()\n",
      "epoch 5164\n",
      "====================================\n",
      "Epoch:  5164 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.687451587916344\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5164 5165\n",
      "Training loss:0.0009254637989215553\n",
      "check (7954,) ()\n",
      "epoch 5165\n",
      "====================================\n",
      "Epoch:  5165 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.686931268151016\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5165 5166\n",
      "Training loss:0.0014367711264640093\n",
      "check (9826,) ()\n",
      "epoch 5166\n",
      "====================================\n",
      "Epoch:  5166 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.68544328300426\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5166 5167\n",
      "Training loss:-0.006687183864414692\n",
      "check (9121,) ()\n",
      "epoch 5167\n",
      "====================================\n",
      "Epoch:  5167 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.68473001741823\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5167 5168\n",
      "Training loss:-0.0010371283860877156\n",
      "check (9714,) ()\n",
      "epoch 5168\n",
      "====================================\n",
      "Epoch:  5168 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.684791021671826\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5168 5169\n",
      "Training loss:-0.006016499362885952\n",
      "check (6398,) ()\n",
      "epoch 5169\n",
      "====================================\n",
      "Epoch:  5169 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.685819307409558\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5169 5170\n",
      "Training loss:-0.007439357228577137\n",
      "check (6635,) ()\n",
      "epoch 5170\n",
      "====================================\n",
      "Epoch:  5170 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.68568665377176\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5170 5171\n",
      "Training loss:-0.010939097963273525\n",
      "check (9645,) ()\n",
      "epoch 5171\n",
      "====================================\n",
      "Epoch:  5171 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.685167279056275\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5171 5172\n",
      "Training loss:0.0012649488635361195\n",
      "check (10000,) ()\n",
      "epoch 5172\n",
      "====================================\n",
      "Epoch:  5172 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.682327919566898\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5172 5173\n",
      "Training loss:-0.0020180302672088146\n",
      "check (8923,) ()\n",
      "epoch 5173\n",
      "====================================\n",
      "Epoch:  5173 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.682196017784651\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5173 5174\n",
      "Training loss:-0.0026827286928892136\n",
      "check (8917,) ()\n",
      "epoch 5174\n",
      "====================================\n",
      "Epoch:  5174 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.68206416698879\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5174 5175\n",
      "Training loss:-0.003312784945592284\n",
      "check (9524,) ()\n",
      "epoch 5175\n",
      "====================================\n",
      "Epoch:  5175 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.682125603864733\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5175 5176\n",
      "Training loss:-0.007745423354208469\n",
      "check (10000,) ()\n",
      "epoch 5176\n",
      "====================================\n",
      "Epoch:  5176 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:4.0\n",
      "Mean Reward of that batch 4.0\n",
      "Average Reward of all training: -13.67870942812983\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5176 5177\n",
      "Training loss:-0.0019767112098634243\n",
      "check (9346,) ()\n",
      "epoch 5177\n",
      "====================================\n",
      "Epoch:  5177 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.678385165153564\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5177 5178\n",
      "Training loss:-0.009596935473382473\n",
      "check (6821,) ()\n",
      "epoch 5178\n",
      "====================================\n",
      "Epoch:  5178 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.677867902665122\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5178 5179\n",
      "Training loss:-0.00825966615229845\n",
      "check (9135,) ()\n",
      "epoch 5179\n",
      "====================================\n",
      "Epoch:  5179 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.677350839930488\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5179 5180\n",
      "Training loss:-0.0009185791132040322\n",
      "check (7186,) ()\n",
      "epoch 5180\n",
      "====================================\n",
      "Epoch:  5180 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.676833976833978\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5180 5181\n",
      "Training loss:-0.004951626528054476\n",
      "check (9324,) ()\n",
      "epoch 5181\n",
      "====================================\n",
      "Epoch:  5181 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.675545261532523\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5181 5182\n",
      "Training loss:0.000721209158655256\n",
      "check (8814,) ()\n",
      "epoch 5182\n",
      "====================================\n",
      "Epoch:  5182 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.674835970667695\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5182 5183\n",
      "Training loss:-0.0012288402067497373\n",
      "check (9786,) ()\n",
      "epoch 5183\n",
      "====================================\n",
      "Epoch:  5183 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.6739340150492\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5183 5184\n",
      "Training loss:-0.0015026371693238616\n",
      "check (7773,) ()\n",
      "epoch 5184\n",
      "====================================\n",
      "Epoch:  5184 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.674189814814815\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5184 5185\n",
      "Training loss:-0.005165876355022192\n",
      "check (9020,) ()\n",
      "epoch 5185\n",
      "====================================\n",
      "Epoch:  5185 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.673095467695275\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5185 5186\n",
      "Training loss:-0.00536960968747735\n",
      "check (7632,) ()\n",
      "epoch 5186\n",
      "====================================\n",
      "Epoch:  5186 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.67315850366371\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5186 5187\n",
      "Training loss:-0.003123524133116007\n",
      "check (10000,) ()\n",
      "epoch 5187\n",
      "====================================\n",
      "Epoch:  5187 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.672064777327936\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5187 5188\n",
      "Training loss:-0.005612585227936506\n",
      "check (9476,) ()\n",
      "epoch 5188\n",
      "====================================\n",
      "Epoch:  5188 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.671164225134927\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5188 5189\n",
      "Training loss:-0.0013720219722017646\n",
      "check (6736,) ()\n",
      "epoch 5189\n",
      "====================================\n",
      "Epoch:  5189 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.671034881480054\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5189 5190\n",
      "Training loss:-0.007719447836279869\n",
      "check (10000,) ()\n",
      "epoch 5190\n",
      "====================================\n",
      "Epoch:  5190 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.66859344894027\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5190 5191\n",
      "Training loss:-0.003217614023014903\n",
      "check (8238,) ()\n",
      "epoch 5191\n",
      "====================================\n",
      "Epoch:  5191 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.667886727027547\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5191 5192\n",
      "Training loss:0.005749979522079229\n",
      "check (10000,) ()\n",
      "epoch 5192\n",
      "====================================\n",
      "Epoch:  5192 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.6654468412943\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5192 5193\n",
      "Training loss:-0.0037645110860466957\n",
      "check (10000,) ()\n",
      "epoch 5193\n",
      "====================================\n",
      "Epoch:  5193 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.66262276140959\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5193 5194\n",
      "Training loss:0.0006814651424065232\n",
      "check (8880,) ()\n",
      "epoch 5194\n",
      "====================================\n",
      "Epoch:  5194 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.661725067385445\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5194 5195\n",
      "Training loss:-0.009951882995665073\n",
      "check (10000,) ()\n",
      "epoch 5195\n",
      "====================================\n",
      "Epoch:  5195 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.660827718960538\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5195 5196\n",
      "Training loss:-0.0017545680748298764\n",
      "check (9270,) ()\n",
      "epoch 5196\n",
      "====================================\n",
      "Epoch:  5196 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.660315627405696\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5196 5197\n",
      "Training loss:-0.005164280068129301\n",
      "check (8520,) ()\n",
      "epoch 5197\n",
      "====================================\n",
      "Epoch:  5197 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.660188570329035\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5197 5198\n",
      "Training loss:-0.00012063510075677186\n",
      "check (10000,) ()\n",
      "epoch 5198\n",
      "====================================\n",
      "Epoch:  5198 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.658330126971912\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5198 5199\n",
      "Training loss:0.0039315782487392426\n",
      "check (8826,) ()\n",
      "epoch 5199\n",
      "====================================\n",
      "Epoch:  5199 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.658011155991536\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5199 5200\n",
      "Training loss:-0.007917433977127075\n",
      "check (9466,) ()\n",
      "epoch 5200\n",
      "====================================\n",
      "Epoch:  5200 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.656923076923077\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5200 5201\n",
      "Training loss:-0.009450779296457767\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 5201\n",
      "====================================\n",
      "Epoch:  5201 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.655066333397423\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5201 5202\n",
      "Training loss:0.0002280799817526713\n",
      "check (6675,) ()\n",
      "epoch 5202\n",
      "====================================\n",
      "Epoch:  5202 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.654940407535562\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5202 5203\n",
      "Training loss:-0.008922976441681385\n",
      "check (9347,) ()\n",
      "epoch 5203\n",
      "====================================\n",
      "Epoch:  5203 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.653853546031137\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5203 5204\n",
      "Training loss:0.00043284223647788167\n",
      "check (9921,) ()\n",
      "epoch 5204\n",
      "====================================\n",
      "Epoch:  5204 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.652574942352038\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5204 5205\n",
      "Training loss:-0.007880333811044693\n",
      "check (9427,) ()\n",
      "epoch 5205\n",
      "====================================\n",
      "Epoch:  5205 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.652065321805956\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5205 5206\n",
      "Training loss:-0.004480042494833469\n",
      "check (9513,) ()\n",
      "epoch 5206\n",
      "====================================\n",
      "Epoch:  5206 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.65117172493277\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5206 5207\n",
      "Training loss:-0.001929710851982236\n",
      "check (10000,) ()\n",
      "epoch 5207\n",
      "====================================\n",
      "Epoch:  5207 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.64931822546572\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5207 5208\n",
      "Training loss:-0.006390804424881935\n",
      "check (10000,) ()\n",
      "epoch 5208\n",
      "====================================\n",
      "Epoch:  5208 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.647657450076805\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5208 5209\n",
      "Training loss:-0.0011580249993130565\n",
      "check (8934,) ()\n",
      "epoch 5209\n",
      "====================================\n",
      "Epoch:  5209 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.646957189479746\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5209 5210\n",
      "Training loss:8.91240342753008e-05\n",
      "check (10000,) ()\n",
      "epoch 5210\n",
      "====================================\n",
      "Epoch:  5210 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.646257197696738\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5210 5211\n",
      "Training loss:-0.002458104630932212\n",
      "check (10000,) ()\n",
      "epoch 5211\n",
      "====================================\n",
      "Epoch:  5211 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.643830358856265\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5211 5212\n",
      "Training loss:-0.004477613139897585\n",
      "check (10000,) ()\n",
      "epoch 5212\n",
      "====================================\n",
      "Epoch:  5212 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.642171910974675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5212 5213\n",
      "Training loss:-0.003294229507446289\n",
      "check (7865,) ()\n",
      "epoch 5213\n",
      "====================================\n",
      "Epoch:  5213 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.642048724342988\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5213 5214\n",
      "Training loss:0.007293394301086664\n",
      "check (8808,) ()\n",
      "epoch 5214\n",
      "====================================\n",
      "Epoch:  5214 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.641350210970463\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5214 5215\n",
      "Training loss:0.0002775313623715192\n",
      "check (8384,) ()\n",
      "epoch 5215\n",
      "====================================\n",
      "Epoch:  5215 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.641610738255034\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5215 5216\n",
      "Training loss:-0.0029453840106725693\n",
      "check (7780,) ()\n",
      "epoch 5216\n",
      "====================================\n",
      "Epoch:  5216 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.641871165644172\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5216 5217\n",
      "Training loss:-0.0011186914052814245\n",
      "check (9262,) ()\n",
      "epoch 5217\n",
      "====================================\n",
      "Epoch:  5217 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.639831320682385\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5217 5218\n",
      "Training loss:-0.008096425794064999\n",
      "check (8978,) ()\n",
      "epoch 5218\n",
      "====================================\n",
      "Epoch:  5218 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.63970870065159\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5218 5219\n",
      "Training loss:-0.009874359704554081\n",
      "check (9844,) ()\n",
      "epoch 5219\n",
      "====================================\n",
      "Epoch:  5219 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.639202912435332\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5219 5220\n",
      "Training loss:-0.008678699843585491\n",
      "check (10000,) ()\n",
      "epoch 5220\n",
      "====================================\n",
      "Epoch:  5220 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.637739463601532\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5220 5221\n",
      "Training loss:0.0004909660201519728\n",
      "check (7356,) ()\n",
      "epoch 5221\n",
      "====================================\n",
      "Epoch:  5221 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.637234246312968\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5221 5222\n",
      "Training loss:-0.003948909230530262\n",
      "check (8827,) ()\n",
      "epoch 5222\n",
      "====================================\n",
      "Epoch:  5222 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.636346227499043\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5222 5223\n",
      "Training loss:0.0013278137193992734\n",
      "check (8259,) ()\n",
      "epoch 5223\n",
      "====================================\n",
      "Epoch:  5223 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.636224392111814\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5223 5224\n",
      "Training loss:-0.00343983992934227\n",
      "check (10000,) ()\n",
      "epoch 5224\n",
      "====================================\n",
      "Epoch:  5224 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.634188361408881\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5224 5225\n",
      "Training loss:0.004580470267683268\n",
      "check (9555,) ()\n",
      "epoch 5225\n",
      "====================================\n",
      "Epoch:  5225 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.634258373205741\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5225 5226\n",
      "Training loss:-0.004399157594889402\n",
      "check (10000,) ()\n",
      "epoch 5226\n",
      "====================================\n",
      "Epoch:  5226 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.631840796019901\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5226 5227\n",
      "Training loss:-0.003913682419806719\n",
      "check (9007,) ()\n",
      "epoch 5227\n",
      "====================================\n",
      "Epoch:  5227 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.631528601492251\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5227 5228\n",
      "Training loss:-0.006549468729645014\n",
      "check (8151,) ()\n",
      "epoch 5228\n",
      "====================================\n",
      "Epoch:  5228 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.629877582249426\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5228 5229\n",
      "Training loss:-0.000798216846305877\n",
      "check (8435,) ()\n",
      "epoch 5229\n",
      "====================================\n",
      "Epoch:  5229 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.629757123733027\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5229 5230\n",
      "Training loss:-0.001239531091414392\n",
      "check (7916,) ()\n",
      "epoch 5230\n",
      "====================================\n",
      "Epoch:  5230 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.629636711281071\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5230 5231\n",
      "Training loss:0.00261132069863379\n",
      "check (8322,) ()\n",
      "epoch 5231\n",
      "====================================\n",
      "Epoch:  5231 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.628751672720322\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5231 5232\n",
      "Training loss:-0.003426054259762168\n",
      "check (8854,) ()\n",
      "epoch 5232\n",
      "====================================\n",
      "Epoch:  5232 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.628440366972477\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5232 5233\n",
      "Training loss:-0.0025645531713962555\n",
      "check (10000,) ()\n",
      "epoch 5233\n",
      "====================================\n",
      "Epoch:  5233 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.626600420408943\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5233 5234\n",
      "Training loss:-0.008742385543882847\n",
      "check (8786,) ()\n",
      "epoch 5234\n",
      "====================================\n",
      "Epoch:  5234 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.627244936950706\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5234 5235\n",
      "Training loss:0.001610668026842177\n",
      "check (8550,) ()\n",
      "epoch 5235\n",
      "====================================\n",
      "Epoch:  5235 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.627889207258836\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5235 5236\n",
      "Training loss:0.0015272015007212758\n",
      "check (9359,) ()\n",
      "epoch 5236\n",
      "====================================\n",
      "Epoch:  5236 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.626623376623376\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5236 5237\n",
      "Training loss:-0.0006373318028636277\n",
      "check (8563,) ()\n",
      "epoch 5237\n",
      "====================================\n",
      "Epoch:  5237 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.625167080389536\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5237 5238\n",
      "Training loss:-0.0029151306953281164\n",
      "check (8115,) ()\n",
      "epoch 5238\n",
      "====================================\n",
      "Epoch:  5238 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.62466590301642\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5238 5239\n",
      "Training loss:0.0001037414331221953\n",
      "check (7841,) ()\n",
      "epoch 5239\n",
      "====================================\n",
      "Epoch:  5239 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.623592288604696\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5239 5240\n",
      "Training loss:-0.006989144254475832\n",
      "check (10000,) ()\n",
      "epoch 5240\n",
      "====================================\n",
      "Epoch:  5240 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.621946564885496\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5240 5241\n",
      "Training loss:-0.003955211024731398\n",
      "check (8544,) ()\n",
      "epoch 5241\n",
      "====================================\n",
      "Epoch:  5241 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.622591108567068\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5241 5242\n",
      "Training loss:-0.010144945234060287\n",
      "check (8197,) ()\n",
      "epoch 5242\n",
      "====================================\n",
      "Epoch:  5242 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.622090805036246\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5242 5243\n",
      "Training loss:-0.012991266325116158\n",
      "check (6928,) ()\n",
      "epoch 5243\n",
      "====================================\n",
      "Epoch:  5243 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.622735075338547\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5243 5244\n",
      "Training loss:-0.0019703186117112637\n",
      "check (9212,) ()\n",
      "epoch 5244\n",
      "====================================\n",
      "Epoch:  5244 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.62280701754386\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5244 5245\n",
      "Training loss:-0.006051338743418455\n",
      "check (7465,) ()\n",
      "epoch 5245\n",
      "====================================\n",
      "Epoch:  5245 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.623069590085796\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5245 5246\n",
      "Training loss:-0.004314550198614597\n",
      "check (10000,) ()\n",
      "epoch 5246\n",
      "====================================\n",
      "Epoch:  5246 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.621235226839497\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5246 5247\n",
      "Training loss:-0.006256511900573969\n",
      "check (10000,) ()\n",
      "epoch 5247\n",
      "====================================\n",
      "Epoch:  5247 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.619592147894034\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5247 5248\n",
      "Training loss:-0.0035959312226623297\n",
      "check (8683,) ()\n",
      "epoch 5248\n",
      "====================================\n",
      "Epoch:  5248 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.618330792682928\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5248 5249\n",
      "Training loss:-0.003932033199816942\n",
      "check (9606,) ()\n",
      "epoch 5249\n",
      "====================================\n",
      "Epoch:  5249 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.617069918079634\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5249 5250\n",
      "Training loss:-0.006222354248166084\n",
      "check (5826,) ()\n",
      "epoch 5250\n",
      "====================================\n",
      "Epoch:  5250 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.618095238095238\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5250 5251\n",
      "Training loss:0.0011563928565010428\n",
      "Model saved\n",
      "check (7898,) ()\n",
      "epoch 5251\n",
      "====================================\n",
      "Epoch:  5251 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.617977528089888\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5251 5252\n",
      "Training loss:-0.007867756299674511\n",
      "check (8856,) ()\n",
      "epoch 5252\n",
      "====================================\n",
      "Epoch:  5252 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.617098248286368\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5252 5253\n",
      "Training loss:-0.007745516952127218\n",
      "check (7404,) ()\n",
      "epoch 5253\n",
      "====================================\n",
      "Epoch:  5253 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.61774224252808\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5253 5254\n",
      "Training loss:-0.0017085319850593805\n",
      "check (10000,) ()\n",
      "epoch 5254\n",
      "====================================\n",
      "Epoch:  5254 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.616102017510467\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5254 5255\n",
      "Training loss:-0.00916757620871067\n",
      "check (7522,) ()\n",
      "epoch 5255\n",
      "====================================\n",
      "Epoch:  5255 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.615794481446242\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5255 5256\n",
      "Training loss:-0.010772636160254478\n",
      "check (7138,) ()\n",
      "epoch 5256\n",
      "====================================\n",
      "Epoch:  5256 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.61624809741248\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5256 5257\n",
      "Training loss:-0.00889110378921032\n",
      "check (8391,) ()\n",
      "epoch 5257\n",
      "====================================\n",
      "Epoch:  5257 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.615560205440365\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5257 5258\n",
      "Training loss:-0.002025280147790909\n",
      "check (7869,) ()\n",
      "epoch 5258\n",
      "====================================\n",
      "Epoch:  5258 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.614682388740967\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5258 5259\n",
      "Training loss:-0.01095519308000803\n",
      "check (10000,) ()\n",
      "epoch 5259\n",
      "====================================\n",
      "Epoch:  5259 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:4.0\n",
      "Mean Reward of that batch 4.0\n",
      "Average Reward of all training: -13.611332953032896\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5259 5260\n",
      "Training loss:-0.0006394708761945367\n",
      "check (8865,) ()\n",
      "epoch 5260\n",
      "====================================\n",
      "Epoch:  5260 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.61083650190114\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5260 5261\n",
      "Training loss:-0.008238822221755981\n",
      "check (8182,) ()\n",
      "epoch 5261\n",
      "====================================\n",
      "Epoch:  5261 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.611100551226002\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5261 5262\n",
      "Training loss:-0.004181950818747282\n",
      "check (9055,) ()\n",
      "epoch 5262\n",
      "====================================\n",
      "Epoch:  5262 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.610984416571645\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5262 5263\n",
      "Training loss:-0.0057557616382837296\n",
      "check (8822,) ()\n",
      "epoch 5263\n",
      "====================================\n",
      "Epoch:  5263 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.609728291848755\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5263 5264\n",
      "Training loss:-0.0025297643151134253\n",
      "check (8670,) ()\n",
      "epoch 5264\n",
      "====================================\n",
      "Epoch:  5264 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.608282674772036\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5264 5265\n",
      "Training loss:-0.0029729700181633234\n",
      "check (10000,) ()\n",
      "epoch 5265\n",
      "====================================\n",
      "Epoch:  5265 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.606077872744539\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5265 5266\n",
      "Training loss:-0.008788942359387875\n",
      "check (8667,) ()\n",
      "epoch 5266\n",
      "====================================\n",
      "Epoch:  5266 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.605962780098746\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5266 5267\n",
      "Training loss:0.004493785556405783\n",
      "check (8489,) ()\n",
      "epoch 5267\n",
      "====================================\n",
      "Epoch:  5267 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.605278146952724\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5267 5268\n",
      "Training loss:-0.011019906960427761\n",
      "check (7199,) ()\n",
      "epoch 5268\n",
      "====================================\n",
      "Epoch:  5268 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.604214123006834\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5268 5269\n",
      "Training loss:-0.00881646666675806\n",
      "check (8947,) ()\n",
      "epoch 5269\n",
      "====================================\n",
      "Epoch:  5269 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.604099449610931\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5269 5270\n",
      "Training loss:-0.002119515324011445\n",
      "check (8324,) ()\n",
      "epoch 5270\n",
      "====================================\n",
      "Epoch:  5270 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.603415559772296\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5270 5271\n",
      "Training loss:-0.005113458726555109\n",
      "check (8308,) ()\n",
      "epoch 5271\n",
      "====================================\n",
      "Epoch:  5271 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.603111364067539\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5271 5272\n",
      "Training loss:-0.01122216321527958\n",
      "check (10000,) ()\n",
      "epoch 5272\n",
      "====================================\n",
      "Epoch:  5272 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.601100151745069\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5272 5273\n",
      "Training loss:-0.0036237849853932858\n",
      "check (9915,) ()\n",
      "epoch 5273\n",
      "====================================\n",
      "Epoch:  5273 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.599658638346293\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5273 5274\n",
      "Training loss:-0.0016377974534407258\n",
      "check (9351,) ()\n",
      "epoch 5274\n",
      "====================================\n",
      "Epoch:  5274 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.59935532802427\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5274 5275\n",
      "Training loss:-4.914926103083417e-05\n",
      "check (8766,) ()\n",
      "epoch 5275\n",
      "====================================\n",
      "Epoch:  5275 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.598483412322276\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5275 5276\n",
      "Training loss:-0.0007249822374433279\n",
      "check (8254,) ()\n",
      "epoch 5276\n",
      "====================================\n",
      "Epoch:  5276 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.598369977255496\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5276 5277\n",
      "Training loss:-0.010094265453517437\n",
      "check (10000,) ()\n",
      "epoch 5277\n",
      "====================================\n",
      "Epoch:  5277 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.595793064241047\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5277 5278\n",
      "Training loss:-0.0030610307585448027\n",
      "check (10000,) ()\n",
      "epoch 5278\n",
      "====================================\n",
      "Epoch:  5278 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.594543387646835\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5278 5279\n",
      "Training loss:-0.0051984223537147045\n",
      "check (9276,) ()\n",
      "epoch 5279\n",
      "====================================\n",
      "Epoch:  5279 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.594809623034665\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5279 5280\n",
      "Training loss:-0.006134792696684599\n",
      "check (10000,) ()\n",
      "epoch 5280\n",
      "====================================\n",
      "Epoch:  5280 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.592424242424242\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5280 5281\n",
      "Training loss:-0.0044267005287110806\n",
      "check (9423,) ()\n",
      "epoch 5281\n",
      "====================================\n",
      "Epoch:  5281 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.590797197500473\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5281 5282\n",
      "Training loss:-0.004825574811547995\n",
      "check (8934,) ()\n",
      "epoch 5282\n",
      "====================================\n",
      "Epoch:  5282 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.590496024233245\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5282 5283\n",
      "Training loss:0.0010698846308514476\n",
      "check (8372,) ()\n",
      "epoch 5283\n",
      "====================================\n",
      "Epoch:  5283 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.589248533030474\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5283 5284\n",
      "Training loss:0.0007797018624842167\n",
      "check (6966,) ()\n",
      "epoch 5284\n",
      "====================================\n",
      "Epoch:  5284 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.589326267978803\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5284 5285\n",
      "Training loss:-0.014225293882191181\n",
      "check (7754,) ()\n",
      "epoch 5285\n",
      "====================================\n",
      "Epoch:  5285 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.588647114474929\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5285 5286\n",
      "Training loss:-0.003146848175674677\n",
      "check (9224,) ()\n",
      "epoch 5286\n",
      "====================================\n",
      "Epoch:  5286 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.588157396897465\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5286 5287\n",
      "Training loss:-0.006531632039695978\n",
      "check (8188,) ()\n",
      "epoch 5287\n",
      "====================================\n",
      "Epoch:  5287 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.58804615093626\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5287 5288\n",
      "Training loss:-0.009953501634299755\n",
      "check (8257,) ()\n",
      "epoch 5288\n",
      "====================================\n",
      "Epoch:  5288 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.588313161875945\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5288 5289\n",
      "Training loss:0.0031601483933627605\n",
      "check (8832,) ()\n",
      "epoch 5289\n",
      "====================================\n",
      "Epoch:  5289 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.587634713556438\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5289 5290\n",
      "Training loss:-0.009203439578413963\n",
      "check (5905,) ()\n",
      "epoch 5290\n",
      "====================================\n",
      "Epoch:  5290 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.58790170132325\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5290 5291\n",
      "Training loss:-0.00019513678853400052\n",
      "check (8663,) ()\n",
      "epoch 5291\n",
      "====================================\n",
      "Epoch:  5291 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.588546588546588\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5291 5292\n",
      "Training loss:-0.010924454778432846\n",
      "check (7711,) ()\n",
      "epoch 5292\n",
      "====================================\n",
      "Epoch:  5292 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.588624338624339\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5292 5293\n",
      "Training loss:-0.006691754795610905\n",
      "check (6647,) ()\n",
      "epoch 5293\n",
      "====================================\n",
      "Epoch:  5293 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.589268845645192\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5293 5294\n",
      "Training loss:-0.0015041523147374392\n",
      "check (9967,) ()\n",
      "epoch 5294\n",
      "====================================\n",
      "Epoch:  5294 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.588590857574612\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5294 5295\n",
      "Training loss:-0.0046423557214438915\n",
      "check (10000,) ()\n",
      "epoch 5295\n",
      "====================================\n",
      "Epoch:  5295 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.587913125590179\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5295 5296\n",
      "Training loss:-0.0022947571706026793\n",
      "check (9516,) ()\n",
      "epoch 5296\n",
      "====================================\n",
      "Epoch:  5296 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.586669184290031\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5296 5297\n",
      "Training loss:0.0028310108464211226\n",
      "check (8792,) ()\n",
      "epoch 5297\n",
      "====================================\n",
      "Epoch:  5297 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.585614498772891\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5297 5298\n",
      "Training loss:-0.011031807400286198\n",
      "check (9758,) ()\n",
      "epoch 5298\n",
      "====================================\n",
      "Epoch:  5298 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.584182710456776\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5298 5299\n",
      "Training loss:-0.003886093618348241\n",
      "check (9016,) ()\n",
      "epoch 5299\n",
      "====================================\n",
      "Epoch:  5299 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.582940177391961\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5299 5300\n",
      "Training loss:0.0002628268557600677\n",
      "check (8372,) ()\n",
      "epoch 5300\n",
      "====================================\n",
      "Epoch:  5300 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.583018867924528\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5300 5301\n",
      "Training loss:0.003942726645618677\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 5301\n",
      "====================================\n",
      "Epoch:  5301 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.580456517638181\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5301 5302\n",
      "Training loss:-0.0009908172069117427\n",
      "check (8200,) ()\n",
      "epoch 5302\n",
      "====================================\n",
      "Epoch:  5302 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.580724254998113\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5302 5303\n",
      "Training loss:-0.003576991381123662\n",
      "check (8467,) ()\n",
      "epoch 5303\n",
      "====================================\n",
      "Epoch:  5303 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.58061474636998\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5303 5304\n",
      "Training loss:0.0007917620823718607\n",
      "check (8264,) ()\n",
      "epoch 5304\n",
      "====================================\n",
      "Epoch:  5304 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.57975113122172\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5304 5305\n",
      "Training loss:-0.007082724012434483\n",
      "check (5847,) ()\n",
      "epoch 5305\n",
      "====================================\n",
      "Epoch:  5305 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -13.580584354382658\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5305 5306\n",
      "Training loss:-4.191991683910601e-05\n",
      "check (10000,) ()\n",
      "epoch 5306\n",
      "====================================\n",
      "Epoch:  5306 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.577836411609498\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5306 5307\n",
      "Training loss:-0.00888101663440466\n",
      "check (9620,) ()\n",
      "epoch 5307\n",
      "====================================\n",
      "Epoch:  5307 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.576220086677973\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5307 5308\n",
      "Training loss:-0.004460261669009924\n",
      "check (7335,) ()\n",
      "epoch 5308\n",
      "====================================\n",
      "Epoch:  5308 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.57629992464205\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5308 5309\n",
      "Training loss:-0.009307622909545898\n",
      "check (10000,) ()\n",
      "epoch 5309\n",
      "====================================\n",
      "Epoch:  5309 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.575061216801657\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5309 5310\n",
      "Training loss:-0.004739806056022644\n",
      "check (8322,) ()\n",
      "epoch 5310\n",
      "====================================\n",
      "Epoch:  5310 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.57457627118644\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5310 5311\n",
      "Training loss:-0.000821719819214195\n",
      "check (9209,) ()\n",
      "epoch 5311\n",
      "====================================\n",
      "Epoch:  5311 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.57390321973263\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5311 5312\n",
      "Training loss:0.003835868090391159\n",
      "check (8978,) ()\n",
      "epoch 5312\n",
      "====================================\n",
      "Epoch:  5312 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.573606927710843\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5312 5313\n",
      "Training loss:-0.005363767966628075\n",
      "check (7907,) ()\n",
      "epoch 5313\n",
      "====================================\n",
      "Epoch:  5313 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.5742518351214\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5313 5314\n",
      "Training loss:-0.0029981599655002356\n",
      "check (10000,) ()\n",
      "epoch 5314\n",
      "====================================\n",
      "Epoch:  5314 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.57207376740685\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5314 5315\n",
      "Training loss:-0.010097810067236423\n",
      "check (9116,) ()\n",
      "epoch 5315\n",
      "====================================\n",
      "Epoch:  5315 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.570460959548448\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5315 5316\n",
      "Training loss:-0.010771096684038639\n",
      "check (10000,) ()\n",
      "epoch 5316\n",
      "====================================\n",
      "Epoch:  5316 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.569789315274642\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5316 5317\n",
      "Training loss:-0.00481921574100852\n",
      "check (10000,) ()\n",
      "epoch 5317\n",
      "====================================\n",
      "Epoch:  5317 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.568741771675757\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5317 5318\n",
      "Training loss:-0.011448083445429802\n",
      "check (8895,) ()\n",
      "epoch 5318\n",
      "====================================\n",
      "Epoch:  5318 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.569010906355773\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5318 5319\n",
      "Training loss:0.0029246886260807514\n",
      "check (10000,) ()\n",
      "epoch 5319\n",
      "====================================\n",
      "Epoch:  5319 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.567775897725136\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5319 5320\n",
      "Training loss:-0.004049870651215315\n",
      "check (10000,) ()\n",
      "epoch 5320\n",
      "====================================\n",
      "Epoch:  5320 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.566353383458647\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5320 5321\n",
      "Training loss:-0.003714445047080517\n",
      "check (10000,) ()\n",
      "epoch 5321\n",
      "====================================\n",
      "Epoch:  5321 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.564179665476415\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5321 5322\n",
      "Training loss:-0.004858316853642464\n",
      "check (9209,) ()\n",
      "epoch 5322\n",
      "====================================\n",
      "Epoch:  5322 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.563509958662157\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5322 5323\n",
      "Training loss:-0.006155191455036402\n",
      "check (9421,) ()\n",
      "epoch 5323\n",
      "====================================\n",
      "Epoch:  5323 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.562840503475483\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5323 5324\n",
      "Training loss:-0.0008230619132518768\n",
      "check (6324,) ()\n",
      "epoch 5324\n",
      "====================================\n",
      "Epoch:  5324 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.563110443275733\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5324 5325\n",
      "Training loss:0.004105811472982168\n",
      "check (8864,) ()\n",
      "epoch 5325\n",
      "====================================\n",
      "Epoch:  5325 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.562253521126761\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5325 5326\n",
      "Training loss:-0.004008775111287832\n",
      "check (9866,) ()\n",
      "epoch 5326\n",
      "====================================\n",
      "Epoch:  5326 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.561960195268494\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5326 5327\n",
      "Training loss:-0.005506651941686869\n",
      "check (9209,) ()\n",
      "epoch 5327\n",
      "====================================\n",
      "Epoch:  5327 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.560352919091422\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5327 5328\n",
      "Training loss:0.0002463236451148987\n",
      "check (9760,) ()\n",
      "epoch 5328\n",
      "====================================\n",
      "Epoch:  5328 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.559121621621621\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5328 5329\n",
      "Training loss:-0.0028049100656062365\n",
      "check (8231,) ()\n",
      "epoch 5329\n",
      "====================================\n",
      "Epoch:  5329 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.558641396134359\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5329 5330\n",
      "Training loss:-0.006526940036565065\n",
      "check (8872,) ()\n",
      "epoch 5330\n",
      "====================================\n",
      "Epoch:  5330 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.557598499061914\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5330 5331\n",
      "Training loss:-0.004791508428752422\n",
      "check (10000,) ()\n",
      "epoch 5331\n",
      "====================================\n",
      "Epoch:  5331 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.555805664978427\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5331 5332\n",
      "Training loss:-0.00025821226881816983\n",
      "check (7231,) ()\n",
      "epoch 5332\n",
      "====================================\n",
      "Epoch:  5332 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.556076519129782\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5332 5333\n",
      "Training loss:-0.0019052299903705716\n",
      "check (8462,) ()\n",
      "epoch 5333\n",
      "====================================\n",
      "Epoch:  5333 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.55709731858241\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5333 5334\n",
      "Training loss:-0.004533753730356693\n",
      "check (7684,) ()\n",
      "epoch 5334\n",
      "====================================\n",
      "Epoch:  5334 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.555680539932508\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5334 5335\n",
      "Training loss:-0.0011732015991583467\n",
      "check (7782,) ()\n",
      "epoch 5335\n",
      "====================================\n",
      "Epoch:  5335 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.555201499531396\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5335 5336\n",
      "Training loss:0.0023348000831902027\n",
      "check (9603,) ()\n",
      "epoch 5336\n",
      "====================================\n",
      "Epoch:  5336 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.554347826086957\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5336 5337\n",
      "Training loss:-0.005137196741998196\n",
      "check (8575,) ()\n",
      "epoch 5337\n",
      "====================================\n",
      "Epoch:  5337 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.554431328461682\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5337 5338\n",
      "Training loss:-0.007029742933809757\n",
      "check (8798,) ()\n",
      "epoch 5338\n",
      "====================================\n",
      "Epoch:  5338 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.554514799550393\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5338 5339\n",
      "Training loss:-0.0033280400093644857\n",
      "check (10000,) ()\n",
      "epoch 5339\n",
      "====================================\n",
      "Epoch:  5339 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.554223637385277\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5339 5340\n",
      "Training loss:-0.0018470176728442311\n",
      "check (10000,) ()\n",
      "epoch 5340\n",
      "====================================\n",
      "Epoch:  5340 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.552621722846443\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5340 5341\n",
      "Training loss:-0.011125593446195126\n",
      "check (8416,) ()\n",
      "epoch 5341\n",
      "====================================\n",
      "Epoch:  5341 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.552892716719715\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5341 5342\n",
      "Training loss:0.008703077211976051\n",
      "check (8877,) ()\n",
      "epoch 5342\n",
      "====================================\n",
      "Epoch:  5342 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.55147884687383\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5342 5343\n",
      "Training loss:-0.009072105400264263\n",
      "check (10000,) ()\n",
      "epoch 5343\n",
      "====================================\n",
      "Epoch:  5343 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.550626988583193\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5343 5344\n",
      "Training loss:0.0032940933015197515\n",
      "check (8294,) ()\n",
      "epoch 5344\n",
      "====================================\n",
      "Epoch:  5344 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.550711077844312\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5344 5345\n",
      "Training loss:-0.00533034885302186\n",
      "check (7603,) ()\n",
      "epoch 5345\n",
      "====================================\n",
      "Epoch:  5345 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.551356407857812\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5345 5346\n",
      "Training loss:0.0018076617270708084\n",
      "check (8958,) ()\n",
      "epoch 5346\n",
      "====================================\n",
      "Epoch:  5346 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.551066217732885\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5346 5347\n",
      "Training loss:-0.00611268961802125\n",
      "check (9840,) ()\n",
      "epoch 5347\n",
      "====================================\n",
      "Epoch:  5347 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.550028053113895\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5347 5348\n",
      "Training loss:-0.0055175540037453175\n",
      "check (7130,) ()\n",
      "epoch 5348\n",
      "====================================\n",
      "Epoch:  5348 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.550299177262527\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5348 5349\n",
      "Training loss:-0.0005652348627336323\n",
      "check (10000,) ()\n",
      "epoch 5349\n",
      "====================================\n",
      "Epoch:  5349 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.548326790054215\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5349 5350\n",
      "Training loss:0.00029602280119434\n",
      "check (10000,) ()\n",
      "epoch 5350\n",
      "====================================\n",
      "Epoch:  5350 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.547289719626168\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5350 5351\n",
      "Training loss:-0.002746293321251869\n",
      "Model saved\n",
      "check (7557,) ()\n",
      "epoch 5351\n",
      "====================================\n",
      "Epoch:  5351 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.54681367968604\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5351 5352\n",
      "Training loss:-0.0049389624036848545\n",
      "check (6515,) ()\n",
      "epoch 5352\n",
      "====================================\n",
      "Epoch:  5352 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.54745889387145\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5352 5353\n",
      "Training loss:-0.005757436156272888\n",
      "check (8261,) ()\n",
      "epoch 5353\n",
      "====================================\n",
      "Epoch:  5353 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.546609377918925\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5353 5354\n",
      "Training loss:-0.002146771876141429\n",
      "check (9085,) ()\n",
      "epoch 5354\n",
      "====================================\n",
      "Epoch:  5354 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.546880836757564\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5354 5355\n",
      "Training loss:0.0005820132209919393\n",
      "check (8353,) ()\n",
      "epoch 5355\n",
      "====================================\n",
      "Epoch:  5355 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.54640522875817\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5355 5356\n",
      "Training loss:-0.006791782099753618\n",
      "check (10000,) ()\n",
      "epoch 5356\n",
      "====================================\n",
      "Epoch:  5356 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.545182972367439\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5356 5357\n",
      "Training loss:0.003973591141402721\n",
      "check (10000,) ()\n",
      "epoch 5357\n",
      "====================================\n",
      "Epoch:  5357 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.542841142430465\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5357 5358\n",
      "Training loss:-0.0019815447740256786\n",
      "check (9435,) ()\n",
      "epoch 5358\n",
      "====================================\n",
      "Epoch:  5358 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.541246733855916\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5358 5359\n",
      "Training loss:0.006592107936739922\n",
      "check (8350,) ()\n",
      "epoch 5359\n",
      "====================================\n",
      "Epoch:  5359 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.540772532188841\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5359 5360\n",
      "Training loss:-0.0027855969965457916\n",
      "check (9864,) ()\n",
      "epoch 5360\n",
      "====================================\n",
      "Epoch:  5360 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.540111940298507\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5360 5361\n",
      "Training loss:-0.005740428809076548\n",
      "check (7183,) ()\n",
      "epoch 5361\n",
      "====================================\n",
      "Epoch:  5361 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.540757321395262\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5361 5362\n",
      "Training loss:-0.002536688232794404\n",
      "check (7533,) ()\n",
      "epoch 5362\n",
      "====================================\n",
      "Epoch:  5362 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.540656471465871\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5362 5363\n",
      "Training loss:0.0023400792852044106\n",
      "check (9456,) ()\n",
      "epoch 5363\n",
      "====================================\n",
      "Epoch:  5363 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.540182733544658\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5363 5364\n",
      "Training loss:-0.0007330935331992805\n",
      "check (8261,) ()\n",
      "epoch 5364\n",
      "====================================\n",
      "Epoch:  5364 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.539709172259508\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5364 5365\n",
      "Training loss:-0.0013394680572673678\n",
      "check (8299,) ()\n",
      "epoch 5365\n",
      "====================================\n",
      "Epoch:  5365 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.539794967381175\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5365 5366\n",
      "Training loss:0.0007721252623014152\n",
      "check (7720,) ()\n",
      "epoch 5366\n",
      "====================================\n",
      "Epoch:  5366 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.538948937756244\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5366 5367\n",
      "Training loss:-0.010328625328838825\n",
      "check (7794,) ()\n",
      "epoch 5367\n",
      "====================================\n",
      "Epoch:  5367 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.538103223402274\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5367 5368\n",
      "Training loss:-0.00857545342296362\n",
      "check (10000,) ()\n",
      "epoch 5368\n",
      "====================================\n",
      "Epoch:  5368 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.537444113263785\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5368 5369\n",
      "Training loss:-0.008865426294505596\n",
      "check (10000,) ()\n",
      "epoch 5369\n",
      "====================================\n",
      "Epoch:  5369 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.535853976531943\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5369 5370\n",
      "Training loss:-0.002724908757954836\n",
      "check (7911,) ()\n",
      "epoch 5370\n",
      "====================================\n",
      "Epoch:  5370 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.535754189944134\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5370 5371\n",
      "Training loss:-0.004140900913625956\n",
      "check (7991,) ()\n",
      "epoch 5371\n",
      "====================================\n",
      "Epoch:  5371 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.535468255445913\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5371 5372\n",
      "Training loss:-0.010030150413513184\n",
      "check (7399,) ()\n",
      "epoch 5372\n",
      "====================================\n",
      "Epoch:  5372 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.53518242740134\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5372 5373\n",
      "Training loss:-0.0034080606419593096\n",
      "check (7796,) ()\n",
      "epoch 5373\n",
      "====================================\n",
      "Epoch:  5373 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.534338358458962\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5373 5374\n",
      "Training loss:-0.003077707951888442\n",
      "check (8038,) ()\n",
      "epoch 5374\n",
      "====================================\n",
      "Epoch:  5374 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.53405284704131\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5374 5375\n",
      "Training loss:0.008983183652162552\n",
      "check (7516,) ()\n",
      "epoch 5375\n",
      "====================================\n",
      "Epoch:  5375 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.533953488372093\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5375 5376\n",
      "Training loss:-0.0014099366962909698\n",
      "check (7447,) ()\n",
      "epoch 5376\n",
      "====================================\n",
      "Epoch:  5376 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.533482142857142\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5376 5377\n",
      "Training loss:1.8429593183100224e-05\n",
      "check (8990,) ()\n",
      "epoch 5377\n",
      "====================================\n",
      "Epoch:  5377 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.532453040729031\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5377 5378\n",
      "Training loss:-0.006400494370609522\n",
      "check (10000,) ()\n",
      "epoch 5378\n",
      "====================================\n",
      "Epoch:  5378 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.530866493120119\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5378 5379\n",
      "Training loss:-0.005815633572638035\n",
      "check (8850,) ()\n",
      "epoch 5379\n",
      "====================================\n",
      "Epoch:  5379 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.530767800706451\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5379 5380\n",
      "Training loss:0.0013681366108357906\n",
      "check (8078,) ()\n",
      "epoch 5380\n",
      "====================================\n",
      "Epoch:  5380 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.530297397769516\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5380 5381\n",
      "Training loss:-0.007357142399996519\n",
      "check (7482,) ()\n",
      "epoch 5381\n",
      "====================================\n",
      "Epoch:  5381 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.529827169671066\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5381 5382\n",
      "Training loss:0.0014611034421250224\n",
      "check (8218,) ()\n",
      "epoch 5382\n",
      "====================================\n",
      "Epoch:  5382 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.529542920847268\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5382 5383\n",
      "Training loss:-0.005113623104989529\n",
      "check (10000,) ()\n",
      "epoch 5383\n",
      "====================================\n",
      "Epoch:  5383 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.527215307449378\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5383 5384\n",
      "Training loss:-0.00574830686673522\n",
      "check (6579,) ()\n",
      "epoch 5384\n",
      "====================================\n",
      "Epoch:  5384 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.527860326894503\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5384 5385\n",
      "Training loss:-0.006272744387388229\n",
      "check (10000,) ()\n",
      "epoch 5385\n",
      "====================================\n",
      "Epoch:  5385 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.527019498607242\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5385 5386\n",
      "Training loss:-0.0008704132051207125\n",
      "check (9461,) ()\n",
      "epoch 5386\n",
      "====================================\n",
      "Epoch:  5386 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -13.524136650575567\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5386 5387\n",
      "Training loss:-0.003944393713027239\n",
      "check (8836,) ()\n",
      "epoch 5387\n",
      "====================================\n",
      "Epoch:  5387 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.52459625023204\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5387 5388\n",
      "Training loss:0.000635063333902508\n",
      "check (10000,) ()\n",
      "epoch 5388\n",
      "====================================\n",
      "Epoch:  5388 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.523199703043801\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5388 5389\n",
      "Training loss:-0.0022010765969753265\n",
      "check (10000,) ()\n",
      "epoch 5389\n",
      "====================================\n",
      "Epoch:  5389 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.520504731861198\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5389 5390\n",
      "Training loss:-0.006507452577352524\n",
      "check (6464,) ()\n",
      "epoch 5390\n",
      "====================================\n",
      "Epoch:  5390 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.52152133580705\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5390 5391\n",
      "Training loss:0.00116196449380368\n",
      "check (7083,) ()\n",
      "epoch 5391\n",
      "====================================\n",
      "Epoch:  5391 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.522166573919495\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5391 5392\n",
      "Training loss:0.002188757760450244\n",
      "check (10000,) ()\n",
      "epoch 5392\n",
      "====================================\n",
      "Epoch:  5392 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.521142433234422\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5392 5393\n",
      "Training loss:-0.00897020660340786\n",
      "check (8245,) ()\n",
      "epoch 5393\n",
      "====================================\n",
      "Epoch:  5393 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.520674949007974\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5393 5394\n",
      "Training loss:-0.0022755879908800125\n",
      "check (8987,) ()\n",
      "epoch 5394\n",
      "====================================\n",
      "Epoch:  5394 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.520578420467185\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5394 5395\n",
      "Training loss:-0.00456240912899375\n",
      "check (9128,) ()\n",
      "epoch 5395\n",
      "====================================\n",
      "Epoch:  5395 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.519369786839667\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5395 5396\n",
      "Training loss:0.00024919924908317626\n",
      "check (9383,) ()\n",
      "epoch 5396\n",
      "====================================\n",
      "Epoch:  5396 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.518717568569311\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5396 5397\n",
      "Training loss:-0.0008980695274658501\n",
      "check (8183,) ()\n",
      "epoch 5397\n",
      "====================================\n",
      "Epoch:  5397 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.517509727626459\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5397 5398\n",
      "Training loss:-0.001814714865759015\n",
      "check (6880,) ()\n",
      "epoch 5398\n",
      "====================================\n",
      "Epoch:  5398 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -13.518340125972582\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5398 5399\n",
      "Training loss:0.0022073842119425535\n",
      "check (10000,) ()\n",
      "epoch 5399\n",
      "====================================\n",
      "Epoch:  5399 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -13.515465827005\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5399 5400\n",
      "Training loss:-0.005616956856101751\n",
      "check (9768,) ()\n",
      "epoch 5400\n",
      "====================================\n",
      "Epoch:  5400 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.515185185185185\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5400 5401\n",
      "Training loss:-0.009868588298559189\n",
      "Model saved\n",
      "check (5921,) ()\n",
      "epoch 5401\n",
      "====================================\n",
      "Epoch:  5401 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.515645250879468\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5401 5402\n",
      "Training loss:-0.0022621110547333956\n",
      "check (8555,) ()\n",
      "epoch 5402\n",
      "====================================\n",
      "Epoch:  5402 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.515179563124768\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5402 5403\n",
      "Training loss:-0.006466621998697519\n",
      "check (7924,) ()\n",
      "epoch 5403\n",
      "====================================\n",
      "Epoch:  5403 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.5148991301129\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5403 5404\n",
      "Training loss:-0.004847797565162182\n",
      "check (7486,) ()\n",
      "epoch 5404\n",
      "====================================\n",
      "Epoch:  5404 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.515173945225758\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5404 5405\n",
      "Training loss:-0.0040690223686397076\n",
      "check (6943,) ()\n",
      "epoch 5405\n",
      "====================================\n",
      "Epoch:  5405 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.51618871415356\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5405 5406\n",
      "Training loss:-0.013723711483180523\n",
      "check (7662,) ()\n",
      "epoch 5406\n",
      "====================================\n",
      "Epoch:  5406 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.516463189049205\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5406 5407\n",
      "Training loss:0.0015866566682234406\n",
      "check (9905,) ()\n",
      "epoch 5407\n",
      "====================================\n",
      "Epoch:  5407 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.515257998890327\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5407 5408\n",
      "Training loss:-0.007193101570010185\n",
      "check (10000,) ()\n",
      "epoch 5408\n",
      "====================================\n",
      "Epoch:  5408 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.513683431952662\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5408 5409\n",
      "Training loss:-0.0024361794348806143\n",
      "check (9658,) ()\n",
      "epoch 5409\n",
      "====================================\n",
      "Epoch:  5409 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.51284895544463\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5409 5410\n",
      "Training loss:-0.0068361712619662285\n",
      "check (7381,) ()\n",
      "epoch 5410\n",
      "====================================\n",
      "Epoch:  5410 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.513123844731977\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5410 5411\n",
      "Training loss:-0.0008521054987795651\n",
      "check (10000,) ()\n",
      "epoch 5411\n",
      "====================================\n",
      "Epoch:  5411 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.511180927739789\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5411 5412\n",
      "Training loss:-0.0025544296950101852\n",
      "check (9913,) ()\n",
      "epoch 5412\n",
      "====================================\n",
      "Epoch:  5412 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.511271249076128\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5412 5413\n",
      "Training loss:-0.0031345090828835964\n",
      "check (10000,) ()\n",
      "epoch 5413\n",
      "====================================\n",
      "Epoch:  5413 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.51062257528173\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5413 5414\n",
      "Training loss:-0.007992100901901722\n",
      "check (9566,) ()\n",
      "epoch 5414\n",
      "====================================\n",
      "Epoch:  5414 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.510158847432582\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5414 5415\n",
      "Training loss:-0.0043535674922168255\n",
      "check (10000,) ()\n",
      "epoch 5415\n",
      "====================================\n",
      "Epoch:  5415 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.507663896583564\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5415 5416\n",
      "Training loss:-0.004312795586884022\n",
      "check (9878,) ()\n",
      "epoch 5416\n",
      "====================================\n",
      "Epoch:  5416 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.506831610044314\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5416 5417\n",
      "Training loss:-0.006766139063984156\n",
      "check (7068,) ()\n",
      "epoch 5417\n",
      "====================================\n",
      "Epoch:  5417 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.506368838840686\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5417 5418\n",
      "Training loss:0.003057303139939904\n",
      "check (7086,) ()\n",
      "epoch 5418\n",
      "====================================\n",
      "Epoch:  5418 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.506275378368402\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5418 5419\n",
      "Training loss:-0.00621230062097311\n",
      "check (10000,) ()\n",
      "epoch 5419\n",
      "====================================\n",
      "Epoch:  5419 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.503967521682968\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5419 5420\n",
      "Training loss:0.00040081635233946145\n",
      "check (10000,) ()\n",
      "epoch 5420\n",
      "====================================\n",
      "Epoch:  5420 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -13.501107011070111\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5420 5421\n",
      "Training loss:-0.0012152233393862844\n",
      "check (10000,) ()\n",
      "epoch 5421\n",
      "====================================\n",
      "Epoch:  5421 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.498616491422247\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5421 5422\n",
      "Training loss:-0.004706209059804678\n",
      "check (8965,) ()\n",
      "epoch 5422\n",
      "====================================\n",
      "Epoch:  5422 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.496680191811139\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5422 5423\n",
      "Training loss:-0.0009041336597874761\n",
      "check (9097,) ()\n",
      "epoch 5423\n",
      "====================================\n",
      "Epoch:  5423 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.496588604093676\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5423 5424\n",
      "Training loss:0.004460545722395182\n",
      "check (8750,) ()\n",
      "epoch 5424\n",
      "====================================\n",
      "Epoch:  5424 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.495575221238939\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5424 5425\n",
      "Training loss:-0.001443638582713902\n",
      "check (8320,) ()\n",
      "epoch 5425\n",
      "====================================\n",
      "Epoch:  5425 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.495483870967742\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5425 5426\n",
      "Training loss:0.002594010205939412\n",
      "check (9459,) ()\n",
      "epoch 5426\n",
      "====================================\n",
      "Epoch:  5426 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.495023958717287\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5426 5427\n",
      "Training loss:-0.0029728098306804895\n",
      "check (7084,) ()\n",
      "epoch 5427\n",
      "====================================\n",
      "Epoch:  5427 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.49548553528653\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5427 5428\n",
      "Training loss:-0.005986787378787994\n",
      "check (7753,) ()\n",
      "epoch 5428\n",
      "====================================\n",
      "Epoch:  5428 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.494657332350775\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5428 5429\n",
      "Training loss:-0.0022344146855175495\n",
      "check (8763,) ()\n",
      "epoch 5429\n",
      "====================================\n",
      "Epoch:  5429 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.493092650580218\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5429 5430\n",
      "Training loss:-0.001060397014953196\n",
      "check (9272,) ()\n",
      "epoch 5430\n",
      "====================================\n",
      "Epoch:  5430 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.493001841620627\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5430 5431\n",
      "Training loss:-0.003910214174538851\n",
      "check (10000,) ()\n",
      "epoch 5431\n",
      "====================================\n",
      "Epoch:  5431 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.49106978457006\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5431 5432\n",
      "Training loss:-0.0010033443104475737\n",
      "check (5593,) ()\n",
      "epoch 5432\n",
      "====================================\n",
      "Epoch:  5432 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.491715758468336\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5432 5433\n",
      "Training loss:0.0024930101353675127\n",
      "check (7956,) ()\n",
      "epoch 5433\n",
      "====================================\n",
      "Epoch:  5433 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.491809313454814\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5433 5434\n",
      "Training loss:-0.0018272553570568562\n",
      "check (7903,) ()\n",
      "epoch 5434\n",
      "====================================\n",
      "Epoch:  5434 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.491718807508281\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5434 5435\n",
      "Training loss:0.007319265510886908\n",
      "check (9188,) ()\n",
      "epoch 5435\n",
      "====================================\n",
      "Epoch:  5435 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.490524379024839\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5435 5436\n",
      "Training loss:-0.007510265335440636\n",
      "check (7285,) ()\n",
      "epoch 5436\n",
      "====================================\n",
      "Epoch:  5436 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.490066225165563\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5436 5437\n",
      "Training loss:-0.0034596859477460384\n",
      "check (7945,) ()\n",
      "epoch 5437\n",
      "====================================\n",
      "Epoch:  5437 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.489608239838146\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5437 5438\n",
      "Training loss:-0.0010145449778065085\n",
      "check (8455,) ()\n",
      "epoch 5438\n",
      "====================================\n",
      "Epoch:  5438 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.489885987495402\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5438 5439\n",
      "Training loss:0.00609254278242588\n",
      "check (8062,) ()\n",
      "epoch 5439\n",
      "====================================\n",
      "Epoch:  5439 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.489244346387203\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5439 5440\n",
      "Training loss:-0.00022483103384729475\n",
      "check (10000,) ()\n",
      "epoch 5440\n",
      "====================================\n",
      "Epoch:  5440 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.488235294117647\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5440 5441\n",
      "Training loss:-0.004885651171207428\n",
      "check (9671,) ()\n",
      "epoch 5441\n",
      "====================================\n",
      "Epoch:  5441 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.48741040249954\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5441 5442\n",
      "Training loss:-0.00040795409586280584\n",
      "check (7717,) ()\n",
      "epoch 5442\n",
      "====================================\n",
      "Epoch:  5442 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.487688349871371\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5442 5443\n",
      "Training loss:-0.0029685082845389843\n",
      "check (6709,) ()\n",
      "epoch 5443\n",
      "====================================\n",
      "Epoch:  5443 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.487966195112989\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5443 5444\n",
      "Training loss:-0.006004030816257\n",
      "check (7418,) ()\n",
      "epoch 5444\n",
      "====================================\n",
      "Epoch:  5444 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.487876561351946\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5444 5445\n",
      "Training loss:-0.006643134169280529\n",
      "check (10000,) ()\n",
      "epoch 5445\n",
      "====================================\n",
      "Epoch:  5445 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.485766758494032\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5445 5446\n",
      "Training loss:0.0004506469704210758\n",
      "check (6715,) ()\n",
      "epoch 5446\n",
      "====================================\n",
      "Epoch:  5446 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.486779287550496\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5446 5447\n",
      "Training loss:-0.0039928448386490345\n",
      "check (7187,) ()\n",
      "epoch 5447\n",
      "====================================\n",
      "Epoch:  5447 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.48705709564898\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5447 5448\n",
      "Training loss:-0.005827706772834063\n",
      "check (10000,) ()\n",
      "epoch 5448\n",
      "====================================\n",
      "Epoch:  5448 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.486233480176212\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5448 5449\n",
      "Training loss:-0.009644201956689358\n",
      "check (7043,) ()\n",
      "epoch 5449\n",
      "====================================\n",
      "Epoch:  5449 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.486694806386494\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5449 5450\n",
      "Training loss:-0.008055008016526699\n",
      "check (7742,) ()\n",
      "epoch 5450\n",
      "====================================\n",
      "Epoch:  5450 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.485871559633027\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5450 5451\n",
      "Training loss:-0.007226909976452589\n",
      "Model saved\n",
      "check (8111,) ()\n",
      "epoch 5451\n",
      "====================================\n",
      "Epoch:  5451 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.485415520088058\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5451 5452\n",
      "Training loss:-0.0030224970541894436\n",
      "check (8714,) ()\n",
      "epoch 5452\n",
      "====================================\n",
      "Epoch:  5452 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.48569332355099\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5452 5453\n",
      "Training loss:-0.011878284625709057\n",
      "check (9815,) ()\n",
      "epoch 5453\n",
      "====================================\n",
      "Epoch:  5453 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.484503942783789\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5453 5454\n",
      "Training loss:0.0005979766137897968\n",
      "check (9361,) ()\n",
      "epoch 5454\n",
      "====================================\n",
      "Epoch:  5454 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.484048404840484\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5454 5455\n",
      "Training loss:0.0034567208494991064\n",
      "check (9575,) ()\n",
      "epoch 5455\n",
      "====================================\n",
      "Epoch:  5455 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.483226397800184\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5455 5456\n",
      "Training loss:-0.015422675758600235\n",
      "check (9544,) ()\n",
      "epoch 5456\n",
      "====================================\n",
      "Epoch:  5456 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.48258797653959\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5456 5457\n",
      "Training loss:-0.00044197848183102906\n",
      "check (9878,) ()\n",
      "epoch 5457\n",
      "====================================\n",
      "Epoch:  5457 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.48103353490929\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5457 5458\n",
      "Training loss:-0.0032214061357080936\n",
      "check (9732,) ()\n",
      "epoch 5458\n",
      "====================================\n",
      "Epoch:  5458 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.4783803591059\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5458 5459\n",
      "Training loss:-0.005364550277590752\n",
      "check (9196,) ()\n",
      "epoch 5459\n",
      "====================================\n",
      "Epoch:  5459 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.477559992672651\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5459 5460\n",
      "Training loss:-0.004010249860584736\n",
      "check (10000,) ()\n",
      "epoch 5460\n",
      "====================================\n",
      "Epoch:  5460 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.476007326007325\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5460 5461\n",
      "Training loss:-0.006953058764338493\n",
      "check (8528,) ()\n",
      "epoch 5461\n",
      "====================================\n",
      "Epoch:  5461 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.476103277787951\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5461 5462\n",
      "Training loss:-0.004302497021853924\n",
      "check (10000,) ()\n",
      "epoch 5462\n",
      "====================================\n",
      "Epoch:  5462 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.47491761259612\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5462 5463\n",
      "Training loss:-0.0010596374049782753\n",
      "check (10000,) ()\n",
      "epoch 5463\n",
      "====================================\n",
      "Epoch:  5463 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.47318323265605\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5463 5464\n",
      "Training loss:-0.007112608291208744\n",
      "check (8843,) ()\n",
      "epoch 5464\n",
      "====================================\n",
      "Epoch:  5464 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.472730600292826\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5464 5465\n",
      "Training loss:0.004115184303373098\n",
      "check (9412,) ()\n",
      "epoch 5465\n",
      "====================================\n",
      "Epoch:  5465 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.472644098810614\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5465 5466\n",
      "Training loss:0.0009142060880549252\n",
      "check (7844,) ()\n",
      "epoch 5466\n",
      "====================================\n",
      "Epoch:  5466 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.472191730698865\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5466 5467\n",
      "Training loss:0.0017896104836836457\n",
      "check (10000,) ()\n",
      "epoch 5467\n",
      "====================================\n",
      "Epoch:  5467 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.469910371318822\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5467 5468\n",
      "Training loss:-0.0053431387059390545\n",
      "check (9116,) ()\n",
      "epoch 5468\n",
      "====================================\n",
      "Epoch:  5468 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.46945866861741\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5468 5469\n",
      "Training loss:-0.006601856090128422\n",
      "check (7697,) ()\n",
      "epoch 5469\n",
      "====================================\n",
      "Epoch:  5469 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.4697385262388\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5469 5470\n",
      "Training loss:-0.0061851791106164455\n",
      "check (6648,) ()\n",
      "epoch 5470\n",
      "====================================\n",
      "Epoch:  5470 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.470383912248629\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5470 5471\n",
      "Training loss:-0.004149976186454296\n",
      "check (9400,) ()\n",
      "epoch 5471\n",
      "====================================\n",
      "Epoch:  5471 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.470297934564066\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5471 5472\n",
      "Training loss:0.004246945027261972\n",
      "check (7466,) ()\n",
      "epoch 5472\n",
      "====================================\n",
      "Epoch:  5472 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.470211988304094\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5472 5473\n",
      "Training loss:-0.011292547918856144\n",
      "check (7230,) ()\n",
      "epoch 5473\n",
      "====================================\n",
      "Epoch:  5473 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.471222364334004\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5473 5474\n",
      "Training loss:-0.007274077273905277\n",
      "check (7055,) ()\n",
      "epoch 5474\n",
      "====================================\n",
      "Epoch:  5474 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.471501644135916\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5474 5475\n",
      "Training loss:0.0007543846149928868\n",
      "check (6859,) ()\n",
      "epoch 5475\n",
      "====================================\n",
      "Epoch:  5475 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.471780821917807\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5475 5476\n",
      "Training loss:-0.007519258186221123\n",
      "check (6540,) ()\n",
      "epoch 5476\n",
      "====================================\n",
      "Epoch:  5476 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.472425127830533\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5476 5477\n",
      "Training loss:-0.003127208212390542\n",
      "check (8453,) ()\n",
      "epoch 5477\n",
      "====================================\n",
      "Epoch:  5477 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.471608544823809\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5477 5478\n",
      "Training loss:-0.005481116473674774\n",
      "check (8570,) ()\n",
      "epoch 5478\n",
      "====================================\n",
      "Epoch:  5478 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.471522453450165\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5478 5479\n",
      "Training loss:-0.0027669824194163084\n",
      "check (5341,) ()\n",
      "epoch 5479\n",
      "====================================\n",
      "Epoch:  5479 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -13.472348968789925\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5479 5480\n",
      "Training loss:-0.006625442765653133\n",
      "check (9950,) ()\n",
      "epoch 5480\n",
      "====================================\n",
      "Epoch:  5480 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.469708029197081\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5480 5481\n",
      "Training loss:-0.0028819057624787092\n",
      "check (8785,) ()\n",
      "epoch 5481\n",
      "====================================\n",
      "Epoch:  5481 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.469439883232987\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5481 5482\n",
      "Training loss:-0.0062934220768511295\n",
      "check (9383,) ()\n",
      "epoch 5482\n",
      "====================================\n",
      "Epoch:  5482 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.469171835096681\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5482 5483\n",
      "Training loss:-0.002613769844174385\n",
      "check (8287,) ()\n",
      "epoch 5483\n",
      "====================================\n",
      "Epoch:  5483 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.46872150282692\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5483 5484\n",
      "Training loss:-0.012084350921213627\n",
      "check (8062,) ()\n",
      "epoch 5484\n",
      "====================================\n",
      "Epoch:  5484 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.468088986141503\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5484 5485\n",
      "Training loss:0.001062756055034697\n",
      "check (9201,) ()\n",
      "epoch 5485\n",
      "====================================\n",
      "Epoch:  5485 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.466909753874202\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5485 5486\n",
      "Training loss:-0.004439385142177343\n",
      "check (8814,) ()\n",
      "epoch 5486\n",
      "====================================\n",
      "Epoch:  5486 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.46609551585855\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5486 5487\n",
      "Training loss:-0.004173878580331802\n",
      "check (8477,) ()\n",
      "epoch 5487\n",
      "====================================\n",
      "Epoch:  5487 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.46601057043922\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5487 5488\n",
      "Training loss:-0.0016920939087867737\n",
      "check (8686,) ()\n",
      "epoch 5488\n",
      "====================================\n",
      "Epoch:  5488 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.464467930029155\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5488 5489\n",
      "Training loss:-0.0021049631759524345\n",
      "check (9052,) ()\n",
      "epoch 5489\n",
      "====================================\n",
      "Epoch:  5489 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.46401894698488\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5489 5490\n",
      "Training loss:-0.002028459683060646\n",
      "check (9448,) ()\n",
      "epoch 5490\n",
      "====================================\n",
      "Epoch:  5490 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.462477231329691\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5490 5491\n",
      "Training loss:0.00212852586992085\n",
      "check (7537,) ()\n",
      "epoch 5491\n",
      "====================================\n",
      "Epoch:  5491 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.462757239118558\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5491 5492\n",
      "Training loss:0.002218338893726468\n",
      "check (8833,) ()\n",
      "epoch 5492\n",
      "====================================\n",
      "Epoch:  5492 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.461944646758923\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5492 5493\n",
      "Training loss:-0.005378889851272106\n",
      "check (7328,) ()\n",
      "epoch 5493\n",
      "====================================\n",
      "Epoch:  5493 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.462588749317312\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5493 5494\n",
      "Training loss:-0.0009423296432942152\n",
      "check (8836,) ()\n",
      "epoch 5494\n",
      "====================================\n",
      "Epoch:  5494 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.461048416454314\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5494 5495\n",
      "Training loss:-0.008321154862642288\n",
      "check (9510,) ()\n",
      "epoch 5495\n",
      "====================================\n",
      "Epoch:  5495 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.460236578707915\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5495 5496\n",
      "Training loss:-0.004263035487383604\n",
      "check (8022,) ()\n",
      "epoch 5496\n",
      "====================================\n",
      "Epoch:  5496 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.46033478893741\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5496 5497\n",
      "Training loss:-0.002003883942961693\n",
      "check (8343,) ()\n",
      "epoch 5497\n",
      "====================================\n",
      "Epoch:  5497 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.460251046025105\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5497 5498\n",
      "Training loss:-0.008251480758190155\n",
      "check (9802,) ()\n",
      "epoch 5498\n",
      "====================================\n",
      "Epoch:  5498 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.459985449254274\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5498 5499\n",
      "Training loss:-0.0010764714097604156\n",
      "check (9839,) ()\n",
      "epoch 5499\n",
      "====================================\n",
      "Epoch:  5499 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.45953809783597\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5499 5500\n",
      "Training loss:-0.005195530131459236\n",
      "check (5890,) ()\n",
      "epoch 5500\n",
      "====================================\n",
      "Epoch:  5500 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.460545454545455\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5500 5501\n",
      "Training loss:0.001969706267118454\n",
      "Model saved\n",
      "check (6149,) ()\n",
      "epoch 5501\n",
      "====================================\n",
      "Epoch:  5501 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -13.461370659880021\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5501 5502\n",
      "Training loss:-0.0031166395638138056\n",
      "check (9768,) ()\n",
      "epoch 5502\n",
      "====================================\n",
      "Epoch:  5502 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.460559796437659\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5502 5503\n",
      "Training loss:-0.005631427280604839\n",
      "check (7210,) ()\n",
      "epoch 5503\n",
      "====================================\n",
      "Epoch:  5503 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.459749227693985\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5503 5504\n",
      "Training loss:-0.004403127357363701\n",
      "check (7462,) ()\n",
      "epoch 5504\n",
      "====================================\n",
      "Epoch:  5504 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.459302325581396\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5504 5505\n",
      "Training loss:-0.0025045396760106087\n",
      "check (8782,) ()\n",
      "epoch 5505\n",
      "====================================\n",
      "Epoch:  5505 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.458855585831063\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5505 5506\n",
      "Training loss:-0.004628001246601343\n",
      "check (9051,) ()\n",
      "epoch 5506\n",
      "====================================\n",
      "Epoch:  5506 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.458045768252815\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5506 5507\n",
      "Training loss:-0.0009877836564555764\n",
      "check (8756,) ()\n",
      "epoch 5507\n",
      "====================================\n",
      "Epoch:  5507 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.456509896495369\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5507 5508\n",
      "Training loss:0.0009306684951297939\n",
      "check (9764,) ()\n",
      "epoch 5508\n",
      "====================================\n",
      "Epoch:  5508 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.454611474219318\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5508 5509\n",
      "Training loss:-0.0005357485497370362\n",
      "check (9481,) ()\n",
      "epoch 5509\n",
      "====================================\n",
      "Epoch:  5509 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.452895262298057\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5509 5510\n",
      "Training loss:-0.004028978757560253\n",
      "check (9473,) ()\n",
      "epoch 5510\n",
      "====================================\n",
      "Epoch:  5510 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.4513611615245\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5510 5511\n",
      "Training loss:-0.008271397091448307\n",
      "check (8346,) ()\n",
      "epoch 5511\n",
      "====================================\n",
      "Epoch:  5511 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.449827617492288\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5511 5512\n",
      "Training loss:-0.001998941646888852\n",
      "check (8452,) ()\n",
      "epoch 5512\n",
      "====================================\n",
      "Epoch:  5512 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.448294629898404\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5512 5513\n",
      "Training loss:-0.00566163519397378\n",
      "check (8500,) ()\n",
      "epoch 5513\n",
      "====================================\n",
      "Epoch:  5513 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.447669145655723\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5513 5514\n",
      "Training loss:-0.0011021109530702233\n",
      "check (6986,) ()\n",
      "epoch 5514\n",
      "====================================\n",
      "Epoch:  5514 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.447043888284368\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5514 5515\n",
      "Training loss:-0.003817946184426546\n",
      "check (7179,) ()\n",
      "epoch 5515\n",
      "====================================\n",
      "Epoch:  5515 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.446418857660925\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5515 5516\n",
      "Training loss:0.001813474576920271\n",
      "check (7755,) ()\n",
      "epoch 5516\n",
      "====================================\n",
      "Epoch:  5516 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.446337926033358\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5516 5517\n",
      "Training loss:-0.00821127463132143\n",
      "check (8275,) ()\n",
      "epoch 5517\n",
      "====================================\n",
      "Epoch:  5517 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.44589450788472\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5517 5518\n",
      "Training loss:-0.008569210767745972\n",
      "check (8281,) ()\n",
      "epoch 5518\n",
      "====================================\n",
      "Epoch:  5518 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.44508880028996\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5518 5519\n",
      "Training loss:-0.007232275791466236\n",
      "check (8424,) ()\n",
      "epoch 5519\n",
      "====================================\n",
      "Epoch:  5519 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.444826961406052\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5519 5520\n",
      "Training loss:-0.0019432019907981157\n",
      "check (8435,) ()\n",
      "epoch 5520\n",
      "====================================\n",
      "Epoch:  5520 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.444384057971014\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5520 5521\n",
      "Training loss:-0.005758961662650108\n",
      "check (10000,) ()\n",
      "epoch 5521\n",
      "====================================\n",
      "Epoch:  5521 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.443760188371671\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5521 5522\n",
      "Training loss:-0.00628758454695344\n",
      "check (10000,) ()\n",
      "epoch 5522\n",
      "====================================\n",
      "Epoch:  5522 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.442231075697212\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5522 5523\n",
      "Training loss:-0.0015737018547952175\n",
      "check (10000,) ()\n",
      "epoch 5523\n",
      "====================================\n",
      "Epoch:  5523 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.440883577765707\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5523 5524\n",
      "Training loss:-0.0038363104686141014\n",
      "check (10000,) ()\n",
      "epoch 5524\n",
      "====================================\n",
      "Epoch:  5524 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.438993482983346\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5524 5525\n",
      "Training loss:-0.0006241565570235252\n",
      "check (7548,) ()\n",
      "epoch 5525\n",
      "====================================\n",
      "Epoch:  5525 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.438552036199095\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5525 5526\n",
      "Training loss:-0.0025808983482420444\n",
      "check (9538,) ()\n",
      "epoch 5526\n",
      "====================================\n",
      "Epoch:  5526 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.43738689829895\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5526 5527\n",
      "Training loss:0.0021103580947965384\n",
      "check (9484,) ()\n",
      "epoch 5527\n",
      "====================================\n",
      "Epoch:  5527 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.43622218201556\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5527 5528\n",
      "Training loss:-0.008835416287183762\n",
      "check (9048,) ()\n",
      "epoch 5528\n",
      "====================================\n",
      "Epoch:  5528 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.435057887120117\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5528 5529\n",
      "Training loss:-0.0006267259013839066\n",
      "check (9426,) ()\n",
      "epoch 5529\n",
      "====================================\n",
      "Epoch:  5529 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.433532284319044\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5529 5530\n",
      "Training loss:-0.005847951862961054\n",
      "check (9039,) ()\n",
      "epoch 5530\n",
      "====================================\n",
      "Epoch:  5530 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.433273056057866\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5530 5531\n",
      "Training loss:-0.01096688024699688\n",
      "check (9056,) ()\n",
      "epoch 5531\n",
      "====================================\n",
      "Epoch:  5531 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.432833122401012\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5531 5532\n",
      "Training loss:-0.005057968199253082\n",
      "check (6370,) ()\n",
      "epoch 5532\n",
      "====================================\n",
      "Epoch:  5532 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.433839479392624\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5532 5533\n",
      "Training loss:0.0008777157054282725\n",
      "check (8171,) ()\n",
      "epoch 5533\n",
      "====================================\n",
      "Epoch:  5533 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.43249593348997\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5533 5534\n",
      "Training loss:-0.0012542179320007563\n",
      "check (9261,) ()\n",
      "epoch 5534\n",
      "====================================\n",
      "Epoch:  5534 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.432237079869894\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5534 5535\n",
      "Training loss:-0.002362571656703949\n",
      "check (7436,) ()\n",
      "epoch 5535\n",
      "====================================\n",
      "Epoch:  5535 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.43215898825655\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5535 5536\n",
      "Training loss:-0.007979325018823147\n",
      "check (8156,) ()\n",
      "epoch 5536\n",
      "====================================\n",
      "Epoch:  5536 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.43208092485549\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5536 5537\n",
      "Training loss:-0.0038535778876394033\n",
      "check (8128,) ()\n",
      "epoch 5537\n",
      "====================================\n",
      "Epoch:  5537 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.432002889651436\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5537 5538\n",
      "Training loss:0.0013017813907936215\n",
      "check (9226,) ()\n",
      "epoch 5538\n",
      "====================================\n",
      "Epoch:  5538 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.430299747201156\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5538 5539\n",
      "Training loss:-0.009078510105609894\n",
      "check (8794,) ()\n",
      "epoch 5539\n",
      "====================================\n",
      "Epoch:  5539 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.428777757717999\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5539 5540\n",
      "Training loss:-0.004985281731933355\n",
      "check (10000,) ()\n",
      "epoch 5540\n",
      "====================================\n",
      "Epoch:  5540 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.426173285198557\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5540 5541\n",
      "Training loss:-7.69821199355647e-05\n",
      "check (10000,) ()\n",
      "epoch 5541\n",
      "====================================\n",
      "Epoch:  5541 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.42519400830175\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5541 5542\n",
      "Training loss:-0.007666431367397308\n",
      "check (9346,) ()\n",
      "epoch 5542\n",
      "====================================\n",
      "Epoch:  5542 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.424034644532659\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5542 5543\n",
      "Training loss:-0.000678666343446821\n",
      "check (8133,) ()\n",
      "epoch 5543\n",
      "====================================\n",
      "Epoch:  5543 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.423597329965723\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5543 5544\n",
      "Training loss:-0.0011626590276136994\n",
      "check (8177,) ()\n",
      "epoch 5544\n",
      "====================================\n",
      "Epoch:  5544 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.4237012987013\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5544 5545\n",
      "Training loss:0.0005657666479237378\n",
      "check (10000,) ()\n",
      "epoch 5545\n",
      "====================================\n",
      "Epoch:  5545 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.422182146077548\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5545 5546\n",
      "Training loss:0.006645088084042072\n",
      "check (10000,) ()\n",
      "epoch 5546\n",
      "====================================\n",
      "Epoch:  5546 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.420302921024161\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5546 5547\n",
      "Training loss:-0.0025949596893042326\n",
      "check (9852,) ()\n",
      "epoch 5547\n",
      "====================================\n",
      "Epoch:  5547 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.41914548404543\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5547 5548\n",
      "Training loss:-0.00687000947073102\n",
      "check (8348,) ()\n",
      "epoch 5548\n",
      "====================================\n",
      "Epoch:  5548 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.418168709444846\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5548 5549\n",
      "Training loss:-0.005043888930231333\n",
      "check (9316,) ()\n",
      "epoch 5549\n",
      "====================================\n",
      "Epoch:  5549 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.416831861596684\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5549 5550\n",
      "Training loss:-0.0035245874896645546\n",
      "check (7478,) ()\n",
      "epoch 5550\n",
      "====================================\n",
      "Epoch:  5550 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.416756756756756\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5550 5551\n",
      "Training loss:-0.003318570787087083\n",
      "Model saved\n",
      "check (9131,) ()\n",
      "epoch 5551\n",
      "====================================\n",
      "Epoch:  5551 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.415420644928842\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5551 5552\n",
      "Training loss:-0.0037065462674945593\n",
      "check (7761,) ()\n",
      "epoch 5552\n",
      "====================================\n",
      "Epoch:  5552 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.415345821325648\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5552 5553\n",
      "Training loss:0.0006851276848465204\n",
      "check (10000,) ()\n",
      "epoch 5553\n",
      "====================================\n",
      "Epoch:  5553 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.413830361966504\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5553 5554\n",
      "Training loss:0.0004844234499614686\n",
      "check (7274,) ()\n",
      "epoch 5554\n",
      "====================================\n",
      "Epoch:  5554 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.41375585163846\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5554 5555\n",
      "Training loss:-0.0019678648095577955\n",
      "check (8860,) ()\n",
      "epoch 5555\n",
      "====================================\n",
      "Epoch:  5555 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.413681368136814\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5555 5556\n",
      "Training loss:-0.010914572514593601\n",
      "check (9651,) ()\n",
      "epoch 5556\n",
      "====================================\n",
      "Epoch:  5556 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.413966882649389\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5556 5557\n",
      "Training loss:-0.004280091729015112\n",
      "check (7879,) ()\n",
      "epoch 5557\n",
      "====================================\n",
      "Epoch:  5557 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.413892387979125\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5557 5558\n",
      "Training loss:-0.004060795996338129\n",
      "check (10000,) ()\n",
      "epoch 5558\n",
      "====================================\n",
      "Epoch:  5558 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.411658870097158\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5558 5559\n",
      "Training loss:-0.005106437020003796\n",
      "check (10000,) ()\n",
      "epoch 5559\n",
      "====================================\n",
      "Epoch:  5559 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.41032559812916\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5559 5560\n",
      "Training loss:-0.004102064296603203\n",
      "check (9829,) ()\n",
      "epoch 5560\n",
      "====================================\n",
      "Epoch:  5560 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.408273381294965\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5560 5561\n",
      "Training loss:0.0008360870415344834\n",
      "check (7883,) ()\n",
      "epoch 5561\n",
      "====================================\n",
      "Epoch:  5561 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.407121021399028\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5561 5562\n",
      "Training loss:-0.005409133154898882\n",
      "check (10000,) ()\n",
      "epoch 5562\n",
      "====================================\n",
      "Epoch:  5562 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.406328658755843\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5562 5563\n",
      "Training loss:0.0017610746435821056\n",
      "check (9089,) ()\n",
      "epoch 5563\n",
      "====================================\n",
      "Epoch:  5563 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.405716340104261\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5563 5564\n",
      "Training loss:-0.00556890619918704\n",
      "check (9603,) ()\n",
      "epoch 5564\n",
      "====================================\n",
      "Epoch:  5564 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.404205607476635\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5564 5565\n",
      "Training loss:-0.0012728082947432995\n",
      "check (7613,) ()\n",
      "epoch 5565\n",
      "====================================\n",
      "Epoch:  5565 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-21.0\n",
      "Mean Reward of that batch -21.0\n",
      "Average Reward of all training: -13.405570530098831\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5565 5566\n",
      "Training loss:-0.006288755685091019\n",
      "check (8998,) ()\n",
      "epoch 5566\n",
      "====================================\n",
      "Epoch:  5566 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.40513833992095\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5566 5567\n",
      "Training loss:0.003761832369491458\n",
      "check (7052,) ()\n",
      "epoch 5567\n",
      "====================================\n",
      "Epoch:  5567 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.405065564936232\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5567 5568\n",
      "Training loss:-0.013312328606843948\n",
      "check (7934,) ()\n",
      "epoch 5568\n",
      "====================================\n",
      "Epoch:  5568 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.404633620689655\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5568 5569\n",
      "Training loss:-0.0063698445446789265\n",
      "check (8468,) ()\n",
      "epoch 5569\n",
      "====================================\n",
      "Epoch:  5569 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.404560962470821\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5569 5570\n",
      "Training loss:-0.0008042388944886625\n",
      "check (10000,) ()\n",
      "epoch 5570\n",
      "====================================\n",
      "Epoch:  5570 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.403770197486535\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5570 5571\n",
      "Training loss:-0.006009379401803017\n",
      "check (5615,) ()\n",
      "epoch 5571\n",
      "====================================\n",
      "Epoch:  5571 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -13.40459522527374\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5571 5572\n",
      "Training loss:-0.002394231501966715\n",
      "check (9058,) ()\n",
      "epoch 5572\n",
      "====================================\n",
      "Epoch:  5572 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.404881550610193\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5572 5573\n",
      "Training loss:-0.0001429707044735551\n",
      "check (10000,) ()\n",
      "epoch 5573\n",
      "====================================\n",
      "Epoch:  5573 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.403732280638794\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5573 5574\n",
      "Training loss:-0.006822344847023487\n",
      "check (7846,) ()\n",
      "epoch 5574\n",
      "====================================\n",
      "Epoch:  5574 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.404018658055257\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5574 5575\n",
      "Training loss:-0.0010604355484247208\n",
      "check (8402,) ()\n",
      "epoch 5575\n",
      "====================================\n",
      "Epoch:  5575 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.403946188340807\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5575 5576\n",
      "Training loss:-0.0044046249240636826\n",
      "check (10000,) ()\n",
      "epoch 5576\n",
      "====================================\n",
      "Epoch:  5576 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.402618364418938\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5576 5577\n",
      "Training loss:-0.002841471927240491\n",
      "check (9312,) ()\n",
      "epoch 5577\n",
      "====================================\n",
      "Epoch:  5577 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.401828940290478\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5577 5578\n",
      "Training loss:-0.006107273045927286\n",
      "check (7885,) ()\n",
      "epoch 5578\n",
      "====================================\n",
      "Epoch:  5578 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.401039799211187\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5578 5579\n",
      "Training loss:-0.009027408435940742\n",
      "check (9957,) ()\n",
      "epoch 5579\n",
      "====================================\n",
      "Epoch:  5579 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.399892453844775\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5579 5580\n",
      "Training loss:-0.0015613207360729575\n",
      "check (7498,) ()\n",
      "epoch 5580\n",
      "====================================\n",
      "Epoch:  5580 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.399462365591399\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5580 5581\n",
      "Training loss:0.00011208026262465864\n",
      "check (8769,) ()\n",
      "epoch 5581\n",
      "====================================\n",
      "Epoch:  5581 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.399749148898048\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5581 5582\n",
      "Training loss:-0.0019491193816065788\n",
      "check (9300,) ()\n",
      "epoch 5582\n",
      "====================================\n",
      "Epoch:  5582 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.399677534933716\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5582 5583\n",
      "Training loss:-0.004741443786770105\n",
      "check (6467,) ()\n",
      "epoch 5583\n",
      "====================================\n",
      "Epoch:  5583 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.400322407307899\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5583 5584\n",
      "Training loss:-0.00922694243490696\n",
      "check (9615,) ()\n",
      "epoch 5584\n",
      "====================================\n",
      "Epoch:  5584 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.400429799426934\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5584 5585\n",
      "Training loss:0.0016240982804447412\n",
      "check (9874,) ()\n",
      "epoch 5585\n",
      "====================================\n",
      "Epoch:  5585 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.399283795881827\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5585 5586\n",
      "Training loss:-0.002341164043173194\n",
      "check (8945,) ()\n",
      "epoch 5586\n",
      "====================================\n",
      "Epoch:  5586 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.39813820264948\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5586 5587\n",
      "Training loss:-0.0041870297864079475\n",
      "check (7732,) ()\n",
      "epoch 5587\n",
      "====================================\n",
      "Epoch:  5587 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.398782888849114\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5587 5588\n",
      "Training loss:0.002662225626409054\n",
      "check (9008,) ()\n",
      "epoch 5588\n",
      "====================================\n",
      "Epoch:  5588 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.398711524695777\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5588 5589\n",
      "Training loss:0.002531798556447029\n",
      "check (7491,) ()\n",
      "epoch 5589\n",
      "====================================\n",
      "Epoch:  5589 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.398461263195562\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5589 5590\n",
      "Training loss:-0.00291324220597744\n",
      "check (8488,) ()\n",
      "epoch 5590\n",
      "====================================\n",
      "Epoch:  5590 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.398747763864042\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5590 5591\n",
      "Training loss:-0.003182572079822421\n",
      "check (7799,) ()\n",
      "epoch 5591\n",
      "====================================\n",
      "Epoch:  5591 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.398676444285458\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5591 5592\n",
      "Training loss:-0.006240640301257372\n",
      "check (8233,) ()\n",
      "epoch 5592\n",
      "====================================\n",
      "Epoch:  5592 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.398426323319027\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5592 5593\n",
      "Training loss:-0.0036425951402634382\n",
      "check (10000,) ()\n",
      "epoch 5593\n",
      "====================================\n",
      "Epoch:  5593 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.397103522259968\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5593 5594\n",
      "Training loss:-0.004069156479090452\n",
      "check (7945,) ()\n",
      "epoch 5594\n",
      "====================================\n",
      "Epoch:  5594 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.397747586700035\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5594 5595\n",
      "Training loss:0.0016889878315851092\n",
      "check (9245,) ()\n",
      "epoch 5595\n",
      "====================================\n",
      "Epoch:  5595 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.396246648793566\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5595 5596\n",
      "Training loss:-0.0072487723082304\n",
      "check (10000,) ()\n",
      "epoch 5596\n",
      "====================================\n",
      "Epoch:  5596 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.39385275196569\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5596 5597\n",
      "Training loss:-0.006540467031300068\n",
      "check (7287,) ()\n",
      "epoch 5597\n",
      "====================================\n",
      "Epoch:  5597 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.394497051992138\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5597 5598\n",
      "Training loss:-0.005021238699555397\n",
      "check (8912,) ()\n",
      "epoch 5598\n",
      "====================================\n",
      "Epoch:  5598 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.394426580921758\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5598 5599\n",
      "Training loss:-0.003744384739547968\n",
      "check (9655,) ()\n",
      "epoch 5599\n",
      "====================================\n",
      "Epoch:  5599 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.393284515091981\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5599 5600\n",
      "Training loss:-0.004517649300396442\n",
      "check (10000,) ()\n",
      "epoch 5600\n",
      "====================================\n",
      "Epoch:  5600 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.391785714285714\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5600 5601\n",
      "Training loss:0.001553525566123426\n",
      "Model saved\n",
      "check (9568,) ()\n",
      "epoch 5601\n",
      "====================================\n",
      "Epoch:  5601 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.391358685948937\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5601 5602\n",
      "Training loss:-0.007481556851416826\n",
      "check (7259,) ()\n",
      "epoch 5602\n",
      "====================================\n",
      "Epoch:  5602 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.391645840771153\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5602 5603\n",
      "Training loss:5.515781958820298e-05\n",
      "check (8776,) ()\n",
      "epoch 5603\n",
      "====================================\n",
      "Epoch:  5603 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.391575941459932\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5603 5604\n",
      "Training loss:0.0017444054828956723\n",
      "check (6266,) ()\n",
      "epoch 5604\n",
      "====================================\n",
      "Epoch:  5604 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.391149179157745\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5604 5605\n",
      "Training loss:-3.70621019101236e-05\n",
      "check (8601,) ()\n",
      "epoch 5605\n",
      "====================================\n",
      "Epoch:  5605 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.390365744870651\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5605 5606\n",
      "Training loss:-0.011150050908327103\n",
      "check (10000,) ()\n",
      "epoch 5606\n",
      "====================================\n",
      "Epoch:  5606 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.389760970388869\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5606 5607\n",
      "Training loss:0.0025208108127117157\n",
      "check (6736,) ()\n",
      "epoch 5607\n",
      "====================================\n",
      "Epoch:  5607 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.389691457107187\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5607 5608\n",
      "Training loss:0.0005252230912446976\n",
      "check (10000,) ()\n",
      "epoch 5608\n",
      "====================================\n",
      "Epoch:  5608 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -13.386947218259628\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5608 5609\n",
      "Training loss:0.00416567362844944\n",
      "check (10000,) ()\n",
      "epoch 5609\n",
      "====================================\n",
      "Epoch:  5609 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.385273667320378\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5609 5610\n",
      "Training loss:0.0003798187244683504\n",
      "check (10000,) ()\n",
      "epoch 5610\n",
      "====================================\n",
      "Epoch:  5610 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.383778966131906\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5610 5611\n",
      "Training loss:0.0035095466300845146\n",
      "check (9517,) ()\n",
      "epoch 5611\n",
      "====================================\n",
      "Epoch:  5611 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.382463019069684\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5611 5612\n",
      "Training loss:0.0006928623770363629\n",
      "check (9497,) ()\n",
      "epoch 5612\n",
      "====================================\n",
      "Epoch:  5612 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.381682109764789\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5612 5613\n",
      "Training loss:-0.00916031002998352\n",
      "check (8356,) ()\n",
      "epoch 5613\n",
      "====================================\n",
      "Epoch:  5613 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.380901478710138\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5613 5614\n",
      "Training loss:-0.005171924363821745\n",
      "check (8150,) ()\n",
      "epoch 5614\n",
      "====================================\n",
      "Epoch:  5614 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.380833630210189\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5614 5615\n",
      "Training loss:-0.0005317907780408859\n",
      "check (9887,) ()\n",
      "epoch 5615\n",
      "====================================\n",
      "Epoch:  5615 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.381121994657168\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5615 5616\n",
      "Training loss:-0.0027592137921601534\n",
      "check (9166,) ()\n",
      "epoch 5616\n",
      "====================================\n",
      "Epoch:  5616 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.380698005698006\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5616 5617\n",
      "Training loss:-0.0034791845828294754\n",
      "check (9023,) ()\n",
      "epoch 5617\n",
      "====================================\n",
      "Epoch:  5617 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.3799181057504\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5617 5618\n",
      "Training loss:-0.006358298473060131\n",
      "check (6603,) ()\n",
      "epoch 5618\n",
      "====================================\n",
      "Epoch:  5618 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.380384478462085\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5618 5619\n",
      "Training loss:0.0037363183218985796\n",
      "check (10000,) ()\n",
      "epoch 5619\n",
      "====================================\n",
      "Epoch:  5619 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.378537106246663\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5619 5620\n",
      "Training loss:0.0026005308609455824\n",
      "check (7383,) ()\n",
      "epoch 5620\n",
      "====================================\n",
      "Epoch:  5620 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.378113879003559\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5620 5621\n",
      "Training loss:-0.003992483951151371\n",
      "check (10000,) ()\n",
      "epoch 5621\n",
      "====================================\n",
      "Epoch:  5621 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.37733499377335\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5621 5622\n",
      "Training loss:-0.004472216125577688\n",
      "check (8561,) ()\n",
      "epoch 5622\n",
      "====================================\n",
      "Epoch:  5622 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.37726787620064\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5622 5623\n",
      "Training loss:-0.0016165858833119273\n",
      "check (10000,) ()\n",
      "epoch 5623\n",
      "====================================\n",
      "Epoch:  5623 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.376667259470034\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5623 5624\n",
      "Training loss:0.0012440673308447003\n",
      "check (10000,) ()\n",
      "epoch 5624\n",
      "====================================\n",
      "Epoch:  5624 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.375711237553343\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5624 5625\n",
      "Training loss:0.0015140388859435916\n",
      "check (7700,) ()\n",
      "epoch 5625\n",
      "====================================\n",
      "Epoch:  5625 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.374933333333333\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5625 5626\n",
      "Training loss:-0.00407731207087636\n",
      "check (8100,) ()\n",
      "epoch 5626\n",
      "====================================\n",
      "Epoch:  5626 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.375044436544615\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5626 5627\n",
      "Training loss:2.977583108076942e-06\n",
      "check (8100,) ()\n",
      "epoch 5627\n",
      "====================================\n",
      "Epoch:  5627 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.37533321485694\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5627 5628\n",
      "Training loss:-0.0019304808229207993\n",
      "check (8632,) ()\n",
      "epoch 5628\n",
      "====================================\n",
      "Epoch:  5628 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.376332622601279\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5628 5629\n",
      "Training loss:-0.0020035195630043745\n",
      "check (8384,) ()\n",
      "epoch 5629\n",
      "====================================\n",
      "Epoch:  5629 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.37573281222242\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5629 5630\n",
      "Training loss:-0.010777073912322521\n",
      "check (10000,) ()\n",
      "epoch 5630\n",
      "====================================\n",
      "Epoch:  5630 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.374777975133215\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5630 5631\n",
      "Training loss:-0.004204519093036652\n",
      "check (7356,) ()\n",
      "epoch 5631\n",
      "====================================\n",
      "Epoch:  5631 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.374178653880305\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5631 5632\n",
      "Training loss:0.00749852042645216\n",
      "check (8715,) ()\n",
      "epoch 5632\n",
      "====================================\n",
      "Epoch:  5632 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.373579545454545\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5632 5633\n",
      "Training loss:-0.0014156195102259517\n",
      "check (8529,) ()\n",
      "epoch 5633\n",
      "====================================\n",
      "Epoch:  5633 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.372980649742589\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5633 5634\n",
      "Training loss:0.007766543887555599\n",
      "check (7515,) ()\n",
      "epoch 5634\n",
      "====================================\n",
      "Epoch:  5634 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.372736954206603\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5634 5635\n",
      "Training loss:-0.0017859800718724728\n",
      "check (8589,) ()\n",
      "epoch 5635\n",
      "====================================\n",
      "Epoch:  5635 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.372315882874888\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5635 5636\n",
      "Training loss:-0.000797439191956073\n",
      "check (7676,) ()\n",
      "epoch 5636\n",
      "====================================\n",
      "Epoch:  5636 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.37154009936125\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5636 5637\n",
      "Training loss:-0.016194745898246765\n",
      "check (9676,) ()\n",
      "epoch 5637\n",
      "====================================\n",
      "Epoch:  5637 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.37058719176867\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5637 5638\n",
      "Training loss:-0.008217389695346355\n",
      "check (8046,) ()\n",
      "epoch 5638\n",
      "====================================\n",
      "Epoch:  5638 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.370876197233061\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5638 5639\n",
      "Training loss:-0.007182658649981022\n",
      "check (10000,) ()\n",
      "epoch 5639\n",
      "====================================\n",
      "Epoch:  5639 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.370278418159248\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5639 5640\n",
      "Training loss:-0.0009364037541672587\n",
      "check (8906,) ()\n",
      "epoch 5640\n",
      "====================================\n",
      "Epoch:  5640 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.368971631205675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5640 5641\n",
      "Training loss:-0.003919191658496857\n",
      "check (10000,) ()\n",
      "epoch 5641\n",
      "====================================\n",
      "Epoch:  5641 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.36660166637121\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5641 5642\n",
      "Training loss:-0.007608191110193729\n",
      "check (10000,) ()\n",
      "epoch 5642\n",
      "====================================\n",
      "Epoch:  5642 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.365650478553704\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5642 5643\n",
      "Training loss:0.0035453238524496555\n",
      "check (8761,) ()\n",
      "epoch 5643\n",
      "====================================\n",
      "Epoch:  5643 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.365585681375155\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5643 5644\n",
      "Training loss:-0.003007519757375121\n",
      "check (10000,) ()\n",
      "epoch 5644\n",
      "====================================\n",
      "Epoch:  5644 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.364989369241673\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5644 5645\n",
      "Training loss:-0.006724356207996607\n",
      "check (9686,) ()\n",
      "epoch 5645\n",
      "====================================\n",
      "Epoch:  5645 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.363507528786537\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5645 5646\n",
      "Training loss:-0.0023986671585589647\n",
      "check (10000,) ()\n",
      "epoch 5646\n",
      "====================================\n",
      "Epoch:  5646 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.361671980162948\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5646 5647\n",
      "Training loss:-0.00550981005653739\n",
      "check (7123,) ()\n",
      "epoch 5647\n",
      "====================================\n",
      "Epoch:  5647 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.361607933415973\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5647 5648\n",
      "Training loss:-0.007563239429146051\n",
      "check (8047,) ()\n",
      "epoch 5648\n",
      "====================================\n",
      "Epoch:  5648 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.361366855524079\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5648 5649\n",
      "Training loss:0.006303905043751001\n",
      "check (10000,) ()\n",
      "epoch 5649\n",
      "====================================\n",
      "Epoch:  5649 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.359001593202336\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5649 5650\n",
      "Training loss:-0.006457986310124397\n",
      "check (8202,) ()\n",
      "epoch 5650\n",
      "====================================\n",
      "Epoch:  5650 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.35858407079646\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5650 5651\n",
      "Training loss:-0.002398368902504444\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 5651\n",
      "====================================\n",
      "Epoch:  5651 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.357635816669616\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5651 5652\n",
      "Training loss:-0.005616387352347374\n",
      "check (10000,) ()\n",
      "epoch 5652\n",
      "====================================\n",
      "Epoch:  5652 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.356334041047417\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5652 5653\n",
      "Training loss:0.003813627175986767\n",
      "check (9868,) ()\n",
      "epoch 5653\n",
      "====================================\n",
      "Epoch:  5653 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.355209623208916\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5653 5654\n",
      "Training loss:-0.003916316200047731\n",
      "check (10000,) ()\n",
      "epoch 5654\n",
      "====================================\n",
      "Epoch:  5654 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.3537318712416\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5654 5655\n",
      "Training loss:-0.0013750579673796892\n",
      "check (10000,) ()\n",
      "epoch 5655\n",
      "====================================\n",
      "Epoch:  5655 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.351900972590627\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5655 5656\n",
      "Training loss:-0.0026448334101587534\n",
      "check (8662,) ()\n",
      "epoch 5656\n",
      "====================================\n",
      "Epoch:  5656 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.350601131541726\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5656 5657\n",
      "Training loss:-0.00636407732963562\n",
      "check (9318,) ()\n",
      "epoch 5657\n",
      "====================================\n",
      "Epoch:  5657 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.350008838607035\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5657 5658\n",
      "Training loss:-0.0012935952981933951\n",
      "check (8542,) ()\n",
      "epoch 5658\n",
      "====================================\n",
      "Epoch:  5658 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.34959349593496\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5658 5659\n",
      "Training loss:-0.005549976136535406\n",
      "check (5804,) ()\n",
      "epoch 5659\n",
      "====================================\n",
      "Epoch:  5659 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.350238558049126\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5659 5660\n",
      "Training loss:-0.0018347379518672824\n",
      "check (10000,) ()\n",
      "epoch 5660\n",
      "====================================\n",
      "Epoch:  5660 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.348056537102474\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5660 5661\n",
      "Training loss:-0.0004794090345967561\n",
      "check (7855,) ()\n",
      "epoch 5661\n",
      "====================================\n",
      "Epoch:  5661 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.347288464935524\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5661 5662\n",
      "Training loss:-0.003282190067693591\n",
      "check (9990,) ()\n",
      "epoch 5662\n",
      "====================================\n",
      "Epoch:  5662 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.347580360296716\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5662 5663\n",
      "Training loss:-0.0030123554170131683\n",
      "check (9643,) ()\n",
      "epoch 5663\n",
      "====================================\n",
      "Epoch:  5663 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.34716581317323\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5663 5664\n",
      "Training loss:-0.00454960810020566\n",
      "check (10000,) ()\n",
      "epoch 5664\n",
      "====================================\n",
      "Epoch:  5664 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.345162429378531\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5664 5665\n",
      "Training loss:-0.004054052755236626\n",
      "check (8079,) ()\n",
      "epoch 5665\n",
      "====================================\n",
      "Epoch:  5665 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.344395410414828\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5665 5666\n",
      "Training loss:-0.004037062171846628\n",
      "check (10000,) ()\n",
      "epoch 5666\n",
      "====================================\n",
      "Epoch:  5666 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.343805153547477\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5666 5667\n",
      "Training loss:-0.004483561031520367\n",
      "check (9063,) ()\n",
      "epoch 5667\n",
      "====================================\n",
      "Epoch:  5667 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.342332803952708\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5667 5668\n",
      "Training loss:-0.0031677342485636473\n",
      "check (9583,) ()\n",
      "epoch 5668\n",
      "====================================\n",
      "Epoch:  5668 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.341743119266056\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5668 5669\n",
      "Training loss:-0.001489512505941093\n",
      "check (10000,) ()\n",
      "epoch 5669\n",
      "====================================\n",
      "Epoch:  5669 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.340800846710177\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5669 5670\n",
      "Training loss:-0.005850862246006727\n",
      "check (7101,) ()\n",
      "epoch 5670\n",
      "====================================\n",
      "Epoch:  5670 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.341446208112874\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5670 5671\n",
      "Training loss:0.0002030905889114365\n",
      "check (9700,) ()\n",
      "epoch 5671\n",
      "====================================\n",
      "Epoch:  5671 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.34085699171222\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5671 5672\n",
      "Training loss:-0.007571328431367874\n",
      "check (9051,) ()\n",
      "epoch 5672\n",
      "====================================\n",
      "Epoch:  5672 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.340973201692524\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5672 5673\n",
      "Training loss:-0.008737188763916492\n",
      "check (7874,) ()\n",
      "epoch 5673\n",
      "====================================\n",
      "Epoch:  5673 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.341618191433104\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5673 5674\n",
      "Training loss:-0.005680404137820005\n",
      "check (10000,) ()\n",
      "epoch 5674\n",
      "====================================\n",
      "Epoch:  5674 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.340324286217836\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5674 5675\n",
      "Training loss:-0.004627819638699293\n",
      "check (9810,) ()\n",
      "epoch 5675\n",
      "====================================\n",
      "Epoch:  5675 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.339383259911894\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5675 5676\n",
      "Training loss:-0.0010092604206874967\n",
      "check (8859,) ()\n",
      "epoch 5676\n",
      "====================================\n",
      "Epoch:  5676 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.338266384778013\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5676 5677\n",
      "Training loss:-0.0042074513621628284\n",
      "check (8409,) ()\n",
      "epoch 5677\n",
      "====================================\n",
      "Epoch:  5677 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.337502201867183\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5677 5678\n",
      "Training loss:-0.0013604243285953999\n",
      "check (7111,) ()\n",
      "epoch 5678\n",
      "====================================\n",
      "Epoch:  5678 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.33814723494188\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5678 5679\n",
      "Training loss:-0.009487489238381386\n",
      "check (9761,) ()\n",
      "epoch 5679\n",
      "====================================\n",
      "Epoch:  5679 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.33720725479838\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5679 5680\n",
      "Training loss:-0.002866620197892189\n",
      "check (10000,) ()\n",
      "epoch 5680\n",
      "====================================\n",
      "Epoch:  5680 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.335387323943662\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5680 5681\n",
      "Training loss:-0.0036102989688515663\n",
      "check (8424,) ()\n",
      "epoch 5681\n",
      "====================================\n",
      "Epoch:  5681 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.334976236578067\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5681 5682\n",
      "Training loss:-0.0018914028769358993\n",
      "check (9035,) ()\n",
      "epoch 5682\n",
      "====================================\n",
      "Epoch:  5682 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.334213305174234\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5682 5683\n",
      "Training loss:-0.0026467260904610157\n",
      "check (8405,) ()\n",
      "epoch 5683\n",
      "====================================\n",
      "Epoch:  5683 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.334506422664086\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5683 5684\n",
      "Training loss:0.0008472639019601047\n",
      "check (7401,) ()\n",
      "epoch 5684\n",
      "====================================\n",
      "Epoch:  5684 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.334623504574244\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5684 5685\n",
      "Training loss:0.0011406444245949388\n",
      "check (7870,) ()\n",
      "epoch 5685\n",
      "====================================\n",
      "Epoch:  5685 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.334212840809148\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5685 5686\n",
      "Training loss:0.0012386934831738472\n",
      "check (10000,) ()\n",
      "epoch 5686\n",
      "====================================\n",
      "Epoch:  5686 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.332747098135773\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5686 5687\n",
      "Training loss:-0.0034360724966973066\n",
      "check (8864,) ()\n",
      "epoch 5687\n",
      "====================================\n",
      "Epoch:  5687 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.331985229470723\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5687 5688\n",
      "Training loss:-0.0041151815094053745\n",
      "check (10000,) ()\n",
      "epoch 5688\n",
      "====================================\n",
      "Epoch:  5688 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.330696202531646\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5688 5689\n",
      "Training loss:0.0007200321415439248\n",
      "check (8847,) ()\n",
      "epoch 5689\n",
      "====================================\n",
      "Epoch:  5689 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.32958340657409\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5689 5690\n",
      "Training loss:-0.005656942259520292\n",
      "check (8793,) ()\n",
      "epoch 5690\n",
      "====================================\n",
      "Epoch:  5690 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.328119507908612\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5690 5691\n",
      "Training loss:-0.002873695222660899\n",
      "check (7052,) ()\n",
      "epoch 5691\n",
      "====================================\n",
      "Epoch:  5691 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.328764716218592\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5691 5692\n",
      "Training loss:-0.007384293247014284\n",
      "check (10000,) ()\n",
      "epoch 5692\n",
      "====================================\n",
      "Epoch:  5692 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.327477160927618\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5692 5693\n",
      "Training loss:-0.0045621199533343315\n",
      "check (7577,) ()\n",
      "epoch 5693\n",
      "====================================\n",
      "Epoch:  5693 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.327770946776743\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5693 5694\n",
      "Training loss:-0.005881441757082939\n",
      "check (10000,) ()\n",
      "epoch 5694\n",
      "====================================\n",
      "Epoch:  5694 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.326835265191429\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5694 5695\n",
      "Training loss:0.002356237731873989\n",
      "check (6870,) ()\n",
      "epoch 5695\n",
      "====================================\n",
      "Epoch:  5695 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.327480245829674\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5695 5696\n",
      "Training loss:-0.0004316443810239434\n",
      "check (8531,) ()\n",
      "epoch 5696\n",
      "====================================\n",
      "Epoch:  5696 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.327949438202246\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5696 5697\n",
      "Training loss:0.0014409861760213971\n",
      "check (9289,) ()\n",
      "epoch 5697\n",
      "====================================\n",
      "Epoch:  5697 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.32683868702826\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5697 5698\n",
      "Training loss:-0.0007900879136286676\n",
      "check (10000,) ()\n",
      "epoch 5698\n",
      "====================================\n",
      "Epoch:  5698 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.326254826254827\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5698 5699\n",
      "Training loss:-0.010171263478696346\n",
      "check (8866,) ()\n",
      "epoch 5699\n",
      "====================================\n",
      "Epoch:  5699 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.326197578522548\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5699 5700\n",
      "Training loss:-0.005866345949470997\n",
      "check (9686,) ()\n",
      "epoch 5700\n",
      "====================================\n",
      "Epoch:  5700 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.325087719298246\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5700 5701\n",
      "Training loss:-0.004644844215363264\n",
      "Model saved\n",
      "check (7203,) ()\n",
      "epoch 5701\n",
      "====================================\n",
      "Epoch:  5701 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.325030696369058\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5701 5702\n",
      "Training loss:-0.0008534944499842823\n",
      "check (9056,) ()\n",
      "epoch 5702\n",
      "====================================\n",
      "Epoch:  5702 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.324096808137496\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5702 5703\n",
      "Training loss:-0.0029187994077801704\n",
      "check (7210,) ()\n",
      "epoch 5703\n",
      "====================================\n",
      "Epoch:  5703 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.324039978958442\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5703 5704\n",
      "Training loss:-0.00504135899245739\n",
      "check (9063,) ()\n",
      "epoch 5704\n",
      "====================================\n",
      "Epoch:  5704 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.32398316970547\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5704 5705\n",
      "Training loss:-0.0042962986044585705\n",
      "check (8568,) ()\n",
      "epoch 5705\n",
      "====================================\n",
      "Epoch:  5705 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.323926380368098\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5705 5706\n",
      "Training loss:-0.002730059204623103\n",
      "check (8387,) ()\n",
      "epoch 5706\n",
      "====================================\n",
      "Epoch:  5706 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.323869610935857\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5706 5707\n",
      "Training loss:-0.005008649546653032\n",
      "check (8005,) ()\n",
      "epoch 5707\n",
      "====================================\n",
      "Epoch:  5707 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.324163308217978\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5707 5708\n",
      "Training loss:-0.00660718372091651\n",
      "check (9545,) ()\n",
      "epoch 5708\n",
      "====================================\n",
      "Epoch:  5708 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.323405746320953\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5708 5709\n",
      "Training loss:-0.002680073259398341\n",
      "check (8097,) ()\n",
      "epoch 5709\n",
      "====================================\n",
      "Epoch:  5709 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.323699421965317\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5709 5710\n",
      "Training loss:-0.0023972170893102884\n",
      "check (10000,) ()\n",
      "epoch 5710\n",
      "====================================\n",
      "Epoch:  5710 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.322591943957969\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5710 5711\n",
      "Training loss:-0.002744971541687846\n",
      "check (9781,) ()\n",
      "epoch 5711\n",
      "====================================\n",
      "Epoch:  5711 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.3221852565225\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5711 5712\n",
      "Training loss:-0.004159440286457539\n",
      "check (9376,) ()\n",
      "epoch 5712\n",
      "====================================\n",
      "Epoch:  5712 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.321603641456583\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5712 5713\n",
      "Training loss:-0.0010794966947287321\n",
      "check (7982,) ()\n",
      "epoch 5713\n",
      "====================================\n",
      "Epoch:  5713 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.32224750568878\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5713 5714\n",
      "Training loss:-0.01334010623395443\n",
      "check (6050,) ()\n",
      "epoch 5714\n",
      "====================================\n",
      "Epoch:  5714 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.323241162058103\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5714 5715\n",
      "Training loss:-0.005703258793801069\n",
      "check (8764,) ()\n",
      "epoch 5715\n",
      "====================================\n",
      "Epoch:  5715 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.322309711286088\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5715 5716\n",
      "Training loss:0.007097230292856693\n",
      "check (8322,) ()\n",
      "epoch 5716\n",
      "====================================\n",
      "Epoch:  5716 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.3222533240028\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5716 5717\n",
      "Training loss:-0.0007806987268850207\n",
      "check (9207,) ()\n",
      "epoch 5717\n",
      "====================================\n",
      "Epoch:  5717 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.322371873360154\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5717 5718\n",
      "Training loss:-0.003670046105980873\n",
      "check (10000,) ()\n",
      "epoch 5718\n",
      "====================================\n",
      "Epoch:  5718 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.32109129066107\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5718 5719\n",
      "Training loss:-0.001484733889810741\n",
      "check (8781,) ()\n",
      "epoch 5719\n",
      "====================================\n",
      "Epoch:  5719 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.319286588564434\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5719 5720\n",
      "Training loss:-0.0007131820311769843\n",
      "check (7501,) ()\n",
      "epoch 5720\n",
      "====================================\n",
      "Epoch:  5720 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.31888111888112\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5720 5721\n",
      "Training loss:-7.110257865861058e-05\n",
      "check (8175,) ()\n",
      "epoch 5721\n",
      "====================================\n",
      "Epoch:  5721 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.318650585561965\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5721 5722\n",
      "Training loss:-0.0059249987825751305\n",
      "check (9034,) ()\n",
      "epoch 5722\n",
      "====================================\n",
      "Epoch:  5722 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.317546312478154\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5722 5723\n",
      "Training loss:-0.005645167548209429\n",
      "check (8121,) ()\n",
      "epoch 5723\n",
      "====================================\n",
      "Epoch:  5723 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.317665560020968\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5723 5724\n",
      "Training loss:-0.010131469927728176\n",
      "check (7619,) ()\n",
      "epoch 5724\n",
      "====================================\n",
      "Epoch:  5724 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.317959468902865\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5724 5725\n",
      "Training loss:-0.00294943037442863\n",
      "check (9728,) ()\n",
      "epoch 5725\n",
      "====================================\n",
      "Epoch:  5725 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.317205240174673\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5725 5726\n",
      "Training loss:0.006492351181805134\n",
      "check (9609,) ()\n",
      "epoch 5726\n",
      "====================================\n",
      "Epoch:  5726 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.317149842822214\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5726 5727\n",
      "Training loss:-0.0038916177581995726\n",
      "check (8028,) ()\n",
      "epoch 5727\n",
      "====================================\n",
      "Epoch:  5727 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.316396018858041\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5727 5728\n",
      "Training loss:0.004288480617105961\n",
      "check (8324,) ()\n",
      "epoch 5728\n",
      "====================================\n",
      "Epoch:  5728 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.315991620111731\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5728 5729\n",
      "Training loss:-0.004088938236236572\n",
      "check (6621,) ()\n",
      "epoch 5729\n",
      "====================================\n",
      "Epoch:  5729 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.316285564670972\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5729 5730\n",
      "Training loss:0.003040233626961708\n",
      "check (8872,) ()\n",
      "epoch 5730\n",
      "====================================\n",
      "Epoch:  5730 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.316230366492146\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5730 5731\n",
      "Training loss:-0.003908009268343449\n",
      "check (8013,) ()\n",
      "epoch 5731\n",
      "====================================\n",
      "Epoch:  5731 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.31617518757634\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5731 5732\n",
      "Training loss:0.0036910688504576683\n",
      "check (10000,) ()\n",
      "epoch 5732\n",
      "====================================\n",
      "Epoch:  5732 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.314375436147941\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5732 5733\n",
      "Training loss:-0.003197266487404704\n",
      "check (7599,) ()\n",
      "epoch 5733\n",
      "====================================\n",
      "Epoch:  5733 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.314320600034886\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5733 5734\n",
      "Training loss:0.00022121680376585573\n",
      "check (7485,) ()\n",
      "epoch 5734\n",
      "====================================\n",
      "Epoch:  5734 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.314091384722706\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5734 5735\n",
      "Training loss:-0.001419514650478959\n",
      "check (8665,) ()\n",
      "epoch 5735\n",
      "====================================\n",
      "Epoch:  5735 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.31333914559721\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5735 5736\n",
      "Training loss:-0.008827227167785168\n",
      "check (8017,) ()\n",
      "epoch 5736\n",
      "====================================\n",
      "Epoch:  5736 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.312935843793584\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5736 5737\n",
      "Training loss:-0.002247708151116967\n",
      "check (9000,) ()\n",
      "epoch 5737\n",
      "====================================\n",
      "Epoch:  5737 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.312532682586717\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5737 5738\n",
      "Training loss:0.0010604184353724122\n",
      "check (8647,) ()\n",
      "epoch 5738\n",
      "====================================\n",
      "Epoch:  5738 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.312478215406065\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5738 5739\n",
      "Training loss:-0.00220274250023067\n",
      "check (8125,) ()\n",
      "epoch 5739\n",
      "====================================\n",
      "Epoch:  5739 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.31242376720683\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5739 5740\n",
      "Training loss:-0.003180207684636116\n",
      "check (9160,) ()\n",
      "epoch 5740\n",
      "====================================\n",
      "Epoch:  5740 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.311324041811847\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5740 5741\n",
      "Training loss:-0.0014794645830988884\n",
      "check (10000,) ()\n",
      "epoch 5741\n",
      "====================================\n",
      "Epoch:  5741 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.30900539975614\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5741 5742\n",
      "Training loss:0.0007706115720793605\n",
      "check (9901,) ()\n",
      "epoch 5742\n",
      "====================================\n",
      "Epoch:  5742 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.30790665273424\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5742 5743\n",
      "Training loss:0.00525532104074955\n",
      "check (6899,) ()\n",
      "epoch 5743\n",
      "====================================\n",
      "Epoch:  5743 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.307504788438099\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5743 5744\n",
      "Training loss:0.0030600475147366524\n",
      "check (8611,) ()\n",
      "epoch 5744\n",
      "====================================\n",
      "Epoch:  5744 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.306928969359332\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5744 5745\n",
      "Training loss:-0.00542829092592001\n",
      "check (9125,) ()\n",
      "epoch 5745\n",
      "====================================\n",
      "Epoch:  5745 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.306527415143604\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5745 5746\n",
      "Training loss:0.0033464236184954643\n",
      "check (9280,) ()\n",
      "epoch 5746\n",
      "====================================\n",
      "Epoch:  5746 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.30595196658545\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5746 5747\n",
      "Training loss:-0.005927154328674078\n",
      "check (8109,) ()\n",
      "epoch 5747\n",
      "====================================\n",
      "Epoch:  5747 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.305028710631634\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5747 5748\n",
      "Training loss:-0.00938518438488245\n",
      "check (8882,) ()\n",
      "epoch 5748\n",
      "====================================\n",
      "Epoch:  5748 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.30375782881002\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5748 5749\n",
      "Training loss:-0.004771587438881397\n",
      "check (9390,) ()\n",
      "epoch 5749\n",
      "====================================\n",
      "Epoch:  5749 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.302661332405636\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5749 5750\n",
      "Training loss:-0.002040741266682744\n",
      "check (9056,) ()\n",
      "epoch 5750\n",
      "====================================\n",
      "Epoch:  5750 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.302608695652173\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5750 5751\n",
      "Training loss:-0.008915712125599384\n",
      "Model saved\n",
      "check (7708,) ()\n",
      "epoch 5751\n",
      "====================================\n",
      "Epoch:  5751 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -13.303425491218919\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5751 5752\n",
      "Training loss:-0.011284262873232365\n",
      "check (9648,) ()\n",
      "epoch 5752\n",
      "====================================\n",
      "Epoch:  5752 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.302155771905424\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5752 5753\n",
      "Training loss:-0.0062010926194489\n",
      "check (10000,) ()\n",
      "epoch 5753\n",
      "====================================\n",
      "Epoch:  5753 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.301060316356683\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5753 5754\n",
      "Training loss:-0.0015924684703350067\n",
      "check (10000,) ()\n",
      "epoch 5754\n",
      "====================================\n",
      "Epoch:  5754 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -13.298401112269726\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5754 5755\n",
      "Training loss:-0.0023142036516219378\n",
      "check (7670,) ()\n",
      "epoch 5755\n",
      "====================================\n",
      "Epoch:  5755 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.298001737619462\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5755 5756\n",
      "Training loss:-0.0014823824167251587\n",
      "check (7984,) ()\n",
      "epoch 5756\n",
      "====================================\n",
      "Epoch:  5756 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.297255038220987\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5756 5757\n",
      "Training loss:0.0013422309421002865\n",
      "check (7615,) ()\n",
      "epoch 5757\n",
      "====================================\n",
      "Epoch:  5757 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.29720340455098\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5757 5758\n",
      "Training loss:-0.002827567746862769\n",
      "check (7583,) ()\n",
      "epoch 5758\n",
      "====================================\n",
      "Epoch:  5758 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.297846474470303\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5758 5759\n",
      "Training loss:-0.012033148668706417\n",
      "check (9569,) ()\n",
      "epoch 5759\n",
      "====================================\n",
      "Epoch:  5759 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.297794756034033\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5759 5760\n",
      "Training loss:-0.006911288946866989\n",
      "check (10000,) ()\n",
      "epoch 5760\n",
      "====================================\n",
      "Epoch:  5760 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.296354166666667\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5760 5761\n",
      "Training loss:-0.001305416109971702\n",
      "check (10000,) ()\n",
      "epoch 5761\n",
      "====================================\n",
      "Epoch:  5761 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -13.293525429612915\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5761 5762\n",
      "Training loss:-0.0018806487787514925\n",
      "check (5420,) ()\n",
      "epoch 5762\n",
      "====================================\n",
      "Epoch:  5762 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-20.0\n",
      "Mean Reward of that batch -20.0\n",
      "Average Reward of all training: -13.294689343977785\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5762 5763\n",
      "Training loss:-0.0038075109478086233\n",
      "check (8934,) ()\n",
      "epoch 5763\n",
      "====================================\n",
      "Epoch:  5763 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.293770605587367\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5763 5764\n",
      "Training loss:-0.004683482460677624\n",
      "check (10000,) ()\n",
      "epoch 5764\n",
      "====================================\n",
      "Epoch:  5764 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.292158223455933\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5764 5765\n",
      "Training loss:0.003184514120221138\n",
      "check (9410,) ()\n",
      "epoch 5765\n",
      "====================================\n",
      "Epoch:  5765 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.29071986123157\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5765 5766\n",
      "Training loss:-0.000570767093449831\n",
      "check (9939,) ()\n",
      "epoch 5766\n",
      "====================================\n",
      "Epoch:  5766 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.289802289281997\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5766 5767\n",
      "Training loss:-0.0009141291375271976\n",
      "check (8697,) ()\n",
      "epoch 5767\n",
      "====================================\n",
      "Epoch:  5767 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.288711635165598\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5767 5768\n",
      "Training loss:0.0007481473730877042\n",
      "check (9070,) ()\n",
      "epoch 5768\n",
      "====================================\n",
      "Epoch:  5768 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.288314840499307\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5768 5769\n",
      "Training loss:-0.0008626860217191279\n",
      "check (7917,) ()\n",
      "epoch 5769\n",
      "====================================\n",
      "Epoch:  5769 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.288091523660947\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5769 5770\n",
      "Training loss:-0.004421028308570385\n",
      "check (8907,) ()\n",
      "epoch 5770\n",
      "====================================\n",
      "Epoch:  5770 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.287001733102253\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5770 5771\n",
      "Training loss:-0.0036537060514092445\n",
      "check (8594,) ()\n",
      "epoch 5771\n",
      "====================================\n",
      "Epoch:  5771 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.28643216080402\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5771 5772\n",
      "Training loss:-0.005176846869289875\n",
      "check (6006,) ()\n",
      "epoch 5772\n",
      "====================================\n",
      "Epoch:  5772 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.287422037422038\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5772 5773\n",
      "Training loss:-0.0007468689582310617\n",
      "check (7781,) ()\n",
      "epoch 5773\n",
      "====================================\n",
      "Epoch:  5773 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.287372250129915\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5773 5774\n",
      "Training loss:-0.0007987037533894181\n",
      "check (8611,) ()\n",
      "epoch 5774\n",
      "====================================\n",
      "Epoch:  5774 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.287149289920333\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5774 5775\n",
      "Training loss:-0.0008065397851169109\n",
      "check (7543,) ()\n",
      "epoch 5775\n",
      "====================================\n",
      "Epoch:  5775 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.287445887445887\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5775 5776\n",
      "Training loss:0.001525227795355022\n",
      "check (8798,) ()\n",
      "epoch 5776\n",
      "====================================\n",
      "Epoch:  5776 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.28722299168975\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5776 5777\n",
      "Training loss:-0.002939024707302451\n",
      "check (9749,) ()\n",
      "epoch 5777\n",
      "====================================\n",
      "Epoch:  5777 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.286827072875194\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5777 5778\n",
      "Training loss:-0.0019847475923597813\n",
      "check (8125,) ()\n",
      "epoch 5778\n",
      "====================================\n",
      "Epoch:  5778 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.286431291104188\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5778 5779\n",
      "Training loss:-0.006873173639178276\n",
      "check (8287,) ()\n",
      "epoch 5779\n",
      "====================================\n",
      "Epoch:  5779 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.285343485032012\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5779 5780\n",
      "Training loss:-0.0018078605644404888\n",
      "check (9645,) ()\n",
      "epoch 5780\n",
      "====================================\n",
      "Epoch:  5780 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.284948096885813\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5780 5781\n",
      "Training loss:-0.0005383967654779553\n",
      "check (7639,) ()\n",
      "epoch 5781\n",
      "====================================\n",
      "Epoch:  5781 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.284725825981663\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5781 5782\n",
      "Training loss:-0.005017738789319992\n",
      "check (10000,) ()\n",
      "epoch 5782\n",
      "====================================\n",
      "Epoch:  5782 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.284849533033553\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5782 5783\n",
      "Training loss:-0.001474877935834229\n",
      "check (9863,) ()\n",
      "epoch 5783\n",
      "====================================\n",
      "Epoch:  5783 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.283416911637559\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5783 5784\n",
      "Training loss:-0.0070859515108168125\n",
      "check (10000,) ()\n",
      "epoch 5784\n",
      "====================================\n",
      "Epoch:  5784 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.282676348547717\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5784 5785\n",
      "Training loss:-0.0019235456129536033\n",
      "check (8191,) ()\n",
      "epoch 5785\n",
      "====================================\n",
      "Epoch:  5785 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.28141745894555\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5785 5786\n",
      "Training loss:-0.0014046354917809367\n",
      "check (9066,) ()\n",
      "epoch 5786\n",
      "====================================\n",
      "Epoch:  5786 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.280850328378845\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5786 5787\n",
      "Training loss:-0.004203313961625099\n",
      "check (6521,) ()\n",
      "epoch 5787\n",
      "====================================\n",
      "Epoch:  5787 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.281320200449283\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5787 5788\n",
      "Training loss:-0.000779578520450741\n",
      "check (6556,) ()\n",
      "epoch 5788\n",
      "====================================\n",
      "Epoch:  5788 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.28230822391154\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5788 5789\n",
      "Training loss:0.0002636167628224939\n",
      "check (9321,) ()\n",
      "epoch 5789\n",
      "====================================\n",
      "Epoch:  5789 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.281913974779755\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5789 5790\n",
      "Training loss:-0.0030506299808621407\n",
      "check (9594,) ()\n",
      "epoch 5790\n",
      "====================================\n",
      "Epoch:  5790 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.281519861830743\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5790 5791\n",
      "Training loss:-0.004170091822743416\n",
      "check (9021,) ()\n",
      "epoch 5791\n",
      "====================================\n",
      "Epoch:  5791 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.281298566741496\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5791 5792\n",
      "Training loss:-0.010178040713071823\n",
      "check (8139,) ()\n",
      "epoch 5792\n",
      "====================================\n",
      "Epoch:  5792 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.2810773480663\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5792 5793\n",
      "Training loss:-0.005574462935328484\n",
      "check (10000,) ()\n",
      "epoch 5793\n",
      "====================================\n",
      "Epoch:  5793 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.279302606594165\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5793 5794\n",
      "Training loss:-0.0019335899269208312\n",
      "check (9787,) ()\n",
      "epoch 5794\n",
      "====================================\n",
      "Epoch:  5794 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.27890921643079\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5794 5795\n",
      "Training loss:-0.002817401196807623\n",
      "check (9609,) ()\n",
      "epoch 5795\n",
      "====================================\n",
      "Epoch:  5795 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.276962899050906\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5795 5796\n",
      "Training loss:-0.0029859619680792093\n",
      "check (10000,) ()\n",
      "epoch 5796\n",
      "====================================\n",
      "Epoch:  5796 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.27639751552795\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5796 5797\n",
      "Training loss:0.0012353984639048576\n",
      "check (8654,) ()\n",
      "epoch 5797\n",
      "====================================\n",
      "Epoch:  5797 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.276004830084526\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5797 5798\n",
      "Training loss:0.005033723544329405\n",
      "check (8676,) ()\n",
      "epoch 5798\n",
      "====================================\n",
      "Epoch:  5798 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.275612280096585\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5798 5799\n",
      "Training loss:-0.004926871508359909\n",
      "check (9390,) ()\n",
      "epoch 5799\n",
      "====================================\n",
      "Epoch:  5799 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.275219865494051\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5799 5800\n",
      "Training loss:-0.005851409863680601\n",
      "check (9702,) ()\n",
      "epoch 5800\n",
      "====================================\n",
      "Epoch:  5800 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.274482758620689\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5800 5801\n",
      "Training loss:-0.0037169533316046\n",
      "Model saved\n",
      "check (8737,) ()\n",
      "epoch 5801\n",
      "====================================\n",
      "Epoch:  5801 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.273745905878297\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5801 5802\n",
      "Training loss:-0.002381160156801343\n",
      "check (9834,) ()\n",
      "epoch 5802\n",
      "====================================\n",
      "Epoch:  5802 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.27231988969321\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5802 5803\n",
      "Training loss:-0.003783132415264845\n",
      "check (8697,) ()\n",
      "epoch 5803\n",
      "====================================\n",
      "Epoch:  5803 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.2722729622609\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5803 5804\n",
      "Training loss:-0.0037244586274027824\n",
      "check (9246,) ()\n",
      "epoch 5804\n",
      "====================================\n",
      "Epoch:  5804 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.271881461061337\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5804 5805\n",
      "Training loss:0.0007863264181651175\n",
      "check (9058,) ()\n",
      "epoch 5805\n",
      "====================================\n",
      "Epoch:  5805 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.271317829457365\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5805 5806\n",
      "Training loss:8.318297477671877e-05\n",
      "check (8423,) ()\n",
      "epoch 5806\n",
      "====================================\n",
      "Epoch:  5806 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.270926627626594\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5806 5807\n",
      "Training loss:0.003914713393896818\n",
      "check (8941,) ()\n",
      "epoch 5807\n",
      "====================================\n",
      "Epoch:  5807 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.269674530738763\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5807 5808\n",
      "Training loss:-0.0017031354364007711\n",
      "check (10000,) ()\n",
      "epoch 5808\n",
      "====================================\n",
      "Epoch:  5808 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.268767217630854\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5808 5809\n",
      "Training loss:-0.005989429075270891\n",
      "check (10000,) ()\n",
      "epoch 5809\n",
      "====================================\n",
      "Epoch:  5809 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.26837665691169\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5809 5810\n",
      "Training loss:0.0005912284832447767\n",
      "check (8856,) ()\n",
      "epoch 5810\n",
      "====================================\n",
      "Epoch:  5810 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.267297762478485\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5810 5811\n",
      "Training loss:0.004738076124340296\n",
      "check (10000,) ()\n",
      "epoch 5811\n",
      "====================================\n",
      "Epoch:  5811 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.265530889691963\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5811 5812\n",
      "Training loss:0.000533119949977845\n",
      "check (8001,) ()\n",
      "epoch 5812\n",
      "====================================\n",
      "Epoch:  5812 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.264796971782518\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5812 5813\n",
      "Training loss:-0.0010201495606452227\n",
      "check (8158,) ()\n",
      "epoch 5813\n",
      "====================================\n",
      "Epoch:  5813 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.2644073628075\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5813 5814\n",
      "Training loss:0.0005692801787517965\n",
      "check (7269,) ()\n",
      "epoch 5814\n",
      "====================================\n",
      "Epoch:  5814 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.264705882352942\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5814 5815\n",
      "Training loss:-0.00524553470313549\n",
      "check (8038,) ()\n",
      "epoch 5815\n",
      "====================================\n",
      "Epoch:  5815 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.26500429922614\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5815 5816\n",
      "Training loss:-0.004810278303921223\n",
      "check (10000,) ()\n",
      "epoch 5816\n",
      "====================================\n",
      "Epoch:  5816 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -13.262379642365888\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5816 5817\n",
      "Training loss:-0.0013365631457418203\n",
      "check (9958,) ()\n",
      "epoch 5817\n",
      "====================================\n",
      "Epoch:  5817 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.260787347429947\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5817 5818\n",
      "Training loss:-0.00048678877647034824\n",
      "check (9150,) ()\n",
      "epoch 5818\n",
      "====================================\n",
      "Epoch:  5818 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.26074252320385\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5818 5819\n",
      "Training loss:-0.005607733502984047\n",
      "check (10000,) ()\n",
      "epoch 5819\n",
      "====================================\n",
      "Epoch:  5819 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.25897920604915\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5819 5820\n",
      "Training loss:-0.0033395898062735796\n",
      "check (10000,) ()\n",
      "epoch 5820\n",
      "====================================\n",
      "Epoch:  5820 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.258075601374571\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5820 5821\n",
      "Training loss:-0.004264435730874538\n",
      "check (9682,) ()\n",
      "epoch 5821\n",
      "====================================\n",
      "Epoch:  5821 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.256656931798661\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5821 5822\n",
      "Training loss:-0.0052829161286354065\n",
      "check (10000,) ()\n",
      "epoch 5822\n",
      "====================================\n",
      "Epoch:  5822 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.254895225008589\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5822 5823\n",
      "Training loss:-0.007432527840137482\n",
      "check (8075,) ()\n",
      "epoch 5823\n",
      "====================================\n",
      "Epoch:  5823 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.254164520006869\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5823 5824\n",
      "Training loss:-0.004308071918785572\n",
      "check (8490,) ()\n",
      "epoch 5824\n",
      "====================================\n",
      "Epoch:  5824 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.25360576923077\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5824 5825\n",
      "Training loss:-0.013745796866714954\n",
      "check (9281,) ()\n",
      "epoch 5825\n",
      "====================================\n",
      "Epoch:  5825 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.253562231759657\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5825 5826\n",
      "Training loss:0.0016590439481660724\n",
      "check (9700,) ()\n",
      "epoch 5826\n",
      "====================================\n",
      "Epoch:  5826 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.253003776175763\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5826 5827\n",
      "Training loss:-0.0014044103445485234\n",
      "check (10000,) ()\n",
      "epoch 5827\n",
      "====================================\n",
      "Epoch:  5827 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.2515874377896\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5827 5828\n",
      "Training loss:0.0009531722753308713\n",
      "check (8776,) ()\n",
      "epoch 5828\n",
      "====================================\n",
      "Epoch:  5828 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.251887439945092\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5828 5829\n",
      "Training loss:0.0012821622658520937\n",
      "check (10000,) ()\n",
      "epoch 5829\n",
      "====================================\n",
      "Epoch:  5829 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.250128667009779\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5829 5830\n",
      "Training loss:-0.007286885287612677\n",
      "check (10000,) ()\n",
      "epoch 5830\n",
      "====================================\n",
      "Epoch:  5830 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.249056603773585\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5830 5831\n",
      "Training loss:-0.007387178018689156\n",
      "check (10000,) ()\n",
      "epoch 5831\n",
      "====================================\n",
      "Epoch:  5831 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.24764191390842\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5831 5832\n",
      "Training loss:0.00035482787643559277\n",
      "check (7372,) ()\n",
      "epoch 5832\n",
      "====================================\n",
      "Epoch:  5832 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.247942386831276\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5832 5833\n",
      "Training loss:-0.008050240576267242\n",
      "check (10000,) ()\n",
      "epoch 5833\n",
      "====================================\n",
      "Epoch:  5833 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.246185496314075\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5833 5834\n",
      "Training loss:-0.00014281120093073696\n",
      "check (9787,) ()\n",
      "epoch 5834\n",
      "====================================\n",
      "Epoch:  5834 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.24580047994515\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5834 5835\n",
      "Training loss:-0.006373132579028606\n",
      "check (9992,) ()\n",
      "epoch 5835\n",
      "====================================\n",
      "Epoch:  5835 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.244215938303341\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5835 5836\n",
      "Training loss:-0.0040278746746480465\n",
      "check (9110,) ()\n",
      "epoch 5836\n",
      "====================================\n",
      "Epoch:  5836 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.243831391363948\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5836 5837\n",
      "Training loss:-0.00736503629013896\n",
      "check (7629,) ()\n",
      "epoch 5837\n",
      "====================================\n",
      "Epoch:  5837 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.243618297070412\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5837 5838\n",
      "Training loss:-0.004966074600815773\n",
      "check (8882,) ()\n",
      "epoch 5838\n",
      "====================================\n",
      "Epoch:  5838 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.242548818088386\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5838 5839\n",
      "Training loss:-0.0003788309695664793\n",
      "check (9257,) ()\n",
      "epoch 5839\n",
      "====================================\n",
      "Epoch:  5839 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.24216475423874\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5839 5840\n",
      "Training loss:-0.002523422474041581\n",
      "check (10000,) ()\n",
      "epoch 5840\n",
      "====================================\n",
      "Epoch:  5840 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.24126712328767\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5840 5841\n",
      "Training loss:-0.003925112076103687\n",
      "check (8095,) ()\n",
      "epoch 5841\n",
      "====================================\n",
      "Epoch:  5841 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.240541003252869\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5841 5842\n",
      "Training loss:-0.0001975712802959606\n",
      "check (8009,) ()\n",
      "epoch 5842\n",
      "====================================\n",
      "Epoch:  5842 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.240157480314961\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5842 5843\n",
      "Training loss:0.001205621287226677\n",
      "check (8716,) ()\n",
      "epoch 5843\n",
      "====================================\n",
      "Epoch:  5843 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.240116378572651\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5843 5844\n",
      "Training loss:-0.0036716714967042208\n",
      "check (7634,) ()\n",
      "epoch 5844\n",
      "====================================\n",
      "Epoch:  5844 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.239904175222451\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5844 5845\n",
      "Training loss:0.004395694471895695\n",
      "check (10000,) ()\n",
      "epoch 5845\n",
      "====================================\n",
      "Epoch:  5845 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.237810094097519\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5845 5846\n",
      "Training loss:-0.006039467640221119\n",
      "check (10000,) ()\n",
      "epoch 5846\n",
      "====================================\n",
      "Epoch:  5846 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.236400957919946\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5846 5847\n",
      "Training loss:-0.006046256981790066\n",
      "check (9144,) ()\n",
      "epoch 5847\n",
      "====================================\n",
      "Epoch:  5847 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.236360526765862\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5847 5848\n",
      "Training loss:-0.0034312759526073933\n",
      "check (9717,) ()\n",
      "epoch 5848\n",
      "====================================\n",
      "Epoch:  5848 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.234781121751025\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5848 5849\n",
      "Training loss:-0.0010412696283310652\n",
      "check (9993,) ()\n",
      "epoch 5849\n",
      "====================================\n",
      "Epoch:  5849 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.234740981364336\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5849 5850\n",
      "Training loss:-0.0056779165752232075\n",
      "check (7227,) ()\n",
      "epoch 5850\n",
      "====================================\n",
      "Epoch:  5850 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.235213675213675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5850 5851\n",
      "Training loss:-0.0038150509353727102\n",
      "Model saved\n",
      "check (8737,) ()\n",
      "epoch 5851\n",
      "====================================\n",
      "Epoch:  5851 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.23483165270894\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5851 5852\n",
      "Training loss:-0.003421820467337966\n",
      "check (10000,) ()\n",
      "epoch 5852\n",
      "====================================\n",
      "Epoch:  5852 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.233766233766234\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5852 5853\n",
      "Training loss:-0.0010472771245986223\n",
      "check (9777,) ()\n",
      "epoch 5853\n",
      "====================================\n",
      "Epoch:  5853 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.232188621219887\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5853 5854\n",
      "Training loss:-0.007114114239811897\n",
      "check (7774,) ()\n",
      "epoch 5854\n",
      "====================================\n",
      "Epoch:  5854 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.231807311240178\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5854 5855\n",
      "Training loss:-0.00921674259006977\n",
      "check (9106,) ()\n",
      "epoch 5855\n",
      "====================================\n",
      "Epoch:  5855 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.231596925704526\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5855 5856\n",
      "Training loss:-0.007986793294548988\n",
      "check (9898,) ()\n",
      "epoch 5856\n",
      "====================================\n",
      "Epoch:  5856 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.23155737704918\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5856 5857\n",
      "Training loss:-0.007954125292599201\n",
      "check (9097,) ()\n",
      "epoch 5857\n",
      "====================================\n",
      "Epoch:  5857 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.230664162540549\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5857 5858\n",
      "Training loss:-0.008003363385796547\n",
      "check (7810,) ()\n",
      "epoch 5858\n",
      "====================================\n",
      "Epoch:  5858 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.230795493342438\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5858 5859\n",
      "Training loss:-0.00017041391402017325\n",
      "check (7252,) ()\n",
      "epoch 5859\n",
      "====================================\n",
      "Epoch:  5859 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.231097456903909\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5859 5860\n",
      "Training loss:-0.004111224319785833\n",
      "check (9958,) ()\n",
      "epoch 5860\n",
      "====================================\n",
      "Epoch:  5860 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.231058020477816\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5860 5861\n",
      "Training loss:0.0006831552600488067\n",
      "check (8789,) ()\n",
      "epoch 5861\n",
      "====================================\n",
      "Epoch:  5861 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.231189216857192\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5861 5862\n",
      "Training loss:-0.00256333383731544\n",
      "check (9164,) ()\n",
      "epoch 5862\n",
      "====================================\n",
      "Epoch:  5862 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.230126236779256\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5862 5863\n",
      "Training loss:-0.0008617167477495968\n",
      "check (9585,) ()\n",
      "epoch 5863\n",
      "====================================\n",
      "Epoch:  5863 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.229404741599863\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5863 5864\n",
      "Training loss:-0.0087809506803751\n",
      "check (10000,) ()\n",
      "epoch 5864\n",
      "====================================\n",
      "Epoch:  5864 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.2274897680764\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5864 5865\n",
      "Training loss:0.0003536605800036341\n",
      "check (7184,) ()\n",
      "epoch 5865\n",
      "====================================\n",
      "Epoch:  5865 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.227791986359762\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5865 5866\n",
      "Training loss:-0.010324380360543728\n",
      "check (6817,) ()\n",
      "epoch 5866\n",
      "====================================\n",
      "Epoch:  5866 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -13.228605523354927\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5866 5867\n",
      "Training loss:0.0055326540023088455\n",
      "check (8698,) ()\n",
      "epoch 5867\n",
      "====================================\n",
      "Epoch:  5867 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.228737003579342\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5867 5868\n",
      "Training loss:-0.00435048621147871\n",
      "check (10000,) ()\n",
      "epoch 5868\n",
      "====================================\n",
      "Epoch:  5868 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.226993865030675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5868 5869\n",
      "Training loss:-0.003984902054071426\n",
      "check (8388,) ()\n",
      "epoch 5869\n",
      "====================================\n",
      "Epoch:  5869 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.226784801499404\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5869 5870\n",
      "Training loss:-0.001805692445486784\n",
      "check (8514,) ()\n",
      "epoch 5870\n",
      "====================================\n",
      "Epoch:  5870 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.227086882453152\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5870 5871\n",
      "Training loss:-0.0011602365411818027\n",
      "check (10000,) ()\n",
      "epoch 5871\n",
      "====================================\n",
      "Epoch:  5871 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.225855901890649\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5871 5872\n",
      "Training loss:-0.0020584380254149437\n",
      "check (9541,) ()\n",
      "epoch 5872\n",
      "====================================\n",
      "Epoch:  5872 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.225136239782016\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5872 5873\n",
      "Training loss:-0.009537212550640106\n",
      "check (10000,) ()\n",
      "epoch 5873\n",
      "====================================\n",
      "Epoch:  5873 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.224246552017709\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5873 5874\n",
      "Training loss:-0.012015231885015965\n",
      "check (9442,) ()\n",
      "epoch 5874\n",
      "====================================\n",
      "Epoch:  5874 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.223527408920667\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5874 5875\n",
      "Training loss:-0.008188250474631786\n",
      "check (10000,) ()\n",
      "epoch 5875\n",
      "====================================\n",
      "Epoch:  5875 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.22263829787234\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5875 5876\n",
      "Training loss:-0.007352712098509073\n",
      "check (8879,) ()\n",
      "epoch 5876\n",
      "====================================\n",
      "Epoch:  5876 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.221749489448605\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5876 5877\n",
      "Training loss:-0.014475514180958271\n",
      "check (8462,) ()\n",
      "epoch 5877\n",
      "====================================\n",
      "Epoch:  5877 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.220350518972264\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5877 5878\n",
      "Training loss:-0.006087218411266804\n",
      "check (9533,) ()\n",
      "epoch 5878\n",
      "====================================\n",
      "Epoch:  5878 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.219802653963933\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5878 5879\n",
      "Training loss:-0.0007187551236711442\n",
      "check (8240,) ()\n",
      "epoch 5879\n",
      "====================================\n",
      "Epoch:  5879 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.219595169246471\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5879 5880\n",
      "Training loss:-0.00765336025506258\n",
      "check (9097,) ()\n",
      "epoch 5880\n",
      "====================================\n",
      "Epoch:  5880 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.219557823129252\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5880 5881\n",
      "Training loss:0.0005427494179457426\n",
      "check (8983,) ()\n",
      "epoch 5881\n",
      "====================================\n",
      "Epoch:  5881 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.218840333276654\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5881 5882\n",
      "Training loss:0.002819867804646492\n",
      "check (10000,) ()\n",
      "epoch 5882\n",
      "====================================\n",
      "Epoch:  5882 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.21710302618157\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5882 5883\n",
      "Training loss:-0.010804933495819569\n",
      "check (7952,) ()\n",
      "epoch 5883\n",
      "====================================\n",
      "Epoch:  5883 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.216726160122386\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5883 5884\n",
      "Training loss:-0.004183073993772268\n",
      "check (9301,) ()\n",
      "epoch 5884\n",
      "====================================\n",
      "Epoch:  5884 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.216689326988444\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5884 5885\n",
      "Training loss:-0.006206165999174118\n",
      "check (7468,) ()\n",
      "epoch 5885\n",
      "====================================\n",
      "Epoch:  5885 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.215802888700084\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5885 5886\n",
      "Training loss:-0.0075363656505942345\n",
      "check (8502,) ()\n",
      "epoch 5886\n",
      "====================================\n",
      "Epoch:  5886 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.215596330275229\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5886 5887\n",
      "Training loss:-0.0001120629021897912\n",
      "check (8667,) ()\n",
      "epoch 5887\n",
      "====================================\n",
      "Epoch:  5887 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.215219976218787\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5887 5888\n",
      "Training loss:-0.004385120235383511\n",
      "check (8087,) ()\n",
      "epoch 5888\n",
      "====================================\n",
      "Epoch:  5888 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.215183423913043\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5888 5889\n",
      "Training loss:-0.004969052039086819\n",
      "check (10000,) ()\n",
      "epoch 5889\n",
      "====================================\n",
      "Epoch:  5889 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.214297843436917\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5889 5890\n",
      "Training loss:-0.005100238602608442\n",
      "check (9552,) ()\n",
      "epoch 5890\n",
      "====================================\n",
      "Epoch:  5890 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.213921901528014\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5890 5891\n",
      "Training loss:-0.0009923939360305667\n",
      "check (9304,) ()\n",
      "epoch 5891\n",
      "====================================\n",
      "Epoch:  5891 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.212867085384485\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5891 5892\n",
      "Training loss:-0.0002857275540009141\n",
      "check (9204,) ()\n",
      "epoch 5892\n",
      "====================================\n",
      "Epoch:  5892 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.213000678886626\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5892 5893\n",
      "Training loss:-0.0066834548488259315\n",
      "check (10000,) ()\n",
      "epoch 5893\n",
      "====================================\n",
      "Epoch:  5893 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.210928219921941\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5893 5894\n",
      "Training loss:-0.0013534176396206021\n",
      "check (7785,) ()\n",
      "epoch 5894\n",
      "====================================\n",
      "Epoch:  5894 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.210892432982694\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5894 5895\n",
      "Training loss:-0.0008217759313993156\n",
      "check (8791,) ()\n",
      "epoch 5895\n",
      "====================================\n",
      "Epoch:  5895 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.210517387616624\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5895 5896\n",
      "Training loss:0.0034320708364248276\n",
      "check (10000,) ()\n",
      "epoch 5896\n",
      "====================================\n",
      "Epoch:  5896 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.208446404341927\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5896 5897\n",
      "Training loss:-0.00833516288548708\n",
      "check (10000,) ()\n",
      "epoch 5897\n",
      "====================================\n",
      "Epoch:  5897 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.2068848567068\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5897 5898\n",
      "Training loss:-0.004393856972455978\n",
      "check (6123,) ()\n",
      "epoch 5898\n",
      "====================================\n",
      "Epoch:  5898 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.207527975584943\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5898 5899\n",
      "Training loss:0.002750946208834648\n",
      "check (8487,) ()\n",
      "epoch 5899\n",
      "====================================\n",
      "Epoch:  5899 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.20766231564672\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5899 5900\n",
      "Training loss:-0.004796439316123724\n",
      "check (8571,) ()\n",
      "epoch 5900\n",
      "====================================\n",
      "Epoch:  5900 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.207457627118645\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5900 5901\n",
      "Training loss:-0.007281527854502201\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 5901\n",
      "====================================\n",
      "Epoch:  5901 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.206066768344348\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5901 5902\n",
      "Training loss:-0.005479669198393822\n",
      "check (8595,) ()\n",
      "epoch 5902\n",
      "====================================\n",
      "Epoch:  5902 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.205015249068113\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5902 5903\n",
      "Training loss:0.00035002100048586726\n",
      "check (10000,) ()\n",
      "epoch 5903\n",
      "====================================\n",
      "Epoch:  5903 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.20328646450957\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5903 5904\n",
      "Training loss:-0.0002926485030911863\n",
      "check (10000,) ()\n",
      "epoch 5904\n",
      "====================================\n",
      "Epoch:  5904 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.200880758807589\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5904 5905\n",
      "Training loss:-0.0014440905069932342\n",
      "check (7121,) ()\n",
      "epoch 5905\n",
      "====================================\n",
      "Epoch:  5905 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.201524132091448\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5905 5906\n",
      "Training loss:-0.006572050042450428\n",
      "check (8075,) ()\n",
      "epoch 5906\n",
      "====================================\n",
      "Epoch:  5906 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.20149001015916\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5906 5907\n",
      "Training loss:-0.005198915023356676\n",
      "check (10000,) ()\n",
      "epoch 5907\n",
      "====================================\n",
      "Epoch:  5907 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.200440155747419\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5907 5908\n",
      "Training loss:0.006592877209186554\n",
      "check (10000,) ()\n",
      "epoch 5908\n",
      "====================================\n",
      "Epoch:  5908 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.199898442789438\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5908 5909\n",
      "Training loss:0.00260370597243309\n",
      "check (7827,) ()\n",
      "epoch 5909\n",
      "====================================\n",
      "Epoch:  5909 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.199526146556101\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5909 5910\n",
      "Training loss:-0.0024781159590929747\n",
      "check (8861,) ()\n",
      "epoch 5910\n",
      "====================================\n",
      "Epoch:  5910 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.199492385786803\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5910 5911\n",
      "Training loss:-0.0014778614277020097\n",
      "check (10000,) ()\n",
      "epoch 5911\n",
      "====================================\n",
      "Epoch:  5911 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.197090170867874\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5911 5912\n",
      "Training loss:-0.004245365038514137\n",
      "check (10000,) ()\n",
      "epoch 5912\n",
      "====================================\n",
      "Epoch:  5912 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.196041948579161\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5912 5913\n",
      "Training loss:0.0020296121947467327\n",
      "check (10000,) ()\n",
      "epoch 5913\n",
      "====================================\n",
      "Epoch:  5913 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -13.193472010823609\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5913 5914\n",
      "Training loss:-0.005136935971677303\n",
      "check (8337,) ()\n",
      "epoch 5914\n",
      "====================================\n",
      "Epoch:  5914 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.193439296584376\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5914 5915\n",
      "Training loss:-0.006667556241154671\n",
      "check (8931,) ()\n",
      "epoch 5915\n",
      "====================================\n",
      "Epoch:  5915 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.192223161453931\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5915 5916\n",
      "Training loss:-0.0019513870356604457\n",
      "check (7850,) ()\n",
      "epoch 5916\n",
      "====================================\n",
      "Epoch:  5916 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.19185260311021\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5916 5917\n",
      "Training loss:-0.011876480653882027\n",
      "check (8665,) ()\n",
      "epoch 5917\n",
      "====================================\n",
      "Epoch:  5917 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.190975156329221\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5917 5918\n",
      "Training loss:-0.002622604602947831\n",
      "check (9637,) ()\n",
      "epoch 5918\n",
      "====================================\n",
      "Epoch:  5918 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.189929030077728\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5918 5919\n",
      "Training loss:-1.1808659110101871e-05\n",
      "check (7395,) ()\n",
      "epoch 5919\n",
      "====================================\n",
      "Epoch:  5919 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.190065889508363\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5919 5920\n",
      "Training loss:0.0002358251513214782\n",
      "check (9329,) ()\n",
      "epoch 5920\n",
      "====================================\n",
      "Epoch:  5920 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.189864864864864\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5920 5921\n",
      "Training loss:-0.0009111688123084605\n",
      "check (10000,) ()\n",
      "epoch 5921\n",
      "====================================\n",
      "Epoch:  5921 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.18898834656308\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5921 5922\n",
      "Training loss:-0.004951426759362221\n",
      "check (8557,) ()\n",
      "epoch 5922\n",
      "====================================\n",
      "Epoch:  5922 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.188618709895305\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5922 5923\n",
      "Training loss:-0.0055267084389925\n",
      "check (10000,) ()\n",
      "epoch 5923\n",
      "====================================\n",
      "Epoch:  5923 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.186898531149755\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5923 5924\n",
      "Training loss:-5.239334132056683e-05\n",
      "check (9041,) ()\n",
      "epoch 5924\n",
      "====================================\n",
      "Epoch:  5924 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.186698176907495\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5924 5925\n",
      "Training loss:-0.007878266274929047\n",
      "check (10000,) ()\n",
      "epoch 5925\n",
      "====================================\n",
      "Epoch:  5925 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.185654008438819\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5925 5926\n",
      "Training loss:-0.0043762861751019955\n",
      "check (8272,) ()\n",
      "epoch 5926\n",
      "====================================\n",
      "Epoch:  5926 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.185285183935202\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5926 5927\n",
      "Training loss:0.0024541798047721386\n",
      "check (7908,) ()\n",
      "epoch 5927\n",
      "====================================\n",
      "Epoch:  5927 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.185085203306901\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5927 5928\n",
      "Training loss:-0.007175641134381294\n",
      "check (10000,) ()\n",
      "epoch 5928\n",
      "====================================\n",
      "Epoch:  5928 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.183367071524966\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5928 5929\n",
      "Training loss:-0.004559544380754232\n",
      "check (10000,) ()\n",
      "epoch 5929\n",
      "====================================\n",
      "Epoch:  5929 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.181818181818182\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5929 5930\n",
      "Training loss:0.0007938791532069445\n",
      "check (9091,) ()\n",
      "epoch 5930\n",
      "====================================\n",
      "Epoch:  5930 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.181112984822935\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5930 5931\n",
      "Training loss:-0.0034722774289548397\n",
      "check (8214,) ()\n",
      "epoch 5931\n",
      "====================================\n",
      "Epoch:  5931 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.180745236890912\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5931 5932\n",
      "Training loss:-0.0054216813296079636\n",
      "check (7451,) ()\n",
      "epoch 5932\n",
      "====================================\n",
      "Epoch:  5932 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.18037761294673\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5932 5933\n",
      "Training loss:-0.003891466883942485\n",
      "check (10000,) ()\n",
      "epoch 5933\n",
      "====================================\n",
      "Epoch:  5933 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.180178661722568\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5933 5934\n",
      "Training loss:0.0008044738788157701\n",
      "check (8461,) ()\n",
      "epoch 5934\n",
      "====================================\n",
      "Epoch:  5934 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.179474216380182\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5934 5935\n",
      "Training loss:-0.0022673411294817924\n",
      "check (8689,) ()\n",
      "epoch 5935\n",
      "====================================\n",
      "Epoch:  5935 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.17910699241786\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5935 5936\n",
      "Training loss:-0.004677863791584969\n",
      "check (8223,) ()\n",
      "epoch 5936\n",
      "====================================\n",
      "Epoch:  5936 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.179076819407008\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5936 5937\n",
      "Training loss:-0.010306313633918762\n",
      "check (10000,) ()\n",
      "epoch 5937\n",
      "====================================\n",
      "Epoch:  5937 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.177867609903991\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5937 5938\n",
      "Training loss:-0.002053176984190941\n",
      "check (10000,) ()\n",
      "epoch 5938\n",
      "====================================\n",
      "Epoch:  5938 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.176995621421353\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5938 5939\n",
      "Training loss:0.004376794211566448\n",
      "check (7174,) ()\n",
      "epoch 5939\n",
      "====================================\n",
      "Epoch:  5939 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.17763933322108\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5939 5940\n",
      "Training loss:-0.01214489247649908\n",
      "check (8674,) ()\n",
      "epoch 5940\n",
      "====================================\n",
      "Epoch:  5940 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.177272727272728\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5940 5941\n",
      "Training loss:-0.003989596385508776\n",
      "check (10000,) ()\n",
      "epoch 5941\n",
      "====================================\n",
      "Epoch:  5941 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.176737922908602\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5941 5942\n",
      "Training loss:-0.0023848041892051697\n",
      "check (10000,) ()\n",
      "epoch 5942\n",
      "====================================\n",
      "Epoch:  5942 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.17502524402558\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5942 5943\n",
      "Training loss:-0.005116653628647327\n",
      "check (9877,) ()\n",
      "epoch 5943\n",
      "====================================\n",
      "Epoch:  5943 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.174154467440687\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5943 5944\n",
      "Training loss:-0.006413188762962818\n",
      "check (10000,) ()\n",
      "epoch 5944\n",
      "====================================\n",
      "Epoch:  5944 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.171769851951547\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5944 5945\n",
      "Training loss:-0.0024122183676809072\n",
      "check (7398,) ()\n",
      "epoch 5945\n",
      "====================================\n",
      "Epoch:  5945 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.172750210260723\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5945 5946\n",
      "Training loss:0.0002973847440443933\n",
      "check (8949,) ()\n",
      "epoch 5946\n",
      "====================================\n",
      "Epoch:  5946 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.17255297679112\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5946 5947\n",
      "Training loss:0.000498298613820225\n",
      "check (6925,) ()\n",
      "epoch 5947\n",
      "====================================\n",
      "Epoch:  5947 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.172692113670758\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5947 5948\n",
      "Training loss:-0.006445616018027067\n",
      "check (9357,) ()\n",
      "epoch 5948\n",
      "====================================\n",
      "Epoch:  5948 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.172158708809684\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5948 5949\n",
      "Training loss:-0.0041015478782355785\n",
      "check (10000,) ()\n",
      "epoch 5949\n",
      "====================================\n",
      "Epoch:  5949 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.170448814926878\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5949 5950\n",
      "Training loss:0.001896367990411818\n",
      "check (10000,) ()\n",
      "epoch 5950\n",
      "====================================\n",
      "Epoch:  5950 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.16890756302521\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5950 5951\n",
      "Training loss:-0.004153011832386255\n",
      "Model saved\n",
      "check (8987,) ()\n",
      "epoch 5951\n",
      "====================================\n",
      "Epoch:  5951 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.16803898504453\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5951 5952\n",
      "Training loss:-0.0025658051017671824\n",
      "check (8133,) ()\n",
      "epoch 5952\n",
      "====================================\n",
      "Epoch:  5952 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.167842741935484\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5952 5953\n",
      "Training loss:0.0007673043292015791\n",
      "check (8532,) ()\n",
      "epoch 5953\n",
      "====================================\n",
      "Epoch:  5953 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.166470687048546\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5953 5954\n",
      "Training loss:-0.011493504978716373\n",
      "check (10000,) ()\n",
      "epoch 5954\n",
      "====================================\n",
      "Epoch:  5954 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.165602955995968\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5954 5955\n",
      "Training loss:-0.00012095756392227486\n",
      "check (10000,) ()\n",
      "epoch 5955\n",
      "====================================\n",
      "Epoch:  5955 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.163895885810243\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5955 5956\n",
      "Training loss:0.0004313751123845577\n",
      "check (10000,) ()\n",
      "epoch 5956\n",
      "====================================\n",
      "Epoch:  5956 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.162021490933512\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5956 5957\n",
      "Training loss:0.00016510086425114423\n",
      "check (6937,) ()\n",
      "epoch 5957\n",
      "====================================\n",
      "Epoch:  5957 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.162665771361423\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5957 5958\n",
      "Training loss:-0.007698096334934235\n",
      "check (10000,) ()\n",
      "epoch 5958\n",
      "====================================\n",
      "Epoch:  5958 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.162302786169855\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5958 5959\n",
      "Training loss:-0.006418333388864994\n",
      "check (7814,) ()\n",
      "epoch 5959\n",
      "====================================\n",
      "Epoch:  5959 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.162778989763384\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5959 5960\n",
      "Training loss:-0.0020760931074619293\n",
      "check (8202,) ()\n",
      "epoch 5960\n",
      "====================================\n",
      "Epoch:  5960 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.162080536912752\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5960 5961\n",
      "Training loss:0.001495419186539948\n",
      "check (9022,) ()\n",
      "epoch 5961\n",
      "====================================\n",
      "Epoch:  5961 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.161046804227478\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5961 5962\n",
      "Training loss:-0.0026549615431576967\n",
      "check (7762,) ()\n",
      "epoch 5962\n",
      "====================================\n",
      "Epoch:  5962 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.161019792016102\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5962 5963\n",
      "Training loss:-0.0025761621072888374\n",
      "check (9260,) ()\n",
      "epoch 5963\n",
      "====================================\n",
      "Epoch:  5963 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.159818883112527\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5963 5964\n",
      "Training loss:-0.002432715380564332\n",
      "check (7356,) ()\n",
      "epoch 5964\n",
      "====================================\n",
      "Epoch:  5964 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.159792085848425\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5964 5965\n",
      "Training loss:-0.011606547981500626\n",
      "check (7334,) ()\n",
      "epoch 5965\n",
      "====================================\n",
      "Epoch:  5965 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.15943000838223\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5965 5966\n",
      "Training loss:-0.0012650290736928582\n",
      "check (9605,) ()\n",
      "epoch 5966\n",
      "====================================\n",
      "Epoch:  5966 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.158900435802883\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5966 5967\n",
      "Training loss:-0.0008174604154191911\n",
      "check (9923,) ()\n",
      "epoch 5967\n",
      "====================================\n",
      "Epoch:  5967 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.158873805932629\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5967 5968\n",
      "Training loss:0.0008029515156522393\n",
      "check (10000,) ()\n",
      "epoch 5968\n",
      "====================================\n",
      "Epoch:  5968 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.158176943699733\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5968 5969\n",
      "Training loss:0.006568692158907652\n",
      "check (9285,) ()\n",
      "epoch 5969\n",
      "====================================\n",
      "Epoch:  5969 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.157982911710505\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5969 5970\n",
      "Training loss:-0.006757042836397886\n",
      "check (8386,) ()\n",
      "epoch 5970\n",
      "====================================\n",
      "Epoch:  5970 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.157621440536014\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5970 5971\n",
      "Training loss:0.003969904035329819\n",
      "check (9518,) ()\n",
      "epoch 5971\n",
      "====================================\n",
      "Epoch:  5971 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.156590185898509\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5971 5972\n",
      "Training loss:-0.0037185875698924065\n",
      "check (9947,) ()\n",
      "epoch 5972\n",
      "====================================\n",
      "Epoch:  5972 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.155726724715338\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5972 5973\n",
      "Training loss:-0.0008967240573838353\n",
      "check (7594,) ()\n",
      "epoch 5973\n",
      "====================================\n",
      "Epoch:  5973 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.156035493052068\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5973 5974\n",
      "Training loss:-0.013390735723078251\n",
      "check (10000,) ()\n",
      "epoch 5974\n",
      "====================================\n",
      "Epoch:  5974 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.154000669568129\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5974 5975\n",
      "Training loss:-0.0015179000329226255\n",
      "check (10000,) ()\n",
      "epoch 5975\n",
      "====================================\n",
      "Epoch:  5975 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.152803347280335\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5975 5976\n",
      "Training loss:-0.0053012920543551445\n",
      "check (7527,) ()\n",
      "epoch 5976\n",
      "====================================\n",
      "Epoch:  5976 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.152777777777779\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5976 5977\n",
      "Training loss:-0.007549717091023922\n",
      "check (9946,) ()\n",
      "epoch 5977\n",
      "====================================\n",
      "Epoch:  5977 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.152250292789025\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5977 5978\n",
      "Training loss:-0.004522385075688362\n",
      "check (7346,) ()\n",
      "epoch 5978\n",
      "====================================\n",
      "Epoch:  5978 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.152559384409502\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5978 5979\n",
      "Training loss:0.00032143472344614565\n",
      "check (9891,) ()\n",
      "epoch 5979\n",
      "====================================\n",
      "Epoch:  5979 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.151363104198026\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5979 5980\n",
      "Training loss:-0.005613057874143124\n",
      "check (8830,) ()\n",
      "epoch 5980\n",
      "====================================\n",
      "Epoch:  5980 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.150167224080267\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5980 5981\n",
      "Training loss:-0.008267108350992203\n",
      "check (9940,) ()\n",
      "epoch 5981\n",
      "====================================\n",
      "Epoch:  5981 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.148804547734493\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5981 5982\n",
      "Training loss:-0.005165386479347944\n",
      "check (9840,) ()\n",
      "epoch 5982\n",
      "====================================\n",
      "Epoch:  5982 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.148278167836844\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5982 5983\n",
      "Training loss:-0.006683169864118099\n",
      "check (8335,) ()\n",
      "epoch 5983\n",
      "====================================\n",
      "Epoch:  5983 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.14775196389771\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5983 5984\n",
      "Training loss:-0.002066226676106453\n",
      "check (10000,) ()\n",
      "epoch 5984\n",
      "====================================\n",
      "Epoch:  5984 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.146557486631016\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5984 5985\n",
      "Training loss:-0.007435748353600502\n",
      "check (9639,) ()\n",
      "epoch 5985\n",
      "====================================\n",
      "Epoch:  5985 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.146198830409357\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5985 5986\n",
      "Training loss:-0.00596675556153059\n",
      "check (10000,) ()\n",
      "epoch 5986\n",
      "====================================\n",
      "Epoch:  5986 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.145172068159038\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 5986 5987\n",
      "Training loss:-0.0014225211925804615\n",
      "check (9649,) ()\n",
      "epoch 5987\n",
      "====================================\n",
      "Epoch:  5987 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.144145648905964\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5987 5988\n",
      "Training loss:-0.002221813891083002\n",
      "check (9350,) ()\n",
      "epoch 5988\n",
      "====================================\n",
      "Epoch:  5988 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.144455577822312\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5988 5989\n",
      "Training loss:-0.006760657299309969\n",
      "check (9221,) ()\n",
      "epoch 5989\n",
      "====================================\n",
      "Epoch:  5989 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.144097512105526\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5989 5990\n",
      "Training loss:-0.0006587983225472271\n",
      "check (7518,) ()\n",
      "epoch 5990\n",
      "====================================\n",
      "Epoch:  5990 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.14440734557596\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5990 5991\n",
      "Training loss:0.004650881979614496\n",
      "check (8747,) ()\n",
      "epoch 5991\n",
      "====================================\n",
      "Epoch:  5991 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.14338173927558\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5991 5992\n",
      "Training loss:0.0028681037947535515\n",
      "check (7288,) ()\n",
      "epoch 5992\n",
      "====================================\n",
      "Epoch:  5992 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.143691588785046\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5992 5993\n",
      "Training loss:-0.00041316289571113884\n",
      "check (9156,) ()\n",
      "epoch 5993\n",
      "====================================\n",
      "Epoch:  5993 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.143333889537795\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5993 5994\n",
      "Training loss:-0.002179427770897746\n",
      "check (8103,) ()\n",
      "epoch 5994\n",
      "====================================\n",
      "Epoch:  5994 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.142976309642977\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5994 5995\n",
      "Training loss:-0.005094650201499462\n",
      "check (8692,) ()\n",
      "epoch 5995\n",
      "====================================\n",
      "Epoch:  5995 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.142952460383652\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5995 5996\n",
      "Training loss:-0.003579994896426797\n",
      "check (6677,) ()\n",
      "epoch 5996\n",
      "====================================\n",
      "Epoch:  5996 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.143262174783189\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5996 5997\n",
      "Training loss:-0.010043914429843426\n",
      "check (9813,) ()\n",
      "epoch 5997\n",
      "====================================\n",
      "Epoch:  5997 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.143238285809572\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5997 5998\n",
      "Training loss:0.00030411218176595867\n",
      "check (7812,) ()\n",
      "epoch 5998\n",
      "====================================\n",
      "Epoch:  5998 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.142880960320106\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5998 5999\n",
      "Training loss:-0.005975023843348026\n",
      "check (9350,) ()\n",
      "epoch 5999\n",
      "====================================\n",
      "Epoch:  5999 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.142023670611769\n",
      "Max reward for a batch so far: 7.0\n",
      "check 5999 6000\n",
      "Training loss:0.005086465273052454\n",
      "check (10000,) ()\n",
      "epoch 6000\n",
      "====================================\n",
      "Epoch:  6000 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.141\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6000 6001\n",
      "Training loss:0.004637629259377718\n",
      "Model saved\n",
      "check (9810,) ()\n",
      "epoch 6001\n",
      "====================================\n",
      "Epoch:  6001 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.140309948341944\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6001 6002\n",
      "Training loss:-0.006446567829698324\n",
      "check (8476,) ()\n",
      "epoch 6002\n",
      "====================================\n",
      "Epoch:  6002 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.139453515494836\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6002 6003\n",
      "Training loss:-0.004503026604652405\n",
      "check (10000,) ()\n",
      "epoch 6003\n",
      "====================================\n",
      "Epoch:  6003 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.137931034482758\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6003 6004\n",
      "Training loss:-0.004406891297549009\n",
      "check (8473,) ()\n",
      "epoch 6004\n",
      "====================================\n",
      "Epoch:  6004 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.138074616922053\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6004 6005\n",
      "Training loss:-0.0036945403553545475\n",
      "check (10000,) ()\n",
      "epoch 6005\n",
      "====================================\n",
      "Epoch:  6005 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.136719400499583\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6005 6006\n",
      "Training loss:0.004919831641018391\n",
      "check (7570,) ()\n",
      "epoch 6006\n",
      "====================================\n",
      "Epoch:  6006 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.136530136530137\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6006 6007\n",
      "Training loss:-0.0027581551112234592\n",
      "check (8753,) ()\n",
      "epoch 6007\n",
      "====================================\n",
      "Epoch:  6007 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.136340935575163\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6007 6008\n",
      "Training loss:-0.004220730159431696\n",
      "check (8996,) ()\n",
      "epoch 6008\n",
      "====================================\n",
      "Epoch:  6008 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.135652463382158\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6008 6009\n",
      "Training loss:-0.0006812745705246925\n",
      "check (9908,) ()\n",
      "epoch 6009\n",
      "====================================\n",
      "Epoch:  6009 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.134132135130637\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6009 6010\n",
      "Training loss:-0.002134546870365739\n",
      "check (10000,) ()\n",
      "epoch 6010\n",
      "====================================\n",
      "Epoch:  6010 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.131946755407654\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6010 6011\n",
      "Training loss:-0.0035028918646275997\n",
      "check (7080,) ()\n",
      "epoch 6011\n",
      "====================================\n",
      "Epoch:  6011 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.132590251206121\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6011 6012\n",
      "Training loss:0.0033290842548012733\n",
      "check (10000,) ()\n",
      "epoch 6012\n",
      "====================================\n",
      "Epoch:  6012 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.131736526946108\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6012 6013\n",
      "Training loss:-0.0073488508351147175\n",
      "check (10000,) ()\n",
      "epoch 6013\n",
      "====================================\n",
      "Epoch:  6013 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.131548311990686\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6013 6014\n",
      "Training loss:-0.0037625636905431747\n",
      "check (6373,) ()\n",
      "epoch 6014\n",
      "====================================\n",
      "Epoch:  6014 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.1321915530429\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6014 6015\n",
      "Training loss:-0.0019118415657430887\n",
      "check (7509,) ()\n",
      "epoch 6015\n",
      "====================================\n",
      "Epoch:  6015 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.132335827098919\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6015 6016\n",
      "Training loss:0.0008734157891012728\n",
      "check (6680,) ()\n",
      "epoch 6016\n",
      "====================================\n",
      "Epoch:  6016 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.13248005319149\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6016 6017\n",
      "Training loss:-0.005594200454652309\n",
      "check (7205,) ()\n",
      "epoch 6017\n",
      "====================================\n",
      "Epoch:  6017 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.132125644008642\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6017 6018\n",
      "Training loss:0.0004504155367612839\n",
      "check (9597,) ()\n",
      "epoch 6018\n",
      "====================================\n",
      "Epoch:  6018 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.13060817547358\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6018 6019\n",
      "Training loss:-0.005660043563693762\n",
      "check (6955,) ()\n",
      "epoch 6019\n",
      "====================================\n",
      "Epoch:  6019 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.13058647615883\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6019 6020\n",
      "Training loss:-0.006099787075072527\n",
      "check (9019,) ()\n",
      "epoch 6020\n",
      "====================================\n",
      "Epoch:  6020 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.129568106312293\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6020 6021\n",
      "Training loss:-0.0008936202502809465\n",
      "check (10000,) ()\n",
      "epoch 6021\n",
      "====================================\n",
      "Epoch:  6021 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.129380501577812\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6021 6022\n",
      "Training loss:-0.005398331210017204\n",
      "check (9246,) ()\n",
      "epoch 6022\n",
      "====================================\n",
      "Epoch:  6022 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.128694785785454\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6022 6023\n",
      "Training loss:-0.0034218612127006054\n",
      "check (9841,) ()\n",
      "epoch 6023\n",
      "====================================\n",
      "Epoch:  6023 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.127345176822182\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6023 6024\n",
      "Training loss:-0.00033215282019227743\n",
      "check (10000,) ()\n",
      "epoch 6024\n",
      "====================================\n",
      "Epoch:  6024 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.126162018592298\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6024 6025\n",
      "Training loss:-0.0023659486323595047\n",
      "check (7209,) ()\n",
      "epoch 6025\n",
      "====================================\n",
      "Epoch:  6025 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.126141078838174\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6025 6026\n",
      "Training loss:0.0030853403732180595\n",
      "check (9654,) ()\n",
      "epoch 6026\n",
      "====================================\n",
      "Epoch:  6026 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.125788250912711\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6026 6027\n",
      "Training loss:-0.003927193116396666\n",
      "check (7486,) ()\n",
      "epoch 6027\n",
      "====================================\n",
      "Epoch:  6027 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.125103700016592\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6027 6028\n",
      "Training loss:-0.011934256181120872\n",
      "check (7761,) ()\n",
      "epoch 6028\n",
      "====================================\n",
      "Epoch:  6028 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.12508294625083\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6028 6029\n",
      "Training loss:-0.0027012068312615156\n",
      "check (8521,) ()\n",
      "epoch 6029\n",
      "====================================\n",
      "Epoch:  6029 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.125062199369713\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6029 6030\n",
      "Training loss:0.0071944911032915115\n",
      "check (9036,) ()\n",
      "epoch 6030\n",
      "====================================\n",
      "Epoch:  6030 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.124709784411277\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6030 6031\n",
      "Training loss:-0.001503721927292645\n",
      "check (9663,) ()\n",
      "epoch 6031\n",
      "====================================\n",
      "Epoch:  6031 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.124025866357155\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6031 6032\n",
      "Training loss:-0.005454466212540865\n",
      "check (10000,) ()\n",
      "epoch 6032\n",
      "====================================\n",
      "Epoch:  6032 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.122181697612731\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6032 6033\n",
      "Training loss:0.0011748748365789652\n",
      "check (7350,) ()\n",
      "epoch 6033\n",
      "====================================\n",
      "Epoch:  6033 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.122161445383723\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6033 6034\n",
      "Training loss:-0.0014054013881832361\n",
      "check (8010,) ()\n",
      "epoch 6034\n",
      "====================================\n",
      "Epoch:  6034 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.121809744779583\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6034 6035\n",
      "Training loss:-0.0012756424257531762\n",
      "check (8708,) ()\n",
      "epoch 6035\n",
      "====================================\n",
      "Epoch:  6035 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.12079536039768\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6035 6036\n",
      "Training loss:-0.0054437872022390366\n",
      "check (7693,) ()\n",
      "epoch 6036\n",
      "====================================\n",
      "Epoch:  6036 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.12027833001988\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6036 6037\n",
      "Training loss:0.004260801710188389\n",
      "check (9744,) ()\n",
      "epoch 6037\n",
      "====================================\n",
      "Epoch:  6037 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.118933244989233\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6037 6038\n",
      "Training loss:-0.003606261918321252\n",
      "check (9555,) ()\n",
      "epoch 6038\n",
      "====================================\n",
      "Epoch:  6038 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.118251076515403\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6038 6039\n",
      "Training loss:-0.0045587532222270966\n",
      "check (8942,) ()\n",
      "epoch 6039\n",
      "====================================\n",
      "Epoch:  6039 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.118231495280675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6039 6040\n",
      "Training loss:-0.0048696668818593025\n",
      "check (8450,) ()\n",
      "epoch 6040\n",
      "====================================\n",
      "Epoch:  6040 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.1182119205298\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6040 6041\n",
      "Training loss:0.002836235798895359\n",
      "check (8993,) ()\n",
      "epoch 6041\n",
      "====================================\n",
      "Epoch:  6041 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.117530210230095\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6041 6042\n",
      "Training loss:-0.0016089000273495913\n",
      "check (7570,) ()\n",
      "epoch 6042\n",
      "====================================\n",
      "Epoch:  6042 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.117841774246939\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6042 6043\n",
      "Training loss:-0.008457733318209648\n",
      "check (10000,) ()\n",
      "epoch 6043\n",
      "====================================\n",
      "Epoch:  6043 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.116167466490154\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6043 6044\n",
      "Training loss:-0.0045081996358931065\n",
      "check (9833,) ()\n",
      "epoch 6044\n",
      "====================================\n",
      "Epoch:  6044 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.115155526141628\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6044 6045\n",
      "Training loss:-0.00532132014632225\n",
      "check (10000,) ()\n",
      "epoch 6045\n",
      "====================================\n",
      "Epoch:  6045 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.113813068651778\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6045 6046\n",
      "Training loss:-0.003779501421377063\n",
      "check (8556,) ()\n",
      "epoch 6046\n",
      "====================================\n",
      "Epoch:  6046 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.113298048296395\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6046 6047\n",
      "Training loss:0.001942574861459434\n",
      "check (10000,) ()\n",
      "epoch 6047\n",
      "====================================\n",
      "Epoch:  6047 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -13.11063337191996\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6047 6048\n",
      "Training loss:-0.003375112544745207\n",
      "check (8278,) ()\n",
      "epoch 6048\n",
      "====================================\n",
      "Epoch:  6048 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.109953703703704\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6048 6049\n",
      "Training loss:-0.004007230047136545\n",
      "check (7000,) ()\n",
      "epoch 6049\n",
      "====================================\n",
      "Epoch:  6049 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.110596792858324\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6049 6050\n",
      "Training loss:-0.0016546216793358326\n",
      "check (8761,) ()\n",
      "epoch 6050\n",
      "====================================\n",
      "Epoch:  6050 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.110413223140496\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6050 6051\n",
      "Training loss:-0.010250227525830269\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 6051\n",
      "====================================\n",
      "Epoch:  6051 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.109072880515617\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6051 6052\n",
      "Training loss:0.0010134694166481495\n",
      "check (9788,) ()\n",
      "epoch 6052\n",
      "====================================\n",
      "Epoch:  6052 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.108724388631858\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6052 6053\n",
      "Training loss:-0.0029427630361169577\n",
      "check (9429,) ()\n",
      "epoch 6053\n",
      "====================================\n",
      "Epoch:  6053 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.108210804559722\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6053 6054\n",
      "Training loss:-0.00010584096162347123\n",
      "check (7111,) ()\n",
      "epoch 6054\n",
      "====================================\n",
      "Epoch:  6054 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.107862570201519\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6054 6055\n",
      "Training loss:-0.0010365379275754094\n",
      "check (9507,) ()\n",
      "epoch 6055\n",
      "====================================\n",
      "Epoch:  6055 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.106523534269199\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6055 6056\n",
      "Training loss:-0.007761597167700529\n",
      "check (6777,) ()\n",
      "epoch 6056\n",
      "====================================\n",
      "Epoch:  6056 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.107496697490092\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6056 6057\n",
      "Training loss:0.004596731625497341\n",
      "check (7769,) ()\n",
      "epoch 6057\n",
      "====================================\n",
      "Epoch:  6057 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.107478949975235\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6057 6058\n",
      "Training loss:0.001579289440996945\n",
      "check (10000,) ()\n",
      "epoch 6058\n",
      "====================================\n",
      "Epoch:  6058 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.106305711455926\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6058 6059\n",
      "Training loss:-0.00634749885648489\n",
      "check (9718,) ()\n",
      "epoch 6059\n",
      "====================================\n",
      "Epoch:  6059 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.106288166364086\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6059 6060\n",
      "Training loss:6.453110836446285e-05\n",
      "check (8111,) ()\n",
      "epoch 6060\n",
      "====================================\n",
      "Epoch:  6060 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.105775577557756\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6060 6061\n",
      "Training loss:-0.010249408893287182\n",
      "check (7466,) ()\n",
      "epoch 6061\n",
      "====================================\n",
      "Epoch:  6061 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.105758125721827\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6061 6062\n",
      "Training loss:-0.006719307508319616\n",
      "check (8510,) ()\n",
      "epoch 6062\n",
      "====================================\n",
      "Epoch:  6062 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.105740679643683\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6062 6063\n",
      "Training loss:-0.009101176634430885\n",
      "check (10000,) ()\n",
      "epoch 6063\n",
      "====================================\n",
      "Epoch:  6063 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.104898565066799\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6063 6064\n",
      "Training loss:-0.007827228866517544\n",
      "check (8265,) ()\n",
      "epoch 6064\n",
      "====================================\n",
      "Epoch:  6064 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.103562005277045\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6064 6065\n",
      "Training loss:-0.0008918900857679546\n",
      "check (10000,) ()\n",
      "epoch 6065\n",
      "====================================\n",
      "Epoch:  6065 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.101236603462489\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6065 6066\n",
      "Training loss:-0.00034964142832905054\n",
      "check (10000,) ()\n",
      "epoch 6066\n",
      "====================================\n",
      "Epoch:  6066 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.099571381470492\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6066 6067\n",
      "Training loss:0.0005687742959707975\n",
      "check (9728,) ()\n",
      "epoch 6067\n",
      "====================================\n",
      "Epoch:  6067 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.098401186747981\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6067 6068\n",
      "Training loss:-0.00016488449182361364\n",
      "check (9103,) ()\n",
      "epoch 6068\n",
      "====================================\n",
      "Epoch:  6068 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.098055372445616\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6068 6069\n",
      "Training loss:-0.006931453011929989\n",
      "check (9270,) ()\n",
      "epoch 6069\n",
      "====================================\n",
      "Epoch:  6069 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.097050584939858\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6069 6070\n",
      "Training loss:0.0037822567392140627\n",
      "check (10000,) ()\n",
      "epoch 6070\n",
      "====================================\n",
      "Epoch:  6070 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.095716639209225\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6070 6071\n",
      "Training loss:-0.009080298244953156\n",
      "check (10000,) ()\n",
      "epoch 6071\n",
      "====================================\n",
      "Epoch:  6071 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.094053697908087\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6071 6072\n",
      "Training loss:-0.0007481746724806726\n",
      "check (7973,) ()\n",
      "epoch 6072\n",
      "====================================\n",
      "Epoch:  6072 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.093544137022398\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6072 6073\n",
      "Training loss:-0.008909362368285656\n",
      "check (8808,) ()\n",
      "epoch 6073\n",
      "====================================\n",
      "Epoch:  6073 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.093034743948625\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6073 6074\n",
      "Training loss:-0.00025408793590031564\n",
      "check (9120,) ()\n",
      "epoch 6074\n",
      "====================================\n",
      "Epoch:  6074 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.092360882449785\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6074 6075\n",
      "Training loss:0.0039114379324018955\n",
      "check (7154,) ()\n",
      "epoch 6075\n",
      "====================================\n",
      "Epoch:  6075 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.092674897119341\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6075 6076\n",
      "Training loss:0.00444371672347188\n",
      "check (8241,) ()\n",
      "epoch 6076\n",
      "====================================\n",
      "Epoch:  6076 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.092659644502962\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6076 6077\n",
      "Training loss:-0.00496822502464056\n",
      "check (10000,) ()\n",
      "epoch 6077\n",
      "====================================\n",
      "Epoch:  6077 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.0911634029949\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6077 6078\n",
      "Training loss:-0.0020843788515776396\n",
      "check (8076,) ()\n",
      "epoch 6078\n",
      "====================================\n",
      "Epoch:  6078 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.090654820664692\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6078 6079\n",
      "Training loss:0.0013927348190918565\n",
      "check (6183,) ()\n",
      "epoch 6079\n",
      "====================================\n",
      "Epoch:  6079 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.091133410100346\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6079 6080\n",
      "Training loss:-0.0029364756774157286\n",
      "check (10000,) ()\n",
      "epoch 6080\n",
      "====================================\n",
      "Epoch:  6080 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.09029605263158\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6080 6081\n",
      "Training loss:0.0012724892003461719\n",
      "check (8152,) ()\n",
      "epoch 6081\n",
      "====================================\n",
      "Epoch:  6081 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.090938990297648\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6081 6082\n",
      "Training loss:-0.0004620238614734262\n",
      "check (8100,) ()\n",
      "epoch 6082\n",
      "====================================\n",
      "Epoch:  6082 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.090595198947714\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6082 6083\n",
      "Training loss:-0.00872847530990839\n",
      "check (8905,) ()\n",
      "epoch 6083\n",
      "====================================\n",
      "Epoch:  6083 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.090909090909092\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6083 6084\n",
      "Training loss:-0.0069383480586111546\n",
      "check (10000,) ()\n",
      "epoch 6084\n",
      "====================================\n",
      "Epoch:  6084 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.089579224194608\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6084 6085\n",
      "Training loss:0.0009550491231493652\n",
      "check (9471,) ()\n",
      "epoch 6085\n",
      "====================================\n",
      "Epoch:  6085 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.089564502875925\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6085 6086\n",
      "Training loss:-0.007716966327279806\n",
      "check (7142,) ()\n",
      "epoch 6086\n",
      "====================================\n",
      "Epoch:  6086 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.089056851790996\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6086 6087\n",
      "Training loss:-0.0010028418619185686\n",
      "check (10000,) ()\n",
      "epoch 6087\n",
      "====================================\n",
      "Epoch:  6087 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.087399375718745\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6087 6088\n",
      "Training loss:-0.0001833171845646575\n",
      "check (8804,) ()\n",
      "epoch 6088\n",
      "====================================\n",
      "Epoch:  6088 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.086235216819974\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6088 6089\n",
      "Training loss:-0.001845628023147583\n",
      "check (9801,) ()\n",
      "epoch 6089\n",
      "====================================\n",
      "Epoch:  6089 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.086221054360323\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6089 6090\n",
      "Training loss:-0.0022825978230684996\n",
      "check (9626,) ()\n",
      "epoch 6090\n",
      "====================================\n",
      "Epoch:  6090 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.085385878489326\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6090 6091\n",
      "Training loss:-0.0040258425287902355\n",
      "check (8559,) ()\n",
      "epoch 6091\n",
      "====================================\n",
      "Epoch:  6091 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.085043506813332\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6091 6092\n",
      "Training loss:-0.000867566850502044\n",
      "check (8736,) ()\n",
      "epoch 6092\n",
      "====================================\n",
      "Epoch:  6092 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.084701247537755\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6092 6093\n",
      "Training loss:0.002398182637989521\n",
      "check (9687,) ()\n",
      "epoch 6093\n",
      "====================================\n",
      "Epoch:  6093 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.083702609551946\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6093 6094\n",
      "Training loss:-0.002880259184166789\n",
      "check (9803,) ()\n",
      "epoch 6094\n",
      "====================================\n",
      "Epoch:  6094 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.083196586806695\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6094 6095\n",
      "Training loss:-0.0026652757078409195\n",
      "check (10000,) ()\n",
      "epoch 6095\n",
      "====================================\n",
      "Epoch:  6095 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.081214109926169\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6095 6096\n",
      "Training loss:-0.0013180732494220138\n",
      "check (8908,) ()\n",
      "epoch 6096\n",
      "====================================\n",
      "Epoch:  6096 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.080872703412073\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6096 6097\n",
      "Training loss:-0.0014333584113046527\n",
      "check (8572,) ()\n",
      "epoch 6097\n",
      "====================================\n",
      "Epoch:  6097 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.080203378710841\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6097 6098\n",
      "Training loss:-0.0011637075804173946\n",
      "check (8709,) ()\n",
      "epoch 6098\n",
      "====================================\n",
      "Epoch:  6098 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.079862249918007\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6098 6099\n",
      "Training loss:-0.003527184249833226\n",
      "check (7479,) ()\n",
      "epoch 6099\n",
      "====================================\n",
      "Epoch:  6099 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.080341039514675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6099 6100\n",
      "Training loss:-0.004487451631575823\n",
      "check (10000,) ()\n",
      "epoch 6100\n",
      "====================================\n",
      "Epoch:  6100 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.078524590163934\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6100 6101\n",
      "Training loss:-0.004303285386413336\n",
      "Model saved\n",
      "check (9094,) ()\n",
      "epoch 6101\n",
      "====================================\n",
      "Epoch:  6101 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.078183904277987\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6101 6102\n",
      "Training loss:-0.002500505419448018\n",
      "check (10000,) ()\n",
      "epoch 6102\n",
      "====================================\n",
      "Epoch:  6102 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.076860045886594\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6102 6103\n",
      "Training loss:-0.002746937796473503\n",
      "check (6928,) ()\n",
      "epoch 6103\n",
      "====================================\n",
      "Epoch:  6103 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.076683598230378\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6103 6104\n",
      "Training loss:0.00042790849693119526\n",
      "check (10000,) ()\n",
      "epoch 6104\n",
      "====================================\n",
      "Epoch:  6104 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -13.07437745740498\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6104 6105\n",
      "Training loss:-0.0025527896359562874\n",
      "check (10000,) ()\n",
      "epoch 6105\n",
      "====================================\n",
      "Epoch:  6105 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.072891072891073\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6105 6106\n",
      "Training loss:-0.002073386451229453\n",
      "check (10000,) ()\n",
      "epoch 6106\n",
      "====================================\n",
      "Epoch:  6106 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.071241401899771\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6106 6107\n",
      "Training loss:-0.0036537800915539265\n",
      "check (7226,) ()\n",
      "epoch 6107\n",
      "====================================\n",
      "Epoch:  6107 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.071557229408874\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6107 6108\n",
      "Training loss:-0.002608773997053504\n",
      "check (8880,) ()\n",
      "epoch 6108\n",
      "====================================\n",
      "Epoch:  6108 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.071381794368042\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6108 6109\n",
      "Training loss:0.0007804417400620878\n",
      "check (9663,) ()\n",
      "epoch 6109\n",
      "====================================\n",
      "Epoch:  6109 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.071370109674252\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6109 6110\n",
      "Training loss:-0.004151010420173407\n",
      "check (9873,) ()\n",
      "epoch 6110\n",
      "====================================\n",
      "Epoch:  6110 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.069885433715221\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6110 6111\n",
      "Training loss:-0.002867572009563446\n",
      "check (6329,) ()\n",
      "epoch 6111\n",
      "====================================\n",
      "Epoch:  6111 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -13.070855833742431\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6111 6112\n",
      "Training loss:-0.0011529390467330813\n",
      "check (8270,) ()\n",
      "epoch 6112\n",
      "====================================\n",
      "Epoch:  6112 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.070680628272251\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6112 6113\n",
      "Training loss:-0.00437142001464963\n",
      "check (8927,) ()\n",
      "epoch 6113\n",
      "====================================\n",
      "Epoch:  6113 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.070669065925077\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6113 6114\n",
      "Training loss:0.0003361155395396054\n",
      "check (10000,) ()\n",
      "epoch 6114\n",
      "====================================\n",
      "Epoch:  6114 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.069676153091265\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6114 6115\n",
      "Training loss:-0.00348144443705678\n",
      "check (8366,) ()\n",
      "epoch 6115\n",
      "====================================\n",
      "Epoch:  6115 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.06966475878986\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6115 6116\n",
      "Training loss:-0.001794181764125824\n",
      "check (9289,) ()\n",
      "epoch 6116\n",
      "====================================\n",
      "Epoch:  6116 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.069326357096141\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6116 6117\n",
      "Training loss:-0.0019241203553974628\n",
      "check (10000,) ()\n",
      "epoch 6117\n",
      "====================================\n",
      "Epoch:  6117 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.068007193068498\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6117 6118\n",
      "Training loss:-0.002124204533174634\n",
      "check (9811,) ()\n",
      "epoch 6118\n",
      "====================================\n",
      "Epoch:  6118 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.066688460281137\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6118 6119\n",
      "Training loss:-0.010241604410111904\n",
      "check (8255,) ()\n",
      "epoch 6119\n",
      "====================================\n",
      "Epoch:  6119 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.066677561693087\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6119 6120\n",
      "Training loss:-0.005188866052776575\n",
      "check (9933,) ()\n",
      "epoch 6120\n",
      "====================================\n",
      "Epoch:  6120 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.066013071895425\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6120 6121\n",
      "Training loss:-0.00020208486239425838\n",
      "check (10000,) ()\n",
      "epoch 6121\n",
      "====================================\n",
      "Epoch:  6121 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.064368567227577\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6121 6122\n",
      "Training loss:0.00015701065422035754\n",
      "check (10000,) ()\n",
      "epoch 6122\n",
      "====================================\n",
      "Epoch:  6122 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.063214635739953\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6122 6123\n",
      "Training loss:0.003086811164394021\n",
      "check (8904,) ()\n",
      "epoch 6123\n",
      "====================================\n",
      "Epoch:  6123 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.062714355707985\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6123 6124\n",
      "Training loss:0.005382682662457228\n",
      "check (9333,) ()\n",
      "epoch 6124\n",
      "====================================\n",
      "Epoch:  6124 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.062214239059438\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6124 6125\n",
      "Training loss:-0.005254141986370087\n",
      "check (9606,) ()\n",
      "epoch 6125\n",
      "====================================\n",
      "Epoch:  6125 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.061551020408164\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6125 6126\n",
      "Training loss:-0.004508123733103275\n",
      "check (10000,) ()\n",
      "epoch 6126\n",
      "====================================\n",
      "Epoch:  6126 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.061051256937644\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6126 6127\n",
      "Training loss:0.0018982223700731993\n",
      "check (6895,) ()\n",
      "epoch 6127\n",
      "====================================\n",
      "Epoch:  6127 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.061041292639139\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6127 6128\n",
      "Training loss:-0.006082131061702967\n",
      "check (10000,) ()\n",
      "epoch 6128\n",
      "====================================\n",
      "Epoch:  6128 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.0592362924282\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6128 6129\n",
      "Training loss:0.0025465525686740875\n",
      "check (10000,) ()\n",
      "epoch 6129\n",
      "====================================\n",
      "Epoch:  6129 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.059063468755099\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6129 6130\n",
      "Training loss:-0.008416760712862015\n",
      "check (8935,) ()\n",
      "epoch 6130\n",
      "====================================\n",
      "Epoch:  6130 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.059216965742252\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6130 6131\n",
      "Training loss:-0.008206839673221111\n",
      "check (9238,) ()\n",
      "epoch 6131\n",
      "====================================\n",
      "Epoch:  6131 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.058554885010603\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6131 6132\n",
      "Training loss:-0.0021373345516622066\n",
      "check (10000,) ()\n",
      "epoch 6132\n",
      "====================================\n",
      "Epoch:  6132 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.057240704500979\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6132 6133\n",
      "Training loss:0.001983684953302145\n",
      "check (8909,) ()\n",
      "epoch 6133\n",
      "====================================\n",
      "Epoch:  6133 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.056905266590576\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6133 6134\n",
      "Training loss:0.006365316454321146\n",
      "check (10000,) ()\n",
      "epoch 6134\n",
      "====================================\n",
      "Epoch:  6134 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.055917835017933\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6134 6135\n",
      "Training loss:0.00016535530448891222\n",
      "check (9053,) ()\n",
      "epoch 6135\n",
      "====================================\n",
      "Epoch:  6135 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.055908720456397\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6135 6136\n",
      "Training loss:-0.00815016683191061\n",
      "check (8274,) ()\n",
      "epoch 6136\n",
      "====================================\n",
      "Epoch:  6136 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.055247718383312\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6136 6137\n",
      "Training loss:-0.011718117631971836\n",
      "check (8664,) ()\n",
      "epoch 6137\n",
      "====================================\n",
      "Epoch:  6137 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.055564608114715\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6137 6138\n",
      "Training loss:-0.006008558440953493\n",
      "check (10000,) ()\n",
      "epoch 6138\n",
      "====================================\n",
      "Epoch:  6138 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.054740957966764\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6138 6139\n",
      "Training loss:-0.0038146714214235544\n",
      "check (8686,) ()\n",
      "epoch 6139\n",
      "====================================\n",
      "Epoch:  6139 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.053754683173155\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6139 6140\n",
      "Training loss:-0.004940584767609835\n",
      "check (7706,) ()\n",
      "epoch 6140\n",
      "====================================\n",
      "Epoch:  6140 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.05342019543974\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6140 6141\n",
      "Training loss:0.004411742091178894\n",
      "check (10000,) ()\n",
      "epoch 6141\n",
      "====================================\n",
      "Epoch:  6141 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.05292297671389\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6141 6142\n",
      "Training loss:-0.0003934375708922744\n",
      "check (10000,) ()\n",
      "epoch 6142\n",
      "====================================\n",
      "Epoch:  6142 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.051286225985022\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6142 6143\n",
      "Training loss:-0.003026461461558938\n",
      "check (9200,) ()\n",
      "epoch 6143\n",
      "====================================\n",
      "Epoch:  6143 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.050789516522872\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6143 6144\n",
      "Training loss:-0.0007651569321751595\n",
      "check (8673,) ()\n",
      "epoch 6144\n",
      "====================================\n",
      "Epoch:  6144 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.050455729166666\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6144 6145\n",
      "Training loss:-0.0014806558610871434\n",
      "check (8814,) ()\n",
      "epoch 6145\n",
      "====================================\n",
      "Epoch:  6145 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.049796582587469\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6145 6146\n",
      "Training loss:-0.0023972499184310436\n",
      "check (10000,) ()\n",
      "epoch 6146\n",
      "====================================\n",
      "Epoch:  6146 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.047673283436382\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6146 6147\n",
      "Training loss:0.001676334417425096\n",
      "check (9088,) ()\n",
      "epoch 6147\n",
      "====================================\n",
      "Epoch:  6147 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.046852122986822\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6147 6148\n",
      "Training loss:0.00047095559420995414\n",
      "check (6632,) ()\n",
      "epoch 6148\n",
      "====================================\n",
      "Epoch:  6148 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.046844502277164\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6148 6149\n",
      "Training loss:-0.0012524441117420793\n",
      "check (10000,) ()\n",
      "epoch 6149\n",
      "====================================\n",
      "Epoch:  6149 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.04488534721093\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6149 6150\n",
      "Training loss:-0.002838748972862959\n",
      "check (8491,) ()\n",
      "epoch 6150\n",
      "====================================\n",
      "Epoch:  6150 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.044227642276423\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6150 6151\n",
      "Training loss:0.003231136128306389\n",
      "Model saved\n",
      "check (8838,) ()\n",
      "epoch 6151\n",
      "====================================\n",
      "Epoch:  6151 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.043570151194928\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6151 6152\n",
      "Training loss:-0.0056237331591546535\n",
      "check (6666,) ()\n",
      "epoch 6152\n",
      "====================================\n",
      "Epoch:  6152 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.043563068920676\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6152 6153\n",
      "Training loss:0.003161774482578039\n",
      "check (9904,) ()\n",
      "epoch 6153\n",
      "====================================\n",
      "Epoch:  6153 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.042255810173899\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6153 6154\n",
      "Training loss:-0.007541890721768141\n",
      "check (9255,) ()\n",
      "epoch 6154\n",
      "====================================\n",
      "Epoch:  6154 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.041923951901202\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6154 6155\n",
      "Training loss:-0.003969632554799318\n",
      "check (9718,) ()\n",
      "epoch 6155\n",
      "====================================\n",
      "Epoch:  6155 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.041592201462226\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6155 6156\n",
      "Training loss:-0.007316636387258768\n",
      "check (9015,) ()\n",
      "epoch 6156\n",
      "====================================\n",
      "Epoch:  6156 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.041585445094217\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6156 6157\n",
      "Training loss:-0.0026526781730353832\n",
      "check (8949,) ()\n",
      "epoch 6157\n",
      "====================================\n",
      "Epoch:  6157 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.040929023875265\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6157 6158\n",
      "Training loss:-0.007708984427154064\n",
      "check (9115,) ()\n",
      "epoch 6158\n",
      "====================================\n",
      "Epoch:  6158 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.039785644689834\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6158 6159\n",
      "Training loss:-0.004528121557086706\n",
      "check (9803,) ()\n",
      "epoch 6159\n",
      "====================================\n",
      "Epoch:  6159 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.03831790875142\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6159 6160\n",
      "Training loss:-0.0009946561185643077\n",
      "check (8894,) ()\n",
      "epoch 6160\n",
      "====================================\n",
      "Epoch:  6160 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.037175324675324\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6160 6161\n",
      "Training loss:-0.0007587301661260426\n",
      "check (9035,) ()\n",
      "epoch 6161\n",
      "====================================\n",
      "Epoch:  6161 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.03716929069956\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6161 6162\n",
      "Training loss:-0.0033737418707460165\n",
      "check (10000,) ()\n",
      "epoch 6162\n",
      "====================================\n",
      "Epoch:  6162 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.035053554040896\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6162 6163\n",
      "Training loss:-0.00187282869592309\n",
      "check (10000,) ()\n",
      "epoch 6163\n",
      "====================================\n",
      "Epoch:  6163 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.033100762615609\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6163 6164\n",
      "Training loss:-0.005571396555751562\n",
      "check (9847,) ()\n",
      "epoch 6164\n",
      "====================================\n",
      "Epoch:  6164 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.032446463335496\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6164 6165\n",
      "Training loss:-0.0022671062033623457\n",
      "check (10000,) ()\n",
      "epoch 6165\n",
      "====================================\n",
      "Epoch:  6165 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.031792376317924\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6165 6166\n",
      "Training loss:-0.0043585351668298244\n",
      "check (7424,) ()\n",
      "epoch 6166\n",
      "====================================\n",
      "Epoch:  6166 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.031787220240027\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6166 6167\n",
      "Training loss:-5.178307765163481e-05\n",
      "check (9008,) ()\n",
      "epoch 6167\n",
      "====================================\n",
      "Epoch:  6167 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.031457759040052\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6167 6168\n",
      "Training loss:0.003322951029986143\n",
      "check (8375,) ()\n",
      "epoch 6168\n",
      "====================================\n",
      "Epoch:  6168 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.03177691309987\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6168 6169\n",
      "Training loss:0.0027171012479811907\n",
      "check (10000,) ()\n",
      "epoch 6169\n",
      "====================================\n",
      "Epoch:  6169 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -13.030312854595559\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6169 6170\n",
      "Training loss:-0.001148372539319098\n",
      "check (9069,) ()\n",
      "epoch 6170\n",
      "====================================\n",
      "Epoch:  6170 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.030307941653161\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6170 6171\n",
      "Training loss:-0.0016194689087569714\n",
      "check (9444,) ()\n",
      "epoch 6171\n",
      "====================================\n",
      "Epoch:  6171 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.029492788851078\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6171 6172\n",
      "Training loss:-0.0058779590763151646\n",
      "check (7657,) ()\n",
      "epoch 6172\n",
      "====================================\n",
      "Epoch:  6172 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.029812054439404\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6172 6173\n",
      "Training loss:-0.008410236798226833\n",
      "check (8704,) ()\n",
      "epoch 6173\n",
      "====================================\n",
      "Epoch:  6173 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.029645229224041\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6173 6174\n",
      "Training loss:-0.001744184410199523\n",
      "check (10000,) ()\n",
      "epoch 6174\n",
      "====================================\n",
      "Epoch:  6174 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.029154518950437\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6174 6175\n",
      "Training loss:-0.0002160736039513722\n",
      "check (9156,) ()\n",
      "epoch 6175\n",
      "====================================\n",
      "Epoch:  6175 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.028178137651821\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6175 6176\n",
      "Training loss:0.003350678365677595\n",
      "check (9801,) ()\n",
      "epoch 6176\n",
      "====================================\n",
      "Epoch:  6176 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.027525906735752\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6176 6177\n",
      "Training loss:-0.005192634183913469\n",
      "check (10000,) ()\n",
      "epoch 6177\n",
      "====================================\n",
      "Epoch:  6177 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.026388214343532\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6177 6178\n",
      "Training loss:-0.005850111600011587\n",
      "check (8375,) ()\n",
      "epoch 6178\n",
      "====================================\n",
      "Epoch:  6178 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.026383943023632\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6178 6179\n",
      "Training loss:-0.005884550511837006\n",
      "check (9897,) ()\n",
      "epoch 6179\n",
      "====================================\n",
      "Epoch:  6179 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.025732319145494\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6179 6180\n",
      "Training loss:-0.006070819683372974\n",
      "check (10000,) ()\n",
      "epoch 6180\n",
      "====================================\n",
      "Epoch:  6180 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -13.023786407766991\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6180 6181\n",
      "Training loss:0.0018382974667474627\n",
      "check (9364,) ()\n",
      "epoch 6181\n",
      "====================================\n",
      "Epoch:  6181 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.023458987218897\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6181 6182\n",
      "Training loss:-0.003097538137808442\n",
      "check (7489,) ()\n",
      "epoch 6182\n",
      "====================================\n",
      "Epoch:  6182 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.023455192494339\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6182 6183\n",
      "Training loss:0.000638296827673912\n",
      "check (9145,) ()\n",
      "epoch 6183\n",
      "====================================\n",
      "Epoch:  6183 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.022804463852498\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6183 6184\n",
      "Training loss:-0.0022178003564476967\n",
      "check (7885,) ()\n",
      "epoch 6184\n",
      "====================================\n",
      "Epoch:  6184 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.021830530401035\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6184 6185\n",
      "Training loss:-0.0007747347699478269\n",
      "check (9651,) ()\n",
      "epoch 6185\n",
      "====================================\n",
      "Epoch:  6185 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.02085691188359\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6185 6186\n",
      "Training loss:-0.0020699340384453535\n",
      "check (9612,) ()\n",
      "epoch 6186\n",
      "====================================\n",
      "Epoch:  6186 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.020206918849015\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6186 6187\n",
      "Training loss:-0.004832128062844276\n",
      "check (7739,) ()\n",
      "epoch 6187\n",
      "====================================\n",
      "Epoch:  6187 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.020850169710684\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6187 6188\n",
      "Training loss:0.0006689477595500648\n",
      "check (10000,) ()\n",
      "epoch 6188\n",
      "====================================\n",
      "Epoch:  6188 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.019715578539108\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6188 6189\n",
      "Training loss:-0.006311443168669939\n",
      "check (7632,) ()\n",
      "epoch 6189\n",
      "====================================\n",
      "Epoch:  6189 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.019712392955244\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6189 6190\n",
      "Training loss:-0.0044168285094201565\n",
      "check (10000,) ()\n",
      "epoch 6190\n",
      "====================================\n",
      "Epoch:  6190 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.018093699515347\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6190 6191\n",
      "Training loss:-0.0040389192290604115\n",
      "check (6898,) ()\n",
      "epoch 6191\n",
      "====================================\n",
      "Epoch:  6191 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.017767727346147\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6191 6192\n",
      "Training loss:-0.006075114943087101\n",
      "check (6944,) ()\n",
      "epoch 6192\n",
      "====================================\n",
      "Epoch:  6192 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.017764857881136\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6192 6193\n",
      "Training loss:-0.007633096072822809\n",
      "check (8952,) ()\n",
      "epoch 6193\n",
      "====================================\n",
      "Epoch:  6193 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.01711609882125\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6193 6194\n",
      "Training loss:-0.002918930258601904\n",
      "check (7121,) ()\n",
      "epoch 6194\n",
      "====================================\n",
      "Epoch:  6194 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.016951888924766\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6194 6195\n",
      "Training loss:-0.002408416476100683\n",
      "check (10000,) ()\n",
      "epoch 6195\n",
      "====================================\n",
      "Epoch:  6195 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.016303470540759\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6195 6196\n",
      "Training loss:-0.004013577941805124\n",
      "check (8575,) ()\n",
      "epoch 6196\n",
      "====================================\n",
      "Epoch:  6196 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.015816655907036\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6196 6197\n",
      "Training loss:0.000863824097905308\n",
      "check (10000,) ()\n",
      "epoch 6197\n",
      "====================================\n",
      "Epoch:  6197 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -13.01371631434565\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6197 6198\n",
      "Training loss:-0.010913433507084846\n",
      "check (9645,) ()\n",
      "epoch 6198\n",
      "====================================\n",
      "Epoch:  6198 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.012746047111971\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6198 6199\n",
      "Training loss:-0.0023255813866853714\n",
      "check (8724,) ()\n",
      "epoch 6199\n",
      "====================================\n",
      "Epoch:  6199 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.012743990966285\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6199 6200\n",
      "Training loss:0.0007335434784181416\n",
      "check (9319,) ()\n",
      "epoch 6200\n",
      "====================================\n",
      "Epoch:  6200 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.012258064516129\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6200 6201\n",
      "Training loss:-0.004496589303016663\n",
      "Model saved\n",
      "check (9305,) ()\n",
      "epoch 6201\n",
      "====================================\n",
      "Epoch:  6201 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.012256087727787\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6201 6202\n",
      "Training loss:-0.002478892682120204\n",
      "check (9173,) ()\n",
      "epoch 6202\n",
      "====================================\n",
      "Epoch:  6202 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.01225411157691\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6202 6203\n",
      "Training loss:0.0007920397911220789\n",
      "check (10000,) ()\n",
      "epoch 6203\n",
      "====================================\n",
      "Epoch:  6203 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.01144607448009\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6203 6204\n",
      "Training loss:-0.008246198296546936\n",
      "check (8841,) ()\n",
      "epoch 6204\n",
      "====================================\n",
      "Epoch:  6204 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.010799484203739\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6204 6205\n",
      "Training loss:-0.0034476544242352247\n",
      "check (8767,) ()\n",
      "epoch 6205\n",
      "====================================\n",
      "Epoch:  6205 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.011120064464142\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6205 6206\n",
      "Training loss:-0.006462495774030685\n",
      "check (9154,) ()\n",
      "epoch 6206\n",
      "====================================\n",
      "Epoch:  6206 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -13.011762810183694\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6206 6207\n",
      "Training loss:-0.0018202658975496888\n",
      "check (10000,) ()\n",
      "epoch 6207\n",
      "====================================\n",
      "Epoch:  6207 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.010472047688094\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6207 6208\n",
      "Training loss:-0.00827263668179512\n",
      "check (9231,) ()\n",
      "epoch 6208\n",
      "====================================\n",
      "Epoch:  6208 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.010470360824742\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6208 6209\n",
      "Training loss:-0.0002852555480785668\n",
      "check (8778,) ()\n",
      "epoch 6209\n",
      "====================================\n",
      "Epoch:  6209 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -13.009985504912224\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6209 6210\n",
      "Training loss:0.0011431754101067781\n",
      "check (7871,) ()\n",
      "epoch 6210\n",
      "====================================\n",
      "Epoch:  6210 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.009339774557166\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6210 6211\n",
      "Training loss:-0.0065309880301356316\n",
      "check (6925,) ()\n",
      "epoch 6211\n",
      "====================================\n",
      "Epoch:  6211 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.009338270809854\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6211 6212\n",
      "Training loss:-0.0012726078275591135\n",
      "check (8931,) ()\n",
      "epoch 6212\n",
      "====================================\n",
      "Epoch:  6212 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.009336767546683\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6212 6213\n",
      "Training loss:-0.006902055814862251\n",
      "check (6824,) ()\n",
      "epoch 6213\n",
      "====================================\n",
      "Epoch:  6213 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.009657170449058\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6213 6214\n",
      "Training loss:-0.0019310087664052844\n",
      "check (8839,) ()\n",
      "epoch 6214\n",
      "====================================\n",
      "Epoch:  6214 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.009333762471838\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6214 6215\n",
      "Training loss:-0.009456825442612171\n",
      "check (9244,) ()\n",
      "epoch 6215\n",
      "====================================\n",
      "Epoch:  6215 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.009332260659694\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6215 6216\n",
      "Training loss:-0.006483246572315693\n",
      "check (9780,) ()\n",
      "epoch 6216\n",
      "====================================\n",
      "Epoch:  6216 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -13.009169884169884\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6216 6217\n",
      "Training loss:-0.0021628178656101227\n",
      "check (7583,) ()\n",
      "epoch 6217\n",
      "====================================\n",
      "Epoch:  6217 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -13.00949010776902\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6217 6218\n",
      "Training loss:-0.0019374204566702247\n",
      "check (8413,) ()\n",
      "epoch 6218\n",
      "====================================\n",
      "Epoch:  6218 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -13.009166934705693\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6218 6219\n",
      "Training loss:-0.004440181888639927\n",
      "check (10000,) ()\n",
      "epoch 6219\n",
      "====================================\n",
      "Epoch:  6219 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -13.00787908023798\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6219 6220\n",
      "Training loss:0.0009904009057208896\n",
      "check (9980,) ()\n",
      "epoch 6220\n",
      "====================================\n",
      "Epoch:  6220 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -13.007877813504823\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6220 6221\n",
      "Training loss:-0.007329836022108793\n",
      "check (9624,) ()\n",
      "epoch 6221\n",
      "====================================\n",
      "Epoch:  6221 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -13.008037293039704\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6221 6222\n",
      "Training loss:-0.006475375033915043\n",
      "check (10000,) ()\n",
      "epoch 6222\n",
      "====================================\n",
      "Epoch:  6222 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.007232401157184\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6222 6223\n",
      "Training loss:-0.004273619968444109\n",
      "check (9842,) ()\n",
      "epoch 6223\n",
      "====================================\n",
      "Epoch:  6223 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -13.006106379559698\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6223 6224\n",
      "Training loss:-0.00947150681167841\n",
      "check (9522,) ()\n",
      "epoch 6224\n",
      "====================================\n",
      "Epoch:  6224 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -13.004338046272494\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6224 6225\n",
      "Training loss:-0.008186505176126957\n",
      "check (7353,) ()\n",
      "epoch 6225\n",
      "====================================\n",
      "Epoch:  6225 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -13.004819277108433\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6225 6226\n",
      "Training loss:-0.005087859928607941\n",
      "check (10000,) ()\n",
      "epoch 6226\n",
      "====================================\n",
      "Epoch:  6226 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -13.003212335367813\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6226 6227\n",
      "Training loss:-0.006851585581898689\n",
      "check (8531,) ()\n",
      "epoch 6227\n",
      "====================================\n",
      "Epoch:  6227 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -13.002408864621808\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6227 6228\n",
      "Training loss:-0.002908863592892885\n",
      "check (9928,) ()\n",
      "epoch 6228\n",
      "====================================\n",
      "Epoch:  6228 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -13.001445086705202\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6228 6229\n",
      "Training loss:-0.003127910429611802\n",
      "check (9033,) ()\n",
      "epoch 6229\n",
      "====================================\n",
      "Epoch:  6229 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -13.000802697062129\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6229 6230\n",
      "Training loss:0.001554955611936748\n",
      "check (10000,) ()\n",
      "epoch 6230\n",
      "====================================\n",
      "Epoch:  6230 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.999357945425361\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6230 6231\n",
      "Training loss:-0.000402123638195917\n",
      "check (7843,) ()\n",
      "epoch 6231\n",
      "====================================\n",
      "Epoch:  6231 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.999037072701011\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6231 6232\n",
      "Training loss:-0.00881986040621996\n",
      "check (10000,) ()\n",
      "epoch 6232\n",
      "====================================\n",
      "Epoch:  6232 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -12.996790757381259\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6232 6233\n",
      "Training loss:-0.002536703133955598\n",
      "check (8032,) ()\n",
      "epoch 6233\n",
      "====================================\n",
      "Epoch:  6233 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.996630835873576\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6233 6234\n",
      "Training loss:-0.0027057977858930826\n",
      "check (9072,) ()\n",
      "epoch 6234\n",
      "====================================\n",
      "Epoch:  6234 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.996310555020854\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6234 6235\n",
      "Training loss:-0.003535263938829303\n",
      "check (10000,) ()\n",
      "epoch 6235\n",
      "====================================\n",
      "Epoch:  6235 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -12.994065757818765\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6235 6236\n",
      "Training loss:-0.003618998685851693\n",
      "check (7021,) ()\n",
      "epoch 6236\n",
      "====================================\n",
      "Epoch:  6236 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.994066709429122\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6236 6237\n",
      "Training loss:0.007915857248008251\n",
      "check (10000,) ()\n",
      "epoch 6237\n",
      "====================================\n",
      "Epoch:  6237 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.993265993265993\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6237 6238\n",
      "Training loss:0.0012330737663432956\n",
      "check (7785,) ()\n",
      "epoch 6238\n",
      "====================================\n",
      "Epoch:  6238 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.993587688361654\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6238 6239\n",
      "Training loss:-0.004372686613351107\n",
      "check (8594,) ()\n",
      "epoch 6239\n",
      "====================================\n",
      "Epoch:  6239 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.992787305657957\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6239 6240\n",
      "Training loss:-0.003931898158043623\n",
      "check (10000,) ()\n",
      "epoch 6240\n",
      "====================================\n",
      "Epoch:  6240 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.990865384615384\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6240 6241\n",
      "Training loss:-0.0003154540900141001\n",
      "check (10000,) ()\n",
      "epoch 6241\n",
      "====================================\n",
      "Epoch:  6241 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.990225925332478\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6241 6242\n",
      "Training loss:-0.006818109191954136\n",
      "check (7630,) ()\n",
      "epoch 6242\n",
      "====================================\n",
      "Epoch:  6242 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.989746876001282\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6242 6243\n",
      "Training loss:-0.005995321553200483\n",
      "check (8094,) ()\n",
      "epoch 6243\n",
      "====================================\n",
      "Epoch:  6243 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.989267980137754\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6243 6244\n",
      "Training loss:-0.0032994928769767284\n",
      "check (10000,) ()\n",
      "epoch 6244\n",
      "====================================\n",
      "Epoch:  6244 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.987668161434977\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6244 6245\n",
      "Training loss:-0.01564948260784149\n",
      "check (9953,) ()\n",
      "epoch 6245\n",
      "====================================\n",
      "Epoch:  6245 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.986549239391513\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6245 6246\n",
      "Training loss:0.00034980004420503974\n",
      "check (10000,) ()\n",
      "epoch 6246\n",
      "====================================\n",
      "Epoch:  6246 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.985430675632404\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6246 6247\n",
      "Training loss:-0.005819128826260567\n",
      "check (8208,) ()\n",
      "epoch 6247\n",
      "====================================\n",
      "Epoch:  6247 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.985433007843765\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6247 6248\n",
      "Training loss:-0.013125558383762836\n",
      "check (9757,) ()\n",
      "epoch 6248\n",
      "====================================\n",
      "Epoch:  6248 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.984314980793854\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6248 6249\n",
      "Training loss:-0.002705589635297656\n",
      "check (9659,) ()\n",
      "epoch 6249\n",
      "====================================\n",
      "Epoch:  6249 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.983357337173947\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6249 6250\n",
      "Training loss:-0.004772098269313574\n",
      "check (9099,) ()\n",
      "epoch 6250\n",
      "====================================\n",
      "Epoch:  6250 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.98384\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6250 6251\n",
      "Training loss:-0.004438029136508703\n",
      "Model saved\n",
      "check (8521,) ()\n",
      "epoch 6251\n",
      "====================================\n",
      "Epoch:  6251 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.984002559590465\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6251 6252\n",
      "Training loss:-0.0021064216271042824\n",
      "check (8950,) ()\n",
      "epoch 6252\n",
      "====================================\n",
      "Epoch:  6252 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.98320537428023\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6252 6253\n",
      "Training loss:-0.002224615542218089\n",
      "check (9356,) ()\n",
      "epoch 6253\n",
      "====================================\n",
      "Epoch:  6253 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.982568367183752\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6253 6254\n",
      "Training loss:-0.0069420519284904\n",
      "check (10000,) ()\n",
      "epoch 6254\n",
      "====================================\n",
      "Epoch:  6254 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.981451870802687\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6254 6255\n",
      "Training loss:-0.0028509909752756357\n",
      "check (9470,) ()\n",
      "epoch 6255\n",
      "====================================\n",
      "Epoch:  6255 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.980015987210232\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6255 6256\n",
      "Training loss:-0.010615142993628979\n",
      "check (7417,) ()\n",
      "epoch 6256\n",
      "====================================\n",
      "Epoch:  6256 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.980658567774936\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6256 6257\n",
      "Training loss:0.009919899515807629\n",
      "check (9130,) ()\n",
      "epoch 6257\n",
      "====================================\n",
      "Epoch:  6257 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.97922326993767\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6257 6258\n",
      "Training loss:0.001141665386967361\n",
      "check (6759,) ()\n",
      "epoch 6258\n",
      "====================================\n",
      "Epoch:  6258 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.979705976350271\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6258 6259\n",
      "Training loss:-0.0043992334976792336\n",
      "check (9489,) ()\n",
      "epoch 6259\n",
      "====================================\n",
      "Epoch:  6259 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.979389678862438\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6259 6260\n",
      "Training loss:0.0011842353269457817\n",
      "check (9563,) ()\n",
      "epoch 6260\n",
      "====================================\n",
      "Epoch:  6260 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.978434504792332\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6260 6261\n",
      "Training loss:-0.006362399086356163\n",
      "check (7984,) ()\n",
      "epoch 6261\n",
      "====================================\n",
      "Epoch:  6261 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.978278230314647\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6261 6262\n",
      "Training loss:0.0032252129167318344\n",
      "check (10000,) ()\n",
      "epoch 6262\n",
      "====================================\n",
      "Epoch:  6262 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.977004152028107\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6262 6263\n",
      "Training loss:-0.006970069836825132\n",
      "check (9950,) ()\n",
      "epoch 6263\n",
      "====================================\n",
      "Epoch:  6263 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.976688487945074\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6263 6264\n",
      "Training loss:-0.0015256603946909308\n",
      "check (9104,) ()\n",
      "epoch 6264\n",
      "====================================\n",
      "Epoch:  6264 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.975415070242656\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6264 6265\n",
      "Training loss:0.005146445706486702\n",
      "check (10000,) ()\n",
      "epoch 6265\n",
      "====================================\n",
      "Epoch:  6265 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.974940143655228\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6265 6266\n",
      "Training loss:-0.003765858942642808\n",
      "check (8453,) ()\n",
      "epoch 6266\n",
      "====================================\n",
      "Epoch:  6266 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.974305777210342\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6266 6267\n",
      "Training loss:-0.008956143632531166\n",
      "check (9875,) ()\n",
      "epoch 6267\n",
      "====================================\n",
      "Epoch:  6267 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.97399074517313\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6267 6268\n",
      "Training loss:-0.004701103549450636\n",
      "check (6894,) ()\n",
      "epoch 6268\n",
      "====================================\n",
      "Epoch:  6268 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.97431397574984\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6268 6269\n",
      "Training loss:-0.0013041602214798331\n",
      "check (6371,) ()\n",
      "epoch 6269\n",
      "====================================\n",
      "Epoch:  6269 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.974637103206254\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6269 6270\n",
      "Training loss:0.0006790999323129654\n",
      "check (10000,) ()\n",
      "epoch 6270\n",
      "====================================\n",
      "Epoch:  6270 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.973684210526315\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6270 6271\n",
      "Training loss:-0.008154202252626419\n",
      "check (9608,) ()\n",
      "epoch 6271\n",
      "====================================\n",
      "Epoch:  6271 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.973050550151491\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6271 6272\n",
      "Training loss:0.00023411631991621107\n",
      "check (10000,) ()\n",
      "epoch 6272\n",
      "====================================\n",
      "Epoch:  6272 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.971938775510203\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6272 6273\n",
      "Training loss:-2.8674698114627972e-05\n",
      "check (8374,) ()\n",
      "epoch 6273\n",
      "====================================\n",
      "Epoch:  6273 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.971943248844253\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6273 6274\n",
      "Training loss:-0.003269564127549529\n",
      "check (9094,) ()\n",
      "epoch 6274\n",
      "====================================\n",
      "Epoch:  6274 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -12.969397513547976\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6274 6275\n",
      "Training loss:-0.004778503440320492\n",
      "check (8299,) ()\n",
      "epoch 6275\n",
      "====================================\n",
      "Epoch:  6275 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.969402390438248\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6275 6276\n",
      "Training loss:-0.002279341220855713\n",
      "check (7422,) ()\n",
      "epoch 6276\n",
      "====================================\n",
      "Epoch:  6276 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.969247928616953\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6276 6277\n",
      "Training loss:-0.0007699070847593248\n",
      "check (9411,) ()\n",
      "epoch 6277\n",
      "====================================\n",
      "Epoch:  6277 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.968615580691413\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6277 6278\n",
      "Training loss:-0.004979453515261412\n",
      "check (8305,) ()\n",
      "epoch 6278\n",
      "====================================\n",
      "Epoch:  6278 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.968939152596368\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6278 6279\n",
      "Training loss:-0.0019668161403387785\n",
      "check (9052,) ()\n",
      "epoch 6279\n",
      "====================================\n",
      "Epoch:  6279 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.969262621436535\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6279 6280\n",
      "Training loss:-0.004421972669661045\n",
      "check (7778,) ()\n",
      "epoch 6280\n",
      "====================================\n",
      "Epoch:  6280 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.969108280254778\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6280 6281\n",
      "Training loss:-0.00023972046619746834\n",
      "check (7422,) ()\n",
      "epoch 6281\n",
      "====================================\n",
      "Epoch:  6281 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.969431619168923\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6281 6282\n",
      "Training loss:-0.0011276729637756944\n",
      "check (9505,) ()\n",
      "epoch 6282\n",
      "====================================\n",
      "Epoch:  6282 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.96927730022286\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6282 6283\n",
      "Training loss:-0.001485215499997139\n",
      "check (8097,) ()\n",
      "epoch 6283\n",
      "====================================\n",
      "Epoch:  6283 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.968963870762375\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6283 6284\n",
      "Training loss:-0.0010329617653042078\n",
      "check (8449,) ()\n",
      "epoch 6284\n",
      "====================================\n",
      "Epoch:  6284 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.968491406747294\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6284 6285\n",
      "Training loss:-0.0017230864614248276\n",
      "check (10000,) ()\n",
      "epoch 6285\n",
      "====================================\n",
      "Epoch:  6285 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -12.966109785202864\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6285 6286\n",
      "Training loss:-0.004639902617782354\n",
      "check (9489,) ()\n",
      "epoch 6286\n",
      "====================================\n",
      "Epoch:  6286 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.965160674514795\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6286 6287\n",
      "Training loss:-0.0030982939060777426\n",
      "check (10000,) ()\n",
      "epoch 6287\n",
      "====================================\n",
      "Epoch:  6287 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.963257515508191\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6287 6288\n",
      "Training loss:-0.003666009521111846\n",
      "check (9785,) ()\n",
      "epoch 6288\n",
      "====================================\n",
      "Epoch:  6288 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.962309160305344\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6288 6289\n",
      "Training loss:0.000655233976431191\n",
      "check (8215,) ()\n",
      "epoch 6289\n",
      "====================================\n",
      "Epoch:  6289 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.962156145651138\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6289 6290\n",
      "Training loss:-0.0027773885522037745\n",
      "check (9017,) ()\n",
      "epoch 6290\n",
      "====================================\n",
      "Epoch:  6290 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.962639109697934\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6290 6291\n",
      "Training loss:-0.007580900564789772\n",
      "check (9095,) ()\n",
      "epoch 6291\n",
      "====================================\n",
      "Epoch:  6291 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.962009219519949\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6291 6292\n",
      "Training loss:-0.00435864320024848\n",
      "check (6821,) ()\n",
      "epoch 6292\n",
      "====================================\n",
      "Epoch:  6292 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.962333121424031\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6292 6293\n",
      "Training loss:-0.009452292695641518\n",
      "check (7633,) ()\n",
      "epoch 6293\n",
      "====================================\n",
      "Epoch:  6293 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.962339106944224\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6293 6294\n",
      "Training loss:-0.001525301137007773\n",
      "check (10000,) ()\n",
      "epoch 6294\n",
      "====================================\n",
      "Epoch:  6294 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.9604385128694\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6294 6295\n",
      "Training loss:0.0018504116451367736\n",
      "check (8671,) ()\n",
      "epoch 6295\n",
      "====================================\n",
      "Epoch:  6295 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.95980937251787\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6295 6296\n",
      "Training loss:-0.0024989277590066195\n",
      "check (8932,) ()\n",
      "epoch 6296\n",
      "====================================\n",
      "Epoch:  6296 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.958545108005083\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6296 6297\n",
      "Training loss:0.002349656308069825\n",
      "check (9683,) ()\n",
      "epoch 6297\n",
      "====================================\n",
      "Epoch:  6297 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.957916468159441\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6297 6298\n",
      "Training loss:-0.006078328937292099\n",
      "check (10000,) ()\n",
      "epoch 6298\n",
      "====================================\n",
      "Epoch:  6298 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.956970466814862\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6298 6299\n",
      "Training loss:0.002042552223429084\n",
      "check (9723,) ()\n",
      "epoch 6299\n",
      "====================================\n",
      "Epoch:  6299 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.95570725511986\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6299 6300\n",
      "Training loss:-0.004334294702857733\n",
      "check (9512,) ()\n",
      "epoch 6300\n",
      "====================================\n",
      "Epoch:  6300 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.955238095238096\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6300 6301\n",
      "Training loss:-0.003427515970543027\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 6301\n",
      "====================================\n",
      "Epoch:  6301 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.954134264402477\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6301 6302\n",
      "Training loss:-0.003983699716627598\n",
      "check (10000,) ()\n",
      "epoch 6302\n",
      "====================================\n",
      "Epoch:  6302 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.953030783878134\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6302 6303\n",
      "Training loss:-0.003008123952895403\n",
      "check (9645,) ()\n",
      "epoch 6303\n",
      "====================================\n",
      "Epoch:  6303 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.952403617325084\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6303 6304\n",
      "Training loss:-0.004635622724890709\n",
      "check (9010,) ()\n",
      "epoch 6304\n",
      "====================================\n",
      "Epoch:  6304 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.95098350253807\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6304 6305\n",
      "Training loss:2.9373592042247765e-05\n",
      "check (9106,) ()\n",
      "epoch 6305\n",
      "====================================\n",
      "Epoch:  6305 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.950198255352895\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6305 6306\n",
      "Training loss:-0.0016942484071478248\n",
      "check (7836,) ()\n",
      "epoch 6306\n",
      "====================================\n",
      "Epoch:  6306 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.949413257215351\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6306 6307\n",
      "Training loss:-0.0018892387161031365\n",
      "check (10000,) ()\n",
      "epoch 6307\n",
      "====================================\n",
      "Epoch:  6307 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.948311400031711\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6307 6308\n",
      "Training loss:0.002860414795577526\n",
      "check (10000,) ()\n",
      "epoch 6308\n",
      "====================================\n",
      "Epoch:  6308 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.946575776791375\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6308 6309\n",
      "Training loss:0.0011574386153370142\n",
      "check (7185,) ()\n",
      "epoch 6309\n",
      "====================================\n",
      "Epoch:  6309 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.947218259629102\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6309 6310\n",
      "Training loss:-0.01498311385512352\n",
      "check (9095,) ()\n",
      "epoch 6310\n",
      "====================================\n",
      "Epoch:  6310 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.946434231378763\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6310 6311\n",
      "Training loss:-0.0061176614835858345\n",
      "check (9219,) ()\n",
      "epoch 6311\n",
      "====================================\n",
      "Epoch:  6311 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.946442719061956\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6311 6312\n",
      "Training loss:-0.0026000093203037977\n",
      "check (10000,) ()\n",
      "epoch 6312\n",
      "====================================\n",
      "Epoch:  6312 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -12.94423320659062\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6312 6313\n",
      "Training loss:-0.0038261765148490667\n",
      "check (10000,) ()\n",
      "epoch 6313\n",
      "====================================\n",
      "Epoch:  6313 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.942182797402186\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6313 6314\n",
      "Training loss:-0.0032265170011669397\n",
      "check (7275,) ()\n",
      "epoch 6314\n",
      "====================================\n",
      "Epoch:  6314 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.94282546721571\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6314 6315\n",
      "Training loss:-0.001265811501070857\n",
      "check (7417,) ()\n",
      "epoch 6315\n",
      "====================================\n",
      "Epoch:  6315 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.942517814726841\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6315 6316\n",
      "Training loss:-0.00028404887416400015\n",
      "check (8032,) ()\n",
      "epoch 6316\n",
      "====================================\n",
      "Epoch:  6316 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.942210259658012\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6316 6317\n",
      "Training loss:-0.008423172868788242\n",
      "check (9505,) ()\n",
      "epoch 6317\n",
      "====================================\n",
      "Epoch:  6317 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.941586195979104\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6317 6318\n",
      "Training loss:-0.00016192416660487652\n",
      "check (10000,) ()\n",
      "epoch 6318\n",
      "====================================\n",
      "Epoch:  6318 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.93985438429883\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6318 6319\n",
      "Training loss:-0.0030427633319050074\n",
      "check (10000,) ()\n",
      "epoch 6319\n",
      "====================================\n",
      "Epoch:  6319 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -12.937331856306377\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6319 6320\n",
      "Training loss:-0.00614419300109148\n",
      "check (10000,) ()\n",
      "epoch 6320\n",
      "====================================\n",
      "Epoch:  6320 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.936550632911393\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6320 6321\n",
      "Training loss:-0.01144816167652607\n",
      "check (10000,) ()\n",
      "epoch 6321\n",
      "====================================\n",
      "Epoch:  6321 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.93561145388388\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6321 6322\n",
      "Training loss:-0.001502382685430348\n",
      "check (9261,) ()\n",
      "epoch 6322\n",
      "====================================\n",
      "Epoch:  6322 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.934830749762734\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6322 6323\n",
      "Training loss:0.0017816211329773068\n",
      "check (10000,) ()\n",
      "epoch 6323\n",
      "====================================\n",
      "Epoch:  6323 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.934050292582635\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6323 6324\n",
      "Training loss:-0.0036920197308063507\n",
      "check (8037,) ()\n",
      "epoch 6324\n",
      "====================================\n",
      "Epoch:  6324 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.93437697659709\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6324 6325\n",
      "Training loss:-0.00044116165372543037\n",
      "check (6765,) ()\n",
      "epoch 6325\n",
      "====================================\n",
      "Epoch:  6325 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.93407114624506\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6325 6326\n",
      "Training loss:-0.002215523971244693\n",
      "check (7341,) ()\n",
      "epoch 6326\n",
      "====================================\n",
      "Epoch:  6326 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.93471387922858\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6326 6327\n",
      "Training loss:-0.002829626202583313\n",
      "check (10000,) ()\n",
      "epoch 6327\n",
      "====================================\n",
      "Epoch:  6327 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -12.932353406037617\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6327 6328\n",
      "Training loss:-0.0034724243450909853\n",
      "check (8743,) ()\n",
      "epoch 6328\n",
      "====================================\n",
      "Epoch:  6328 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.931890012642224\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6328 6329\n",
      "Training loss:0.0051359254866838455\n",
      "check (8667,) ()\n",
      "epoch 6329\n",
      "====================================\n",
      "Epoch:  6329 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.93111075999368\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6329 6330\n",
      "Training loss:-0.0036474140360951424\n",
      "check (10000,) ()\n",
      "epoch 6330\n",
      "====================================\n",
      "Epoch:  6330 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.929699842022117\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6330 6331\n",
      "Training loss:-0.0037782390136271715\n",
      "check (7910,) ()\n",
      "epoch 6331\n",
      "====================================\n",
      "Epoch:  6331 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.930026851998104\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6331 6332\n",
      "Training loss:-0.002527569653466344\n",
      "check (10000,) ()\n",
      "epoch 6332\n",
      "====================================\n",
      "Epoch:  6332 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.929564118761844\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6332 6333\n",
      "Training loss:-0.005208167247474194\n",
      "check (8933,) ()\n",
      "epoch 6333\n",
      "====================================\n",
      "Epoch:  6333 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.929891046897206\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6333 6334\n",
      "Training loss:0.002288550604134798\n",
      "check (10000,) ()\n",
      "epoch 6334\n",
      "====================================\n",
      "Epoch:  6334 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.928796968740132\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6334 6335\n",
      "Training loss:-7.287216430995613e-05\n",
      "check (10000,) ()\n",
      "epoch 6335\n",
      "====================================\n",
      "Epoch:  6335 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.927861089187056\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6335 6336\n",
      "Training loss:-0.005845366045832634\n",
      "check (9246,) ()\n",
      "epoch 6336\n",
      "====================================\n",
      "Epoch:  6336 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.927556818181818\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6336 6337\n",
      "Training loss:0.0009617196046747267\n",
      "check (10000,) ()\n",
      "epoch 6337\n",
      "====================================\n",
      "Epoch:  6337 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -12.925359002682658\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6337 6338\n",
      "Training loss:-0.002587015274912119\n",
      "check (8812,) ()\n",
      "epoch 6338\n",
      "====================================\n",
      "Epoch:  6338 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.925370779425686\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6338 6339\n",
      "Training loss:0.0018013734370470047\n",
      "check (8191,) ()\n",
      "epoch 6339\n",
      "====================================\n",
      "Epoch:  6339 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.924593784508598\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6339 6340\n",
      "Training loss:-0.005772242788225412\n",
      "check (9025,) ()\n",
      "epoch 6340\n",
      "====================================\n",
      "Epoch:  6340 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.923501577287066\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6340 6341\n",
      "Training loss:-0.0020285681821405888\n",
      "check (7836,) ()\n",
      "epoch 6341\n",
      "====================================\n",
      "Epoch:  6341 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.924144456710298\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6341 6342\n",
      "Training loss:-0.004130159504711628\n",
      "check (9725,) ()\n",
      "epoch 6342\n",
      "====================================\n",
      "Epoch:  6342 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.923998738568274\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6342 6343\n",
      "Training loss:0.0007794399280101061\n",
      "check (10000,) ()\n",
      "epoch 6343\n",
      "====================================\n",
      "Epoch:  6343 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.9235377581586\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6343 6344\n",
      "Training loss:0.0022413625847548246\n",
      "check (9711,) ()\n",
      "epoch 6344\n",
      "====================================\n",
      "Epoch:  6344 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.921973518284993\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6344 6345\n",
      "Training loss:-0.00064684241078794\n",
      "check (10000,) ()\n",
      "epoch 6345\n",
      "====================================\n",
      "Epoch:  6345 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.920252167060678\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6345 6346\n",
      "Training loss:-0.004486295394599438\n",
      "check (9547,) ()\n",
      "epoch 6346\n",
      "====================================\n",
      "Epoch:  6346 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.91994957453514\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6346 6347\n",
      "Training loss:0.002393836621195078\n",
      "check (10000,) ()\n",
      "epoch 6347\n",
      "====================================\n",
      "Epoch:  6347 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.918229084606901\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6347 6348\n",
      "Training loss:-0.002808342454954982\n",
      "check (10000,) ()\n",
      "epoch 6348\n",
      "====================================\n",
      "Epoch:  6348 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.917139256458727\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6348 6349\n",
      "Training loss:-0.007330711465328932\n",
      "check (10000,) ()\n",
      "epoch 6349\n",
      "====================================\n",
      "Epoch:  6349 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.916207276736493\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6349 6350\n",
      "Training loss:0.0030218891333788633\n",
      "check (8048,) ()\n",
      "epoch 6350\n",
      "====================================\n",
      "Epoch:  6350 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.916692913385827\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6350 6351\n",
      "Training loss:-0.0018714768812060356\n",
      "Model saved\n",
      "check (9242,) ()\n",
      "epoch 6351\n",
      "====================================\n",
      "Epoch:  6351 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.916076208471107\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6351 6352\n",
      "Training loss:-0.010207945480942726\n",
      "check (8361,) ()\n",
      "epoch 6352\n",
      "====================================\n",
      "Epoch:  6352 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.916719143576826\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6352 6353\n",
      "Training loss:-0.005922750104218721\n",
      "check (10000,) ()\n",
      "epoch 6353\n",
      "====================================\n",
      "Epoch:  6353 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.914843381079805\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6353 6354\n",
      "Training loss:-0.004008545074611902\n",
      "check (7433,) ()\n",
      "epoch 6354\n",
      "====================================\n",
      "Epoch:  6354 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.914069877242682\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6354 6355\n",
      "Training loss:-0.0022595953196287155\n",
      "check (9992,) ()\n",
      "epoch 6355\n",
      "====================================\n",
      "Epoch:  6355 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.913139260424863\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6355 6356\n",
      "Training loss:-0.006098369602113962\n",
      "check (8717,) ()\n",
      "epoch 6356\n",
      "====================================\n",
      "Epoch:  6356 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.912523599748269\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6356 6357\n",
      "Training loss:0.003156584221869707\n",
      "check (10000,) ()\n",
      "epoch 6357\n",
      "====================================\n",
      "Epoch:  6357 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.911593518955483\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6357 6358\n",
      "Training loss:0.0033601485192775726\n",
      "check (10000,) ()\n",
      "epoch 6358\n",
      "====================================\n",
      "Epoch:  6358 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.910506448568732\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6358 6359\n",
      "Training loss:-0.0016263648867607117\n",
      "check (8756,) ()\n",
      "epoch 6359\n",
      "====================================\n",
      "Epoch:  6359 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.909891492373015\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6359 6360\n",
      "Training loss:-0.003593004308640957\n",
      "check (9007,) ()\n",
      "epoch 6360\n",
      "====================================\n",
      "Epoch:  6360 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.909591194968554\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6360 6361\n",
      "Training loss:-0.010387472808361053\n",
      "check (10000,) ()\n",
      "epoch 6361\n",
      "====================================\n",
      "Epoch:  6361 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.907876120106902\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6361 6362\n",
      "Training loss:-0.004843585193157196\n",
      "check (8989,) ()\n",
      "epoch 6362\n",
      "====================================\n",
      "Epoch:  6362 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.907890600440114\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6362 6363\n",
      "Training loss:-0.0013123613316565752\n",
      "check (10000,) ()\n",
      "epoch 6363\n",
      "====================================\n",
      "Epoch:  6363 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.905862014772906\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6363 6364\n",
      "Training loss:-0.005148446653038263\n",
      "check (10000,) ()\n",
      "epoch 6364\n",
      "====================================\n",
      "Epoch:  6364 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.904934003771213\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6364 6365\n",
      "Training loss:-0.0018235675524920225\n",
      "check (10000,) ()\n",
      "epoch 6365\n",
      "====================================\n",
      "Epoch:  6365 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.90510604870385\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6365 6366\n",
      "Training loss:-0.0012211623834446073\n",
      "check (10000,) ()\n",
      "epoch 6366\n",
      "====================================\n",
      "Epoch:  6366 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.904021363493559\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6366 6367\n",
      "Training loss:-0.008786007761955261\n",
      "check (9029,) ()\n",
      "epoch 6367\n",
      "====================================\n",
      "Epoch:  6367 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.903722318203235\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6367 6368\n",
      "Training loss:-0.008874563500285149\n",
      "check (10000,) ()\n",
      "epoch 6368\n",
      "====================================\n",
      "Epoch:  6368 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.902795226130653\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6368 6369\n",
      "Training loss:0.0015439697308465838\n",
      "check (8303,) ()\n",
      "epoch 6369\n",
      "====================================\n",
      "Epoch:  6369 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.902810488302716\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6369 6370\n",
      "Training loss:-0.0069245160557329655\n",
      "check (10000,) ()\n",
      "epoch 6370\n",
      "====================================\n",
      "Epoch:  6370 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.901412872841444\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6370 6371\n",
      "Training loss:0.0006082374602556229\n",
      "check (10000,) ()\n",
      "epoch 6371\n",
      "====================================\n",
      "Epoch:  6371 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.899701773661905\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6371 6372\n",
      "Training loss:-0.0008548448677174747\n",
      "check (10000,) ()\n",
      "epoch 6372\n",
      "====================================\n",
      "Epoch:  6372 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.89924670433145\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6372 6373\n",
      "Training loss:-0.003113096347078681\n",
      "check (10000,) ()\n",
      "epoch 6373\n",
      "====================================\n",
      "Epoch:  6373 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.897379570061196\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6373 6374\n",
      "Training loss:-0.007331226486712694\n",
      "check (9553,) ()\n",
      "epoch 6374\n",
      "====================================\n",
      "Epoch:  6374 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.896768120489488\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6374 6375\n",
      "Training loss:-0.003594041336327791\n",
      "check (10000,) ()\n",
      "epoch 6375\n",
      "====================================\n",
      "Epoch:  6375 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.895372549019608\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6375 6376\n",
      "Training loss:0.00029743689810857177\n",
      "check (9647,) ()\n",
      "epoch 6376\n",
      "====================================\n",
      "Epoch:  6376 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.894134253450439\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6376 6377\n",
      "Training loss:-0.007717810571193695\n",
      "check (10000,) ()\n",
      "epoch 6377\n",
      "====================================\n",
      "Epoch:  6377 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.892739532695625\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6377 6378\n",
      "Training loss:0.0011983802542090416\n",
      "check (6734,) ()\n",
      "epoch 6378\n",
      "====================================\n",
      "Epoch:  6378 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.893226716839134\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6378 6379\n",
      "Training loss:-0.00245660194195807\n",
      "check (9188,) ()\n",
      "epoch 6379\n",
      "====================================\n",
      "Epoch:  6379 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.892616397554475\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6379 6380\n",
      "Training loss:-0.005765457171946764\n",
      "check (7607,) ()\n",
      "epoch 6380\n",
      "====================================\n",
      "Epoch:  6380 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.892633228840126\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6380 6381\n",
      "Training loss:-0.007470566779375076\n",
      "check (9605,) ()\n",
      "epoch 6381\n",
      "====================================\n",
      "Epoch:  6381 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.891709763359975\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6381 6382\n",
      "Training loss:-0.0063101863488554955\n",
      "check (9136,) ()\n",
      "epoch 6382\n",
      "====================================\n",
      "Epoch:  6382 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.891413350047007\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6382 6383\n",
      "Training loss:-0.007929131388664246\n",
      "check (9586,) ()\n",
      "epoch 6383\n",
      "====================================\n",
      "Epoch:  6383 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.891430361898793\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6383 6384\n",
      "Training loss:0.0011480730026960373\n",
      "check (8869,) ()\n",
      "epoch 6384\n",
      "====================================\n",
      "Epoch:  6384 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.891290726817042\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6384 6385\n",
      "Training loss:0.001773783122189343\n",
      "check (8865,) ()\n",
      "epoch 6385\n",
      "====================================\n",
      "Epoch:  6385 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.891464369616289\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6385 6386\n",
      "Training loss:-0.005329118110239506\n",
      "check (9691,) ()\n",
      "epoch 6386\n",
      "====================================\n",
      "Epoch:  6386 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.890698402756028\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6386 6387\n",
      "Training loss:-0.0021353105548769236\n",
      "check (9818,) ()\n",
      "epoch 6387\n",
      "====================================\n",
      "Epoch:  6387 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.89024581180523\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6387 6388\n",
      "Training loss:-0.0027878296095877886\n",
      "check (10000,) ()\n",
      "epoch 6388\n",
      "====================================\n",
      "Epoch:  6388 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.889480275516593\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6388 6389\n",
      "Training loss:0.0026864015962928534\n",
      "check (10000,) ()\n",
      "epoch 6389\n",
      "====================================\n",
      "Epoch:  6389 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.889341054938175\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6389 6390\n",
      "Training loss:-0.00039114951505325735\n",
      "check (8433,) ()\n",
      "epoch 6390\n",
      "====================================\n",
      "Epoch:  6390 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.889201877934273\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6390 6391\n",
      "Training loss:-0.0008597756968811154\n",
      "check (9671,) ()\n",
      "epoch 6391\n",
      "====================================\n",
      "Epoch:  6391 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.88906274448443\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6391 6392\n",
      "Training loss:0.0030979719012975693\n",
      "check (10000,) ()\n",
      "epoch 6392\n",
      "====================================\n",
      "Epoch:  6392 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.887359198998748\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6392 6393\n",
      "Training loss:0.003581122262403369\n",
      "check (8903,) ()\n",
      "epoch 6393\n",
      "====================================\n",
      "Epoch:  6393 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.887533239480682\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6393 6394\n",
      "Training loss:-0.0016551715089008212\n",
      "check (10000,) ()\n",
      "epoch 6394\n",
      "====================================\n",
      "Epoch:  6394 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.88676884579293\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6394 6395\n",
      "Training loss:-0.007447604555636644\n",
      "check (8530,) ()\n",
      "epoch 6395\n",
      "====================================\n",
      "Epoch:  6395 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.886161063330727\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6395 6396\n",
      "Training loss:-0.0014470542082563043\n",
      "check (9854,) ()\n",
      "epoch 6396\n",
      "====================================\n",
      "Epoch:  6396 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.885240775484679\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6396 6397\n",
      "Training loss:-0.005011407192796469\n",
      "check (10000,) ()\n",
      "epoch 6397\n",
      "====================================\n",
      "Epoch:  6397 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.884320775363452\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6397 6398\n",
      "Training loss:-0.004879386629909277\n",
      "check (8312,) ()\n",
      "epoch 6398\n",
      "====================================\n",
      "Epoch:  6398 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.883557361675523\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6398 6399\n",
      "Training loss:-0.01263729203492403\n",
      "check (8188,) ()\n",
      "epoch 6399\n",
      "====================================\n",
      "Epoch:  6399 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.883419284263166\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6399 6400\n",
      "Training loss:-0.004716816823929548\n",
      "check (9694,) ()\n",
      "epoch 6400\n",
      "====================================\n",
      "Epoch:  6400 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.88234375\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6400 6401\n",
      "Training loss:-0.0007668969919905066\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 6401\n",
      "====================================\n",
      "Epoch:  6401 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -12.88001874707077\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6401 6402\n",
      "Training loss:-0.00011188163625774905\n",
      "check (10000,) ()\n",
      "epoch 6402\n",
      "====================================\n",
      "Epoch:  6402 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.878944079975009\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6402 6403\n",
      "Training loss:-0.004249339923262596\n",
      "check (10000,) ()\n",
      "epoch 6403\n",
      "====================================\n",
      "Epoch:  6403 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.877869748555364\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6403 6404\n",
      "Training loss:-0.007448743563145399\n",
      "check (10000,) ()\n",
      "epoch 6404\n",
      "====================================\n",
      "Epoch:  6404 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.876639600249844\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6404 6405\n",
      "Training loss:0.0022512616124004126\n",
      "check (10000,) ()\n",
      "epoch 6405\n",
      "====================================\n",
      "Epoch:  6405 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.875722092115534\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6405 6406\n",
      "Training loss:0.006920091807842255\n",
      "check (9493,) ()\n",
      "epoch 6406\n",
      "====================================\n",
      "Epoch:  6406 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.875117077739619\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6406 6407\n",
      "Training loss:-0.0030926992185413837\n",
      "check (8653,) ()\n",
      "epoch 6407\n",
      "====================================\n",
      "Epoch:  6407 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.87451225222413\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6407 6408\n",
      "Training loss:-0.005155120510607958\n",
      "check (9183,) ()\n",
      "epoch 6408\n",
      "====================================\n",
      "Epoch:  6408 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.873283395755307\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6408 6409\n",
      "Training loss:-0.004940349142998457\n",
      "check (7862,) ()\n",
      "epoch 6409\n",
      "====================================\n",
      "Epoch:  6409 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.872835075674832\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6409 6410\n",
      "Training loss:-0.006961675826460123\n",
      "check (8180,) ()\n",
      "epoch 6410\n",
      "====================================\n",
      "Epoch:  6410 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.871606864274572\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6410 6411\n",
      "Training loss:0.0005365497781895101\n",
      "check (10000,) ()\n",
      "epoch 6411\n",
      "====================================\n",
      "Epoch:  6411 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.871626891280611\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6411 6412\n",
      "Training loss:-0.005151417572051287\n",
      "check (7125,) ()\n",
      "epoch 6412\n",
      "====================================\n",
      "Epoch:  6412 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.871490954460386\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6412 6413\n",
      "Training loss:0.0006922585889697075\n",
      "check (8276,) ()\n",
      "epoch 6413\n",
      "====================================\n",
      "Epoch:  6413 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.87119912677374\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6413 6414\n",
      "Training loss:0.002083555795252323\n",
      "check (9966,) ()\n",
      "epoch 6414\n",
      "====================================\n",
      "Epoch:  6414 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.870907390084191\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6414 6415\n",
      "Training loss:0.001680950983427465\n",
      "check (9481,) ()\n",
      "epoch 6415\n",
      "====================================\n",
      "Epoch:  6415 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.870615744349182\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6415 6416\n",
      "Training loss:0.0005809054709970951\n",
      "check (8874,) ()\n",
      "epoch 6416\n",
      "====================================\n",
      "Epoch:  6416 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.87001246882793\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6416 6417\n",
      "Training loss:-0.008369697257876396\n",
      "check (8312,) ()\n",
      "epoch 6417\n",
      "====================================\n",
      "Epoch:  6417 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.870500233754091\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6417 6418\n",
      "Training loss:0.002572468714788556\n",
      "check (10000,) ()\n",
      "epoch 6418\n",
      "====================================\n",
      "Epoch:  6418 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.870520411343097\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6418 6419\n",
      "Training loss:0.00023848953424021602\n",
      "check (10000,) ()\n",
      "epoch 6419\n",
      "====================================\n",
      "Epoch:  6419 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:4.0\n",
      "Mean Reward of that batch 4.0\n",
      "Average Reward of all training: -12.867892195045957\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6419 6420\n",
      "Training loss:0.005542616359889507\n",
      "check (9724,) ()\n",
      "epoch 6420\n",
      "====================================\n",
      "Epoch:  6420 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.866978193146418\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6420 6421\n",
      "Training loss:0.006831751670688391\n",
      "check (8889,) ()\n",
      "epoch 6421\n",
      "====================================\n",
      "Epoch:  6421 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.866687431864195\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6421 6422\n",
      "Training loss:0.0064872330985963345\n",
      "check (10000,) ()\n",
      "epoch 6422\n",
      "====================================\n",
      "Epoch:  6422 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.864683899096855\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6422 6423\n",
      "Training loss:-0.006534980610013008\n",
      "check (9637,) ()\n",
      "epoch 6423\n",
      "====================================\n",
      "Epoch:  6423 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.8640822045773\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6423 6424\n",
      "Training loss:-0.001967232208698988\n",
      "check (6221,) ()\n",
      "epoch 6424\n",
      "====================================\n",
      "Epoch:  6424 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.86472602739726\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6424 6425\n",
      "Training loss:0.006155644543468952\n",
      "check (7969,) ()\n",
      "epoch 6425\n",
      "====================================\n",
      "Epoch:  6425 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.864124513618677\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6425 6426\n",
      "Training loss:-0.0057991486974060535\n",
      "check (9230,) ()\n",
      "epoch 6426\n",
      "====================================\n",
      "Epoch:  6426 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.864456893868658\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6426 6427\n",
      "Training loss:-0.004427677486091852\n",
      "check (6684,) ()\n",
      "epoch 6427\n",
      "====================================\n",
      "Epoch:  6427 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.864011202738448\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6427 6428\n",
      "Training loss:-0.005403232295066118\n",
      "check (8482,) ()\n",
      "epoch 6428\n",
      "====================================\n",
      "Epoch:  6428 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.864187927815806\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6428 6429\n",
      "Training loss:1.0518526323721744e-05\n",
      "check (10000,) ()\n",
      "epoch 6429\n",
      "====================================\n",
      "Epoch:  6429 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.862653600871052\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6429 6430\n",
      "Training loss:-0.007098020054399967\n",
      "check (10000,) ()\n",
      "epoch 6430\n",
      "====================================\n",
      "Epoch:  6430 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.860653188180404\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6430 6431\n",
      "Training loss:-1.648216311878059e-05\n",
      "check (8518,) ()\n",
      "epoch 6431\n",
      "====================================\n",
      "Epoch:  6431 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.86129684341471\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6431 6432\n",
      "Training loss:-0.003988833632320166\n",
      "check (9581,) ()\n",
      "epoch 6432\n",
      "====================================\n",
      "Epoch:  6432 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.860230099502488\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6432 6433\n",
      "Training loss:-0.006064002402126789\n",
      "check (9214,) ()\n",
      "epoch 6433\n",
      "====================================\n",
      "Epoch:  6433 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.859940929581844\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6433 6434\n",
      "Training loss:-0.00464976392686367\n",
      "check (9226,) ()\n",
      "epoch 6434\n",
      "====================================\n",
      "Epoch:  6434 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.859962698165994\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6434 6435\n",
      "Training loss:-0.001015953253954649\n",
      "check (10000,) ()\n",
      "epoch 6435\n",
      "====================================\n",
      "Epoch:  6435 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.858741258741258\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6435 6436\n",
      "Training loss:-0.0026440871879458427\n",
      "check (8742,) ()\n",
      "epoch 6436\n",
      "====================================\n",
      "Epoch:  6436 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.857986326911124\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6436 6437\n",
      "Training loss:-0.001364591415040195\n",
      "check (7597,) ()\n",
      "epoch 6437\n",
      "====================================\n",
      "Epoch:  6437 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.857697685257108\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6437 6438\n",
      "Training loss:-0.007956244982779026\n",
      "check (10000,) ()\n",
      "epoch 6438\n",
      "====================================\n",
      "Epoch:  6438 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.856943150046598\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6438 6439\n",
      "Training loss:-0.005970208905637264\n",
      "check (8707,) ()\n",
      "epoch 6439\n",
      "====================================\n",
      "Epoch:  6439 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.857275974530207\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6439 6440\n",
      "Training loss:-0.0067250486463308334\n",
      "check (9487,) ()\n",
      "epoch 6440\n",
      "====================================\n",
      "Epoch:  6440 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.85636645962733\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6440 6441\n",
      "Training loss:-0.003179343417286873\n",
      "check (10000,) ()\n",
      "epoch 6441\n",
      "====================================\n",
      "Epoch:  6441 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.856078248719143\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6441 6442\n",
      "Training loss:-0.0009778259554877877\n",
      "check (10000,) ()\n",
      "epoch 6442\n",
      "====================================\n",
      "Epoch:  6442 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.855479664700404\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6442 6443\n",
      "Training loss:-0.0015839412808418274\n",
      "check (8107,) ()\n",
      "epoch 6443\n",
      "====================================\n",
      "Epoch:  6443 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.855502095297222\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6443 6444\n",
      "Training loss:0.0021347925066947937\n",
      "check (9424,) ()\n",
      "epoch 6444\n",
      "====================================\n",
      "Epoch:  6444 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.85397268777157\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6444 6445\n",
      "Training loss:0.00020671254605986178\n",
      "check (10000,) ()\n",
      "epoch 6445\n",
      "====================================\n",
      "Epoch:  6445 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.852133436772691\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6445 6446\n",
      "Training loss:-0.002853627782315016\n",
      "check (9313,) ()\n",
      "epoch 6446\n",
      "====================================\n",
      "Epoch:  6446 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.85215637604716\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6446 6447\n",
      "Training loss:0.0031677172519266605\n",
      "check (7934,) ()\n",
      "epoch 6447\n",
      "====================================\n",
      "Epoch:  6447 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.85248953001396\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6447 6448\n",
      "Training loss:0.005565590690821409\n",
      "check (10000,) ()\n",
      "epoch 6448\n",
      "====================================\n",
      "Epoch:  6448 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.85220223325062\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6448 6449\n",
      "Training loss:0.0027136877179145813\n",
      "check (7728,) ()\n",
      "epoch 6449\n",
      "====================================\n",
      "Epoch:  6449 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.85222515118623\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6449 6450\n",
      "Training loss:-0.004291749559342861\n",
      "check (10000,) ()\n",
      "epoch 6450\n",
      "====================================\n",
      "Epoch:  6450 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.851782945736435\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6450 6451\n",
      "Training loss:-0.003115051193162799\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 6451\n",
      "====================================\n",
      "Epoch:  6451 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -12.849480700666563\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6451 6452\n",
      "Training loss:-0.007541267201304436\n",
      "check (8483,) ()\n",
      "epoch 6452\n",
      "====================================\n",
      "Epoch:  6452 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.849194048357099\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6452 6453\n",
      "Training loss:-0.0014118418330326676\n",
      "check (9166,) ()\n",
      "epoch 6453\n",
      "====================================\n",
      "Epoch:  6453 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.848597551526423\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6453 6454\n",
      "Training loss:-0.004714279901236296\n",
      "check (9319,) ()\n",
      "epoch 6454\n",
      "====================================\n",
      "Epoch:  6454 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.848930895568639\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6454 6455\n",
      "Training loss:-0.0032801078632473946\n",
      "check (9872,) ()\n",
      "epoch 6455\n",
      "====================================\n",
      "Epoch:  6455 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.848179705654532\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6455 6456\n",
      "Training loss:-0.008628424257040024\n",
      "check (10000,) ()\n",
      "epoch 6456\n",
      "====================================\n",
      "Epoch:  6456 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.847583643122677\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6456 6457\n",
      "Training loss:0.0010021133348345757\n",
      "check (8466,) ()\n",
      "epoch 6457\n",
      "====================================\n",
      "Epoch:  6457 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.847762118630943\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6457 6458\n",
      "Training loss:-0.0005369698046706617\n",
      "check (8990,) ()\n",
      "epoch 6458\n",
      "====================================\n",
      "Epoch:  6458 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.846856611954165\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6458 6459\n",
      "Training loss:0.0019926803652197123\n",
      "check (10000,) ()\n",
      "epoch 6459\n",
      "====================================\n",
      "Epoch:  6459 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.845796562935439\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6459 6460\n",
      "Training loss:-0.0032434798777103424\n",
      "check (6237,) ()\n",
      "epoch 6460\n",
      "====================================\n",
      "Epoch:  6460 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.846130030959753\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6460 6461\n",
      "Training loss:-0.003334694541990757\n",
      "check (8580,) ()\n",
      "epoch 6461\n",
      "====================================\n",
      "Epoch:  6461 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.845534746943198\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6461 6462\n",
      "Training loss:-0.0037394054234027863\n",
      "check (9808,) ()\n",
      "epoch 6462\n",
      "====================================\n",
      "Epoch:  6462 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.84524914887032\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6462 6463\n",
      "Training loss:-0.012245439924299717\n",
      "check (9539,) ()\n",
      "epoch 6463\n",
      "====================================\n",
      "Epoch:  6463 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.844808912269844\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6463 6464\n",
      "Training loss:0.0017917284276336432\n",
      "check (10000,) ()\n",
      "epoch 6464\n",
      "====================================\n",
      "Epoch:  6464 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.843440594059405\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6464 6465\n",
      "Training loss:-0.0003061019815504551\n",
      "check (8633,) ()\n",
      "epoch 6465\n",
      "====================================\n",
      "Epoch:  6465 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.843464810518174\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6465 6466\n",
      "Training loss:-0.0026328263338655233\n",
      "check (8424,) ()\n",
      "epoch 6466\n",
      "====================================\n",
      "Epoch:  6466 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.84364367460563\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6466 6467\n",
      "Training loss:-0.007089576218277216\n",
      "check (10000,) ()\n",
      "epoch 6467\n",
      "====================================\n",
      "Epoch:  6467 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.842430802535953\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6467 6468\n",
      "Training loss:-0.005287387408316135\n",
      "check (7784,) ()\n",
      "epoch 6468\n",
      "====================================\n",
      "Epoch:  6468 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.842764378478664\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6468 6469\n",
      "Training loss:-0.0011000260710716248\n",
      "check (8698,) ()\n",
      "epoch 6469\n",
      "====================================\n",
      "Epoch:  6469 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.842324934302056\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6469 6470\n",
      "Training loss:0.0028026620857417583\n",
      "check (8325,) ()\n",
      "epoch 6470\n",
      "====================================\n",
      "Epoch:  6470 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.842967542503864\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6470 6471\n",
      "Training loss:-0.0003102945920545608\n",
      "check (9174,) ()\n",
      "epoch 6471\n",
      "====================================\n",
      "Epoch:  6471 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.842991809612116\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6471 6472\n",
      "Training loss:-0.005358682945370674\n",
      "check (6294,) ()\n",
      "epoch 6472\n",
      "====================================\n",
      "Epoch:  6472 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -12.843788627935723\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6472 6473\n",
      "Training loss:-0.0026383250951766968\n",
      "check (8620,) ()\n",
      "epoch 6473\n",
      "====================================\n",
      "Epoch:  6473 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.842885833462073\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6473 6474\n",
      "Training loss:-0.0007693396764807403\n",
      "check (9416,) ()\n",
      "epoch 6474\n",
      "====================================\n",
      "Epoch:  6474 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.842601173926475\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6474 6475\n",
      "Training loss:-0.0024880627170205116\n",
      "check (8988,) ()\n",
      "epoch 6475\n",
      "====================================\n",
      "Epoch:  6475 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.842625482625483\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6475 6476\n",
      "Training loss:0.0012166877277195454\n",
      "check (8734,) ()\n",
      "epoch 6476\n",
      "====================================\n",
      "Epoch:  6476 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.84187770228536\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6476 6477\n",
      "Training loss:-0.0043066865764558315\n",
      "check (7911,) ()\n",
      "epoch 6477\n",
      "====================================\n",
      "Epoch:  6477 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.84251968503937\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6477 6478\n",
      "Training loss:-0.0013465958181768656\n",
      "check (10000,) ()\n",
      "epoch 6478\n",
      "====================================\n",
      "Epoch:  6478 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.840845940104971\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6478 6479\n",
      "Training loss:0.004842238500714302\n",
      "check (8599,) ()\n",
      "epoch 6479\n",
      "====================================\n",
      "Epoch:  6479 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.840870504707517\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6479 6480\n",
      "Training loss:-0.00519842142239213\n",
      "check (7913,) ()\n",
      "epoch 6480\n",
      "====================================\n",
      "Epoch:  6480 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.841512345679012\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6480 6481\n",
      "Training loss:-0.00602452177554369\n",
      "check (7325,) ()\n",
      "epoch 6481\n",
      "====================================\n",
      "Epoch:  6481 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.841073908347477\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6481 6482\n",
      "Training loss:-0.008240347728133202\n",
      "check (9449,) ()\n",
      "epoch 6482\n",
      "====================================\n",
      "Epoch:  6482 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.840481332921938\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6482 6483\n",
      "Training loss:-0.006897271610796452\n",
      "check (8691,) ()\n",
      "epoch 6483\n",
      "====================================\n",
      "Epoch:  6483 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.840505938608668\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6483 6484\n",
      "Training loss:-0.000578726117964834\n",
      "check (8609,) ()\n",
      "epoch 6484\n",
      "====================================\n",
      "Epoch:  6484 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.840376310919186\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6484 6485\n",
      "Training loss:0.004484361503273249\n",
      "check (7729,) ()\n",
      "epoch 6485\n",
      "====================================\n",
      "Epoch:  6485 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.839784117193524\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6485 6486\n",
      "Training loss:-0.002979760756716132\n",
      "check (10000,) ()\n",
      "epoch 6486\n",
      "====================================\n",
      "Epoch:  6486 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.83950046253469\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6486 6487\n",
      "Training loss:-0.00577984843403101\n",
      "check (9880,) ()\n",
      "epoch 6487\n",
      "====================================\n",
      "Epoch:  6487 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.838600277478033\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6487 6488\n",
      "Training loss:-0.002722540870308876\n",
      "check (10000,) ()\n",
      "epoch 6488\n",
      "====================================\n",
      "Epoch:  6488 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.836775585696671\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6488 6489\n",
      "Training loss:-0.0020048709120601416\n",
      "check (8874,) ()\n",
      "epoch 6489\n",
      "====================================\n",
      "Epoch:  6489 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.83587609801202\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6489 6490\n",
      "Training loss:-0.0039458973333239555\n",
      "check (9103,) ()\n",
      "epoch 6490\n",
      "====================================\n",
      "Epoch:  6490 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.835901386748844\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6490 6491\n",
      "Training loss:-0.004494335502386093\n",
      "check (8941,) ()\n",
      "epoch 6491\n",
      "====================================\n",
      "Epoch:  6491 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.835772608226776\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6491 6492\n",
      "Training loss:0.000832064775750041\n",
      "check (10000,) ()\n",
      "epoch 6492\n",
      "====================================\n",
      "Epoch:  6492 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.834257547751077\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6492 6493\n",
      "Training loss:-0.002481480361893773\n",
      "check (10000,) ()\n",
      "epoch 6493\n",
      "====================================\n",
      "Epoch:  6493 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.832896965963345\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6493 6494\n",
      "Training loss:-0.0040281848050653934\n",
      "check (10000,) ()\n",
      "epoch 6494\n",
      "====================================\n",
      "Epoch:  6494 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.832306744687404\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6494 6495\n",
      "Training loss:-0.010506152175366879\n",
      "check (10000,) ()\n",
      "epoch 6495\n",
      "====================================\n",
      "Epoch:  6495 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:4.0\n",
      "Mean Reward of that batch 4.0\n",
      "Average Reward of all training: -12.829715165511931\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6495 6496\n",
      "Training loss:-0.005779524799436331\n",
      "check (10000,) ()\n",
      "epoch 6496\n",
      "====================================\n",
      "Epoch:  6496 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.828971674876847\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6496 6497\n",
      "Training loss:-0.006888046395033598\n",
      "check (8287,) ()\n",
      "epoch 6497\n",
      "====================================\n",
      "Epoch:  6497 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.828382330306296\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6497 6498\n",
      "Training loss:-0.003944646567106247\n",
      "check (10000,) ()\n",
      "epoch 6498\n",
      "====================================\n",
      "Epoch:  6498 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.826562019082795\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6498 6499\n",
      "Training loss:-0.0007623207056894898\n",
      "check (9144,) ()\n",
      "epoch 6499\n",
      "====================================\n",
      "Epoch:  6499 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.826896445607016\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6499 6500\n",
      "Training loss:-0.004412811249494553\n",
      "check (10000,) ()\n",
      "epoch 6500\n",
      "====================================\n",
      "Epoch:  6500 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.825846153846154\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6500 6501\n",
      "Training loss:-0.001482242252677679\n",
      "Model saved\n",
      "check (9219,) ()\n",
      "epoch 6501\n",
      "====================================\n",
      "Epoch:  6501 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.825565297646516\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6501 6502\n",
      "Training loss:-0.004217283800244331\n",
      "check (10000,) ()\n",
      "epoch 6502\n",
      "====================================\n",
      "Epoch:  6502 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.824669332513073\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6502 6503\n",
      "Training loss:-0.00044440230703912675\n",
      "check (8987,) ()\n",
      "epoch 6503\n",
      "====================================\n",
      "Epoch:  6503 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.824388743656774\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6503 6504\n",
      "Training loss:-0.005873486399650574\n",
      "check (8023,) ()\n",
      "epoch 6504\n",
      "====================================\n",
      "Epoch:  6504 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.823954489544896\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6504 6505\n",
      "Training loss:-0.007707494311034679\n",
      "check (6739,) ()\n",
      "epoch 6505\n",
      "====================================\n",
      "Epoch:  6505 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.823674096848578\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6505 6506\n",
      "Training loss:-0.0015783531125634909\n",
      "check (9340,) ()\n",
      "epoch 6506\n",
      "====================================\n",
      "Epoch:  6506 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.823086381801414\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6506 6507\n",
      "Training loss:-0.0029671445954591036\n",
      "check (8153,) ()\n",
      "epoch 6507\n",
      "====================================\n",
      "Epoch:  6507 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.823267250653142\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6507 6508\n",
      "Training loss:-0.002646306063979864\n",
      "check (10000,) ()\n",
      "epoch 6508\n",
      "====================================\n",
      "Epoch:  6508 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.822526121696374\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6508 6509\n",
      "Training loss:-0.004658794496208429\n",
      "check (9037,) ()\n",
      "epoch 6509\n",
      "====================================\n",
      "Epoch:  6509 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.822246120755876\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6509 6510\n",
      "Training loss:-0.0028813432436436415\n",
      "check (7672,) ()\n",
      "epoch 6510\n",
      "====================================\n",
      "Epoch:  6510 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.821966205837173\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6510 6511\n",
      "Training loss:-0.00032282821484841406\n",
      "check (8657,) ()\n",
      "epoch 6511\n",
      "====================================\n",
      "Epoch:  6511 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.821532790661957\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6511 6512\n",
      "Training loss:-0.0011911505134776235\n",
      "check (9101,) ()\n",
      "epoch 6512\n",
      "====================================\n",
      "Epoch:  6512 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.821253071253071\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6512 6513\n",
      "Training loss:0.00047057337360456586\n",
      "check (9185,) ()\n",
      "epoch 6513\n",
      "====================================\n",
      "Epoch:  6513 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.820052203285735\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6513 6514\n",
      "Training loss:-0.006289531476795673\n",
      "check (7251,) ()\n",
      "epoch 6514\n",
      "====================================\n",
      "Epoch:  6514 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.818851704022107\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6514 6515\n",
      "Training loss:-0.005356168374419212\n",
      "check (6808,) ()\n",
      "epoch 6515\n",
      "====================================\n",
      "Epoch:  6515 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.819493476592479\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6515 6516\n",
      "Training loss:-0.007293873932212591\n",
      "check (8643,) ()\n",
      "epoch 6516\n",
      "====================================\n",
      "Epoch:  6516 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.819828115408226\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6516 6517\n",
      "Training loss:-0.004629467613995075\n",
      "check (10000,) ()\n",
      "epoch 6517\n",
      "====================================\n",
      "Epoch:  6517 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.819548872180452\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6517 6518\n",
      "Training loss:-0.0015019234269857407\n",
      "check (10000,) ()\n",
      "epoch 6518\n",
      "====================================\n",
      "Epoch:  6518 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.81896287204664\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6518 6519\n",
      "Training loss:-0.003029312239959836\n",
      "check (10000,) ()\n",
      "epoch 6519\n",
      "====================================\n",
      "Epoch:  6519 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.818377051695045\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6519 6520\n",
      "Training loss:-0.006333907134830952\n",
      "check (9205,) ()\n",
      "epoch 6520\n",
      "====================================\n",
      "Epoch:  6520 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.817944785276074\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6520 6521\n",
      "Training loss:-0.001595581998117268\n",
      "check (9174,) ()\n",
      "epoch 6521\n",
      "====================================\n",
      "Epoch:  6521 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.817359300720748\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6521 6522\n",
      "Training loss:-0.004462364129722118\n",
      "check (10000,) ()\n",
      "epoch 6522\n",
      "====================================\n",
      "Epoch:  6522 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.816927322907084\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6522 6523\n",
      "Training loss:-0.0035226319450885057\n",
      "check (10000,) ()\n",
      "epoch 6523\n",
      "====================================\n",
      "Epoch:  6523 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.816802084930247\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6523 6524\n",
      "Training loss:-0.0046118455938994884\n",
      "check (9408,) ()\n",
      "epoch 6524\n",
      "====================================\n",
      "Epoch:  6524 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.816217044757817\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6524 6525\n",
      "Training loss:-0.004913328681141138\n",
      "check (4971,) ()\n",
      "epoch 6525\n",
      "====================================\n",
      "Epoch:  6525 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.816858237547892\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6525 6526\n",
      "Training loss:-0.006560195703059435\n",
      "check (9441,) ()\n",
      "epoch 6526\n",
      "====================================\n",
      "Epoch:  6526 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.816733067729084\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6526 6527\n",
      "Training loss:-0.0034014275297522545\n",
      "check (9280,) ()\n",
      "epoch 6527\n",
      "====================================\n",
      "Epoch:  6527 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.815995097288187\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6527 6528\n",
      "Training loss:-0.0028438284061849117\n",
      "check (8437,) ()\n",
      "epoch 6528\n",
      "====================================\n",
      "Epoch:  6528 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.815716911764707\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6528 6529\n",
      "Training loss:-0.006890596356242895\n",
      "check (9436,) ()\n",
      "epoch 6529\n",
      "====================================\n",
      "Epoch:  6529 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.815591974268647\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6529 6530\n",
      "Training loss:0.001458250917494297\n",
      "check (9639,) ()\n",
      "epoch 6530\n",
      "====================================\n",
      "Epoch:  6530 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.815773353751915\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6530 6531\n",
      "Training loss:-0.0032025515101850033\n",
      "check (9985,) ()\n",
      "epoch 6531\n",
      "====================================\n",
      "Epoch:  6531 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.81534221405604\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6531 6532\n",
      "Training loss:-0.0027412050403654575\n",
      "check (9741,) ()\n",
      "epoch 6532\n",
      "====================================\n",
      "Epoch:  6532 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.814758113900796\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6532 6533\n",
      "Training loss:-0.007034978363662958\n",
      "check (9746,) ()\n",
      "epoch 6533\n",
      "====================================\n",
      "Epoch:  6533 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.814480330629113\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6533 6534\n",
      "Training loss:-0.004724253434687853\n",
      "check (9435,) ()\n",
      "epoch 6534\n",
      "====================================\n",
      "Epoch:  6534 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.814508723599634\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6534 6535\n",
      "Training loss:0.007014371454715729\n",
      "check (7745,) ()\n",
      "epoch 6535\n",
      "====================================\n",
      "Epoch:  6535 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.815149196633511\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6535 6536\n",
      "Training loss:0.001704260939732194\n",
      "check (10000,) ()\n",
      "epoch 6536\n",
      "====================================\n",
      "Epoch:  6536 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.813800489596083\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6536 6537\n",
      "Training loss:-0.0012716774363070726\n",
      "check (10000,) ()\n",
      "epoch 6537\n",
      "====================================\n",
      "Epoch:  6537 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.812758145938504\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6537 6538\n",
      "Training loss:-0.00780464569106698\n",
      "check (10000,) ()\n",
      "epoch 6538\n",
      "====================================\n",
      "Epoch:  6538 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.811869073111042\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6538 6539\n",
      "Training loss:0.0015565402572974563\n",
      "check (10000,) ()\n",
      "epoch 6539\n",
      "====================================\n",
      "Epoch:  6539 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.809909772136413\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6539 6540\n",
      "Training loss:-0.001479682163335383\n",
      "check (10000,) ()\n",
      "epoch 6540\n",
      "====================================\n",
      "Epoch:  6540 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.808103975535168\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6540 6541\n",
      "Training loss:-0.005569363012909889\n",
      "check (9807,) ()\n",
      "epoch 6541\n",
      "====================================\n",
      "Epoch:  6541 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.807827549304388\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6541 6542\n",
      "Training loss:-0.008569528348743916\n",
      "check (10000,) ()\n",
      "epoch 6542\n",
      "====================================\n",
      "Epoch:  6542 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.807092632222561\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6542 6543\n",
      "Training loss:-0.0015877563273534179\n",
      "check (10000,) ()\n",
      "epoch 6543\n",
      "====================================\n",
      "Epoch:  6543 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.806969280146722\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6543 6544\n",
      "Training loss:-0.00012542057083919644\n",
      "check (9214,) ()\n",
      "epoch 6544\n",
      "====================================\n",
      "Epoch:  6544 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.806998777506113\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6544 6545\n",
      "Training loss:-0.0020452048629522324\n",
      "check (7157,) ()\n",
      "epoch 6545\n",
      "====================================\n",
      "Epoch:  6545 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.807486631016042\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6545 6546\n",
      "Training loss:-0.0007145151030272245\n",
      "check (10000,) ()\n",
      "epoch 6546\n",
      "====================================\n",
      "Epoch:  6546 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.807210510235258\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6546 6547\n",
      "Training loss:-0.007189909461885691\n",
      "check (7668,) ()\n",
      "epoch 6547\n",
      "====================================\n",
      "Epoch:  6547 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.807239957232321\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6547 6548\n",
      "Training loss:-0.0071113258600234985\n",
      "check (7183,) ()\n",
      "epoch 6548\n",
      "====================================\n",
      "Epoch:  6548 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.807269395235187\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6548 6549\n",
      "Training loss:-0.0010051557328552008\n",
      "check (10000,) ()\n",
      "epoch 6549\n",
      "====================================\n",
      "Epoch:  6549 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.805619178500534\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6549 6550\n",
      "Training loss:-0.0010025016963481903\n",
      "check (7957,) ()\n",
      "epoch 6550\n",
      "====================================\n",
      "Epoch:  6550 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.805343511450381\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6550 6551\n",
      "Training loss:-0.007408323232084513\n",
      "Model saved\n",
      "check (9579,) ()\n",
      "epoch 6551\n",
      "====================================\n",
      "Epoch:  6551 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.805067928560526\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6551 6552\n",
      "Training loss:-0.002761072712019086\n",
      "check (7336,) ()\n",
      "epoch 6552\n",
      "====================================\n",
      "Epoch:  6552 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.80509768009768\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6552 6553\n",
      "Training loss:0.0018707574345171452\n",
      "check (9645,) ()\n",
      "epoch 6553\n",
      "====================================\n",
      "Epoch:  6553 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.804059209522356\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6553 6554\n",
      "Training loss:-0.006635996047407389\n",
      "check (7113,) ()\n",
      "epoch 6554\n",
      "====================================\n",
      "Epoch:  6554 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.804089105889533\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6554 6555\n",
      "Training loss:0.00426663551479578\n",
      "check (10000,) ()\n",
      "epoch 6555\n",
      "====================================\n",
      "Epoch:  6555 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -12.801678108314263\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6555 6556\n",
      "Training loss:0.0028084602672606707\n",
      "check (9584,) ()\n",
      "epoch 6556\n",
      "====================================\n",
      "Epoch:  6556 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.801403294691886\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6556 6557\n",
      "Training loss:0.0014276339206844568\n",
      "check (8314,) ()\n",
      "epoch 6557\n",
      "====================================\n",
      "Epoch:  6557 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.801128564892482\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6557 6558\n",
      "Training loss:0.001788659836165607\n",
      "check (8630,) ()\n",
      "epoch 6558\n",
      "====================================\n",
      "Epoch:  6558 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.801006404391583\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6558 6559\n",
      "Training loss:-0.0016755423275753856\n",
      "check (10000,) ()\n",
      "epoch 6559\n",
      "====================================\n",
      "Epoch:  6559 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.80042689434365\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6559 6560\n",
      "Training loss:0.006825167220085859\n",
      "check (10000,) ()\n",
      "epoch 6560\n",
      "====================================\n",
      "Epoch:  6560 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.799085365853658\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6560 6561\n",
      "Training loss:0.005835673306137323\n",
      "check (10000,) ()\n",
      "epoch 6561\n",
      "====================================\n",
      "Epoch:  6561 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.79804907788447\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6561 6562\n",
      "Training loss:0.00019163779506925493\n",
      "check (10000,) ()\n",
      "epoch 6562\n",
      "====================================\n",
      "Epoch:  6562 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.79655592807071\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6562 6563\n",
      "Training loss:0.0019311985233798623\n",
      "check (9019,) ()\n",
      "epoch 6563\n",
      "====================================\n",
      "Epoch:  6563 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.795977449337194\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6563 6564\n",
      "Training loss:0.001594614703208208\n",
      "check (8837,) ()\n",
      "epoch 6564\n",
      "====================================\n",
      "Epoch:  6564 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.795856185252894\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6564 6565\n",
      "Training loss:-0.004338190425187349\n",
      "check (10000,) ()\n",
      "epoch 6565\n",
      "====================================\n",
      "Epoch:  6565 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.794516374714394\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6565 6566\n",
      "Training loss:-0.0034631674643605947\n",
      "check (9906,) ()\n",
      "epoch 6566\n",
      "====================================\n",
      "Epoch:  6566 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.79332927200731\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6566 6567\n",
      "Training loss:-0.0004175703215878457\n",
      "check (8015,) ()\n",
      "epoch 6567\n",
      "====================================\n",
      "Epoch:  6567 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.793360743109487\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6567 6568\n",
      "Training loss:-0.00653686560690403\n",
      "check (10000,) ()\n",
      "epoch 6568\n",
      "====================================\n",
      "Epoch:  6568 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.792630937880633\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6568 6569\n",
      "Training loss:-0.006337336730211973\n",
      "check (8763,) ()\n",
      "epoch 6569\n",
      "====================================\n",
      "Epoch:  6569 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.792966966052672\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6569 6570\n",
      "Training loss:-0.006239128299057484\n",
      "check (10000,) ()\n",
      "epoch 6570\n",
      "====================================\n",
      "Epoch:  6570 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.792389649923896\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6570 6571\n",
      "Training loss:-0.0045450665056705475\n",
      "check (9779,) ()\n",
      "epoch 6571\n",
      "====================================\n",
      "Epoch:  6571 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.79181250951149\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6571 6572\n",
      "Training loss:-0.002810180187225342\n",
      "check (10000,) ()\n",
      "epoch 6572\n",
      "====================================\n",
      "Epoch:  6572 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.79169202678028\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6572 6573\n",
      "Training loss:-0.0024379154201596975\n",
      "check (8734,) ()\n",
      "epoch 6573\n",
      "====================================\n",
      "Epoch:  6573 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.79141944317663\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6573 6574\n",
      "Training loss:-0.012448856607079506\n",
      "check (9562,) ()\n",
      "epoch 6574\n",
      "====================================\n",
      "Epoch:  6574 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.790842713720718\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6574 6575\n",
      "Training loss:0.0015905029140412807\n",
      "check (10000,) ()\n",
      "epoch 6575\n",
      "====================================\n",
      "Epoch:  6575 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.790114068441065\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6575 6576\n",
      "Training loss:-0.00882742553949356\n",
      "check (7819,) ()\n",
      "epoch 6576\n",
      "====================================\n",
      "Epoch:  6576 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.78999391727494\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6576 6577\n",
      "Training loss:0.0031112965662032366\n",
      "check (9854,) ()\n",
      "epoch 6577\n",
      "====================================\n",
      "Epoch:  6577 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.78865744260301\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6577 6578\n",
      "Training loss:-0.003889136016368866\n",
      "check (9288,) ()\n",
      "epoch 6578\n",
      "====================================\n",
      "Epoch:  6578 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.787777439951354\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6578 6579\n",
      "Training loss:-0.00039582495810464025\n",
      "check (10000,) ()\n",
      "epoch 6579\n",
      "====================================\n",
      "Epoch:  6579 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.786137710898313\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6579 6580\n",
      "Training loss:-0.003813953371718526\n",
      "check (8294,) ()\n",
      "epoch 6580\n",
      "====================================\n",
      "Epoch:  6580 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.785714285714286\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6580 6581\n",
      "Training loss:0.0032431711442768574\n",
      "check (9501,) ()\n",
      "epoch 6581\n",
      "====================================\n",
      "Epoch:  6581 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.784227321075825\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6581 6582\n",
      "Training loss:-0.009813009761273861\n",
      "check (10000,) ()\n",
      "epoch 6582\n",
      "====================================\n",
      "Epoch:  6582 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.782740808264965\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6582 6583\n",
      "Training loss:-0.0013220749096944928\n",
      "check (7798,) ()\n",
      "epoch 6583\n",
      "====================================\n",
      "Epoch:  6583 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.78277381133222\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6583 6584\n",
      "Training loss:-0.0034793883096426725\n",
      "check (10000,) ()\n",
      "epoch 6584\n",
      "====================================\n",
      "Epoch:  6584 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -12.780680437424058\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6584 6585\n",
      "Training loss:-0.0036448531318455935\n",
      "check (10000,) ()\n",
      "epoch 6585\n",
      "====================================\n",
      "Epoch:  6585 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.77965072133637\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6585 6586\n",
      "Training loss:-0.003177762497216463\n",
      "check (8771,) ()\n",
      "epoch 6586\n",
      "====================================\n",
      "Epoch:  6586 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.779076829638628\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6586 6587\n",
      "Training loss:-0.009588558226823807\n",
      "check (10000,) ()\n",
      "epoch 6587\n",
      "====================================\n",
      "Epoch:  6587 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.77713678457568\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6587 6588\n",
      "Training loss:0.0035876831971108913\n",
      "check (6541,) ()\n",
      "epoch 6588\n",
      "====================================\n",
      "Epoch:  6588 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.777170613236187\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6588 6589\n",
      "Training loss:-0.002286717761307955\n",
      "check (9634,) ()\n",
      "epoch 6589\n",
      "====================================\n",
      "Epoch:  6589 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.775990286841706\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6589 6590\n",
      "Training loss:-0.004278823267668486\n",
      "check (8693,) ()\n",
      "epoch 6590\n",
      "====================================\n",
      "Epoch:  6590 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.775113808801214\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6590 6591\n",
      "Training loss:-0.002874123165383935\n",
      "check (8329,) ()\n",
      "epoch 6591\n",
      "====================================\n",
      "Epoch:  6591 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.775147928994082\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6591 6592\n",
      "Training loss:-0.001375478459522128\n",
      "check (8526,) ()\n",
      "epoch 6592\n",
      "====================================\n",
      "Epoch:  6592 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.774271844660195\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6592 6593\n",
      "Training loss:0.00028102274518460035\n",
      "check (8858,) ()\n",
      "epoch 6593\n",
      "====================================\n",
      "Epoch:  6593 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.773699378128319\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6593 6594\n",
      "Training loss:-0.005760932806879282\n",
      "check (9440,) ()\n",
      "epoch 6594\n",
      "====================================\n",
      "Epoch:  6594 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.773733697300576\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6594 6595\n",
      "Training loss:-0.005318493116647005\n",
      "check (9479,) ()\n",
      "epoch 6595\n",
      "====================================\n",
      "Epoch:  6595 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.773161485974223\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6595 6596\n",
      "Training loss:0.001384188886731863\n",
      "check (8580,) ()\n",
      "epoch 6596\n",
      "====================================\n",
      "Epoch:  6596 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.772892662219528\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6596 6597\n",
      "Training loss:-0.002573625184595585\n",
      "check (7412,) ()\n",
      "epoch 6597\n",
      "====================================\n",
      "Epoch:  6597 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.77262391996362\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6597 6598\n",
      "Training loss:0.002455970272421837\n",
      "check (8730,) ()\n",
      "epoch 6598\n",
      "====================================\n",
      "Epoch:  6598 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.772658381327675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6598 6599\n",
      "Training loss:0.002041260013356805\n",
      "check (10000,) ()\n",
      "epoch 6599\n",
      "====================================\n",
      "Epoch:  6599 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.77238975602364\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6599 6600\n",
      "Training loss:0.0006354135693982244\n",
      "check (8661,) ()\n",
      "epoch 6600\n",
      "====================================\n",
      "Epoch:  6600 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.771363636363636\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6600 6601\n",
      "Training loss:-0.00027194395079277456\n",
      "Model saved\n",
      "check (10000,) ()\n",
      "epoch 6601\n",
      "====================================\n",
      "Epoch:  6601 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.770034843205575\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6601 6602\n",
      "Training loss:-0.0036891452036798\n",
      "check (8240,) ()\n",
      "epoch 6602\n",
      "====================================\n",
      "Epoch:  6602 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.770372614359285\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6602 6603\n",
      "Training loss:-0.004321902059018612\n",
      "check (9314,) ()\n",
      "epoch 6603\n",
      "====================================\n",
      "Epoch:  6603 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.76980160533091\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6603 6604\n",
      "Training loss:-0.0012378490064293146\n",
      "check (8224,) ()\n",
      "epoch 6604\n",
      "====================================\n",
      "Epoch:  6604 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.770290732889158\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6604 6605\n",
      "Training loss:0.003499637357890606\n",
      "check (10000,) ()\n",
      "epoch 6605\n",
      "====================================\n",
      "Epoch:  6605 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.769719909159727\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6605 6606\n",
      "Training loss:-0.0022665224969387054\n",
      "check (10000,) ()\n",
      "epoch 6606\n",
      "====================================\n",
      "Epoch:  6606 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.76808961550106\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6606 6607\n",
      "Training loss:0.00031059113098308444\n",
      "check (8193,) ()\n",
      "epoch 6607\n",
      "====================================\n",
      "Epoch:  6607 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.767519297714545\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6607 6608\n",
      "Training loss:-1.8228414774057455e-05\n",
      "check (9723,) ()\n",
      "epoch 6608\n",
      "====================================\n",
      "Epoch:  6608 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.766949152542374\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6608 6609\n",
      "Training loss:0.0029880425427109003\n",
      "check (8647,) ()\n",
      "epoch 6609\n",
      "====================================\n",
      "Epoch:  6609 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.766681797548797\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6609 6610\n",
      "Training loss:-0.007769651245325804\n",
      "check (10000,) ()\n",
      "epoch 6610\n",
      "====================================\n",
      "Epoch:  6610 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.76535552193646\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6610 6611\n",
      "Training loss:-0.0005917249945923686\n",
      "check (8706,) ()\n",
      "epoch 6611\n",
      "====================================\n",
      "Epoch:  6611 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.765391014975041\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6611 6612\n",
      "Training loss:-0.0022079539485275745\n",
      "check (9215,) ()\n",
      "epoch 6612\n",
      "====================================\n",
      "Epoch:  6612 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.76482153660012\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6612 6613\n",
      "Training loss:-0.003483289387077093\n",
      "check (9709,) ()\n",
      "epoch 6613\n",
      "====================================\n",
      "Epoch:  6613 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.763949795856647\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6613 6614\n",
      "Training loss:-0.003719695145264268\n",
      "check (9298,) ()\n",
      "epoch 6614\n",
      "====================================\n",
      "Epoch:  6614 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.763380707589961\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6614 6615\n",
      "Training loss:-0.00596320116892457\n",
      "check (8376,) ()\n",
      "epoch 6615\n",
      "====================================\n",
      "Epoch:  6615 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.763718820861678\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6615 6616\n",
      "Training loss:-0.003940623253583908\n",
      "check (10000,) ()\n",
      "epoch 6616\n",
      "====================================\n",
      "Epoch:  6616 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.762545344619106\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6616 6617\n",
      "Training loss:-0.005430079530924559\n",
      "check (9440,) ()\n",
      "epoch 6617\n",
      "====================================\n",
      "Epoch:  6617 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.762127852501134\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6617 6618\n",
      "Training loss:0.00047273797099478543\n",
      "check (9886,) ()\n",
      "epoch 6618\n",
      "====================================\n",
      "Epoch:  6618 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.760803868238138\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6618 6619\n",
      "Training loss:-0.004293309990316629\n",
      "check (10000,) ()\n",
      "epoch 6619\n",
      "====================================\n",
      "Epoch:  6619 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.75948028403082\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6619 6620\n",
      "Training loss:-0.0052892775274813175\n",
      "check (10000,) ()\n",
      "epoch 6620\n",
      "====================================\n",
      "Epoch:  6620 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.759365558912387\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6620 6621\n",
      "Training loss:-0.005879772361367941\n",
      "check (9443,) ()\n",
      "epoch 6621\n",
      "====================================\n",
      "Epoch:  6621 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.758646730101193\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6621 6622\n",
      "Training loss:-0.006746191531419754\n",
      "check (10000,) ()\n",
      "epoch 6622\n",
      "====================================\n",
      "Epoch:  6622 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.758079130172153\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6622 6623\n",
      "Training loss:0.0019783915486186743\n",
      "check (8015,) ()\n",
      "epoch 6623\n",
      "====================================\n",
      "Epoch:  6623 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.758417635512608\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6623 6624\n",
      "Training loss:0.0031276836525648832\n",
      "check (10000,) ()\n",
      "epoch 6624\n",
      "====================================\n",
      "Epoch:  6624 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.757246376811594\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6624 6625\n",
      "Training loss:-0.010089836083352566\n",
      "check (10000,) ()\n",
      "epoch 6625\n",
      "====================================\n",
      "Epoch:  6625 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.756075471698113\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6625 6626\n",
      "Training loss:0.0007727248012088239\n",
      "check (8125,) ()\n",
      "epoch 6626\n",
      "====================================\n",
      "Epoch:  6626 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.755961364322367\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6626 6627\n",
      "Training loss:-0.0054516904056072235\n",
      "check (8013,) ()\n",
      "epoch 6627\n",
      "====================================\n",
      "Epoch:  6627 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.755998189225894\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6627 6628\n",
      "Training loss:0.003584054997190833\n",
      "check (9672,) ()\n",
      "epoch 6628\n",
      "====================================\n",
      "Epoch:  6628 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.755431502715751\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6628 6629\n",
      "Training loss:-0.004155650269240141\n",
      "check (10000,) ()\n",
      "epoch 6629\n",
      "====================================\n",
      "Epoch:  6629 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.753959873284055\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6629 6630\n",
      "Training loss:0.00395711837336421\n",
      "check (9278,) ()\n",
      "epoch 6630\n",
      "====================================\n",
      "Epoch:  6630 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.752790346907995\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6630 6631\n",
      "Training loss:-0.0056664287112653255\n",
      "check (10000,) ()\n",
      "epoch 6631\n",
      "====================================\n",
      "Epoch:  6631 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.7517719800935\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6631 6632\n",
      "Training loss:0.0009761627297848463\n",
      "check (10000,) ()\n",
      "epoch 6632\n",
      "====================================\n",
      "Epoch:  6632 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.751960193003619\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6632 6633\n",
      "Training loss:0.002032309304922819\n",
      "check (7112,) ()\n",
      "epoch 6633\n",
      "====================================\n",
      "Epoch:  6633 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -12.75290215588723\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6633 6634\n",
      "Training loss:-0.005173079203814268\n",
      "check (7862,) ()\n",
      "epoch 6634\n",
      "====================================\n",
      "Epoch:  6634 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.753090141694303\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6634 6635\n",
      "Training loss:0.0029247726779431105\n",
      "check (8265,) ()\n",
      "epoch 6635\n",
      "====================================\n",
      "Epoch:  6635 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.75282592313489\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6635 6636\n",
      "Training loss:0.0007421065238304436\n",
      "check (7662,) ()\n",
      "epoch 6636\n",
      "====================================\n",
      "Epoch:  6636 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.752863170584689\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6636 6637\n",
      "Training loss:-0.0013633444905281067\n",
      "check (8139,) ()\n",
      "epoch 6637\n",
      "====================================\n",
      "Epoch:  6637 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.752147054392045\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6637 6638\n",
      "Training loss:-0.006671978626400232\n",
      "check (10000,) ()\n",
      "epoch 6638\n",
      "====================================\n",
      "Epoch:  6638 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.750828562820127\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6638 6639\n",
      "Training loss:-0.004568740725517273\n",
      "check (8870,) ()\n",
      "epoch 6639\n",
      "====================================\n",
      "Epoch:  6639 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.750564844103028\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6639 6640\n",
      "Training loss:0.0014627176569774747\n",
      "check (10000,) ()\n",
      "epoch 6640\n",
      "====================================\n",
      "Epoch:  6640 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.749096385542169\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6640 6641\n",
      "Training loss:-0.0063180746510624886\n",
      "check (10000,) ()\n",
      "epoch 6641\n",
      "====================================\n",
      "Epoch:  6641 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.747477789489535\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6641 6642\n",
      "Training loss:-0.0005614502006210387\n",
      "check (8730,) ()\n",
      "epoch 6642\n",
      "====================================\n",
      "Epoch:  6642 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.746763023185787\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6642 6643\n",
      "Training loss:-0.005417544860392809\n",
      "check (10000,) ()\n",
      "epoch 6643\n",
      "====================================\n",
      "Epoch:  6643 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.74574740328165\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6643 6644\n",
      "Training loss:-0.004521541763097048\n",
      "check (7533,) ()\n",
      "epoch 6644\n",
      "====================================\n",
      "Epoch:  6644 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.74578567128236\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6644 6645\n",
      "Training loss:-0.007181985769420862\n",
      "check (7421,) ()\n",
      "epoch 6645\n",
      "====================================\n",
      "Epoch:  6645 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.746124905944319\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6645 6646\n",
      "Training loss:0.0016371090896427631\n",
      "check (10000,) ()\n",
      "epoch 6646\n",
      "====================================\n",
      "Epoch:  6646 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.745711706289498\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6646 6647\n",
      "Training loss:-0.004988973028957844\n",
      "check (9947,) ()\n",
      "epoch 6647\n",
      "====================================\n",
      "Epoch:  6647 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.744546411915149\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6647 6648\n",
      "Training loss:-0.006430640816688538\n",
      "check (9200,) ()\n",
      "epoch 6648\n",
      "====================================\n",
      "Epoch:  6648 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.744434416365824\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6648 6649\n",
      "Training loss:-0.001324682030826807\n",
      "check (8192,) ()\n",
      "epoch 6649\n",
      "====================================\n",
      "Epoch:  6649 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.743871258835915\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6649 6650\n",
      "Training loss:-0.009889164008200169\n",
      "check (9133,) ()\n",
      "epoch 6650\n",
      "====================================\n",
      "Epoch:  6650 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.743157894736843\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6650 6651\n",
      "Training loss:-0.003596522379666567\n",
      "Model saved\n",
      "check (8975,) ()\n",
      "epoch 6651\n",
      "====================================\n",
      "Epoch:  6651 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.742895805142084\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6651 6652\n",
      "Training loss:-0.004463386721909046\n",
      "check (10000,) ()\n",
      "epoch 6652\n",
      "====================================\n",
      "Epoch:  6652 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.742333132892362\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6652 6653\n",
      "Training loss:-0.004690486937761307\n",
      "check (8852,) ()\n",
      "epoch 6653\n",
      "====================================\n",
      "Epoch:  6653 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.742522170449421\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6653 6654\n",
      "Training loss:-0.004967960529029369\n",
      "check (7359,) ()\n",
      "epoch 6654\n",
      "====================================\n",
      "Epoch:  6654 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.74165915238954\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6654 6655\n",
      "Training loss:-0.0005243392079137266\n",
      "check (10000,) ()\n",
      "epoch 6655\n",
      "====================================\n",
      "Epoch:  6655 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.740796393688957\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6655 6656\n",
      "Training loss:-0.004605110734701157\n",
      "check (9533,) ()\n",
      "epoch 6656\n",
      "====================================\n",
      "Epoch:  6656 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -12.73858173076923\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6656 6657\n",
      "Training loss:-0.003430247539654374\n",
      "check (7838,) ()\n",
      "epoch 6657\n",
      "====================================\n",
      "Epoch:  6657 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.738621000450653\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6657 6658\n",
      "Training loss:0.007744568400084972\n",
      "check (9881,) ()\n",
      "epoch 6658\n",
      "====================================\n",
      "Epoch:  6658 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.738059477320517\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6658 6659\n",
      "Training loss:-0.0008727448876015842\n",
      "check (8922,) ()\n",
      "epoch 6659\n",
      "====================================\n",
      "Epoch:  6659 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.73674725934825\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6659 6660\n",
      "Training loss:-0.0022887345403432846\n",
      "check (8299,) ()\n",
      "epoch 6660\n",
      "====================================\n",
      "Epoch:  6660 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.735735735735735\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6660 6661\n",
      "Training loss:-0.004704127088189125\n",
      "check (9703,) ()\n",
      "epoch 6661\n",
      "====================================\n",
      "Epoch:  6661 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.735775409097734\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6661 6662\n",
      "Training loss:-0.003749378491193056\n",
      "check (10000,) ()\n",
      "epoch 6662\n",
      "====================================\n",
      "Epoch:  6662 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.735214650255179\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6662 6663\n",
      "Training loss:-0.001954419305548072\n",
      "check (8768,) ()\n",
      "epoch 6663\n",
      "====================================\n",
      "Epoch:  6663 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.735104307369053\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6663 6664\n",
      "Training loss:-0.006943719461560249\n",
      "check (8822,) ()\n",
      "epoch 6664\n",
      "====================================\n",
      "Epoch:  6664 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.73454381752701\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6664 6665\n",
      "Training loss:-0.0044423374347388744\n",
      "check (10000,) ()\n",
      "epoch 6665\n",
      "====================================\n",
      "Epoch:  6665 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.734133533383346\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6665 6666\n",
      "Training loss:-0.0006623496883548796\n",
      "check (9819,) ()\n",
      "epoch 6666\n",
      "====================================\n",
      "Epoch:  6666 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.733723372337234\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6666 6667\n",
      "Training loss:-0.005238774698227644\n",
      "check (8850,) ()\n",
      "epoch 6667\n",
      "====================================\n",
      "Epoch:  6667 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.733463326833657\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6667 6668\n",
      "Training loss:-0.0002923092688433826\n",
      "check (9578,) ()\n",
      "epoch 6668\n",
      "====================================\n",
      "Epoch:  6668 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.733353329334133\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6668 6669\n",
      "Training loss:6.887524068588391e-05\n",
      "check (9285,) ()\n",
      "epoch 6669\n",
      "====================================\n",
      "Epoch:  6669 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.733093417303945\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6669 6670\n",
      "Training loss:-0.0008695973083376884\n",
      "check (10000,) ()\n",
      "epoch 6670\n",
      "====================================\n",
      "Epoch:  6670 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.731334332833583\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6670 6671\n",
      "Training loss:-0.0035816372837871313\n",
      "check (9362,) ()\n",
      "epoch 6671\n",
      "====================================\n",
      "Epoch:  6671 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.73137460650577\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6671 6672\n",
      "Training loss:-0.0013188234297558665\n",
      "check (10000,) ()\n",
      "epoch 6672\n",
      "====================================\n",
      "Epoch:  6672 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.730815347721823\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6672 6673\n",
      "Training loss:-0.003942995332181454\n",
      "check (9358,) ()\n",
      "epoch 6673\n",
      "====================================\n",
      "Epoch:  6673 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.729956541285778\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6673 6674\n",
      "Training loss:-0.0013869324466213584\n",
      "check (8708,) ()\n",
      "epoch 6674\n",
      "====================================\n",
      "Epoch:  6674 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.729997003296374\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6674 6675\n",
      "Training loss:-0.00198149960488081\n",
      "check (8643,) ()\n",
      "epoch 6675\n",
      "====================================\n",
      "Epoch:  6675 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.730337078651685\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6675 6676\n",
      "Training loss:-0.001533837290480733\n",
      "check (10000,) ()\n",
      "epoch 6676\n",
      "====================================\n",
      "Epoch:  6676 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.729928100659077\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6676 6677\n",
      "Training loss:-0.008554807864129543\n",
      "check (9486,) ()\n",
      "epoch 6677\n",
      "====================================\n",
      "Epoch:  6677 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.729069941590534\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6677 6678\n",
      "Training loss:-0.001308834063820541\n",
      "check (10000,) ()\n",
      "epoch 6678\n",
      "====================================\n",
      "Epoch:  6678 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.727313566936209\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6678 6679\n",
      "Training loss:-0.007308450527489185\n",
      "check (9353,) ()\n",
      "epoch 6679\n",
      "====================================\n",
      "Epoch:  6679 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.726755502320707\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6679 6680\n",
      "Training loss:-0.009991714730858803\n",
      "check (8921,) ()\n",
      "epoch 6680\n",
      "====================================\n",
      "Epoch:  6680 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.726047904191617\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6680 6681\n",
      "Training loss:-0.005158451851457357\n",
      "check (9726,) ()\n",
      "epoch 6681\n",
      "====================================\n",
      "Epoch:  6681 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.72608890884598\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6681 6682\n",
      "Training loss:-0.0012283431133255363\n",
      "check (7552,) ()\n",
      "epoch 6682\n",
      "====================================\n",
      "Epoch:  6682 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -12.727027835977252\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6682 6683\n",
      "Training loss:-0.008811292238533497\n",
      "check (8581,) ()\n",
      "epoch 6683\n",
      "====================================\n",
      "Epoch:  6683 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.72736794852611\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6683 6684\n",
      "Training loss:-0.007213175296783447\n",
      "check (9819,) ()\n",
      "epoch 6684\n",
      "====================================\n",
      "Epoch:  6684 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.727109515260324\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6684 6685\n",
      "Training loss:-0.0011949994368478656\n",
      "check (9328,) ()\n",
      "epoch 6685\n",
      "====================================\n",
      "Epoch:  6685 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.726701570680628\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6685 6686\n",
      "Training loss:-0.0037021145690232515\n",
      "check (9714,) ()\n",
      "epoch 6686\n",
      "====================================\n",
      "Epoch:  6686 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.725994615614717\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6686 6687\n",
      "Training loss:-0.00596687151119113\n",
      "check (10000,) ()\n",
      "epoch 6687\n",
      "====================================\n",
      "Epoch:  6687 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.72528787199043\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6687 6688\n",
      "Training loss:-0.008068072609603405\n",
      "check (8854,) ()\n",
      "epoch 6688\n",
      "====================================\n",
      "Epoch:  6688 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.725627990430622\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6688 6689\n",
      "Training loss:-0.0009617703035473824\n",
      "check (6408,) ()\n",
      "epoch 6689\n",
      "====================================\n",
      "Epoch:  6689 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.725669008820452\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6689 6690\n",
      "Training loss:0.0003089630918111652\n",
      "check (9612,) ()\n",
      "epoch 6690\n",
      "====================================\n",
      "Epoch:  6690 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.725112107623318\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6690 6691\n",
      "Training loss:-0.005346119869500399\n",
      "check (9222,) ()\n",
      "epoch 6691\n",
      "====================================\n",
      "Epoch:  6691 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.724555372888956\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6691 6692\n",
      "Training loss:0.0019230310572311282\n",
      "check (8866,) ()\n",
      "epoch 6692\n",
      "====================================\n",
      "Epoch:  6692 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.72489539748954\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6692 6693\n",
      "Training loss:-0.010219045914709568\n",
      "check (8936,) ()\n",
      "epoch 6693\n",
      "====================================\n",
      "Epoch:  6693 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.724787090990587\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6693 6694\n",
      "Training loss:-0.005817154888063669\n",
      "check (8350,) ()\n",
      "epoch 6694\n",
      "====================================\n",
      "Epoch:  6694 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.7242306543173\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6694 6695\n",
      "Training loss:-0.0059090256690979\n",
      "check (8787,) ()\n",
      "epoch 6695\n",
      "====================================\n",
      "Epoch:  6695 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.723375653472742\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6695 6696\n",
      "Training loss:-0.00870394054800272\n",
      "check (9196,) ()\n",
      "epoch 6696\n",
      "====================================\n",
      "Epoch:  6696 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.722968936678614\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6696 6697\n",
      "Training loss:-0.005640474148094654\n",
      "check (7836,) ()\n",
      "epoch 6697\n",
      "====================================\n",
      "Epoch:  6697 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.7230103031208\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6697 6698\n",
      "Training loss:0.0032236159313470125\n",
      "check (10000,) ()\n",
      "epoch 6698\n",
      "====================================\n",
      "Epoch:  6698 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.721857270827112\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6698 6699\n",
      "Training loss:-0.003434303216636181\n",
      "check (10000,) ()\n",
      "epoch 6699\n",
      "====================================\n",
      "Epoch:  6699 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.719958202716823\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6699 6700\n",
      "Training loss:-0.002516435459256172\n",
      "check (7663,) ()\n",
      "epoch 6700\n",
      "====================================\n",
      "Epoch:  6700 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.720149253731343\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6700 6701\n",
      "Training loss:-0.001148658455349505\n",
      "Model saved\n",
      "check (9097,) ()\n",
      "epoch 6701\n",
      "====================================\n",
      "Epoch:  6701 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.720191016266229\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6701 6702\n",
      "Training loss:-0.0005334478919394314\n",
      "check (9140,) ()\n",
      "epoch 6702\n",
      "====================================\n",
      "Epoch:  6702 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.719486720381976\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6702 6703\n",
      "Training loss:-0.0023224211763590574\n",
      "check (9999,) ()\n",
      "epoch 6703\n",
      "====================================\n",
      "Epoch:  6703 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.719081008503656\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6703 6704\n",
      "Training loss:-0.00380715518258512\n",
      "check (7750,) ()\n",
      "epoch 6704\n",
      "====================================\n",
      "Epoch:  6704 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.718973747016706\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6704 6705\n",
      "Training loss:-0.0006650641444139183\n",
      "check (7638,) ()\n",
      "epoch 6705\n",
      "====================================\n",
      "Epoch:  6705 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.719313944817301\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6705 6706\n",
      "Training loss:-0.0015994220739230514\n",
      "check (10000,) ()\n",
      "epoch 6706\n",
      "====================================\n",
      "Epoch:  6706 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.718311959439308\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6706 6707\n",
      "Training loss:-0.004400245845317841\n",
      "check (5675,) ()\n",
      "epoch 6707\n",
      "====================================\n",
      "Epoch:  6707 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.718950350380199\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6707 6708\n",
      "Training loss:-0.006396915763616562\n",
      "check (10000,) ()\n",
      "epoch 6708\n",
      "====================================\n",
      "Epoch:  6708 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.718843172331544\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6708 6709\n",
      "Training loss:-0.001601525698788464\n",
      "check (8560,) ()\n",
      "epoch 6709\n",
      "====================================\n",
      "Epoch:  6709 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.718586972723207\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6709 6710\n",
      "Training loss:0.0002589145442470908\n",
      "check (9310,) ()\n",
      "epoch 6710\n",
      "====================================\n",
      "Epoch:  6710 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.718032786885246\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6710 6711\n",
      "Training loss:-0.012050208635628223\n",
      "check (10000,) ()\n",
      "epoch 6711\n",
      "====================================\n",
      "Epoch:  6711 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.717627775294293\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6711 6712\n",
      "Training loss:-0.003965973854064941\n",
      "check (9616,) ()\n",
      "epoch 6712\n",
      "====================================\n",
      "Epoch:  6712 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.716924910607867\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6712 6713\n",
      "Training loss:-0.002161274664103985\n",
      "check (7886,) ()\n",
      "epoch 6713\n",
      "====================================\n",
      "Epoch:  6713 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.717562937583793\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6713 6714\n",
      "Training loss:-9.859390956989955e-06\n",
      "check (7876,) ()\n",
      "epoch 6714\n",
      "====================================\n",
      "Epoch:  6714 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.717605004468275\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6714 6715\n",
      "Training loss:-0.0020878328941762447\n",
      "check (10000,) ()\n",
      "epoch 6715\n",
      "====================================\n",
      "Epoch:  6715 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.716008935219657\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6715 6716\n",
      "Training loss:-0.008933407254517078\n",
      "check (8208,) ()\n",
      "epoch 6716\n",
      "====================================\n",
      "Epoch:  6716 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.715753424657533\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6716 6717\n",
      "Training loss:-0.008897942490875721\n",
      "check (10000,) ()\n",
      "epoch 6717\n",
      "====================================\n",
      "Epoch:  6717 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.71445585827006\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6717 6718\n",
      "Training loss:-0.010773451067507267\n",
      "check (8562,) ()\n",
      "epoch 6718\n",
      "====================================\n",
      "Epoch:  6718 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.714647216433463\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6718 6719\n",
      "Training loss:-0.0018882924923673272\n",
      "check (9414,) ()\n",
      "epoch 6719\n",
      "====================================\n",
      "Epoch:  6719 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.713499032594136\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6719 6720\n",
      "Training loss:-0.006634168792515993\n",
      "check (8773,) ()\n",
      "epoch 6720\n",
      "====================================\n",
      "Epoch:  6720 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.713244047619048\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6720 6721\n",
      "Training loss:-0.007131555117666721\n",
      "check (9298,) ()\n",
      "epoch 6721\n",
      "====================================\n",
      "Epoch:  6721 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.713435500669544\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6721 6722\n",
      "Training loss:-0.0077523174695670605\n",
      "check (8774,) ()\n",
      "epoch 6722\n",
      "====================================\n",
      "Epoch:  6722 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.713031835763166\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6722 6723\n",
      "Training loss:-0.0049116467125713825\n",
      "check (8723,) ()\n",
      "epoch 6723\n",
      "====================================\n",
      "Epoch:  6723 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.713372006544697\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6723 6724\n",
      "Training loss:-0.003570845816284418\n",
      "check (9601,) ()\n",
      "epoch 6724\n",
      "====================================\n",
      "Epoch:  6724 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.712671029149316\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6724 6725\n",
      "Training loss:-0.00646461034193635\n",
      "check (10000,) ()\n",
      "epoch 6725\n",
      "====================================\n",
      "Epoch:  6725 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.711226765799257\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6725 6726\n",
      "Training loss:-0.006213128101080656\n",
      "check (9408,) ()\n",
      "epoch 6726\n",
      "====================================\n",
      "Epoch:  6726 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.711567053226286\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6726 6727\n",
      "Training loss:-0.012535063549876213\n",
      "check (8668,) ()\n",
      "epoch 6727\n",
      "====================================\n",
      "Epoch:  6727 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.711163966106733\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6727 6728\n",
      "Training loss:-8.218762377509847e-05\n",
      "check (9884,) ()\n",
      "epoch 6728\n",
      "====================================\n",
      "Epoch:  6728 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.709720570749107\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6728 6729\n",
      "Training loss:-0.005015723407268524\n",
      "check (8331,) ()\n",
      "epoch 6729\n",
      "====================================\n",
      "Epoch:  6729 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.710358151285481\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6729 6730\n",
      "Training loss:-0.007161029614508152\n",
      "check (8769,) ()\n",
      "epoch 6730\n",
      "====================================\n",
      "Epoch:  6730 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.710698365527488\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6730 6731\n",
      "Training loss:-0.0029565757140517235\n",
      "check (9762,) ()\n",
      "epoch 6731\n",
      "====================================\n",
      "Epoch:  6731 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.70925568266231\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6731 6732\n",
      "Training loss:-0.0006129743997007608\n",
      "check (7507,) ()\n",
      "epoch 6732\n",
      "====================================\n",
      "Epoch:  6732 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.709001782531194\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6732 6733\n",
      "Training loss:-0.0021332092583179474\n",
      "check (8885,) ()\n",
      "epoch 6733\n",
      "====================================\n",
      "Epoch:  6733 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.709045002227834\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6733 6734\n",
      "Training loss:0.005560949444770813\n",
      "check (9412,) ()\n",
      "epoch 6734\n",
      "====================================\n",
      "Epoch:  6734 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.70893970893971\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6734 6735\n",
      "Training loss:-0.0006851114449091256\n",
      "check (9749,) ()\n",
      "epoch 6735\n",
      "====================================\n",
      "Epoch:  6735 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.7086859688196\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6735 6736\n",
      "Training loss:-0.0035938064102083445\n",
      "check (9507,) ()\n",
      "epoch 6736\n",
      "====================================\n",
      "Epoch:  6736 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.707838479809975\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6736 6737\n",
      "Training loss:-0.007562641520053148\n",
      "check (8852,) ()\n",
      "epoch 6737\n",
      "====================================\n",
      "Epoch:  6737 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.707288110434911\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6737 6738\n",
      "Training loss:-0.002201010473072529\n",
      "check (7691,) ()\n",
      "epoch 6738\n",
      "====================================\n",
      "Epoch:  6738 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.707034728406056\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6738 6739\n",
      "Training loss:-0.003416231367737055\n",
      "check (10000,) ()\n",
      "epoch 6739\n",
      "====================================\n",
      "Epoch:  6739 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.705742691794034\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6739 6740\n",
      "Training loss:-0.005707110278308392\n",
      "check (9658,) ()\n",
      "epoch 6740\n",
      "====================================\n",
      "Epoch:  6740 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.705637982195846\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6740 6741\n",
      "Training loss:-0.0012222998775541782\n",
      "check (10000,) ()\n",
      "epoch 6741\n",
      "====================================\n",
      "Epoch:  6741 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.704643228007715\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6741 6742\n",
      "Training loss:-0.006430069915950298\n",
      "check (8093,) ()\n",
      "epoch 6742\n",
      "====================================\n",
      "Epoch:  6742 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.704390388608722\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6742 6743\n",
      "Training loss:-0.004174227360635996\n",
      "check (8055,) ()\n",
      "epoch 6743\n",
      "====================================\n",
      "Epoch:  6743 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.704434228088388\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6743 6744\n",
      "Training loss:0.0007393413688987494\n",
      "check (8575,) ()\n",
      "epoch 6744\n",
      "====================================\n",
      "Epoch:  6744 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.704478054567023\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6744 6745\n",
      "Training loss:0.009795216843485832\n",
      "check (10000,) ()\n",
      "epoch 6745\n",
      "====================================\n",
      "Epoch:  6745 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.70303928836175\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6745 6746\n",
      "Training loss:-0.0034339691046625376\n",
      "check (10000,) ()\n",
      "epoch 6746\n",
      "====================================\n",
      "Epoch:  6746 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.702045656685444\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6746 6747\n",
      "Training loss:-0.002645349595695734\n",
      "check (10000,) ()\n",
      "epoch 6747\n",
      "====================================\n",
      "Epoch:  6747 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.701200533570475\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6747 6748\n",
      "Training loss:-0.0034663293045014143\n",
      "check (8799,) ()\n",
      "epoch 6748\n",
      "====================================\n",
      "Epoch:  6748 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -12.699021932424422\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6748 6749\n",
      "Training loss:-0.0036272916477173567\n",
      "check (10000,) ()\n",
      "epoch 6749\n",
      "====================================\n",
      "Epoch:  6749 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.69743665728256\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6749 6750\n",
      "Training loss:-0.003183686174452305\n",
      "check (7790,) ()\n",
      "epoch 6750\n",
      "====================================\n",
      "Epoch:  6750 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.697481481481482\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6750 6751\n",
      "Training loss:-0.0022097097244113684\n",
      "Model saved\n",
      "check (9384,) ()\n",
      "epoch 6751\n",
      "====================================\n",
      "Epoch:  6751 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.697822544808176\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6751 6752\n",
      "Training loss:-0.0026322954799979925\n",
      "check (8596,) ()\n",
      "epoch 6752\n",
      "====================================\n",
      "Epoch:  6752 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.697274881516588\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6752 6753\n",
      "Training loss:-0.004580134991556406\n",
      "check (10000,) ()\n",
      "epoch 6753\n",
      "====================================\n",
      "Epoch:  6753 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.696727380423516\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6753 6754\n",
      "Training loss:-0.0030676170717924833\n",
      "check (10000,) ()\n",
      "epoch 6754\n",
      "====================================\n",
      "Epoch:  6754 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.69543973941368\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6754 6755\n",
      "Training loss:-0.005101371090859175\n",
      "check (9206,) ()\n",
      "epoch 6755\n",
      "====================================\n",
      "Epoch:  6755 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.69459659511473\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6755 6756\n",
      "Training loss:-0.005279963836073875\n",
      "check (8878,) ()\n",
      "epoch 6756\n",
      "====================================\n",
      "Epoch:  6756 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.694789816459444\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6756 6757\n",
      "Training loss:-0.0033650642726570368\n",
      "check (10000,) ()\n",
      "epoch 6757\n",
      "====================================\n",
      "Epoch:  6757 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.693207044546396\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6757 6758\n",
      "Training loss:0.002472946885973215\n",
      "check (10000,) ()\n",
      "epoch 6758\n",
      "====================================\n",
      "Epoch:  6758 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.692068659366676\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6758 6759\n",
      "Training loss:-0.0025698028039187193\n",
      "check (10000,) ()\n",
      "epoch 6759\n",
      "====================================\n",
      "Epoch:  6759 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -12.689747003994674\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6759 6760\n",
      "Training loss:-0.005868774838745594\n",
      "check (9658,) ()\n",
      "epoch 6760\n",
      "====================================\n",
      "Epoch:  6760 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.689497041420118\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6760 6761\n",
      "Training loss:-0.005775720812380314\n",
      "check (9864,) ()\n",
      "epoch 6761\n",
      "====================================\n",
      "Epoch:  6761 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.689690874131045\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6761 6762\n",
      "Training loss:0.00021593413839582354\n",
      "check (9419,) ()\n",
      "epoch 6762\n",
      "====================================\n",
      "Epoch:  6762 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.689145223306713\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6762 6763\n",
      "Training loss:-0.0055701956152915955\n",
      "check (7717,) ()\n",
      "epoch 6763\n",
      "====================================\n",
      "Epoch:  6763 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.688747597220168\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6763 6764\n",
      "Training loss:0.0047336905263364315\n",
      "check (8956,) ()\n",
      "epoch 6764\n",
      "====================================\n",
      "Epoch:  6764 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.689089296274394\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6764 6765\n",
      "Training loss:-0.006709444336593151\n",
      "check (9958,) ()\n",
      "epoch 6765\n",
      "====================================\n",
      "Epoch:  6765 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.687952697708795\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6765 6766\n",
      "Training loss:-0.0034778921399265528\n",
      "check (10000,) ()\n",
      "epoch 6766\n",
      "====================================\n",
      "Epoch:  6766 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.6860774460538\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6766 6767\n",
      "Training loss:-0.006306287832558155\n",
      "check (9196,) ()\n",
      "epoch 6767\n",
      "====================================\n",
      "Epoch:  6767 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.685089404462834\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6767 6768\n",
      "Training loss:0.0018351692706346512\n",
      "check (10000,) ()\n",
      "epoch 6768\n",
      "====================================\n",
      "Epoch:  6768 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -12.683067375886525\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6768 6769\n",
      "Training loss:-0.0016336948610842228\n",
      "check (10000,) ()\n",
      "epoch 6769\n",
      "====================================\n",
      "Epoch:  6769 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.681489141675284\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6769 6770\n",
      "Training loss:-0.0066083939746022224\n",
      "check (8980,) ()\n",
      "epoch 6770\n",
      "====================================\n",
      "Epoch:  6770 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.68109305760709\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6770 6771\n",
      "Training loss:0.003549092449247837\n",
      "check (9370,) ()\n",
      "epoch 6771\n",
      "====================================\n",
      "Epoch:  6771 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.681140156549993\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6771 6772\n",
      "Training loss:-0.0009534165146760643\n",
      "check (10000,) ()\n",
      "epoch 6772\n",
      "====================================\n",
      "Epoch:  6772 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.679858239810986\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6772 6773\n",
      "Training loss:-0.0027584258932620287\n",
      "check (9327,) ()\n",
      "epoch 6773\n",
      "====================================\n",
      "Epoch:  6773 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.679905507160786\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6773 6774\n",
      "Training loss:0.003442514920607209\n",
      "check (7844,) ()\n",
      "epoch 6774\n",
      "====================================\n",
      "Epoch:  6774 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.679362267493357\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6774 6775\n",
      "Training loss:-0.0024182728957384825\n",
      "check (10000,) ()\n",
      "epoch 6775\n",
      "====================================\n",
      "Epoch:  6775 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.678228782287823\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6775 6776\n",
      "Training loss:-0.0028912315610796213\n",
      "check (10000,) ()\n",
      "epoch 6776\n",
      "====================================\n",
      "Epoch:  6776 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.677538370720189\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6776 6777\n",
      "Training loss:-0.007664727978408337\n",
      "check (9605,) ()\n",
      "epoch 6777\n",
      "====================================\n",
      "Epoch:  6777 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:5.0\n",
      "Mean Reward of that batch 5.0\n",
      "Average Reward of all training: -12.674929909989672\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6777 6778\n",
      "Training loss:-0.008351565338671207\n",
      "check (10000,) ()\n",
      "epoch 6778\n",
      "====================================\n",
      "Epoch:  6778 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.673650044260844\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6778 6779\n",
      "Training loss:-0.005920978728681803\n",
      "check (10000,) ()\n",
      "epoch 6779\n",
      "====================================\n",
      "Epoch:  6779 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.67222304174657\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6779 6780\n",
      "Training loss:0.0005256962031126022\n",
      "check (7690,) ()\n",
      "epoch 6780\n",
      "====================================\n",
      "Epoch:  6780 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.672271386430678\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6780 6781\n",
      "Training loss:-0.005730342119932175\n",
      "check (10000,) ()\n",
      "epoch 6781\n",
      "====================================\n",
      "Epoch:  6781 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.671434891608907\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6781 6782\n",
      "Training loss:-0.007799604907631874\n",
      "check (10000,) ()\n",
      "epoch 6782\n",
      "====================================\n",
      "Epoch:  6782 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.670746092598053\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6782 6783\n",
      "Training loss:-0.0005539226694963872\n",
      "check (9335,) ()\n",
      "epoch 6783\n",
      "====================================\n",
      "Epoch:  6783 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.670352351466903\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6783 6784\n",
      "Training loss:0.004159333184361458\n",
      "check (10000,) ()\n",
      "epoch 6784\n",
      "====================================\n",
      "Epoch:  6784 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.66848466981132\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6784 6785\n",
      "Training loss:-0.004223498981446028\n",
      "check (9497,) ()\n",
      "epoch 6785\n",
      "====================================\n",
      "Epoch:  6785 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.668238761974944\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6785 6786\n",
      "Training loss:-0.0004936500336043537\n",
      "check (10000,) ()\n",
      "epoch 6786\n",
      "====================================\n",
      "Epoch:  6786 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.66651930445034\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6786 6787\n",
      "Training loss:0.004159840755164623\n",
      "check (10000,) ()\n",
      "epoch 6787\n",
      "====================================\n",
      "Epoch:  6787 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.665831737144542\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6787 6788\n",
      "Training loss:-0.010574528947472572\n",
      "check (10000,) ()\n",
      "epoch 6788\n",
      "====================================\n",
      "Epoch:  6788 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.664555097230407\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6788 6789\n",
      "Training loss:-0.0036231193225830793\n",
      "check (9866,) ()\n",
      "epoch 6789\n",
      "====================================\n",
      "Epoch:  6789 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.66342613050523\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6789 6790\n",
      "Training loss:-0.009945464320480824\n",
      "check (10000,) ()\n",
      "epoch 6790\n",
      "====================================\n",
      "Epoch:  6790 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.661855670103092\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6790 6791\n",
      "Training loss:-0.0066171735525131226\n",
      "check (10000,) ()\n",
      "epoch 6791\n",
      "====================================\n",
      "Epoch:  6791 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.661463701958475\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6791 6792\n",
      "Training loss:-0.0014313082210719585\n",
      "check (7330,) ()\n",
      "epoch 6792\n",
      "====================================\n",
      "Epoch:  6792 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.66180800942285\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6792 6793\n",
      "Training loss:-0.003466811031103134\n",
      "check (8418,) ()\n",
      "epoch 6793\n",
      "====================================\n",
      "Epoch:  6793 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.661563374061535\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6793 6794\n",
      "Training loss:-0.003867983352392912\n",
      "check (9236,) ()\n",
      "epoch 6794\n",
      "====================================\n",
      "Epoch:  6794 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.66102443332352\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6794 6795\n",
      "Training loss:-0.007933571003377438\n",
      "check (10000,) ()\n",
      "epoch 6795\n",
      "====================================\n",
      "Epoch:  6795 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.66019131714496\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6795 6796\n",
      "Training loss:-0.004723437130451202\n",
      "check (9706,) ()\n",
      "epoch 6796\n",
      "====================================\n",
      "Epoch:  6796 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.659505591524427\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6796 6797\n",
      "Training loss:-0.0014646523632109165\n",
      "check (8768,) ()\n",
      "epoch 6797\n",
      "====================================\n",
      "Epoch:  6797 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.659408562601147\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6797 6798\n",
      "Training loss:-0.0013087647967040539\n",
      "check (9564,) ()\n",
      "epoch 6798\n",
      "====================================\n",
      "Epoch:  6798 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.658281847602236\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6798 6799\n",
      "Training loss:-0.003421205095946789\n",
      "check (10000,) ()\n",
      "epoch 6799\n",
      "====================================\n",
      "Epoch:  6799 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.657302544491838\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6799 6800\n",
      "Training loss:-0.0048113600350916386\n",
      "check (8878,) ()\n",
      "epoch 6800\n",
      "====================================\n",
      "Epoch:  6800 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.657352941176471\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6800 6801\n",
      "Training loss:-0.0026432955637574196\n",
      "Model saved\n",
      "check (8962,) ()\n",
      "epoch 6801\n",
      "====================================\n",
      "Epoch:  6801 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.656227025437436\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6801 6802\n",
      "Training loss:-0.00329733663238585\n",
      "check (9083,) ()\n",
      "epoch 6802\n",
      "====================================\n",
      "Epoch:  6802 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.655689503087327\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6802 6803\n",
      "Training loss:-0.005270281340926886\n",
      "check (9226,) ()\n",
      "epoch 6803\n",
      "====================================\n",
      "Epoch:  6803 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.655593120682052\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6803 6804\n",
      "Training loss:-0.004723393823951483\n",
      "check (8136,) ()\n",
      "epoch 6804\n",
      "====================================\n",
      "Epoch:  6804 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.655937683715461\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6804 6805\n",
      "Training loss:0.00030837743543088436\n",
      "check (9541,) ()\n",
      "epoch 6805\n",
      "====================================\n",
      "Epoch:  6805 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.65584129316679\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6805 6806\n",
      "Training loss:-0.012210479937493801\n",
      "check (8429,) ()\n",
      "epoch 6806\n",
      "====================================\n",
      "Epoch:  6806 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.655451072583014\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6806 6807\n",
      "Training loss:-0.00019351272203493863\n",
      "check (10000,) ()\n",
      "epoch 6807\n",
      "====================================\n",
      "Epoch:  6807 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:6.0\n",
      "Mean Reward of that batch 6.0\n",
      "Average Reward of all training: -12.652710445130014\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6807 6808\n",
      "Training loss:-0.0014109613839536905\n",
      "check (10000,) ()\n",
      "epoch 6808\n",
      "====================================\n",
      "Epoch:  6808 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.652173913043478\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6808 6809\n",
      "Training loss:-0.0034912200644612312\n",
      "check (9840,) ()\n",
      "epoch 6809\n",
      "====================================\n",
      "Epoch:  6809 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.652518725216625\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6809 6810\n",
      "Training loss:-0.0036993364337831736\n",
      "check (10000,) ()\n",
      "epoch 6810\n",
      "====================================\n",
      "Epoch:  6810 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.650954478707783\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6810 6811\n",
      "Training loss:-0.0012886796612292528\n",
      "check (10000,) ()\n",
      "epoch 6811\n",
      "====================================\n",
      "Epoch:  6811 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.649831155483776\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6811 6812\n",
      "Training loss:-0.00012274322216399014\n",
      "check (10000,) ()\n",
      "epoch 6812\n",
      "====================================\n",
      "Epoch:  6812 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.64826776277158\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6812 6813\n",
      "Training loss:-0.0032699420116841793\n",
      "check (9081,) ()\n",
      "epoch 6813\n",
      "====================================\n",
      "Epoch:  6813 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.647732276530164\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6813 6814\n",
      "Training loss:-0.0016723924782127142\n",
      "check (9538,) ()\n",
      "epoch 6814\n",
      "====================================\n",
      "Epoch:  6814 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.646756677428822\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6814 6815\n",
      "Training loss:-0.0038921318482607603\n",
      "check (10000,) ()\n",
      "epoch 6815\n",
      "====================================\n",
      "Epoch:  6815 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.645487894350698\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6815 6816\n",
      "Training loss:-0.004807590506970882\n",
      "check (5795,) ()\n",
      "epoch 6816\n",
      "====================================\n",
      "Epoch:  6816 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.64612676056338\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6816 6817\n",
      "Training loss:0.0020544887520372868\n",
      "check (10000,) ()\n",
      "epoch 6817\n",
      "====================================\n",
      "Epoch:  6817 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.644711750036674\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6817 6818\n",
      "Training loss:-0.0018709736177697778\n",
      "check (8244,) ()\n",
      "epoch 6818\n",
      "====================================\n",
      "Epoch:  6818 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.643737166324435\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6818 6819\n",
      "Training loss:-0.006469743326306343\n",
      "check (10000,) ()\n",
      "epoch 6819\n",
      "====================================\n",
      "Epoch:  6819 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.642469570318228\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6819 6820\n",
      "Training loss:-0.006502008065581322\n",
      "check (10000,) ()\n",
      "epoch 6820\n",
      "====================================\n",
      "Epoch:  6820 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.64149560117302\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6820 6821\n",
      "Training loss:-0.008685721084475517\n",
      "check (9327,) ()\n",
      "epoch 6821\n",
      "====================================\n",
      "Epoch:  6821 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.640961735815862\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6821 6822\n",
      "Training loss:-0.005714584141969681\n",
      "check (10000,) ()\n",
      "epoch 6822\n",
      "====================================\n",
      "Epoch:  6822 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.639988273233655\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6822 6823\n",
      "Training loss:-0.003975969739258289\n",
      "check (10000,) ()\n",
      "epoch 6823\n",
      "====================================\n",
      "Epoch:  6823 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.638135717426351\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6823 6824\n",
      "Training loss:-0.0036141604650765657\n",
      "check (7670,) ()\n",
      "epoch 6824\n",
      "====================================\n",
      "Epoch:  6824 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.637162954279015\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6824 6825\n",
      "Training loss:-0.006882588379085064\n",
      "check (10000,) ()\n",
      "epoch 6825\n",
      "====================================\n",
      "Epoch:  6825 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.636630036630036\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6825 6826\n",
      "Training loss:-0.00865611620247364\n",
      "check (6734,) ()\n",
      "epoch 6826\n",
      "====================================\n",
      "Epoch:  6826 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.636976267213596\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6826 6827\n",
      "Training loss:-0.0061216712929308414\n",
      "check (10000,) ()\n",
      "epoch 6827\n",
      "====================================\n",
      "Epoch:  6827 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.635564669693862\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6827 6828\n",
      "Training loss:-0.003339070128276944\n",
      "check (10000,) ()\n",
      "epoch 6828\n",
      "====================================\n",
      "Epoch:  6828 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.633714118336263\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6828 6829\n",
      "Training loss:-0.007992925122380257\n",
      "check (10000,) ()\n",
      "epoch 6829\n",
      "====================================\n",
      "Epoch:  6829 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.632303411919754\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6829 6830\n",
      "Training loss:-0.005313448142260313\n",
      "check (9143,) ()\n",
      "epoch 6830\n",
      "====================================\n",
      "Epoch:  6830 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.631478770131771\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6830 6831\n",
      "Training loss:0.0018193824216723442\n",
      "check (8048,) ()\n",
      "epoch 6831\n",
      "====================================\n",
      "Epoch:  6831 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.631679109939979\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6831 6832\n",
      "Training loss:0.00014264066703617573\n",
      "check (10000,) ()\n",
      "epoch 6832\n",
      "====================================\n",
      "Epoch:  6832 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.631001170960188\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6832 6833\n",
      "Training loss:-0.00465626735240221\n",
      "check (9500,) ()\n",
      "epoch 6833\n",
      "====================================\n",
      "Epoch:  6833 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.630762476218353\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6833 6834\n",
      "Training loss:-0.007823031395673752\n",
      "check (7298,) ()\n",
      "epoch 6834\n",
      "====================================\n",
      "Epoch:  6834 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.631109160081943\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6834 6835\n",
      "Training loss:-0.002067022258415818\n",
      "check (9455,) ()\n",
      "epoch 6835\n",
      "====================================\n",
      "Epoch:  6835 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.630577907827359\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6835 6836\n",
      "Training loss:-0.0028188673313707113\n",
      "check (9620,) ()\n",
      "epoch 6836\n",
      "====================================\n",
      "Epoch:  6836 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.63048566413107\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6836 6837\n",
      "Training loss:-0.0035859281197190285\n",
      "check (10000,) ()\n",
      "epoch 6837\n",
      "====================================\n",
      "Epoch:  6837 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.628784554629224\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6837 6838\n",
      "Training loss:-4.610271571436897e-05\n",
      "check (8176,) ()\n",
      "epoch 6838\n",
      "====================================\n",
      "Epoch:  6838 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.629131324948816\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6838 6839\n",
      "Training loss:-0.00241733156144619\n",
      "check (7215,) ()\n",
      "epoch 6839\n",
      "====================================\n",
      "Epoch:  6839 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.629477993858751\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6839 6840\n",
      "Training loss:0.0035865616519004107\n",
      "check (8653,) ()\n",
      "epoch 6840\n",
      "====================================\n",
      "Epoch:  6840 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.629239766081872\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6840 6841\n",
      "Training loss:0.0034680531825870275\n",
      "check (8272,) ()\n",
      "epoch 6841\n",
      "====================================\n",
      "Epoch:  6841 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.629001607952054\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6841 6842\n",
      "Training loss:-0.014298534020781517\n",
      "check (9476,) ()\n",
      "epoch 6842\n",
      "====================================\n",
      "Epoch:  6842 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.629055831628179\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6842 6843\n",
      "Training loss:-0.004416459705680609\n",
      "check (10000,) ()\n",
      "epoch 6843\n",
      "====================================\n",
      "Epoch:  6843 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.62808709630279\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6843 6844\n",
      "Training loss:0.0002819908258970827\n",
      "check (10000,) ()\n",
      "epoch 6844\n",
      "====================================\n",
      "Epoch:  6844 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.626534190531853\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6844 6845\n",
      "Training loss:0.0006233776221051812\n",
      "check (10000,) ()\n",
      "epoch 6845\n",
      "====================================\n",
      "Epoch:  6845 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.625858290723155\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6845 6846\n",
      "Training loss:-0.0011827315902337432\n",
      "check (10000,) ()\n",
      "epoch 6846\n",
      "====================================\n",
      "Epoch:  6846 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.624306164183464\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6846 6847\n",
      "Training loss:-0.002373429946601391\n",
      "check (10000,) ()\n",
      "epoch 6847\n",
      "====================================\n",
      "Epoch:  6847 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.623338688476705\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6847 6848\n",
      "Training loss:-0.00627153879031539\n",
      "check (10000,) ()\n",
      "epoch 6848\n",
      "====================================\n",
      "Epoch:  6848 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.622517523364486\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6848 6849\n",
      "Training loss:0.0012774921488016844\n",
      "check (10000,) ()\n",
      "epoch 6849\n",
      "====================================\n",
      "Epoch:  6849 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -12.62023653088042\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6849 6850\n",
      "Training loss:-0.004251749254763126\n",
      "check (7775,) ()\n",
      "epoch 6850\n",
      "====================================\n",
      "Epoch:  6850 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.620291970802919\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6850 6851\n",
      "Training loss:-0.002611238043755293\n",
      "Model saved\n",
      "check (6296,) ()\n",
      "epoch 6851\n",
      "====================================\n",
      "Epoch:  6851 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -12.621223179097942\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6851 6852\n",
      "Training loss:-0.004250348545610905\n",
      "check (9542,) ()\n",
      "epoch 6852\n",
      "====================================\n",
      "Epoch:  6852 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.619964973730298\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6852 6853\n",
      "Training loss:-0.007741336245089769\n",
      "check (10000,) ()\n",
      "epoch 6853\n",
      "====================================\n",
      "Epoch:  6853 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -12.617977528089888\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6853 6854\n",
      "Training loss:-0.002436903305351734\n",
      "check (9768,) ()\n",
      "epoch 6854\n",
      "====================================\n",
      "Epoch:  6854 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.61744966442953\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6854 6855\n",
      "Training loss:-0.0007117846980690956\n",
      "check (10000,) ()\n",
      "epoch 6855\n",
      "====================================\n",
      "Epoch:  6855 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.616630196936542\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6855 6856\n",
      "Training loss:-0.0028257400263100863\n",
      "check (10000,) ()\n",
      "epoch 6856\n",
      "====================================\n",
      "Epoch:  6856 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.61610268378063\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6856 6857\n",
      "Training loss:-0.005636249203234911\n",
      "check (10000,) ()\n",
      "epoch 6857\n",
      "====================================\n",
      "Epoch:  6857 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.614408633513198\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6857 6858\n",
      "Training loss:-0.0023093060590326786\n",
      "check (8165,) ()\n",
      "epoch 6858\n",
      "====================================\n",
      "Epoch:  6858 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.613444152814232\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6858 6859\n",
      "Training loss:-0.0025802687741816044\n",
      "check (10000,) ()\n",
      "epoch 6859\n",
      "====================================\n",
      "Epoch:  6859 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.613646304125966\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6859 6860\n",
      "Training loss:-0.0003247627173550427\n",
      "check (8261,) ()\n",
      "epoch 6860\n",
      "====================================\n",
      "Epoch:  6860 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.61399416909621\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6860 6861\n",
      "Training loss:-0.003478199942037463\n",
      "check (7670,) ()\n",
      "epoch 6861\n",
      "====================================\n",
      "Epoch:  6861 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.614341932662876\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6861 6862\n",
      "Training loss:-0.0008773708250373602\n",
      "check (10000,) ()\n",
      "epoch 6862\n",
      "====================================\n",
      "Epoch:  6862 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.613523754007577\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6862 6863\n",
      "Training loss:1.3992309959576232e-06\n",
      "check (9166,) ()\n",
      "epoch 6863\n",
      "====================================\n",
      "Epoch:  6863 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.61285152265773\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6863 6864\n",
      "Training loss:0.002445811405777931\n",
      "check (9120,) ()\n",
      "epoch 6864\n",
      "====================================\n",
      "Epoch:  6864 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.612325174825175\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6864 6865\n",
      "Training loss:-0.004971390124410391\n",
      "check (7222,) ()\n",
      "epoch 6865\n",
      "====================================\n",
      "Epoch:  6865 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.612964311726147\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6865 6866\n",
      "Training loss:0.0007864731014706194\n",
      "check (9699,) ()\n",
      "epoch 6866\n",
      "====================================\n",
      "Epoch:  6866 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.612729391203029\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6866 6867\n",
      "Training loss:-0.007664777338504791\n",
      "check (8751,) ()\n",
      "epoch 6867\n",
      "====================================\n",
      "Epoch:  6867 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.612494539100044\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6867 6868\n",
      "Training loss:-0.00028777230181731284\n",
      "check (10000,) ()\n",
      "epoch 6868\n",
      "====================================\n",
      "Epoch:  6868 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.611531741409435\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6868 6869\n",
      "Training loss:-0.0037075653672218323\n",
      "check (8896,) ()\n",
      "epoch 6869\n",
      "====================================\n",
      "Epoch:  6869 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.61129713204251\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6869 6870\n",
      "Training loss:0.0013448653044179082\n",
      "check (7762,) ()\n",
      "epoch 6870\n",
      "====================================\n",
      "Epoch:  6870 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.61193595342067\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6870 6871\n",
      "Training loss:-0.0007349027437157929\n",
      "check (9885,) ()\n",
      "epoch 6871\n",
      "====================================\n",
      "Epoch:  6871 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.611701353514773\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6871 6872\n",
      "Training loss:0.0009077184950001538\n",
      "check (7483,) ()\n",
      "epoch 6872\n",
      "====================================\n",
      "Epoch:  6872 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.61175785797439\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6872 6873\n",
      "Training loss:-0.0039713820442557335\n",
      "check (10000,) ()\n",
      "epoch 6873\n",
      "====================================\n",
      "Epoch:  6873 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.610504874145207\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6873 6874\n",
      "Training loss:-0.0022255394142121077\n",
      "check (9664,) ()\n",
      "epoch 6874\n",
      "====================================\n",
      "Epoch:  6874 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.609688681990107\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6874 6875\n",
      "Training loss:-0.0044819386675953865\n",
      "check (10000,) ()\n",
      "epoch 6875\n",
      "====================================\n",
      "Epoch:  6875 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.609018181818183\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6875 6876\n",
      "Training loss:-0.009716666303575039\n",
      "check (8296,) ()\n",
      "epoch 6876\n",
      "====================================\n",
      "Epoch:  6876 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.608493310063992\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6876 6877\n",
      "Training loss:-0.0035120428074151278\n",
      "check (9767,) ()\n",
      "epoch 6877\n",
      "====================================\n",
      "Epoch:  6877 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.608259415442781\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6877 6878\n",
      "Training loss:-0.007031991146504879\n",
      "check (10000,) ()\n",
      "epoch 6878\n",
      "====================================\n",
      "Epoch:  6878 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.60729863332364\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6878 6879\n",
      "Training loss:-0.005370230879634619\n",
      "check (6666,) ()\n",
      "epoch 6879\n",
      "====================================\n",
      "Epoch:  6879 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.607791830207878\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6879 6880\n",
      "Training loss:-0.0028132395818829536\n",
      "check (9608,) ()\n",
      "epoch 6880\n",
      "====================================\n",
      "Epoch:  6880 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.607412790697675\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6880 6881\n",
      "Training loss:-0.004623629152774811\n",
      "check (7664,) ()\n",
      "epoch 6881\n",
      "====================================\n",
      "Epoch:  6881 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.607760499927336\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6881 6882\n",
      "Training loss:0.0034081581979990005\n",
      "check (9082,) ()\n",
      "epoch 6882\n",
      "====================================\n",
      "Epoch:  6882 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.607817494914269\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6882 6883\n",
      "Training loss:-0.005675337743014097\n",
      "check (8562,) ()\n",
      "epoch 6883\n",
      "====================================\n",
      "Epoch:  6883 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.608019758826094\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6883 6884\n",
      "Training loss:-0.0032754894345998764\n",
      "check (9425,) ()\n",
      "epoch 6884\n",
      "====================================\n",
      "Epoch:  6884 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.607786170830913\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6884 6885\n",
      "Training loss:-0.008128643035888672\n",
      "check (9348,) ()\n",
      "epoch 6885\n",
      "====================================\n",
      "Epoch:  6885 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.607552650689906\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6885 6886\n",
      "Training loss:0.0023812917061150074\n",
      "check (9046,) ()\n",
      "epoch 6886\n",
      "====================================\n",
      "Epoch:  6886 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:5.0\n",
      "Mean Reward of that batch 5.0\n",
      "Average Reward of all training: -12.604995643334302\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6886 6887\n",
      "Training loss:0.00047162326518446207\n",
      "check (9847,) ()\n",
      "epoch 6887\n",
      "====================================\n",
      "Epoch:  6887 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.60490779729926\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6887 6888\n",
      "Training loss:0.00034262542612850666\n",
      "check (9126,) ()\n",
      "epoch 6888\n",
      "====================================\n",
      "Epoch:  6888 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.604094076655052\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6888 6889\n",
      "Training loss:-0.005204752553254366\n",
      "check (10000,) ()\n",
      "epoch 6889\n",
      "====================================\n",
      "Epoch:  6889 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.603280592248511\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6889 6890\n",
      "Training loss:-0.006017919164150953\n",
      "check (9518,) ()\n",
      "epoch 6890\n",
      "====================================\n",
      "Epoch:  6890 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.603338171262699\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6890 6891\n",
      "Training loss:0.0010578831424936652\n",
      "check (9100,) ()\n",
      "epoch 6891\n",
      "====================================\n",
      "Epoch:  6891 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.602960383108401\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6891 6892\n",
      "Training loss:-0.003699089400470257\n",
      "check (10000,) ()\n",
      "epoch 6892\n",
      "====================================\n",
      "Epoch:  6892 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:2.0\n",
      "Mean Reward of that batch 2.0\n",
      "Average Reward of all training: -12.600841555426582\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6892 6893\n",
      "Training loss:-0.00620961282402277\n",
      "check (10000,) ()\n",
      "epoch 6893\n",
      "====================================\n",
      "Epoch:  6893 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.599158566661831\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6893 6894\n",
      "Training loss:-0.0017706603975966573\n",
      "check (8344,) ()\n",
      "epoch 6894\n",
      "====================================\n",
      "Epoch:  6894 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.597911227154047\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6894 6895\n",
      "Training loss:-0.007403320632874966\n",
      "check (10000,) ()\n",
      "epoch 6895\n",
      "====================================\n",
      "Epoch:  6895 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.59680928208847\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6895 6896\n",
      "Training loss:0.0026542290579527617\n",
      "check (9043,) ()\n",
      "epoch 6896\n",
      "====================================\n",
      "Epoch:  6896 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.597447795823665\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6896 6897\n",
      "Training loss:0.0002295622689416632\n",
      "check (10000,) ()\n",
      "epoch 6897\n",
      "====================================\n",
      "Epoch:  6897 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.59620124691895\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6897 6898\n",
      "Training loss:-0.007731327787041664\n",
      "check (8354,) ()\n",
      "epoch 6898\n",
      "====================================\n",
      "Epoch:  6898 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.595100028993912\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6898 6899\n",
      "Training loss:-0.0034804181195795536\n",
      "check (10000,) ()\n",
      "epoch 6899\n",
      "====================================\n",
      "Epoch:  6899 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.593274387592405\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6899 6900\n",
      "Training loss:-0.005621968302875757\n",
      "check (7546,) ()\n",
      "epoch 6900\n",
      "====================================\n",
      "Epoch:  6900 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.593623188405797\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6900 6901\n",
      "Training loss:0.0007710963836871088\n",
      "Model saved\n",
      "check (9094,) ()\n",
      "epoch 6901\n",
      "====================================\n",
      "Epoch:  6901 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.593392261991015\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6901 6902\n",
      "Training loss:-0.006371631752699614\n",
      "check (9217,) ()\n",
      "epoch 6902\n",
      "====================================\n",
      "Epoch:  6902 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.592436974789916\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6902 6903\n",
      "Training loss:-0.005597887560725212\n",
      "check (7984,) ()\n",
      "epoch 6903\n",
      "====================================\n",
      "Epoch:  6903 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.592640880776473\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6903 6904\n",
      "Training loss:-0.005360566545277834\n",
      "check (10000,) ()\n",
      "epoch 6904\n",
      "====================================\n",
      "Epoch:  6904 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-1.0\n",
      "Mean Reward of that batch -1.0\n",
      "Average Reward of all training: -12.590961761297798\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6904 6905\n",
      "Training loss:-0.00680706650018692\n",
      "check (9485,) ()\n",
      "epoch 6905\n",
      "====================================\n",
      "Epoch:  6905 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.590731354091238\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6905 6906\n",
      "Training loss:0.001986000221222639\n",
      "check (10000,) ()\n",
      "epoch 6906\n",
      "====================================\n",
      "Epoch:  6906 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -12.588763394150014\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6906 6907\n",
      "Training loss:-0.0023227573838084936\n",
      "check (9132,) ()\n",
      "epoch 6907\n",
      "====================================\n",
      "Epoch:  6907 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.587954249312292\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6907 6908\n",
      "Training loss:-0.0007125342381186783\n",
      "check (8484,) ()\n",
      "epoch 6908\n",
      "====================================\n",
      "Epoch:  6908 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.587579617834395\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6908 6909\n",
      "Training loss:-0.004372510127723217\n",
      "check (8816,) ()\n",
      "epoch 6909\n",
      "====================================\n",
      "Epoch:  6909 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.587060356057316\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6909 6910\n",
      "Training loss:-0.0037035192362964153\n",
      "check (8562,) ()\n",
      "epoch 6910\n",
      "====================================\n",
      "Epoch:  6910 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.586251808972504\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6910 6911\n",
      "Training loss:-0.004861891735345125\n",
      "check (10000,) ()\n",
      "epoch 6911\n",
      "====================================\n",
      "Epoch:  6911 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.585877586456373\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6911 6912\n",
      "Training loss:-0.006140538491308689\n",
      "check (9714,) ()\n",
      "epoch 6912\n",
      "====================================\n",
      "Epoch:  6912 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.586082175925926\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6912 6913\n",
      "Training loss:-0.0033762233797460794\n",
      "check (8827,) ()\n",
      "epoch 6913\n",
      "====================================\n",
      "Epoch:  6913 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.585852741212209\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6913 6914\n",
      "Training loss:-0.00119780283421278\n",
      "check (9692,) ()\n",
      "epoch 6914\n",
      "====================================\n",
      "Epoch:  6914 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.58547873879086\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6914 6915\n",
      "Training loss:-0.008584794588387012\n",
      "check (10000,) ()\n",
      "epoch 6915\n",
      "====================================\n",
      "Epoch:  6915 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:1.0\n",
      "Mean Reward of that batch 1.0\n",
      "Average Reward of all training: -12.58351409978308\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6915 6916\n",
      "Training loss:-0.004136956762522459\n",
      "check (9294,) ()\n",
      "epoch 6916\n",
      "====================================\n",
      "Epoch:  6916 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.582995951417004\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6916 6917\n",
      "Training loss:-0.0014661169843748212\n",
      "check (7924,) ()\n",
      "epoch 6917\n",
      "====================================\n",
      "Epoch:  6917 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.58276709556166\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6917 6918\n",
      "Training loss:-0.010877272114157677\n",
      "check (8866,) ()\n",
      "epoch 6918\n",
      "====================================\n",
      "Epoch:  6918 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.582249204972536\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6918 6919\n",
      "Training loss:-0.003967294469475746\n",
      "check (10000,) ()\n",
      "epoch 6919\n",
      "====================================\n",
      "Epoch:  6919 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.581153345859228\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6919 6920\n",
      "Training loss:-0.006434275768697262\n",
      "check (10000,) ()\n",
      "epoch 6920\n",
      "====================================\n",
      "Epoch:  6920 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.58063583815029\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6920 6921\n",
      "Training loss:-0.001372973551042378\n",
      "check (10000,) ()\n",
      "epoch 6921\n",
      "====================================\n",
      "Epoch:  6921 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.580262967779223\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6921 6922\n",
      "Training loss:-0.005123776383697987\n",
      "check (9339,) ()\n",
      "epoch 6922\n",
      "====================================\n",
      "Epoch:  6922 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.580034672060098\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6922 6923\n",
      "Training loss:-0.004928802140057087\n",
      "check (9260,) ()\n",
      "epoch 6923\n",
      "====================================\n",
      "Epoch:  6923 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.579950888343204\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6923 6924\n",
      "Training loss:-0.004102091770619154\n",
      "check (7189,) ()\n",
      "epoch 6924\n",
      "====================================\n",
      "Epoch:  6924 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.580300404390526\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6924 6925\n",
      "Training loss:0.0036924874875694513\n",
      "check (10000,) ()\n",
      "epoch 6925\n",
      "====================================\n",
      "Epoch:  6925 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.579927797833935\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6925 6926\n",
      "Training loss:-0.0022423500195145607\n",
      "check (8179,) ()\n",
      "epoch 6926\n",
      "====================================\n",
      "Epoch:  6926 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.579988449321398\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6926 6927\n",
      "Training loss:-0.0018457183614373207\n",
      "check (9808,) ()\n",
      "epoch 6927\n",
      "====================================\n",
      "Epoch:  6927 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.578461094268803\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6927 6928\n",
      "Training loss:-0.007713808678090572\n",
      "check (8319,) ()\n",
      "epoch 6928\n",
      "====================================\n",
      "Epoch:  6928 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.578233256351039\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6928 6929\n",
      "Training loss:-0.0038868256378918886\n",
      "check (7100,) ()\n",
      "epoch 6929\n",
      "====================================\n",
      "Epoch:  6929 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.5785827680762\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6929 6930\n",
      "Training loss:-0.006656744983047247\n",
      "check (8849,) ()\n",
      "epoch 6930\n",
      "====================================\n",
      "Epoch:  6930 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.578210678210679\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6930 6931\n",
      "Training loss:-0.001755450968630612\n",
      "check (7752,) ()\n",
      "epoch 6931\n",
      "====================================\n",
      "Epoch:  6931 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.577982975039676\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6931 6932\n",
      "Training loss:-0.0034467941150069237\n",
      "check (7834,) ()\n",
      "epoch 6932\n",
      "====================================\n",
      "Epoch:  6932 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.57804385458742\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6932 6933\n",
      "Training loss:-0.0055184741504490376\n",
      "check (9013,) ()\n",
      "epoch 6933\n",
      "====================================\n",
      "Epoch:  6933 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.578393191980384\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6933 6934\n",
      "Training loss:0.004687380511313677\n",
      "check (10000,) ()\n",
      "epoch 6934\n",
      "====================================\n",
      "Epoch:  6934 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.577300259590425\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6934 6935\n",
      "Training loss:-0.005729986820369959\n",
      "check (10000,) ()\n",
      "epoch 6935\n",
      "====================================\n",
      "Epoch:  6935 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.57606344628695\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6935 6936\n",
      "Training loss:-0.00426151417195797\n",
      "check (8748,) ()\n",
      "epoch 6936\n",
      "====================================\n",
      "Epoch:  6936 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.57540369088812\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6936 6937\n",
      "Training loss:-0.00040184182580560446\n",
      "check (10000,) ()\n",
      "epoch 6937\n",
      "====================================\n",
      "Epoch:  6937 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:0.0\n",
      "Mean Reward of that batch 0.0\n",
      "Average Reward of all training: -12.573590889433472\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6937 6938\n",
      "Training loss:-0.002711242763325572\n",
      "check (10000,) ()\n",
      "epoch 6938\n",
      "====================================\n",
      "Epoch:  6938 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.57249927933122\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6938 6939\n",
      "Training loss:-0.0019254391081631184\n",
      "check (9062,) ()\n",
      "epoch 6939\n",
      "====================================\n",
      "Epoch:  6939 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.571984435797665\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6939 6940\n",
      "Training loss:-0.006301078014075756\n",
      "check (9566,) ()\n",
      "epoch 6940\n",
      "====================================\n",
      "Epoch:  6940 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:4.0\n",
      "Mean Reward of that batch 4.0\n",
      "Average Reward of all training: -12.569596541786744\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6940 6941\n",
      "Training loss:-0.005738453008234501\n",
      "check (9042,) ()\n",
      "epoch 6941\n",
      "====================================\n",
      "Epoch:  6941 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.56937040772223\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6941 6942\n",
      "Training loss:-0.006560041569173336\n",
      "check (10000,) ()\n",
      "epoch 6942\n",
      "====================================\n",
      "Epoch:  6942 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:4.0\n",
      "Mean Reward of that batch 4.0\n",
      "Average Reward of all training: -12.566983578219533\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6942 6943\n",
      "Training loss:-0.0026085502468049526\n",
      "check (10000,) ()\n",
      "epoch 6943\n",
      "====================================\n",
      "Epoch:  6943 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -12.564741466224975\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6943 6944\n",
      "Training loss:-0.005373334977775812\n",
      "check (9683,) ()\n",
      "epoch 6944\n",
      "====================================\n",
      "Epoch:  6944 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.564372119815669\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6944 6945\n",
      "Training loss:0.0016299328999593854\n",
      "check (10000,) ()\n",
      "epoch 6945\n",
      "====================================\n",
      "Epoch:  6945 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.56313894888409\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6945 6946\n",
      "Training loss:-0.0034518928732722998\n",
      "check (10000,) ()\n",
      "epoch 6946\n",
      "====================================\n",
      "Epoch:  6946 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.562338036279874\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6946 6947\n",
      "Training loss:-0.00806908868253231\n",
      "check (10000,) ()\n",
      "epoch 6947\n",
      "====================================\n",
      "Epoch:  6947 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.562401036418597\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6947 6948\n",
      "Training loss:-0.006509596947580576\n",
      "check (8628,) ()\n",
      "epoch 6948\n",
      "====================================\n",
      "Epoch:  6948 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.56203223949338\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6948 6949\n",
      "Training loss:-0.006577145308256149\n",
      "check (8417,) ()\n",
      "epoch 6949\n",
      "====================================\n",
      "Epoch:  6949 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.562095265505828\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6949 6950\n",
      "Training loss:-4.622232881956734e-05\n",
      "check (9893,) ()\n",
      "epoch 6950\n",
      "====================================\n",
      "Epoch:  6950 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.56115107913669\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6950 6951\n",
      "Training loss:0.0014325962401926517\n",
      "Model saved\n",
      "check (9857,) ()\n",
      "epoch 6951\n",
      "====================================\n",
      "Epoch:  6951 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.559775571860165\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6951 6952\n",
      "Training loss:-0.002713955007493496\n",
      "check (8741,) ()\n",
      "epoch 6952\n",
      "====================================\n",
      "Epoch:  6952 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.559838895281933\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6952 6953\n",
      "Training loss:8.790954598225653e-05\n",
      "check (10000,) ()\n",
      "epoch 6953\n",
      "====================================\n",
      "Epoch:  6953 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.559039263627211\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6953 6954\n",
      "Training loss:-0.0020814789459109306\n",
      "check (9126,) ()\n",
      "epoch 6954\n",
      "====================================\n",
      "Epoch:  6954 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.558239861949957\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6954 6955\n",
      "Training loss:-0.0015623689396306872\n",
      "check (9975,) ()\n",
      "epoch 6955\n",
      "====================================\n",
      "Epoch:  6955 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.557872034507549\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6955 6956\n",
      "Training loss:-0.0019112781155854464\n",
      "check (8023,) ()\n",
      "epoch 6956\n",
      "====================================\n",
      "Epoch:  6956 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.55764807360552\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6956 6957\n",
      "Training loss:-0.0001582878321642056\n",
      "check (9924,) ()\n",
      "epoch 6957\n",
      "====================================\n",
      "Epoch:  6957 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.556561736380624\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6957 6958\n",
      "Training loss:-0.006486796773970127\n",
      "check (7918,) ()\n",
      "epoch 6958\n",
      "====================================\n",
      "Epoch:  6958 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.556625467088244\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6958 6959\n",
      "Training loss:-0.0016627946170046926\n",
      "check (8431,) ()\n",
      "epoch 6959\n",
      "====================================\n",
      "Epoch:  6959 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.55712027590171\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6959 6960\n",
      "Training loss:-0.0022560274228453636\n",
      "check (9004,) ()\n",
      "epoch 6960\n",
      "====================================\n",
      "Epoch:  6960 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.557471264367816\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6960 6961\n",
      "Training loss:0.004865976981818676\n",
      "check (9044,) ()\n",
      "epoch 6961\n",
      "====================================\n",
      "Epoch:  6961 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.557678494469185\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6961 6962\n",
      "Training loss:-0.009261195547878742\n",
      "check (9147,) ()\n",
      "epoch 6962\n",
      "====================================\n",
      "Epoch:  6962 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.55774202815283\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6962 6963\n",
      "Training loss:0.004264025948941708\n",
      "check (9772,) ()\n",
      "epoch 6963\n",
      "====================================\n",
      "Epoch:  6963 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.556943846043373\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6963 6964\n",
      "Training loss:-0.007272332441061735\n",
      "check (10000,) ()\n",
      "epoch 6964\n",
      "====================================\n",
      "Epoch:  6964 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.555858701895461\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6964 6965\n",
      "Training loss:-0.009610938839614391\n",
      "check (10000,) ()\n",
      "epoch 6965\n",
      "====================================\n",
      "Epoch:  6965 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.554773869346734\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6965 6966\n",
      "Training loss:-0.0013772625243291259\n",
      "check (8776,) ()\n",
      "epoch 6966\n",
      "====================================\n",
      "Epoch:  6966 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.554837783519954\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6966 6967\n",
      "Training loss:-0.0033209214452654123\n",
      "check (9822,) ()\n",
      "epoch 6967\n",
      "====================================\n",
      "Epoch:  6967 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.554327544136644\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6967 6968\n",
      "Training loss:-0.002532654907554388\n",
      "check (10000,) ()\n",
      "epoch 6968\n",
      "====================================\n",
      "Epoch:  6968 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.553386911595867\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6968 6969\n",
      "Training loss:-0.0023983248975127935\n",
      "check (8087,) ()\n",
      "epoch 6969\n",
      "====================================\n",
      "Epoch:  6969 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.553737982493901\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6969 6970\n",
      "Training loss:-8.554153464501724e-05\n",
      "check (8873,) ()\n",
      "epoch 6970\n",
      "====================================\n",
      "Epoch:  6970 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.553802008608322\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6970 6971\n",
      "Training loss:0.0005977432592771947\n",
      "check (9496,) ()\n",
      "epoch 6971\n",
      "====================================\n",
      "Epoch:  6971 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.55400946779515\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6971 6972\n",
      "Training loss:-0.001313829212449491\n",
      "check (8979,) ()\n",
      "epoch 6972\n",
      "====================================\n",
      "Epoch:  6972 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.553212851405622\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6972 6973\n",
      "Training loss:-0.003038346767425537\n",
      "check (10000,) ()\n",
      "epoch 6973\n",
      "====================================\n",
      "Epoch:  6973 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.55227305320522\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6973 6974\n",
      "Training loss:-0.0066507370211184025\n",
      "check (9111,) ()\n",
      "epoch 6974\n",
      "====================================\n",
      "Epoch:  6974 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -12.550043016919988\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 6974 6975\n",
      "Training loss:-0.011509115807712078\n",
      "check (7990,) ()\n",
      "epoch 6975\n",
      "====================================\n",
      "Epoch:  6975 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.550394265232974\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6975 6976\n",
      "Training loss:-0.0009406713070347905\n",
      "check (10000,) ()\n",
      "epoch 6976\n",
      "====================================\n",
      "Epoch:  6976 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.549455275229358\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6976 6977\n",
      "Training loss:-0.012035680934786797\n",
      "check (8080,) ()\n",
      "epoch 6977\n",
      "====================================\n",
      "Epoch:  6977 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.54994983517271\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6977 6978\n",
      "Training loss:-0.005515200551599264\n",
      "check (10000,) ()\n",
      "epoch 6978\n",
      "====================================\n",
      "Epoch:  6978 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.549011177987962\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6978 6979\n",
      "Training loss:0.0010476494207978249\n",
      "check (10000,) ()\n",
      "epoch 6979\n",
      "====================================\n",
      "Epoch:  6979 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.547786215790229\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6979 6980\n",
      "Training loss:-0.005509584676474333\n",
      "check (10000,) ()\n",
      "epoch 6980\n",
      "====================================\n",
      "Epoch:  6980 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.546275071633238\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6980 6981\n",
      "Training loss:-0.004880874417722225\n",
      "check (8026,) ()\n",
      "epoch 6981\n",
      "====================================\n",
      "Epoch:  6981 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.545910328033234\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6981 6982\n",
      "Training loss:-0.0019018490565940738\n",
      "check (9877,) ()\n",
      "epoch 6982\n",
      "====================================\n",
      "Epoch:  6982 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.544686336293326\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6982 6983\n",
      "Training loss:-0.007230511866509914\n",
      "check (9726,) ()\n",
      "epoch 6983\n",
      "====================================\n",
      "Epoch:  6983 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.545037949305456\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6983 6984\n",
      "Training loss:-0.0029439511708915234\n",
      "check (10000,) ()\n",
      "epoch 6984\n",
      "====================================\n",
      "Epoch:  6984 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.54352806414662\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6984 6985\n",
      "Training loss:-0.0027893639635294676\n",
      "check (9483,) ()\n",
      "epoch 6985\n",
      "====================================\n",
      "Epoch:  6985 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.542734430923407\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6985 6986\n",
      "Training loss:-0.0053093768656253815\n",
      "check (9435,) ()\n",
      "epoch 6986\n",
      "====================================\n",
      "Epoch:  6986 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.542370455196107\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6986 6987\n",
      "Training loss:-0.0012392598437145352\n",
      "check (10000,) ()\n",
      "epoch 6987\n",
      "====================================\n",
      "Epoch:  6987 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.541720337770144\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6987 6988\n",
      "Training loss:0.002362891100347042\n",
      "check (9825,) ()\n",
      "epoch 6988\n",
      "====================================\n",
      "Epoch:  6988 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.541785918717801\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6988 6989\n",
      "Training loss:-0.0002972773218061775\n",
      "check (10000,) ()\n",
      "epoch 6989\n",
      "====================================\n",
      "Epoch:  6989 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.540420661038775\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6989 6990\n",
      "Training loss:-0.0036908751353621483\n",
      "check (7423,) ()\n",
      "epoch 6990\n",
      "====================================\n",
      "Epoch:  6990 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.540772532188841\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6990 6991\n",
      "Training loss:-0.007569885812699795\n",
      "check (9608,) ()\n",
      "epoch 6991\n",
      "====================================\n",
      "Epoch:  6991 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.539693892147046\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6991 6992\n",
      "Training loss:-0.0037759277038276196\n",
      "check (8893,) ()\n",
      "epoch 6992\n",
      "====================================\n",
      "Epoch:  6992 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.539473684210526\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6992 6993\n",
      "Training loss:-0.003097759559750557\n",
      "check (7285,) ()\n",
      "epoch 6993\n",
      "====================================\n",
      "Epoch:  6993 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.53982553982554\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6993 6994\n",
      "Training loss:-0.0008821106748655438\n",
      "check (7067,) ()\n",
      "epoch 6994\n",
      "====================================\n",
      "Epoch:  6994 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.5404632542179\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6994 6995\n",
      "Training loss:-0.002948411274701357\n",
      "check (9474,) ()\n",
      "epoch 6995\n",
      "====================================\n",
      "Epoch:  6995 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.540528949249463\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6995 6996\n",
      "Training loss:-0.004777562338858843\n",
      "check (8848,) ()\n",
      "epoch 6996\n",
      "====================================\n",
      "Epoch:  6996 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.540594625500287\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6996 6997\n",
      "Training loss:-0.00285158958286047\n",
      "check (7841,) ()\n",
      "epoch 6997\n",
      "====================================\n",
      "Epoch:  6997 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.541231956552808\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6997 6998\n",
      "Training loss:0.0002452232292853296\n",
      "check (8938,) ()\n",
      "epoch 6998\n",
      "====================================\n",
      "Epoch:  6998 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.541440411546157\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6998 6999\n",
      "Training loss:-0.00264184782281518\n",
      "check (7570,) ()\n",
      "epoch 6999\n",
      "====================================\n",
      "Epoch:  6999 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.542077439634234\n",
      "Max reward for a batch so far: 7.0\n",
      "check 6999 7000\n",
      "Training loss:-0.005214753560721874\n",
      "check (9686,) ()\n",
      "epoch 7000\n",
      "====================================\n",
      "Epoch:  7000 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.541142857142857\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 7000 7001\n",
      "Training loss:-0.007642824202775955\n",
      "Model saved\n",
      "check (7811,) ()\n",
      "epoch 7001\n",
      "====================================\n",
      "Epoch:  7001 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.54149407227539\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7001 7002\n",
      "Training loss:-0.006405393127351999\n",
      "check (8765,) ()\n",
      "epoch 7002\n",
      "====================================\n",
      "Epoch:  7002 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.541416738074835\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7002 7003\n",
      "Training loss:-0.004629538394510746\n",
      "check (10000,) ()\n",
      "epoch 7003\n",
      "====================================\n",
      "Epoch:  7003 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.540339854348137\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7003 7004\n",
      "Training loss:-0.0058171311393380165\n",
      "check (10000,) ()\n",
      "epoch 7004\n",
      "====================================\n",
      "Epoch:  7004 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.539548829240434\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7004 7005\n",
      "Training loss:-0.006751165725290775\n",
      "check (10000,) ()\n",
      "epoch 7005\n",
      "====================================\n",
      "Epoch:  7005 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-8.0\n",
      "Mean Reward of that batch -8.0\n",
      "Average Reward of all training: -12.538900785153462\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7005 7006\n",
      "Training loss:-0.0015343818813562393\n",
      "check (8843,) ()\n",
      "epoch 7006\n",
      "====================================\n",
      "Epoch:  7006 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.538966600057094\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7006 7007\n",
      "Training loss:-0.008953744545578957\n",
      "check (10000,) ()\n",
      "epoch 7007\n",
      "====================================\n",
      "Epoch:  7007 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.538604252889968\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7007 7008\n",
      "Training loss:-0.0039549279026687145\n",
      "check (8122,) ()\n",
      "epoch 7008\n",
      "====================================\n",
      "Epoch:  7008 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.53781392694064\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7008 7009\n",
      "Training loss:-0.006435808259993792\n",
      "check (8464,) ()\n",
      "epoch 7009\n",
      "====================================\n",
      "Epoch:  7009 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.537451847624483\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7009 7010\n",
      "Training loss:-0.006288550794124603\n",
      "check (9890,) ()\n",
      "epoch 7010\n",
      "====================================\n",
      "Epoch:  7010 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-5.0\n",
      "Mean Reward of that batch -5.0\n",
      "Average Reward of all training: -12.536376604850213\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7010 7011\n",
      "Training loss:-0.003816393669694662\n",
      "check (8276,) ()\n",
      "epoch 7011\n",
      "====================================\n",
      "Epoch:  7011 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.536870631864213\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7011 7012\n",
      "Training loss:-0.005224474240094423\n",
      "check (8125,) ()\n",
      "epoch 7012\n",
      "====================================\n",
      "Epoch:  7012 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.536794067313178\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7012 7013\n",
      "Training loss:-0.004855786915868521\n",
      "check (8661,) ()\n",
      "epoch 7013\n",
      "====================================\n",
      "Epoch:  7013 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.536289747611578\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7013 7014\n",
      "Training loss:0.003725299146026373\n",
      "check (8960,) ()\n",
      "epoch 7014\n",
      "====================================\n",
      "Epoch:  7014 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.536213287710293\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7014 7015\n",
      "Training loss:-0.001851345645263791\n",
      "check (9055,) ()\n",
      "epoch 7015\n",
      "====================================\n",
      "Epoch:  7015 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.536279401282965\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7015 7016\n",
      "Training loss:-0.0028773753438144922\n",
      "check (9823,) ()\n",
      "epoch 7016\n",
      "====================================\n",
      "Epoch:  7016 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-10.0\n",
      "Mean Reward of that batch -10.0\n",
      "Average Reward of all training: -12.535917901938426\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7016 7017\n",
      "Training loss:-0.013034647330641747\n",
      "check (9172,) ()\n",
      "epoch 7017\n",
      "====================================\n",
      "Epoch:  7017 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.53541399458458\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7017 7018\n",
      "Training loss:0.0030350417364388704\n",
      "check (8010,) ()\n",
      "epoch 7018\n",
      "====================================\n",
      "Epoch:  7018 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.53590766600171\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7018 7019\n",
      "Training loss:-0.0005030964384786785\n",
      "check (7346,) ()\n",
      "epoch 7019\n",
      "====================================\n",
      "Epoch:  7019 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.53625872631429\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7019 7020\n",
      "Training loss:-9.081015014089644e-05\n",
      "check (8765,) ()\n",
      "epoch 7020\n",
      "====================================\n",
      "Epoch:  7020 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.535754985754986\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7020 7021\n",
      "Training loss:-0.011394558474421501\n",
      "check (10000,) ()\n",
      "epoch 7021\n",
      "====================================\n",
      "Epoch:  7021 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.534539239424584\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7021 7022\n",
      "Training loss:-0.004438099451363087\n",
      "check (10000,) ()\n",
      "epoch 7022\n",
      "====================================\n",
      "Epoch:  7022 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.533608658501851\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7022 7023\n",
      "Training loss:-0.0015484098112210631\n",
      "check (7980,) ()\n",
      "epoch 7023\n",
      "====================================\n",
      "Epoch:  7023 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.533959846219565\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7023 7024\n",
      "Training loss:0.0019584009423851967\n",
      "check (8732,) ()\n",
      "epoch 7024\n",
      "====================================\n",
      "Epoch:  7024 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-15.0\n",
      "Mean Reward of that batch -15.0\n",
      "Average Reward of all training: -12.534310933940775\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7024 7025\n",
      "Training loss:0.0018714034231379628\n",
      "check (9844,) ()\n",
      "epoch 7025\n",
      "====================================\n",
      "Epoch:  7025 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.533807829181494\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7025 7026\n",
      "Training loss:-0.00791863538324833\n",
      "check (9203,) ()\n",
      "epoch 7026\n",
      "====================================\n",
      "Epoch:  7026 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.533020210646171\n",
      "Max reward for a batch so far: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 7026 7027\n",
      "Training loss:-0.009919706732034683\n",
      "check (10000,) ()\n",
      "epoch 7027\n",
      "====================================\n",
      "Epoch:  7027 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.532090508040415\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7027 7028\n",
      "Training loss:4.949188223690726e-05\n",
      "check (9792,) ()\n",
      "epoch 7028\n",
      "====================================\n",
      "Epoch:  7028 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.532014797951053\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7028 7029\n",
      "Training loss:-0.003838525852188468\n",
      "check (8390,) ()\n",
      "epoch 7029\n",
      "====================================\n",
      "Epoch:  7029 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-12.0\n",
      "Mean Reward of that batch -12.0\n",
      "Average Reward of all training: -12.531939109403899\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7029 7030\n",
      "Training loss:0.0016822946490719914\n",
      "check (5818,) ()\n",
      "epoch 7030\n",
      "====================================\n",
      "Epoch:  7030 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-14.0\n",
      "Mean Reward of that batch -14.0\n",
      "Average Reward of all training: -12.532147937411095\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7030 7031\n",
      "Training loss:-0.005346319638192654\n",
      "check (8300,) ()\n",
      "epoch 7031\n",
      "====================================\n",
      "Epoch:  7031 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.532214478737021\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7031 7032\n",
      "Training loss:-0.007623507175594568\n",
      "check (9313,) ()\n",
      "epoch 7032\n",
      "====================================\n",
      "Epoch:  7032 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.531712172923777\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7032 7033\n",
      "Training loss:0.007372862193733454\n",
      "check (8528,) ()\n",
      "epoch 7033\n",
      "====================================\n",
      "Epoch:  7033 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:3.0\n",
      "Mean Reward of that batch 3.0\n",
      "Average Reward of all training: -12.529503767951088\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7033 7034\n",
      "Training loss:-0.008578660897910595\n",
      "check (7506,) ()\n",
      "epoch 7034\n",
      "====================================\n",
      "Epoch:  7034 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-19.0\n",
      "Mean Reward of that batch -19.0\n",
      "Average Reward of all training: -12.530423656525448\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7034 7035\n",
      "Training loss:-0.003689604112878442\n",
      "check (8385,) ()\n",
      "epoch 7035\n",
      "====================================\n",
      "Epoch:  7035 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.530206112295664\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7035 7036\n",
      "Training loss:0.0004567223077174276\n",
      "check (9806,) ()\n",
      "epoch 7036\n",
      "====================================\n",
      "Epoch:  7036 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.528851620238772\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7036 7037\n",
      "Training loss:-0.0031365281902253628\n",
      "check (10000,) ()\n",
      "epoch 7037\n",
      "====================================\n",
      "Epoch:  7037 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-4.0\n",
      "Mean Reward of that batch -4.0\n",
      "Average Reward of all training: -12.52763961915589\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7037 7038\n",
      "Training loss:-0.003143757814541459\n",
      "check (10000,) ()\n",
      "epoch 7038\n",
      "====================================\n",
      "Epoch:  7038 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-3.0\n",
      "Mean Reward of that batch -3.0\n",
      "Average Reward of all training: -12.526285876669508\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7038 7039\n",
      "Training loss:-0.0021657864563167095\n",
      "check (10000,) ()\n",
      "epoch 7039\n",
      "====================================\n",
      "Epoch:  7039 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.52550078136099\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7039 7040\n",
      "Training loss:-0.004296631086617708\n",
      "check (10000,) ()\n",
      "epoch 7040\n",
      "====================================\n",
      "Epoch:  7040 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-2.0\n",
      "Mean Reward of that batch -2.0\n",
      "Average Reward of all training: -12.524005681818181\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7040 7041\n",
      "Training loss:-0.005146515555679798\n",
      "check (7607,) ()\n",
      "epoch 7041\n",
      "====================================\n",
      "Epoch:  7041 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.523505183922738\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7041 7042\n",
      "Training loss:-0.0012103603221476078\n",
      "check (9320,) ()\n",
      "epoch 7042\n",
      "====================================\n",
      "Epoch:  7042 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.523004828173814\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7042 7043\n",
      "Training loss:-0.0018645583186298609\n",
      "check (9701,) ()\n",
      "epoch 7043\n",
      "====================================\n",
      "Epoch:  7043 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.522504614510861\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7043 7044\n",
      "Training loss:-0.001581213204190135\n",
      "check (6688,) ()\n",
      "epoch 7044\n",
      "====================================\n",
      "Epoch:  7044 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-17.0\n",
      "Mean Reward of that batch -17.0\n",
      "Average Reward of all training: -12.523140261215218\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7044 7045\n",
      "Training loss:-0.008601823821663857\n",
      "check (10000,) ()\n",
      "epoch 7045\n",
      "====================================\n",
      "Epoch:  7045 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-6.0\n",
      "Mean Reward of that batch -6.0\n",
      "Average Reward of all training: -12.522214336408801\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7045 7046\n",
      "Training loss:0.0008027961594052613\n",
      "check (9953,) ()\n",
      "epoch 7046\n",
      "====================================\n",
      "Epoch:  7046 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-7.0\n",
      "Mean Reward of that batch -7.0\n",
      "Average Reward of all training: -12.521430598921373\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7046 7047\n",
      "Training loss:-0.002202467992901802\n",
      "check (8813,) ()\n",
      "epoch 7047\n",
      "====================================\n",
      "Epoch:  7047 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-11.0\n",
      "Mean Reward of that batch -11.0\n",
      "Average Reward of all training: -12.52121470129133\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7047 7048\n",
      "Training loss:-0.008569425903260708\n",
      "check (10000,) ()\n",
      "epoch 7048\n",
      "====================================\n",
      "Epoch:  7048 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-9.0\n",
      "Mean Reward of that batch -9.0\n",
      "Average Reward of all training: -12.520715096481272\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7048 7049\n",
      "Training loss:-0.006928442511707544\n",
      "check (9535,) ()\n",
      "epoch 7049\n",
      "====================================\n",
      "Epoch:  7049 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-13.0\n",
      "Mean Reward of that batch -13.0\n",
      "Average Reward of all training: -12.520783089799972\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7049 7050\n",
      "Training loss:-0.0011002338724210858\n",
      "check (6817,) ()\n",
      "epoch 7050\n",
      "====================================\n",
      "Epoch:  7050 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-18.0\n",
      "Mean Reward of that batch -18.0\n",
      "Average Reward of all training: -12.521560283687943\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7050 7051\n",
      "Training loss:-0.0012141427723690867\n",
      "Model saved\n",
      "check (7685,) ()\n",
      "epoch 7051\n",
      "====================================\n",
      "Epoch:  7051 / 10000\n",
      "------------\n",
      "Number of training episodes: 1\n",
      "Total reward:-16.0\n",
      "Mean Reward of that batch -16.0\n",
      "Average Reward of all training: -12.522053609417103\n",
      "Max reward for a batch so far: 7.0\n",
      "check 7051 7052\n",
      "Training loss:-0.0017269618110731244\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-13acbf089d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumber_epoch\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mstates_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_of_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscounted_rewards_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_episodes_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtotal_reward_of_that_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards_of_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5dd10dc1106f>\u001b[0m in \u001b[0;36mmake_batch\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ziyan/.local/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ziyan/.local/lib/python3.6/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ziyan/.local/lib/python3.6/site-packages/atari_py/ale_python_interface.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if training:\n",
    "    # number of iterations\n",
    "    while epoch < number_epoch +1:\n",
    "        states_mb, actions_mb, rewards_of_batch, discounted_rewards_mb, nb_episodes_mb = make_batch(batch_size)\n",
    "        \n",
    "        total_reward_of_that_batch = np.sum(rewards_of_batch)\n",
    "        print('check',rewards_of_batch.shape, np.array(total_reward_of_that_batch).shape)\n",
    "        allRewards.append(total_reward_of_that_batch)\n",
    "        \n",
    "        mean_reward_of_that_batch = np.divide(total_reward_of_that_batch, nb_episodes_mb)\n",
    "        mean_reward_total.append(mean_reward_of_that_batch)\n",
    "        average_reward_of_all_training = np.divide(np.sum(mean_reward_total), epoch)\n",
    "        maximumRewardRecorded = np.amax(allRewards)\n",
    "        print('epoch',epoch)\n",
    "        epoch_1.append(epoch)\n",
    "        print('====================================')\n",
    "        print(\"Epoch: \", epoch, '/', number_epoch)\n",
    "        print('------------')\n",
    "        print(\"Number of training episodes: {}\".format(nb_episodes_mb))\n",
    "        print(\"Total reward:{}\".format(total_reward_of_that_batch, nb_episodes_mb))\n",
    "        print(\"Mean Reward of that batch {}\".format(mean_reward_of_that_batch))\n",
    "        print(\"Average Reward of all training: {}\".format(average_reward_of_all_training))\n",
    "        print(\"Max reward for a batch so far: {}\".format(maximumRewardRecorded))\n",
    "\n",
    "        loss_,cross, _= sess.run([PGN.loss, PGN.cross_entropy, PGN.train_opt],feed_dict = {PGN.inputs: states_mb.reshape([len(states_mb), *state_size]), PGN.actions: actions_mb,PGN.discounted_episode_rewards: discounted_rewards_mb})    \n",
    "        loss_VE, _= sess.run([VEN.loss, VEN.train_opt],feed_dict = {VEN.inputs: states_mb.reshape([len(states_mb), *state_size]), VEN.discounted_episode_rewards: discounted_rewards_mb})    \n",
    "        average_reward.append(mean_reward_of_that_batch) \n",
    "        print('check',epoch, len(average_reward))\n",
    "        print('Training loss:{}'.format(loss_) )\n",
    "        #print('Cross Entropy:{}'.format(cross) )\n",
    "        #print('VE Training loss:{}'.format(loss_VE) )\n",
    "             \n",
    "        if epoch % 50 == 0:\n",
    "            saver.save(sess, \"./models/model6.ckpt\")\n",
    "            print('Model saved')\n",
    "            with open('mean_reward6.txt', 'w') as myFile:\n",
    "                print('{}'.format(average_reward), file=myFile)\n",
    "        epoch += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'average_reward_each_episode')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a6c7f8eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epoch), average_reward)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('average_reward_each_episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal commnent on the second problem: \n",
    "It is hard to train the Pong game (adjust its hyperparameters to get the convergence result), because its state_size is large. The above figure is what I got with constant baseline and learning rate 1e-3. The line goes up and down means the model is at least learning. It does not lead to the optimal result may be due to the time limit. Training the Pong game needs to do a lot of experiments, and the above result is the best I got, even though it does not lead to convergence. My number of epoch is set to be 10000, but I only plotted around the first 7000 result/epochs because I did not finish training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
